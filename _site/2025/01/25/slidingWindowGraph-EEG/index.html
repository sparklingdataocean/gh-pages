<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Spark for Big Data Analytics.">

    <title>Sliding Graph Neural Networks for EEG Analysis - Sparkling Data Ocean</title>

    <link rel="canonical" href="http://localhost:4000/2025/01/25/slidingWindowGraph-EEG/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/clean-blog.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Sparkling Data Ocean" />
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-114694347-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-114694347-1');
    </script>

</head>


<body>

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Sparkling Data Ocean</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="/">Home</a>
                </li>
                
				
                <li>
                    <a href="/about/">About</a>
                </li>
				
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


    <!-- Post Header -->
<header class="intro-header" style="background-image: url('/img/page115y.jpg')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <h1>Sliding Graph Neural Networks for EEG Analysis</h1>
                    
                    <h2 class="subheading">Capturing Temporal Dynamics in Brain Activity</h2>
                    
                    <span class="meta">Posted by Melenar on January 25, 2025</span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">

				<p></p>

<p></p>

<p></p>
<h2>Exploring EEG Through Graph-Based Methods</h2>
<p></p>
<p>Over the years, we are looking to uncover the secrets of brain connectivity using EEG data.
Our work has evolved from traditional graph analysis techniques to cutting-edge Graph Neural Networks (GNNs),
each step uncovering deeper insights into neural dynamics. Let’s take a closer look at these studies.</p>

<p></p>
<p><h4>Study 1: Traditional Graph Analysis</h4></p>
<p></p>
<p>Our journey began with a traditional graph analysis approach. In this study, we constructed connectivity graphs from EEG trials using
<strong>cosine similarity</strong> between channels. Each graph’s nodes represented EEG electrodes, and the edges reflected their functional connectivity.</p>
<p></p>
<p>Key Findings:</p>
<ul>
    <li>Differences in connectivity patterns emerged between the <strong>Alcoholic</strong> and <strong>Control</strong> groups, providing insights into altered neural activity.</li>
    <li>Graph features like clustering coefficients and edge density helped highlight these differences.</li>
    <li>However, traditional methods struggled to distinguish subtle variations, particularly in <strong>single-stimulus conditions</strong>, prompting the need for more advanced techniques.</li>
</ul>
<figure>
    <img src="/img/dataSource5.jpg" alt="Traditional EEG Graph Example" style="width:75%; margin:auto;" />
    <figcaption>Figure 1: A sample connectivity graph constructed from EEG data using cosine similarity.</figcaption>
</figure>
<p></p>
<p>For a deeper dive into this work, check out our post <a href="http://sparklingdataocean.com/2020/08/19/brainGraphEeg/">“EEG Patterns by Deep Learning and Graph Mining”</a> or refer to the paper <a href="https://link.springer.com/chapter/10.1007/978-3-030-87101-7_19">Time Series Pattern Discovery by Deep Learning and Graph Mining</a>.</p>

<p></p>

<p></p>
<h4>Study 2: Graph Neural Networks for Trial Classification</h4>
<p></p>
<p>Building on our first study, we introduced <strong>Graph Neural Networks (GNNs)</strong> to analyze EEG data at the trial level. Each graph represented an entire EEG trial, encapsulating the connectivity across all channels.</p>
<p></p>
<p>Why GNNs? GNNs brought a new level of sophistication by enabling the model to learn spatial relationships and connectivity dynamics within the graph.</p>
<p></p>
<p>Key Findings:</p>
<ul>
    <li><strong>Improved Classification Accuracy:</strong> GNNs significantly outperformed traditional methods in differentiating between Alcoholic and Control groups.</li>
    <li><strong>Enhanced Connectivity Insights:</strong> Subtle variations in connectivity, previously missed, were captured.</li>
    <li><strong>Challenges:</strong> Misclassifications within the Control group highlighted the complexity of EEG connectivity patterns.</li>
</ul>

<p></p>

<p></p>
<p>This approach is detailed further in our post <a href="http://sparklingdataocean.com/2023/05/08/classGraphEeg/">“GNN Graph Classification for EEG Pattern Analysis”</a> or refer to the paper <a href="https://www.springerprofessional.de/en/enhancing-time-series-analysis-with-gnn-graph-classification-mod/26751028">Enhancing Time Series Analysis with GNN Graph Classification Models</a>.</p>

<p></p>

<h4>Study 3: Graph Neural Networks for Link Prediction</h4>
<p></p>
<p>In our third study, the focus shifted to <strong>link prediction</strong>, using GNNs to analyze node- and edge-level connectivity. A unified graph constructed from EEG electrode distances was used to predict connectivity dynamics.</p>
<p></p>
<p>Key Findings:</p>
<ul>
    <li><strong>Revealing Hidden Connectivity:</strong> GNNs highlighted relationships between electrodes that were previously unobserved.</li>
    <li><strong>Node Importance:</strong> Certain electrodes emerged as more central to connectivity patterns.</li>
    <li><strong>Limitations:</strong> This method focused primarily on short-term EEG segments, leaving the dynamics of long-term recordings unexplored.</li>
</ul>

<p></p>
<p>For more on this work, check out our <a href="http://sparklingdataocean.com/2024/11/09/GNN_timeSeries_EEG/">“Graph Neural Networks for EEG Connectivity Analysis”<a href="#"></a> or refer to the paper <a href="https://iwain.lucentia.es/proceedings/">Graph Neural Networks in Action: Uncovering Patterns in EEG Time Series Data.  1st International Workshop on Artificial Intelligence for Neuroscience (IWAIN’24), pp. 4–15</a>.</a></p>
<p></p>
<p></p>
<figure>
    <img src="/img/brain4.jpg" alt="Traditional EEG Graph Example" style="width:75%; margin:auto;" />
    <figcaption>Figure 2: A sample connectivity graph constructed from EEG data using cosine similarity.</figcaption>
</figure>

<p></p>
<h4>Looking Ahead: Current Study</h4>
<p></p>
<p>This study applies sliding graphs to long-time EEG series, capturing evolving neural activity during sleep and rest. This approach reveals extended brain states, uncovering transitions and sustained neural processes, offering deeper insights into EEG dynamics over time.</p>
<p></p>

<p></p>

<h2>GNN Sliding Graph Classification: Introduction</h2>

<p></p>

<p>In our previous work, we introduced two key methods for time series analysis. The methodology consists of three key steps:</p>

<ul>
  <li>
    <strong>Sliding Graph Construction:</strong> Transform time series data into graph structures by segmenting it into overlapping windows. Each graph captures localized temporal and spatial relationships, representing distinct patterns over the chosen time frame.
  </li>
  <li>
    <strong>GNN-Based Graph Classification:</strong> Utilize GNNs to classify these graphs, extracting high-level features from their topology while preserving the structural and temporal dependencies in the data.
  </li>
  <li>
    <strong>Pre-final Vectors:</strong> Obtain graph embeddings (pre-final vectors) from the GNN model during classification. These embeddings represent the learned topological features and are further analyzed to reveal temporal and structural patterns in the time series.
  </li>
</ul>

<p></p>

<p>Both methods were successfully applied to <em>climate time series data</em>, revealing complex patterns in large-scale datasets. However, these techniques have never been combined in a single study.</p>

<p></p>

<p>In this study, we integrate these approaches and apply them to <strong>EEG time series data</strong>, specifically in the context of <em>sleep studies</em>. EEG analysis presents unique challenges, requiring methods that can detect both <em>long-term trends</em> and <em>local brain connectivity changes</em>. By leveraging <strong>sliding graph construction</strong> and <strong>pre-final vector extraction</strong>, we aim to uncover <em>hidden EEG patterns</em> that traditional signal processing techniques might miss.</p>
<p></p>
<p>Objectives of This Study</p>
<p></p>
<ul>
    <li>Demonstrate the effectiveness of <strong>graph-based models</strong> for long-duration biomedical signal analysis.</li>
    <li>Validate the generalizability of <strong>GNN Sliding Graph Classification</strong> and <strong>Pre-Final Vectors</strong> beyond climate data, applying them to neuroscience.</li>
</ul>

<p>This approach bridges sliding window techniques and graph-based modeling, providing a powerful framework for analyzing complex temporal EEG data. By capturing both localized and global topological patterns, it enhances our understanding of brain activity dynamics during sleep.</p>

<p></p>
<p>For more detailed information about GNN Sliding Graphs, look at our post <a href="http://sparklingdataocean.com/2024/05/25/slidingWindowGraph/">“Sliding Window Graph in GNN Graph Classification”</a> or refer to the paper <a href="https://dl.acm.org/doi/10.1145/3674029.3674059">GNN Graph Classification for Time Series: A New Perspective on Climate Change Analysis</a>.</p>

<p></p>

<p>For information about catching embedded graphs, look at our post <a href="http://sparklingdataocean.com/2024/07/04/vectorsGNN/">“Unlocking the Power of Pre-Final Vectors in GNN Graph Classification”</a> or refer to the paper <a href="https://mlg-europe.github.io/2024/">Utilizing Pre-Final Vectors from GNN Graph Classification for Enhanced Climate Analysis</a>.</p>

<p></p>

<h2>Methods</h2>
<p></p>
<h3>Sliding Graph Construction</h3>
<p></p>
<p>In our study, we introduce a novel approach to constructing graphs from EEG data using the
<em>Sliding Window Method</em>.</p>

<p></p>
<p><a href="#">
      <img src="/img/eegSlide3.jpg" alt="Post Sample Image" width="600" />
</a></p>
<p></p>
<p></p>
<h3>Sliding Window Method</h3>
<ul>
    <li>
      <strong>Nodes</strong>: Represent data points within each sliding window, with features reflecting their respective values.
    </li>
    <li>
      <strong>Edges</strong>: Connect sequential points to preserve the temporal sequence and structure.
    </li>
    <li>
      <strong>Labels</strong>: Assigned to detect and analyze patterns within the time series.
    </li>
  </ul>
<p></p>
<h3>Pipeline</h3>
<p></p>
<p>Our pipeline for <strong>Graph Neural Network (GNN) Graph Classification</strong> consists of the following stages:</p>
<ol>
    <li><strong>Data Input</strong>: For instance, EEG data representing brain activity during sleep and rest states.</li>
    <li>
      <strong>Graph Construction</strong>:
      <ul>
        <li><em>Sliding Window Method</em>: Segmenting time series data into smaller, overlapping graphs.</li>
        <li>
          <em>Virtual Nodes</em>: Acting as central hubs in small graphs, improving accuracy and enabling model tuning.
        </li>
      </ul>
    </li>
    <li><strong>GNN Model Application</strong>: Classifying graphs based on detected patterns using a GNN model.</li>
  </ol>
<p></p>
<h3>Methodology for Sliding Window Graph Construction</h3>
<p></p>
<h4>Data to Graph Transformation</h4>
<p></p>
<p>Time series data is segmented into overlapping windows using the sliding
window technique. Each segment forms a unique graph, allowing for the analysis of local temporal dynamics.</p>
<p></p>
<p>In these graphs:</p>

<ul>
    <li>
      <strong>Nodes</strong>: Represent data points within the window, with features derived from their values.
    </li>
    <li>
      <strong>Edges</strong>: Connect sequential nodes to maintain temporal relationships.
    </li>
  </ul>
<p></p>
<p>Key Parameters:</p>
<ul>
    <li>
      <strong>Window Size (W)</strong>: Determines the size of each segment.
    </li>
    <li>
      <strong>Shift Size (S)</strong>: Defines the degree of overlap between windows.
    </li>
    <li>
      <strong>Edge Definitions</strong>: Tailored to the specific characteristics of the time series, helping detect meaningful
      patterns.
    </li>
  </ul>

<p></p>
<p></p>
<h4>Node Calculation</h4>
<p></p>
<p>For a dataset with N data points, we apply a sliding window of size W with a shift of S to create nodes. The number of nodes, N<sub>nodes</sub>, is calculated as:
    <math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
            <msub>
                <mi>N</mi>
                <mi>nodes</mi>
            </msub>
            <mo>=</mo>
            <mrow>
                <mo>&lfloor;</mo>
                <mfrac>
                    <mrow>
                        <mi>N</mi>
                        <mo>-</mo>
                        <mi>W</mi>
                    </mrow>
                    <mi>S</mi>
                </mfrac>
                <mo>&rfloor;</mo>
            </mrow>
            <mo>+</mo>
            <mn>1</mn>
        </mrow>
    </math></p>
<p></p>
<p></p>
<p></p>

<p></p>
<h4>Graph Calculation</h4>
<p></p>
<p>With the nodes determined, we construct graphs, each comprising G nodes, with a shift of S<sub>g</sub> between successive graphs. The number of graphs, N<sub>graphs</sub>, is calculated by:
    <math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
            <msub>
                <mi>N</mi>
                <mi>graphs</mi>
            </msub>
            <mo>=</mo>
            <mrow>
                <mo>&lfloor;</mo>
                <mfrac>
                    <mrow>
                        <msub>
                            <mi>N</mi>
                            <mi>nodes</mi>
                        </msub>
                        <mo>-</mo>
                        <mi>G</mi>
                    </mrow>
                    <msub>
                        <mi>S</mi>
                        <mi>g</mi>
                    </msub>
                </mfrac>
                <mo>&rfloor;</mo>
            </mrow>
            <mo>+</mo>
            <mn>1</mn>
        </mrow>
    </math></p>
<p></p>
<p></p>
<h4>Graph Construction</h4>
<p></p>
<p>Cosine similarity matrices are generated from the time series data and transformed into graph adjacency matrices.</p>
<p></p>
<ul>
    <li>
      <strong>Edge Creation</strong>: Edges are established for vector pairs with cosine values above a defined threshold.
    </li>
    <li>
      <strong>Virtual Nodes</strong>: Added to ensure network connectivity, enhancing graph representation.
    </li>
  </ul>
<p></p>

<p></p>
<p></p>
<p>This framework effectively captures both local and global patterns within the time series, yielding valuable insights into temporal dynamics.</p>
<p></p>

<p></p>
<h4>Graph Classification</h4>
<p></p>
<p>We employ the <em>GCNConv</em> model from the PyTorch Geometric Library for graph classification tasks. This model performs convolutional operations, leveraging edges, node attributes, and graph labels to extract features and analyze graph structures comprehensively.</p>
<p></p>
<p>By combining the sliding window technique with Graph Neural Networks, our approach offers a robust framework for analyzing time series data. It captures intricate temporal dynamics and provides actionable insights into both local and global patterns, making it particularly well-suited for applications such as EEG analysis and classification tasks.</p>

<p></p>

<p>This method allows us to analyze time series data effectively by capturing both local and global patterns, providing valuable insights into temporal dynamics.</p>
<p></p>
<h4>Model Training</h4>
<p></p>

<p>Our methodology involves processing both city-centric and sliding window graphs. We start by generating cosine similarity matrices from time series data, which are then converted into graph adjacency matrices. This process includes creating edges for vector pairs with cosine values above a set threshold and adding a virtual node to ensure network connectivity, a critical step for preparing the graph structure.</p>
<p></p>
<p>For graph classification tasks, we use the GCNConv model from the PyTorch Geometric Library. This model excels in feature extraction through its convolutional operations, taking into account edges, node attributes, and graph labels for comprehensive graph analysis. The approach concludes with the training phase of the GNN model, applying these techniques to both types of graphs for robust classification.</p>
<p></p>

<p></p>
<h2>Experiments Overview</h2>
<p></p>
<h3>Data Source: EEG Data</h3>
<p></p>
<p>For this study, we utilized EEG data from the
<i><a href="https://github.com/OpenNeuroDatasets/ds003768/tree/master/sub-01/eeg" target="_blank">OpenNeuroDatasets</a></i>.</p>
<p></p>
<p>This dataset includes EEG data collected from 33 healthy participants using a 32-channel MR-compatible EEG system (Brain Products, Munich, Germany). The EEG data were recorded during two 10-minute resting-state sessions (before and after a visual-motor adaptation task) and multiple 15-minute sleep sessions.</p>
<p></p>
<p>For our analysis, we specifically focused on data from one resting-state session and one sleep session, using the raw EEG data for processing and comparative analysis of activity patterns during rest and sleep states.</p>

<p></p>

<p>We used the <code>mne</code> Python library to process EEG data. The dataset includes recordings in the BrainVision format, which were preloaded for analysis. Below is the Python code used for this preprocessing step:</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">mne</span>
<span class="kn">import</span> <span class="n">mne</span>
<span class="n">vhdr_file_path1</span> <span class="o">=</span> <span class="n">filePath</span><span class="o">+</span><span class="sh">'</span><span class="s">sub-01_task-rest_run-1_eeg.vhdr</span><span class="sh">'</span>
<span class="n">vhdr_file_path2</span> <span class="o">=</span> <span class="n">filePath</span><span class="o">+</span><span class="sh">'</span><span class="s">sub-01_task-sleep_run-3_eeg.vhdr</span><span class="sh">'</span>
<span class="n">raw1</span> <span class="o">=</span> <span class="n">mne</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="nf">read_raw_brainvision</span><span class="p">(</span><span class="n">vhdr_file_path1</span><span class="p">,</span> <span class="n">preload</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">raw2</span> <span class="o">=</span> <span class="n">mne</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="nf">read_raw_brainvision</span><span class="p">(</span><span class="n">vhdr_file_path2</span><span class="p">,</span> <span class="n">preload</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>
<p>We specifically extracted EEG data from one resting-state session (<code>sub-01_task-rest_run-1_eeg.vhdr</code>) and one sleep session (<code>sub-01_task-sleep_run-3_eeg.vhdr</code>), which were recorded using a 32-channel MR-compatible EEG system (Brain Products, Munich, Germany). These raw EEG signals were prepared for further analysis and sliding graph construction.</p>

<p></p>
<p>After loading the EEG data, we transformed the raw signals into structured pandas DataFrames for ease of analysis. The following code snippet demonstrates this step:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">eeg_data1</span><span class="p">,</span> <span class="n">times1</span> <span class="o">=</span> <span class="n">raw1</span><span class="p">.</span><span class="nf">get_data</span><span class="p">(</span><span class="n">return_times</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">eeg_df1</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">eeg_data1</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">channel_names1</span><span class="p">)</span>
<span class="n">eeg_df1</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">times1</span>
<span class="n">eeg_data2</span><span class="p">,</span> <span class="n">times2</span> <span class="o">=</span> <span class="n">raw2</span><span class="p">.</span><span class="nf">get_data</span><span class="p">(</span><span class="n">return_times</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">eeg_df2</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">eeg_data2</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">channel_names1</span><span class="p">)</span>
<span class="n">eeg_df2</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">times2</span>
<span class="n">eeg_df1</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span><span class="n">eeg_df2</span><span class="p">.</span><span class="n">shape</span>
<span class="p">((</span><span class="mi">4042800</span><span class="p">,</span> <span class="mi">33</span><span class="p">),</span> <span class="p">(</span><span class="mi">4632500</span><span class="p">,</span> <span class="mi">33</span><span class="p">))</span></code></pre></figure>

<p></p>

<p>The EEG signals from both the rest and sleep sessions were converted into DataFrames. Each DataFrame contains 32 EEG channels and a corresponding <code>Time</code> column, enabling a clear representation of time series data for further processing. The shapes of the resulting DataFrames are as follows:
  &lt;/p&gt;</p>
<ul>
    <li><strong>Rest session:</strong> 4,042,800 rows × 33 columns</li>
    <li><strong>Sleep session:</strong> 4,632,500 rows × 33 columns</li>
  </ul>

<p>This structured format facilitates segmentation, feature extraction, and the eventual construction of sliding graphs.</p>

<p></p>

<p>Given the large size of the EEG datasets, we applied downsampling to reduce the number of rows while retaining the temporal structure of the signals. Specifically, every 20th row from each DataFrame was selected, effectively reducing the data size by a factor of 20.</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">eeg_df1</span> <span class="o">=</span> <span class="n">eeg_df1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[::</span><span class="mi">20</span><span class="p">,</span> <span class="p">:].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">eeg_df2</span> <span class="o">=</span> <span class="n">eeg_df2</span><span class="p">.</span><span class="n">iloc</span><span class="p">[::</span><span class="mi">20</span><span class="p">,</span> <span class="p">:].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">eeg_df1</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">eeg_df2</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="p">(</span><span class="mi">202140</span><span class="p">,</span> <span class="mi">33</span><span class="p">)</span> <span class="p">(</span><span class="mi">231625</span><span class="p">,</span> <span class="mi">33</span><span class="p">)</span></code></pre></figure>

<p></p>

<ul>
    <li><strong>Rest session:</strong> 202,140 rows × 33 columns</li>
    <li><strong>Sleep session:</strong> 231,625 rows × 33 columns</li>
  </ul>
<p>
This step significantly reduced the computational overhead for subsequent processing steps while preserving meaningful patterns in the data.
<p></p>

To ensure compatibility during analysis, both EEG DataFrames were truncated to have the same number of rows. This step is essential to facilitate pairwise comparisons and maintain consistency across the datasets.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="n">min_rows</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">eeg_df1</span><span class="p">),</span> <span class="nf">len</span><span class="p">(</span><span class="n">eeg_df2</span><span class="p">))</span>
<span class="n">eeg1df</span> <span class="o">=</span> <span class="n">eeg_df1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">min_rows</span><span class="p">]</span>
<span class="n">eeg2df</span> <span class="o">=</span> <span class="n">eeg_df2</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">min_rows</span><span class="p">]</span>
<span class="n">eeg1df</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span><span class="n">eeg2df</span><span class="p">.</span><span class="n">shape</span>
<span class="p">((</span><span class="mi">202140</span><span class="p">,</span> <span class="mi">33</span><span class="p">),</span> <span class="p">(</span><span class="mi">202140</span><span class="p">,</span> <span class="mi">33</span><span class="p">))</span></code></pre></figure>

<p></p>

After truncation, both DataFrames contain:

<ul>
  <li><strong>Row count:</strong> 202,140</li>
  <li><strong>Column count:</strong> 33 EEG channels</li>
</ul>
<p></p>
This ensures that subsequent operations, such as similarity calculations or graph-based analysis, can be performed without inconsistencies in data alignment.

<p></p>

To prepare the EEG data for analysis, numerical columns were normalized to ensure consistent scaling across features. The 'Time' column was excluded during normalization and re-added afterward. This step helps improve the performance of subsequent analytical methods by standardizing the data.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">eeg1_features</span> <span class="o">=</span> <span class="n">eeg1df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">])</span>
<span class="n">eeg2_features</span> <span class="o">=</span> <span class="n">eeg2df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">])</span>
<span class="n">eeg1</span> <span class="o">=</span> <span class="p">(</span><span class="n">eeg1_features</span> <span class="o">-</span> <span class="n">eeg1_features</span><span class="p">.</span><span class="nf">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">eeg1_features</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">)</span>
<span class="n">eeg2</span> <span class="o">=</span> <span class="p">(</span><span class="n">eeg2_features</span> <span class="o">-</span> <span class="n">eeg2_features</span><span class="p">.</span><span class="nf">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">eeg2_features</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">)</span>
<span class="n">eeg1</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">eeg1df</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span>
<span class="n">eeg2</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">eeg2df</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span></code></pre></figure>

<p></p>

To enhance data tracking and processing, the 'Time' column was renamed, formatted as a string, and additional metadata columns were added:

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">eeg1</span><span class="o">=</span><span class="n">eeg1</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">})</span>
<span class="n">eeg2</span><span class="o">=</span><span class="n">eeg2</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">})</span>
<span class="n">eeg1</span><span class="p">[</span><span class="sh">'</span><span class="s">dateStr</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>  <span class="sh">'</span><span class="s">~</span><span class="sh">'</span> <span class="o">+</span> <span class="n">eeg1</span><span class="p">[</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">eeg2</span><span class="p">[</span><span class="sh">'</span><span class="s">dateStr</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>  <span class="sh">'</span><span class="s">~</span><span class="sh">'</span> <span class="o">+</span> <span class="n">eeg2</span><span class="p">[</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">eeg1</span><span class="p">[</span><span class="sh">'</span><span class="s">rowIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">eeg1</span><span class="p">))</span>
<span class="n">eeg2</span><span class="p">[</span><span class="sh">'</span><span class="s">rowIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">eeg2</span><span class="p">))</span></code></pre></figure>

<p></p>

These steps ensure that the data is not only normalized but also organized with clear metadata, facilitating downstream analysis and visualization tasks.



<p></p>
<h3>Raw Data Analysis</h3>
<p></p>
This step of data analysis focuses on comparing the cosine similarity between EEG channels during sleep and rest states. The top bar chart visualizes the channel-wise differences, highlighting which brain regions exhibit notable variations in activity patterns. The bottom chart aggregates these comparisons region-wise (e.g., Central, Occipital, Temporal), providing a high-level view of how different brain regions behave in sleep versus rest.
<p></p>
<a href="#">
    <img src="/img/eegSlide1.jpg" alt="Post Sample Image" width="678" />
</a>
<p></p>
<p></p>
<a href="#">
    <img src="/img/eegSlide2.jpg" alt="Post Sample Image" width="600" />
</a>
<p></p>
Since time measures in separate sections do not overlap, this comparison offers a broad overview, serving as a basis for more detailed studies on individual sessions.

<p></p>
<h4>Normalization and Preprocessing</h4>
<p></p>
In this step, we normalized the EEG data to ensure consistency across different sessions and reduce the impact of varying scales. The following processes were carried out:

<ul>
  <li>
    <strong>Numerical Column Selection:</strong>
    Excluded the 'Time' column to focus only on the numerical EEG data for normalization.
  </li>
  <li>
    <strong>Data Normalization:</strong>
    Each feature was normalized using z-score normalization:
    <br />
    <code>Normalized Value = (Value - Mean) / (Standard Deviation + 1e-5)</code>
    <br />
    This ensures the data has a mean of 0 and a standard deviation of 1, improving the stability of subsequent analyses.
  </li>
  <li>
    <strong>Reintegrating the Time Column:</strong>
    The 'Time' column was added back to the normalized dataset and renamed to <code>date</code> for easier readability and alignment with temporal analyses.
  </li>
  <li>
    <strong>String Representation for Dates:</strong>
    Created a <code>dateStr</code> column by prefixing the time values with a tilde (<code>~</code>), providing a textual representation of the timestamps.
  </li>
  <li>
    <strong>Index Assignment:</strong>
    Added a <code>rowIndex</code> column to assign a unique index to each row for tracking during further analysis.
  </li>
</ul>
<p></p>
This normalization step prepared the data for sliding window segmentation and graph construction, ensuring consistency and improving the robustness of the subsequent analyses.


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">eeg1_features</span> <span class="o">=</span> <span class="n">eeg1df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">])</span>
<span class="n">eeg2_features</span> <span class="o">=</span> <span class="n">eeg2df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">])</span>
<span class="n">eeg1</span> <span class="o">=</span> <span class="p">(</span><span class="n">eeg1_features</span> <span class="o">-</span> <span class="n">eeg1_features</span><span class="p">.</span><span class="nf">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">eeg1_features</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">)</span>
<span class="n">eeg2</span> <span class="o">=</span> <span class="p">(</span><span class="n">eeg2_features</span> <span class="o">-</span> <span class="n">eeg2_features</span><span class="p">.</span><span class="nf">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">eeg2_features</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">)</span>
<span class="n">eeg1</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">eeg1df</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span>
<span class="n">eeg2</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">eeg2df</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span>
<span class="n">eeg1</span><span class="o">=</span><span class="n">eeg1</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">})</span>
<span class="n">eeg2</span><span class="o">=</span><span class="n">eeg2</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">})</span>
<span class="n">eeg1</span><span class="p">[</span><span class="sh">'</span><span class="s">dateStr</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>  <span class="sh">'</span><span class="s">~</span><span class="sh">'</span> <span class="o">+</span> <span class="n">eeg1</span><span class="p">[</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">eeg2</span><span class="p">[</span><span class="sh">'</span><span class="s">dateStr</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>  <span class="sh">'</span><span class="s">~</span><span class="sh">'</span> <span class="o">+</span> <span class="n">eeg2</span><span class="p">[</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">eeg1</span><span class="p">[</span><span class="sh">'</span><span class="s">rowIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">eeg1</span><span class="p">))</span>
<span class="n">eeg2</span><span class="p">[</span><span class="sh">'</span><span class="s">rowIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">eeg2</span><span class="p">))</span></code></pre></figure>

<p></p>

<h4>Channel Grouping by Brain Regions</h4>
<p></p>
To organize the EEG channels for our study, we grouped them based on their prefixes. This grouping helps us focus on specific brain regions for analysis and simplifies the selection process. Below are the steps and results of this process:
<p></p>
<ul>
  <li>
    <strong>Grouping Channels:</strong>
    Each EEG channel was categorized by its prefix, which corresponds to the brain region it represents. Channels ending with <code>'z'</code> were treated as central and grouped by removing the trailing <code>'z'</code>. For all other channels, their alphabetical prefix was used for grouping.
  </li>
  <li>
    <strong>Code Implementation:</strong>
    The grouping was performed programmatically using a dictionary structure where the keys represent brain region prefixes, and the values contain the corresponding EEG channels.
  </li>
</ul>
<p></p>
Below is the Python implementation used for channel grouping:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="n">channel_groups</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="k">for</span> <span class="n">channel</span> <span class="ow">in</span> <span class="n">eeg1</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">channel</span><span class="p">.</span><span class="nf">endswith</span><span class="p">(</span><span class="sh">'</span><span class="s">z</span><span class="sh">'</span><span class="p">):</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="n">channel</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="sh">''</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="n">char</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">channel</span> <span class="k">if</span> <span class="n">char</span><span class="p">.</span><span class="nf">isalpha</span><span class="p">()])</span>
    <span class="n">channel_groups</span><span class="p">[</span><span class="n">prefix</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">channel</span><span class="p">)</span>
<span class="k">for</span> <span class="n">group</span><span class="p">,</span> <span class="n">channels</span> <span class="ow">in</span> <span class="n">channel_groups</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">group</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">channels</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span></code></pre></figure>

<p></p>

<h4>Grouped Channels</h4>
<p></p>
The resulting channel groups are as follows:
<ul>
  <li><strong>Fp:</strong> ['Fp1', 'Fp2']</li>
  <li><strong>F:</strong> ['F3', 'F4', 'F7', 'F8', 'Fz']</li>
  <li><strong>C:</strong> ['C3', 'C4', 'Cz']</li>
  <li><strong>P:</strong> ['P3', 'P4', 'P7', 'P8', 'Pz']</li>
  <li><strong>O:</strong> ['O1', 'O2', 'Oz']</li>
  <li><strong>T:</strong> ['T7', 'T8']</li>
  <li><strong>FC:</strong> ['FC1', 'FC2', 'FC5', 'FC6']</li>
  <li><strong>CP:</strong> ['CP1', 'CP2', 'CP5', 'CP6']</li>
  <li><strong>TP:</strong> ['TP9', 'TP10']</li>
  <li><strong>EOG:</strong> ['EOG']</li>
  <li><strong>ECG:</strong> ['ECG']</li>
  <li><strong>Time:</strong> ['Time']</li>
</ul>
<p></p>
These groups will guide our selection of brain regions and EEG channels for further analysis in the study.

<p></p>

<h3>Computing Cosine Similarities Within EEG Channel Groups</h3>
<p></p>
As part of our EEG analysis, we calculated cosine similarities between channel pairs within the same group. This step focuses on understanding relationships between channels in specific brain regions. Below are the details of the process and implementation:
<p></p>
<h4>Steps in Analysis</h4>
<p></p>
<ol>
  <li><strong>Channel Grouping:</strong> EEG channels were grouped based on their prefixes, corresponding to specific brain regions. Channels ending with <code>'z'</code> were adjusted by removing the trailing <code>'z'</code>, and other channels were grouped by their letter prefixes.</li>
  <li><strong>Sorting Channels:</strong> Channels within each group were sorted alphabetically to ensure consistent pairwise comparisons.</li>
  <li><strong>Cosine Similarity Calculation:</strong> Cosine similarities were computed for all possible pairs within each group using their numerical feature vectors.</li>
  <li><strong>Sorting Results:</strong> The cosine similarity pairs were sorted alphabetically for easy interpretation and analysis.</li>
</ol>
<p></p>
The following Python code was used to perform the analysis:

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="n">channel_groups</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="k">for</span> <span class="n">channel</span> <span class="ow">in</span> <span class="n">eeg_df1_truncated</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">channel</span><span class="p">.</span><span class="nf">endswith</span><span class="p">(</span><span class="sh">'</span><span class="s">z</span><span class="sh">'</span><span class="p">):</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="n">channel</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="sh">''</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="n">char</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">channel</span> <span class="k">if</span> <span class="n">char</span><span class="p">.</span><span class="nf">isalpha</span><span class="p">()])</span>
    <span class="n">channel_groups</span><span class="p">[</span><span class="n">prefix</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">channel</span><span class="p">)</span>
<span class="n">cosine_similarities</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">group</span><span class="p">,</span> <span class="n">channels</span> <span class="ow">in</span> <span class="n">channel_groups</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
    <span class="n">channels</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">channels</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">channel1</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">channels</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">channel2</span> <span class="ow">in</span> <span class="n">channels</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]:</span>
            <span class="n">vector1</span> <span class="o">=</span> <span class="n">eeg_df1_truncated</span><span class="p">[</span><span class="n">channel1</span><span class="p">].</span><span class="nf">to_numpy</span><span class="p">().</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">vector2</span> <span class="o">=</span> <span class="n">eeg_df1_truncated</span><span class="p">[</span><span class="n">channel2</span><span class="p">].</span><span class="nf">to_numpy</span><span class="p">().</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">similarity</span> <span class="o">=</span> <span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="n">vector2</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">cosine_similarities</span><span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">channel1</span><span class="si">}</span><span class="s">-</span><span class="si">{</span><span class="n">channel2</span><span class="si">}</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">similarity</span>
<span class="n">sorted_cosine_similarities</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="nf">sorted</span><span class="p">(</span><span class="n">cosine_similarities</span><span class="p">.</span><span class="nf">items</span><span class="p">()))</span></code></pre></figure>

<p></p>


<ul>
  <li>Cosine similarities provide insights into the relationships between EEG channels within the same brain region.</li>
  <li>The sorted similarity pairs offer a clear view of which channels are most or least correlated within each group.</li>
</ul>

<p></p>
This method helps isolate patterns within specific brain regions, contributing to our understanding of channel interactions during rest and sleep sessions.

<p></p>
<figure>
    <img src="/img/eegSlide5.jpg" alt="Data Analysis: Cosine Similarities" style="width:50%; margin:auto;" />
    <figcaption>The table summarizes cosine similarity values for EEG channel pairs during sleep and rest states, alongside the difference between these states (Sleep - Rest).</figcaption>
</figure>

<p></p>
<p></p>
<a href="#">
    <img src="/img/eegSlide7.jpg" alt="Post Sample Image" width="600" />
</a>
<p></p>
<p></p>
<a href="#">
    <img src="/img/eegSlide8.jpg" alt="Post Sample Image" width="600" />
</a>
<p></p>
<ul>
  <li><strong>Channel Pairs</strong>: EEG channel pairs analyzed for similarity.</li>
  <li><strong>Sleep Cos</strong>: Cosine similarity during the sleep session.</li>
  <li><strong>Rest Cos</strong>: Cosine similarity during the rest session.</li>
  <li><strong>Sleep-Rest</strong>: Difference in similarity between sleep and rest, showing how connectivity changes across states.</li>
</ul>
<p></p>
<a href="#">
    <img src="/img/eegSlide9.jpg" alt="Post Sample Image" width="600" />
</a>
<p></p>
<p></p>
<a href="#">
    <img src="/img/eegSlide10.jpg" alt="Post Sample Image" width="600" />
</a>
<p></p>
<p></p>

For our analysis, we selected the EEG channel pairs C4-Cz, F3-F4, and O1-O2. These pairs were chosen based on their relevance to brain region interactions and their notable differences in connectivity between sleep and rest states. These channels represent central, frontal, and occipital brain regions, providing a comprehensive view of neural activity across different areas of the brain.

<p></p>
<h3>Sliding Graph</h3>
<p></p>
This function, <code>create_segments_df</code>, is designed to process a time series DataFrame by creating overlapping segments for a specified column. It helps prepare data for sliding window analysis, which is essential for studying temporal patterns in EEG signals. Below is a high-level description of its workflow:

<ul>
  <li><strong>Inputs:</strong> The function takes the following parameters:
    <ul>
      <li><code>df</code>: The DataFrame containing the data.</li>
      <li><code>column_name</code>: The column to segment.</li>
      <li><code>window_size</code>: The size of each sliding window.</li>
      <li><code>shift</code>: The step size for sliding the window.</li>
      <li><code>columnLabel</code>: A label to annotate the segments.</li>
    </ul>
  </li>

  <li>Process:
    <ul>
      <li>Iterates over the DataFrame to extract overlapping windows of the specified size.</li>
      <li>Transposes each window to arrange its data as a single row for easier concatenation.</li>
      <li>Adds metadata to each segment, including:
        <ul>
          <li><code>start_date</code>: The start time of the segment.</li>
          <li><code>rowIndex</code>: The row index of the original DataFrame.</li>
          <li><code>theColumn</code>: The name of the column being segmented.</li>
          <li><code>columnLabel</code>: A label for the segment.</li>
        </ul>
      </li>
      <li>Appends each processed segment to a list.</li>
    </ul>
  </li>
  <li><strong>Output:</strong> Combines all segments into a single DataFrame for downstream analysis.</li>
</ul>
<p></p>
This function is particularly useful in EEG studies, enabling the division of continuous signals into manageable segments for sliding graph or time-series analysis.
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">create_segments_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">column_name</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span><span class="n">columnLabel</span><span class="p">):</span>
    <span class="n">segments</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">-</span> <span class="n">window_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">shift</span><span class="p">):</span>
        <span class="n">segment</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">window_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
          <span class="p">[</span><span class="n">column_name</span><span class="p">]].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">segment</span> <span class="o">=</span> <span class="n">segment</span><span class="p">.</span><span class="n">T</span>  
        <span class="n">segment</span><span class="p">[</span><span class="sh">'</span><span class="s">start_date</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
        <span class="n">segment</span><span class="p">[</span><span class="sh">'</span><span class="s">rowIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">rowIndex</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
        <span class="n">segment</span><span class="p">[</span><span class="sh">'</span><span class="s">theColumn</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">column_name</span>
        <span class="n">segment</span><span class="p">[</span><span class="sh">'</span><span class="s">columnLabel</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">columnLabel</span>
        <span class="n">segments</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">segment</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">segments</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>
The function <code>group_segments</code> is designed to group smaller data segments into larger groups for graph-based analysis. This process is crucial for aggregating segments in sliding window studies, particularly for EEG analysis. Here’s a detailed explanation:

<ul>
  <li><strong>Inputs:</strong> The function takes the following parameters:
    <ul>
      <li><code>segments_df</code>: The DataFrame containing individual segments.</li>
      <li><code>group_size</code>: The number of segments in each group.</li>
      <li><code>group_shift</code>: The step size for sliding between groups.</li>
    </ul>
  </li>
<p></p>
  <li>Process:
    <ul>
      <li>Iterates over the DataFrame to extract overlapping groups of the specified size.</li>
      <li>Resets the index for each group to maintain consistent indexing.</li>
      <li>Adds a new column, <code>graphIndex</code>, to assign a unique identifier to each group.</li>
      <li>Appends each grouped segment to a list for aggregation.</li>
      <li>Increments the <code>group_index</code> after each group to ensure unique identifiers.</li>
    </ul>
  </li>
  <li><strong>Output:</strong> Combines all grouped segments into a single DataFrame for further analysis or graph construction.</li>
</ul>

<p></p>
This function facilitates efficient grouping of sliding window segments, enabling robust graph-based analysis for temporal patterns in EEG data.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">group_segments</span><span class="p">(</span><span class="n">segments_df</span><span class="p">,</span> <span class="n">group_size</span><span class="p">,</span> <span class="n">group_shift</span><span class="p">):</span>
    <span class="n">grouped_segments</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">group_index</span> <span class="o">=</span> <span class="mi">0</span>  
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">segments_df</span><span class="p">)</span> <span class="o">-</span> <span class="n">group_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">group_shift</span><span class="p">):</span>
        <span class="n">group</span> <span class="o">=</span> <span class="n">segments_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">group_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">group</span><span class="p">[</span><span class="sh">'</span><span class="s">graphIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">group_index</span>  
        <span class="n">grouped_segments</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">group</span><span class="p">)</span>
        <span class="n">group_index</span> <span class="o">+=</span> <span class="mi">1</span>  
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">grouped_segments</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>

<h4>Preprocessing and Sliding Window Preparation</h4>

<p></p>
Parameters for Sliding Window and Grouping:
<p></p>
We defined the following parameters for creating sliding windows and grouping segments:
<p></p>
<ul>
  <li><em>Window size (W):</em> 32 data points per segment.</li>
  <li><em>Shift (S):</em> 16 data points between segments.</li>
  <li><em>Group size (G):</em> 32 segments per group.</li>
  <li><em>Group shift (S<sub>g</sub>):</em> 16 segments between groups.</li>
</ul>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">window_size</span><span class="o">=</span><span class="mi">32</span>
<span class="n">shift</span><span class="o">=</span><span class="mi">16</span>
<span class="n">group_size</span><span class="o">=</span><span class="mi">32</span>
<span class="n">group_shift</span><span class="o">=</span><span class="mi">16</span></code></pre></figure>

<p></p>
Data Scaling and Handling Missing Values:
<p></p>
We selected EEG channels (e.g., <code>O1</code> and <code>O2</code>) for analysis and processed them as follows:
<ul>
  <li>Missing values were replaced with the mean of the respective column.</li>
  <li>Min-Max Scaling was applied to normalize the data for consistency across features.</li>
</ul>
<p></p>
Sliding Window Segmentation and Grouping:
<p></p>
Using the defined parameters, sliding windows were created for each channel (e.g., <code>O1</code> and <code>O2</code>), with each segment assigned a unique node index. Segments were then grouped into larger units for graph analysis.

<p></p>
Dataset Creation:
<p></p>
The grouped segments for both channels were concatenated into a single dataset. Each group was assigned a unique graph index, resulting in a dataset with 787 graph groups, ready for graph-based processing and analysis.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="n">pairColumns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">O1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">O2</span><span class="sh">'</span><span class="p">]</span>
<span class="n">col1</span> <span class="o">=</span> <span class="n">pairColumns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">col2</span> <span class="o">=</span> <span class="n">pairColumns</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="nc">MinMaxScaler</span><span class="p">()</span>
<span class="n">fx_data</span><span class="o">=</span><span class="n">df</span>
<span class="k">if</span> <span class="n">col1</span> <span class="ow">in</span> <span class="n">fx_data</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">fx_data</span><span class="p">[</span><span class="n">col1</span><span class="p">]</span> <span class="o">=</span> <span class="n">fx_data</span><span class="p">[</span><span class="n">col1</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">fx_data</span><span class="p">[</span><span class="n">col1</span><span class="p">].</span><span class="nf">mean</span><span class="p">())</span>
    <span class="n">fx_data</span><span class="p">[</span><span class="n">col1</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">fx_data</span><span class="p">[[</span><span class="n">col1</span><span class="p">]])</span>
<span class="k">if</span> <span class="n">col2</span> <span class="ow">in</span> <span class="n">fx_data</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">fx_data</span><span class="p">[</span><span class="n">col2</span><span class="p">]</span> <span class="o">=</span> <span class="n">fx_data</span><span class="p">[</span><span class="n">col2</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">fx_data</span><span class="p">[</span><span class="n">col2</span><span class="p">].</span><span class="nf">mean</span><span class="p">())</span>
    <span class="n">fx_data</span><span class="p">[</span><span class="n">col2</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">fx_data</span><span class="p">[[</span><span class="n">col2</span><span class="p">]])</span>
<span class="n">columnLabel</span><span class="o">=</span><span class="mi">0</span>
<span class="n">segments1</span> <span class="o">=</span> <span class="nf">create_segments_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">col1</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span> <span class="n">columnLabel</span><span class="p">)</span>
<span class="n">columnLabel</span><span class="o">=</span><span class="mi">1</span>
<span class="n">segments2</span> <span class="o">=</span> <span class="nf">create_segments_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">col2</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span> <span class="n">columnLabel</span><span class="p">)</span>  
<span class="n">segments1</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIndex</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">segments1</span><span class="p">.</span><span class="n">index</span>
<span class="n">segments2</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIndex</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">segments2</span><span class="p">.</span><span class="n">index</span>
<span class="n">grouped_segments1</span> <span class="o">=</span> <span class="nf">group_segments</span><span class="p">(</span><span class="n">segments1</span><span class="p">,</span> <span class="n">group_size</span><span class="p">,</span> <span class="n">group_shift</span><span class="p">)</span>
<span class="n">grouped_segments2</span> <span class="o">=</span> <span class="nf">group_segments</span><span class="p">(</span><span class="n">segments2</span><span class="p">,</span> <span class="n">group_size</span><span class="p">,</span> <span class="n">group_shift</span><span class="p">)</span>
<span class="n">dataSet</span><span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">grouped_segments1</span><span class="p">,</span> <span class="n">grouped_segments2</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">graphMax</span> <span class="o">=</span> <span class="n">dataSet</span><span class="p">[</span><span class="sh">'</span><span class="s">graphIndex</span><span class="sh">'</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span>
<span class="n">graphMax</span>
<span class="mi">787</span>  </code></pre></figure>

<p></p>


<p></p>

<p></p>

<p></p>
<h4>Sliding Window Graph as Input for GNN Graph Classification</h4>
<p></p>
In this stage of our analysis, we prepared sliding window graphs as input for a Graph Neural Network (GNN) classification task. Below is a high-level description of the process:
<p></p>
Process Overview:
<p></p>
We iteratively constructed graphs for EEG data using the predefined sliding windows and grouped segments. Each graph corresponds to a unique segment of the EEG data, capturing temporal relationships within the window. For each graph:
<ul>
  <li>Features (<code>x</code>): Derived from EEG signal values within the segment, including the average of node features to enhance representation.</li>
  <li>Edges (<code>edge_index</code>): Created based on cosine similarity between node pairs, using a threshold (<code>cos &gt; 0.9</code>) to establish connections between nodes.</li>
  <li>Labels (<code>y</code>): Assigned based on the channel being analyzed (e.g., <code>O1</code> or <code>O2</code>).</li>
</ul>
<p></p>
Cosine Similarity Calculation:
<p></p>
Cosine similarity was computed for all node pairs within each graph to determine connectivity. Node pairs exceeding the threshold of 0.9 were added as edges. This ensures that only significant relationships within the EEG signals are represented in the graph structure.
<p></p>
DataLoader Preparation:
<p></p>
The resulting graphs were packaged into datasets for model training and testing:
<ul>
  <li><em>DatasetTest:</em> Contains graphs prepared for evaluation.</li>
  <li><em>DatasetModel:</em> Contains graphs ready for training the GNN model.</li>
</ul>
<p></p>
These datasets were loaded into PyTorch Geometric's <code>DataLoader</code> for efficient batch processing during model training and evaluation.

<p></p>
Outcome:
The constructed sliding window graphs provide a structured and efficient way to capture temporal EEG patterns for graph-based classification. This approach highlights the power of combining sliding window analysis with GNNs to study EEG signals.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="n">cos</span><span class="o">=</span><span class="mf">0.9</span>
<span class="n">datasetTest</span><span class="o">=</span><span class="nf">list</span><span class="p">()</span>
<span class="n">datasetModel</span><span class="o">=</span><span class="nf">list</span><span class="p">()</span>
<span class="n">cosPairsUnion</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">):</span>
  <span class="n">column</span><span class="o">=</span><span class="n">pairColumns</span><span class="p">[</span><span class="n">label</span><span class="p">]</span>
  <span class="k">for</span> <span class="n">graphIdx</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">graphMax</span><span class="p">):</span>
    <span class="n">data1</span><span class="o">=</span><span class="n">dataSet</span><span class="p">[(</span><span class="n">dataSet</span><span class="p">[</span><span class="sh">'</span><span class="s">graphIndex</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">graphIdx</span><span class="p">)</span>
      <span class="o">&amp;</span> <span class="p">(</span><span class="n">dataSet</span><span class="p">[</span><span class="sh">'</span><span class="s">theColumn</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">column</span><span class="p">)]</span>
    <span class="n">values1</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">7</span><span class="p">]</span>
    <span class="n">fXValues1</span><span class="o">=</span> <span class="n">values1</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">values</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">fXValuesPT1</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">fXValues1</span><span class="p">)</span>
    <span class="n">fXValuesPT1avg</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">fXValuesPT1</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">fXValuesPT1union</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">fXValuesPT1</span><span class="p">,</span><span class="n">fXValuesPT1avg</span><span class="p">),</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">cosine_scores1</span> <span class="o">=</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">fXValuesPT1</span><span class="p">,</span> <span class="n">fXValuesPT1</span><span class="p">)</span>
    <span class="n">cosPairs1</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">score0</span><span class="o">=</span><span class="n">cosine_scores1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">group_size</span><span class="p">):</span>
      <span class="n">date1</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">'</span><span class="s">start_date</span><span class="sh">'</span><span class="p">]</span>
      <span class="n">datasetIdx</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">]</span>
      <span class="n">cosPairs1</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span><span class="n">score0</span><span class="p">,</span> <span class="sh">'</span><span class="s">graphIdx</span><span class="sh">'</span><span class="p">:</span><span class="n">graphIdx</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span><span class="sh">'</span><span class="s">theColumn</span><span class="sh">'</span><span class="p">:</span><span class="n">column</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">:</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">:</span><span class="n">window_size</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">date1</span><span class="sh">'</span><span class="p">:</span><span class="n">date1</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">date2</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">XXX</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">:</span> <span class="n">datasetIdx</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">score0</span><span class="p">})</span>
      <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">group_size</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">j</span><span class="p">:</span>
          <span class="n">score</span><span class="o">=</span><span class="n">cosine_scores1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
          <span class="k">if</span> <span class="n">score</span><span class="o">&gt;</span><span class="n">cos</span><span class="p">:</span>
            <span class="n">date2</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="sh">'</span><span class="s">start_date</span><span class="sh">'</span><span class="p">]</span>
            <span class="n">datasetIdx</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">]</span>
            <span class="n">cosPairs1</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span><span class="n">cos</span><span class="p">,</span> <span class="sh">'</span><span class="s">graphIdx</span><span class="sh">'</span><span class="p">:</span><span class="n">graphIdx</span><span class="p">,</span>
                              <span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span><span class="n">score0</span><span class="p">,</span> <span class="sh">'</span><span class="s">graphIdx</span><span class="sh">'</span><span class="p">:</span><span class="n">graphIdx</span><span class="p">,</span>
                              <span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span><span class="sh">'</span><span class="s">theColumn</span><span class="sh">'</span><span class="p">:</span><span class="n">column</span><span class="p">,</span>
                              <span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">:</span><span class="n">i</span><span class="p">,</span>
                              <span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">:</span><span class="n">j</span><span class="p">,</span>
                              <span class="sh">'</span><span class="s">date1</span><span class="sh">'</span><span class="p">:</span><span class="n">date1</span><span class="p">,</span>
                              <span class="sh">'</span><span class="s">date2</span><span class="sh">'</span><span class="p">:</span><span class="n">date2</span><span class="p">,</span>
                              <span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">:</span> <span class="n">datasetIdx</span><span class="p">,</span>
                              <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">score</span><span class="p">})</span>
    <span class="n">dfCosPairs1</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">cosPairs1</span><span class="p">)</span>
    <span class="n">edge1</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">dfCosPairs1</span><span class="p">[[</span><span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">,</span>	<span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">]].</span><span class="n">T</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">dataset1</span> <span class="o">=</span> <span class="nc">Data</span><span class="p">(</span><span class="n">edge_index</span><span class="o">=</span><span class="n">edge1</span><span class="p">)</span>
    <span class="n">dataset1</span><span class="p">.</span><span class="n">y</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">label</span><span class="p">])</span>
    <span class="n">dataset1</span><span class="p">.</span><span class="n">x</span><span class="o">=</span><span class="n">fXValuesPT1union</span>
    <span class="n">datasetTest</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">dataset1</span><span class="p">)</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">datasetTest</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">datasetModel</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">cosPairsUnion</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">cosPairsUnion</span><span class="p">,</span> <span class="n">dfCosPairs1</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>   
<h4>GNN Graph Classification: Model Training.</h4>
<p></p>  

To classify EEG data using a graph neural network (GNN), we implemented a training pipeline that incorporates data splitting, model definition, and training steps. Below is an overview of the process:



<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.17</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span>
  <span class="nf">train_test_split</span><span class="p">(</span><span class="n">graphInput</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></figure>

<p></p>
<strong>Dataset Splitting:</strong> The dataset was split into training and testing sets with a 17% test size. The data was prepared for training using PyTorch Geometric's DataLoader, ensuring efficient batch processing.

<p></p>

<strong>Model Architecture:</strong> A Graph Convolutional Network (GCN) was designed for EEG graph classification. The model includes:
<ul>
<li><strong>Node Embedding Steps:</strong> Three graph convolutional layers process node-level information.</li>
<li><strong>Graph Embedding Step:</strong> A global mean pooling layer aggregates node-level embeddings into graph-level embeddings.</li>
<li><strong>Classification Step:</strong> A fully connected layer classifies graphs into two categories.</li>
</ul>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch.nn</span> <span class="kn">import</span> <span class="n">Linear</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GCNConv</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">global_mean_pool</span>
<span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">GCN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">window_size</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lin</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">return_graph_embedding</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">graph_embedding</span> <span class="o">=</span> <span class="nf">global_mean_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>  
        <span class="k">if</span> <span class="n">return_graph_embedding</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">graph_embedding</span>  
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">graph_embedding</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span></code></pre></figure>

<p></p>
The model is now ready for training and evaluation using the prepared data loaders. This architecture leverages node-level and graph-level features for effective classification.

<p></p>
<h3>Model Training and Evaluation</h3>
<p></p>

The training and evaluation process for the GNN model involves key steps to optimize the parameters and assess performance. Below is an overview of the methodology:
<p></p>
<strong>Training Process:</strong>
<ul>
  <li>Perform a single forward pass over batches in the training dataset.</li>
  <li>Compute the loss using the cross-entropy loss function.</li>
  <li>Derive gradients using backpropagation.</li>
  <li>Update model parameters based on the computed gradients.</li>
  <li>Clear gradients after each step to prevent accumulation.</li>
</ul>
<p></p>
<strong>Evaluation Process:</strong>
<ul>
  <li>Iterate over the test dataset in batches.</li>
  <li>Perform forward passes to compute predictions.</li>
  <li>Use the class with the highest probability as the predicted label.</li>
  <li>Compare predictions with ground-truth labels to compute the accuracy.</li>
  <li>Return the ratio of correct predictions as the evaluation metric.</li>
</ul>
<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">IPython.display</span> <span class="kn">import</span> <span class="n">Javascript</span>
<span class="nf">display</span><span class="p">(</span><span class="nc">Javascript</span><span class="p">(</span><span class="sh">'''</span><span class="s">google.colab.output.setIframeHeight(0, true, {maxHeight: 300})</span><span class="sh">'''</span><span class="p">))</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
         <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>  
         <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>  
         <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>  
         <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>  
         <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>  
<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">loader</span><span class="p">):</span>
     <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
     <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
     <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>  
         <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>
         <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
         <span class="n">correct</span> <span class="o">+=</span> <span class="nf">int</span><span class="p">((</span><span class="n">pred</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">).</span><span class="nf">sum</span><span class="p">())</span>
     <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">)</span>  </code></pre></figure>

<p></p>


This section details the training and evaluation process of the graph neural network (GNN) model for the EEG channel pair F3-F4 during the sleep session. The model was trained over 16 epochs, with accuracy metrics computed for both the training and test datasets at each epoch.


<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">17</span><span class="p">):</span>
    <span class="nf">train</span><span class="p">()</span>
    <span class="n">train_acc</span> <span class="o">=</span> <span class="nf">test</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="nf">test</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="mi">03</span><span class="n">d</span><span class="si">}</span><span class="s">,
      Train Acc: </span><span class="si">{</span><span class="n">train_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">,
      Test Acc: </span><span class="si">{</span><span class="n">test_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>

<a href="#">
    <img src="/img/eegSlide6.jpg" alt="Post Sample Image" width="445" />
</a>
<p></p>
<ul>
  <li><b>Training Accuracy:</b> Indicates the model's ability to learn patterns from the training dataset. Accuracy steadily increased across epochs, reaching a peak of <strong>0.9502</strong>.</li>
  <li><b>Test Accuracy:</b> Reflects the model's performance on unseen test data, gradually improving and achieving a high value of <strong>0.9366</strong> by the final epoch.</li>
</ul>
<p></p>
The consistent improvement in both training and test accuracy demonstrates the model's capability to generalize well. This highlights its effectiveness in classifying EEG data based on sliding window graphs for the F3-F4 channel pair during sleep.

<p></p>

<p></p>
<p></p>
The table summarizes cosine similarity values and graph neural network (GNN) performance for selected EEG channel pairs across sleep and rest sessions. It provides insights into how these pairs interact during different states and how well the GNN model captures these patterns.
<p></p>
<h4>Analysis of Cosine Similarity and GNN Performance for Selected EEG Pairs</h4>
<p></p>
The table summarizes cosine similarity values and graph neural network (GNN) performance for selected EEG channel pairs across sleep and rest sessions. It provides insights into how these pairs interact during different states and how well the GNN model captures these patterns.

<p></p>
<a href="#">
    <img src="/img/eegSlide11.jpg" alt="Post Sample Image" width="657" />
</a>
<p></p>

Key Observations:
<ul>
  <li><b>Channel Pairs and Cosine Similarity:</b> Cosine similarity values highlight the relationship between EEG signals. For example, the C4-Cz pair showed stronger similarity during sleep, while the O1-O2 pair maintained consistently high similarity across both states.</li>
  <li><b>Brain Regions Affected:</b> The F3-F4 pair, associated with frontal brain activity, showed notable differences in similarity between sleep and rest, reflecting the frontal lobe's role in decision-making and reduced cognitive activity during sleep. The occipital pair (O1-O2), responsible for visual processing, showed consistently high similarity across both states, indicating stable interactions in this region.</li>
  <li><b>Training Accuracy:</b> The GNN model effectively learned patterns from the training data, with the F3-F4 pair achieving the highest training accuracy during sleep.</li>
  <li><b>Test Accuracy:</b> Performance on test data varied across pairs and states. The F3-F4 pair demonstrated strong generalization during sleep, while other pairs showed moderate accuracy differences between states.</li>
</ul>
<p></p>
Interpreting High Cosine Similarity and Low Accuracy:

<p></p>

While high cosine similarity values suggest stable and predictable relationships between EEG signals, they can reduce the variability necessary for effective machine learning classification. When similarity values are consistently high, the model struggles to differentiate patterns, resulting in lower classification accuracy. This is particularly evident in the O1-O2 pair, where consistently high cosine similarity across both states contributed to reduced GNN accuracy.
<p></p>
These results underscore the variability in EEG signal relationships and model performance, reflecting the distinct dynamics of sleep and rest states, as well as the challenges of analyzing highly correlated data.</p>

<p>These results underscore the variability in EEG signal relationships and model performance, reflecting the distinct dynamics of sleep and rest states.</p>

<p></p>

<p></p>
<p></p>

<p></p>

<p></p>
<p></p>
<h3>Model Results Interpretation</h3>
<p></p>

<p>The results interpretation phase of the study focused on analyzing the predictions and embeddings generated by the graph neural network (GNN) model. Using a softmax function, the model’s outputs were transformed into probabilities to better understand the classification predictions and identify the most likely labels for each graph.</p>

<p>Process:</p>
<ul>
  <li><i>Softmax Transformation:</i> The raw outputs of the GNN model were passed through a softmax function to convert them into probability distributions over the possible classes.</li>
  <li><i>Prediction Extraction:</i> The predicted labels for each graph were determined by identifying the class with the highest probability.</li>
  <li><i>Graph Embeddings:</i> The GNN model also generated graph-level embeddings for each graph, providing a compact vector representation of the patterns captured within the graph.</li>
  <li><i>Data Storage:</i> These embeddings, along with the predicted labels and probabilities, were stored in a structured DataFrame for further analysis and visualization.</li>
</ul>
<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Softmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">graphUnion</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">graphCount</span><span class="p">):</span>
  <span class="n">label</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_graph_embedding</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="n">output</span> <span class="o">=</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">out</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">graphUnion</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">:</span><span class="n">g</span><span class="p">,</span><span class="sh">'</span><span class="s">vector</span><span class="sh">'</span><span class="p">:</span> <span class="n">out</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()})</span></code></pre></figure>

<p></p>

<p>The resulting DataFrame contains each graph’s index, embedding vectors, and prediction results. The embeddings serve as high-dimensional representations of the EEG data, enabling further analysis of the underlying patterns and relationships identified by the GNN model.</p>

<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">graphUnion_df</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">graphUnion</span><span class="p">)</span>
<span class="n">graphUnion_df</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span>
      <span class="n">index</span>	<span class="n">vector</span>
<span class="mi">1569</span>	<span class="mi">1569</span>	<span class="p">[[</span><span class="mf">0.17810732</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.19235992</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.16263075</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.167</span><span class="bp">...</span>
<span class="mi">1570</span>	<span class="mi">1570</span>	<span class="p">[[</span><span class="mf">0.2913107</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.073132396</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.09579194</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.039</span><span class="bp">...</span>
<span class="mi">1571</span>	<span class="mi">1571</span>	<span class="p">[[</span><span class="mf">0.030929727</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.10722159</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.040990006</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span><span class="bp">...</span>
<span class="mi">1572</span>	<span class="mi">1572</span>	<span class="p">[[</span><span class="mf">0.3690454</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.014458519</span><span class="p">,</span> <span class="mf">0.03268631</span><span class="p">,</span> <span class="mf">0.04397</span><span class="bp">...</span>
<span class="mi">1573</span>	<span class="mi">1573</span>	<span class="p">[[</span><span class="mf">0.123519175</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.23811509</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.22812074</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.16</span><span class="p">.</span></code></pre></figure>

<p></p>
<p>This step bridges the gap between model training and interpretability, allowing for a deeper understanding of how the GNN processes and classifies EEG-based sliding window graphs.</p>
<p></p>
<h4>Cosine Similarity Analysis for Graph Embeddings</h4>
<p></p>
<p>This step evaluates the similarity between pre-final embedding vectors generated by the GNN model for sliding window graphs. By calculating cosine similarity, we gain insights into the relationships and connectivity patterns captured by the model.</p>
<p></p>
<p>Key Steps:</p>
<ul>
    <li><strong>Graph Embedding Vectors:</strong> Each graph is represented by a vector derived from the GNN's pre-final embedding layer, summarizing temporal and spatial relationships within the EEG signal.</li>
    <li><strong>Middle Point Calculation:</strong> For each pair of graph embeddings, the middle point between their corresponding time windows is calculated to align temporal information with similarity analysis.</li>
    <li><strong>Cosine Similarity:</strong> Cosine similarity is computed between graph embedding vectors to quantify the relationship between graphs. This metric reveals how closely related the patterns in the two time segments are.</li>
    <li><strong>Result Compilation:</strong> The results include cosine similarity scores and metadata like the middle point of time windows. These scores provide a basis for exploring the relationships in EEG data.</li>
</ul>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cosine_sim_pairs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">graphList_1</span><span class="p">)):</span>
    <span class="n">datasetIdx_0</span><span class="o">=</span><span class="n">graphList_0</span><span class="p">[</span><span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>   
    <span class="n">datasetIdx_1</span><span class="o">=</span><span class="n">graphList_1</span><span class="p">[</span><span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
    <span class="nb">min</span> <span class="o">=</span> <span class="n">graphList_0</span><span class="p">[</span><span class="sh">'</span><span class="s">min</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
    <span class="nb">max</span> <span class="o">=</span> <span class="n">graphList_1</span><span class="p">[</span><span class="sh">'</span><span class="s">max</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
    <span class="n">middle_point</span> <span class="o">=</span> <span class="p">(</span><span class="nb">min</span><span class="o">+</span><span class="nb">max</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
    <span class="c1"># cos_sim_value = cos_sim(datasetIdx_0, datasetIdx_1).numpy().flatten
</span>    <span class="n">vector_0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">graphUnion_df</span><span class="p">[</span><span class="sh">'</span><span class="s">vector</span><span class="sh">'</span><span class="p">][</span><span class="n">datasetIdx_0</span><span class="p">])</span>
    <span class="n">vector_1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">graphUnion_df</span><span class="p">[</span><span class="sh">'</span><span class="s">vector</span><span class="sh">'</span><span class="p">][</span><span class="n">datasetIdx_1</span><span class="p">])</span>
    <span class="n">cos_sim_value</span> <span class="o">=</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">vector_0</span><span class="p">,</span> <span class="n">vector_1</span><span class="p">).</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">flatten</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">cosine_sim_pairs</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span>            
            <span class="sh">'</span><span class="s">middle_point</span><span class="sh">'</span><span class="p">:</span><span class="n">middle_point</span><span class="p">,</span>            
            <span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span> <span class="n">cos_sim_value</span>
        <span class="p">})</span></code></pre></figure>

<p></p>

<p>This analysis bridges the gap between model outputs and interpretability, offering a clearer understanding of how the GNN captures and distinguishes temporal patterns. By identifying regions of high and low similarity, this step enables further exploration of brain dynamics during sleep and rest states, paving the way for advanced graph-based analyses.</p>

<p></p>
<h4>Transforming Time Points</h4>
<p></p>
<p>First, we converted the middle points of each sliding window into minutes and seconds to provide a clear temporal context. This was achieved by calculating the integer division and modulo of the middle points by 60 to derive minutes and seconds, respectively. These were then formatted into readable time labels (e.g., “12m 34.5s”) for enhanced interpretability in our plots.</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cosine_sim_pairs_df</span><span class="p">[</span><span class="sh">'</span><span class="s">minutes</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cosine_sim_pairs_df</span><span class="p">[</span><span class="sh">'</span><span class="s">middle_point</span><span class="sh">'</span><span class="p">]</span> <span class="o">//</span> <span class="mi">60</span>
<span class="n">cosine_sim_pairs_df</span><span class="p">[</span><span class="sh">'</span><span class="s">seconds</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cosine_sim_pairs_df</span><span class="p">[</span><span class="sh">'</span><span class="s">middle_point</span><span class="sh">'</span><span class="p">]</span> <span class="o">%</span> <span class="mi">60</span>
<span class="n">cosine_sim_pairs_df</span><span class="p">[</span><span class="sh">'</span><span class="s">time_label</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cosine_sim_pairs_df</span><span class="p">[</span><span class="sh">'</span><span class="s">minutes</span><span class="sh">'</span><span class="p">]</span>
  <span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span> <span class="sh">'</span><span class="s">m </span><span class="sh">'</span> <span class="o">+</span> <span class="n">cosine_sim_pairs_df</span><span class="p">[</span><span class="sh">'</span><span class="s">seconds</span><span class="sh">'</span><span class="p">]</span>
  <span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span> <span class="sh">'</span><span class="s">s</span><span class="sh">'</span></code></pre></figure>

<p></p>
<p></p>

<h4>Smoothing Cosine Similarity Values</h4>
<p></p>

<p>Next, to reduce noise and highlight meaningful trends, we applied a Gaussian smoothing filter to the cosine similarity values. This technique helps clarify patterns by averaging adjacent points in the time series, resulting in smoother curves that better represent the underlying data.</p>
<p></p>
<h4>Creating the Plot</h4>
<p></p>
<p>The smoothed cosine similarity values for both channel pairs were plotted against their corresponding time points. Key details of the plot include:</p>
<ul>
    <li><strong>X-axis:</strong> Time in minutes and seconds, with custom ticks to reduce clutter, ensuring a clear and focused visualization.</li>
    <li><strong>Y-axis:</strong> Cosine similarity values, representing the strength of connectivity between the selected EEG channels.</li>
    <li><strong>Curves:</strong> Separate lines for each channel pair (F3-F4 and C4-Cz) to allow for direct comparison of their temporal dynamics.</li>
</ul>
<p></p>
<h4>Insights and Observations</h4>
<p></p>
<p>The resulting plot showcases how connectivity between specific brain regions changes over time. The F3-F4 pair, for instance, might exhibit distinct patterns compared to C4-Cz, reflecting differences in activity across these regions. This visualization provides a foundation for deeper analyses, such as correlating these dynamics with behavioral or physiological states.</p>

<p></p>
<h4>Technical Details</h4>
<p></p>
<p>The plot was created using Python libraries, including <code>matplotlib</code> for visualization and <code>scipy.ndimage</code> for smoothing. The data preparation involved grouping cosine similarity values, aligning them temporally, and ensuring consistency in the time axis for both channel pairs. This ensures an accurate and visually compelling comparison of the EEG data’s temporal features.</p>
<p></p>
<p>By transforming, smoothing, and plotting the cosine similarity values, this analysis offers a detailed view of temporal connectivity dynamics in EEG data. It provides a vital step in understanding the intricate relationships between brain regions and their changes across different states, such as sleep and rest.</p>

<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">scipy.ndimage</span> <span class="kn">import</span> <span class="n">gaussian_filter1d</span>
<span class="n">cos_smoothed_sleep</span> <span class="o">=</span> <span class="nf">gaussian_filter1d</span><span class="p">(</span><span class="n">cosine_sim_pairs_df1</span><span class="p">[</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">],</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">cos_smoothed_rest</span> <span class="o">=</span> <span class="nf">gaussian_filter1d</span><span class="p">(</span><span class="n">cosine_sim_pairs_df2</span><span class="p">[</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">],</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">time_labels</span> <span class="o">=</span> <span class="n">cosine_sim_pairs_df1</span><span class="p">[</span><span class="sh">'</span><span class="s">time_label</span><span class="sh">'</span><span class="p">]</span>  
<span class="n">step_size</span> <span class="o">=</span> <span class="mi">60</span>
<span class="n">x_ticks</span> <span class="o">=</span> <span class="n">cosine_sim_pairs_df1</span><span class="p">[</span><span class="sh">'</span><span class="s">middle_point</span><span class="sh">'</span><span class="p">][::</span><span class="n">step_size</span><span class="p">]</span>
<span class="n">x_labels</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="nf">int</span><span class="p">(</span><span class="n">m</span><span class="p">)</span><span class="si">}</span><span class="s">:</span><span class="si">{</span><span class="n">s</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span> <span class="k">for</span> <span class="n">m</span><span class="p">,</span>
  <span class="n">s</span> <span class="ow">in</span> <span class="n">cosine_sim_pairs_df1</span><span class="p">[[</span><span class="sh">'</span><span class="s">minutes</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">seconds</span><span class="sh">'</span><span class="p">]].</span><span class="n">iloc</span><span class="p">[::</span><span class="n">step_size</span><span class="p">].</span><span class="n">values</span><span class="p">]</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span>
    <span class="n">cosine_sim_pairs_df1</span><span class="p">[</span><span class="sh">'</span><span class="s">middle_point</span><span class="sh">'</span><span class="p">],</span> <span class="n">cos_smoothed_sleep</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">F3-F4</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">brown</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span>
<span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span>
    <span class="n">cosine_sim_pairs_df2</span><span class="p">[</span><span class="sh">'</span><span class="s">middle_point</span><span class="sh">'</span><span class="p">],</span> <span class="n">cos_smoothed_rest</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">C4-Cz</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span>
<span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">x_ticks</span><span class="p">,</span> <span class="n">x_labels</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Time (minutes:seconds)</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Cosine Similarity</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Cosine Similarity at Rest Time: F3-F4 vs. C4-Cz</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure>

<p></p>

<p></p>
<h3>Explanation and Suggested Descriptions for the Figures</h3>
<p></p>
<h4>Figure 1: Cosine Similarity at Sleep Time: F3-F4 vs. C4-Cz</h4>
<p></p>
<p>This figure illustrates the temporal dynamics of cosine similarity for two EEG channel pairs, <strong>F3-F4</strong> and <strong>C4-Cz</strong>, during sleep. The x-axis represents time in minutes and seconds, while the y-axis shows the cosine similarity values. The red line corresponds to the F3-F4 channel pair, and the green line corresponds to the C4-Cz channel pair. The fluctuations in similarity values over time highlight differences in connectivity between these brain regions during sleep. This visualization offers a detailed view of how specific brain areas interact dynamically during sleep, capturing subtle connectivity changes.</p>

<p></p>

<figure>
    <img src="/img/eegSlide12.jpg" alt="Traditional EEG Graph Example" style="width:90%; margin:auto;" />
    <figcaption>Temporal dynamics of cosine similarity during sleep for EEG channel pairs F3-F4 and C4-Cz, showcasing distinct connectivity patterns in brain regions associated with motor and sensory processing..</figcaption>
</figure>

<p></p>
<h4>Figure 2: Cosine Similarity at Rest Time: F3-F4 vs. C4-Cz</h4>
<p></p>
<p>This figure depicts the cosine similarity for the same EEG channel pairs, <strong>F3-F4</strong> and <strong>C4-Cz</strong>, during rest. Similar to the sleep plot, the x-axis indicates time in minutes and seconds, and the y-axis represents cosine similarity values. The trends for F3-F4 (red) and C4-Cz (green) reveal distinct patterns of connectivity during rest, differing from the sleep state. These patterns reflect how brain activity and connectivity are modulated across different states.</p>

<p></p>
<figure>
    <img src="/img/eegSlide13.jpg" alt="Traditional EEG Graph Example" style="width:90%; margin:auto;" />
    <figcaption>Temporal dynamics of cosine similarity during rest for EEG channel pairs F3-F4 and C4-Cz, highlighting connectivity differences in brain regions compared to the sleep state.</figcaption>
</figure>
<p></p>

<h4>Note on O1-O2 Analysis</h4>
<p></p>
<p>Although <strong>O1-O2</strong> was initially included as part of the analysis, its results have been excluded from the figures and detailed discussion due to the very low model training and testing accuracy observed for this channel pair. This suggests that the model failed to capture meaningful patterns or dynamics for O1-O2, likely due to insufficient signal quality or inherent limitations in the data for this pair.</p>

<p></p>
<p></p>

<p></p>

<p></p>
<h2>Conclusion</h2>
<p></p>

<p>Bridging neuroscience and graph theory isn’t just a challenge—it’s an opportunity. Sliding graphs offer neuroscientists a fresh way to uncover EEG patterns that traditional methods might miss, while graph experts get to see their tools applied to real-world, high-impact challenges like sleep research. By bringing these perspectives together, we’re not just analyzing data—we’re building connections between fields, showing how graph-based techniques can transform the way we study the brain.</p>
<p></p>

<p></p>

<p></p>

<p></p>
<p></p>


                <hr>

                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2025/01/20/vectors2gafGNN/" data-toggle="tooltip" data-placement="top" title="Exploring Geo-Connectivity and Multi-Feature Graphs with GNNs">&larr; Previous Post</a>
                    </li>
                    
                    
                </ul>

            </div>
        </div>
    </div>
</article>

<hr>


    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    <li>
                        <a href="/feed.xml">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    
                    <li>
                        <a href="mailto:sparkling.dataocean@gmail.com">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                </ul>
                <p class="copyright text-muted">Copyright &copy; Melenar 2025</p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/clean-blog.min.js "></script>


    
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-114694347-1', 'auto');
  ga('send', 'pageview');

</script>



</body>

</html>
