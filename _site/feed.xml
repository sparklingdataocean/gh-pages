<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-12-25T20:14:39-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Sparkling Data Ocean</title><subtitle>Spark for Big Data Analytics.</subtitle><entry><title type="html">Temporal–Spatial GNN Fusion for Climate Analytics</title><link href="http://localhost:4000/2025/06/25/voronoiGNN/" rel="alternate" type="text/html" title="Temporal–Spatial GNN Fusion for Climate Analytics" /><published>2025-06-25T08:00:00-04:00</published><updated>2025-06-25T08:00:00-04:00</updated><id>http://localhost:4000/2025/06/25/voronoiGNN</id><content type="html" xml:base="http://localhost:4000/2025/06/25/voronoiGNN/"><![CDATA[<h2>Spatio-Temporal Graphs for Climate Patterns</h2>
<p>
  Here we combine <strong>time series graphs</strong> with a global <strong>spatial graph</strong>
  of cities to create a spatio-temporal view of climate. Decades of daily temperatures are turned
  into graph-based climate fingerprints for each city, then injected into a Voronoi-based world
  graph where neighboring regions share borders. A GNN refines this fused graph so we can see
  which distant cities behave almost identically, which nearby cities quietly diverge, and which
  “bridge cities” connect climate regions. The same method can be applied to any setting where
  signals evolve over time and are anchored in space—sensors, assets, patients, or networks.
</p>

<h2>Conference</h2>
<p>
  The work <em>“GNN Fusion of Voronoi Spatial Graphs and City–Year Temporal Graphs for Climate Analysis”</em>
  was presented at <strong>SCAI 2025</strong> in Ljubljana, Slovenia, on <strong>8 October 2025</strong>.
  The corresponding paper is currently not yet published in archival proceedings.
</p>

<h2>Fusing Space &amp; Time with Graph Neural Networks</h2>
<p>
  Climate isn’t only about <em>where</em> you are; it’s about how conditions <em>evolve together</em> across the map.
  Here we use <strong>Graph Neural Networks (GNNs)</strong> to connect <strong>1,000 cities</strong> across
  <strong>40 years</strong> of daily temperatures, revealing hidden climate “neighborhoods” and long-range “bridges”
  that geography alone can’t explain. Modeling both space and time as graphs shows when distant regions behave like
  close neighbors—and when nearby cities drift apart.
</p>

<figure>
  <img src="/img/voronoi34.jpg" alt="Four perspectives: Average, Spatial, Temporal, Spatial+Temporal" />
  <figcaption>Figure 1. Four perspectives combining spatial and temporal graph inputs for climate analysis.</figcaption>
</figure>

<p>This diagram shows the four different ways we explore climate similarity, based on combinations of input data and graph structures. Here is color guide:
<ul>
  <li><strong>Yellow area</strong> — represents the use of <strong>raw data</strong>, specifically the <em>average temperature vectors</em> for each city.</li>
  <li><strong>Light green area</strong> — represents the use of <strong>temporal data</strong>, meaning the <em>city-level graphs</em> built from year-to-year climate patterns.</li>
  <li><strong>Purple area</strong> — represents the use of <strong>spatial data</strong>, specifically the <em>Voronoi graph</em> that defines proximity between cities.</li>
</ul>


<h3>Four perspectives we analyze</h3>
<ul>
  <li><strong>Average:</strong> a city’s typical year-round temperature profile</li>
  <li><strong>Spatial:</strong> proximity connections via a Voronoi graph</li>
  <li><strong>Temporal:</strong> how climate evolves across years within one city</li>
  <li><strong>Spatial + Temporal:</strong> fusion of both for the richest signal</li>
</ul>

<h3>Why this matters</h3>
<p>
  Most climate work emphasizes either geography or time series. This study fuses both:
  <strong>space</strong> (how cities influence one another through adjacency) and
  <strong>time</strong> (how each city’s climate changes year to year). The joint view exposes patterns a single axis
  misses—regional belts that shift together, regime matches across oceans, and nearby microclimates that diverge.
</p>

<h3>How the model learns similarity</h3>
<p>We build two complementary graph families and train GNNs with link prediction to learn embeddings:</p>
<ul>
  <li><strong>Spatial graphs:</strong> nodes are cities; edges come from Voronoi adjacency.</li>
  <li><strong>Temporal city-year graphs:</strong> each city becomes a chain of yearly nodes; edges link years with high cosine similarity of their daily temperature vectors.</li>
</ul>

<h3>Feature spaces produced</h3>
<ol>
  <li><strong>Average temperature vectors</strong> (365-dim per city)</li>
  <li><strong>City graph embeddings</strong> from GNN graph classification over city-year structures</li>
  <li><strong>Link-prediction embeddings (average vectors):</strong> predict spatial edges from average profiles</li>
  <li><strong>Link-prediction embeddings (city-graph vectors):</strong> same task using city-level GNN vectors, fusing spatial and temporal signals</li>
</ol>

<h3>Reusable blueprint</h3>
<p>
  Although the focus is temperature, this two-stream graph fusion is a reusable approach for evolving systems—mobility,
  pollution, public health, and more.
</p>



<p></p>




<p></p>
<h2>Transforming Data to Graphs</h2>
<p></p>
<p></p>
<h3>Raw Data</h3>
<p></p>

This study is based on a large and detailed dataset: 


<ol>
  <li>1,000 the most populous cities worldwide </li>
  <li>Geo-coordinates</li>
  <li>40 years of daily temperatures (1980–2019)</li>
</ol>

<p></p>
This data is giving us long-term, high-resolution climate information across the globe. It allows us to fuse geography (space) with decades of daily temperatures (time) and
reveal hidden climate neighborhoods &amp; bridges.

<p></p>
<h3>Spatial Graph -- Voronoi</h3>
<p></p>
To model geography we use a Voronoi diagram. Think of several coffee shops in a town: each shop “owns” the area closer to it than to any other shop. We apply the same idea to cities. Each city becomes a node; two cities are connected if their Voronoi regions share a boundary. Some neighbors are nearby; others can be surprisingly far apart (see the Québec–Porto example).
<p></p>

<p></p>

<a href="#">
    <img src="/img/voronoi41.jpg" alt="Post Sample Image" width="333" />
</a>
<p></p>

<ul>
  <li><strong>Coffee shops → areas:</strong> each site covers its closest region.</li>
  <li><strong>Neighbors →  edges:</strong> regions that share a border become connected.</li>
  <li><strong>Cities → nodes:</strong> cities sit at Voronoi centers; shared borders define graph edges.</li>

</ul>


<p></p>
We use the Voronoi diagram to define natural neighbors between cities: space is partitioned so every location belongs to its closest city. Cities are connected if their regions share a border. For example, Québec, Canada and Porto, Portugal are neighbors because no more-populated cities lie between them at that scale; the shared Voronoi boundary falls near the midpoint of the great-circle path.
   <a href="#">
       <img src="/img/voronoi17.jpg" alt="Post Sample Image" width="777" />
   </a>

<p></p>
Because cities are on the curved Earth, we first project latitude/longitude into a planar coordinate system (EPSG:3857) so the Voronoi algorithm—which expects Cartesian coordinates—can run. Any equal, consistent projection is acceptable here; the goal is topological adjacency, not precise distances.
<p></p>
This produces a spatial graph over 1,000 cities in which each node carries a 365-value average-temperature vector (mean daily temperatures across 40 years). The result captures true proximity determined by spatial partitioning—not arbitrary distance thresholds—and highlights dense regional clusters as well as isolated cities.
<p></p>
A spatial graph that connects all 1,000 cities built using a Voronoi diagram, which links cities that are geographically close
Each city is a node, described by a 365-value vector (its average daily temperatures across 40 years)
This gives us a global view of how nearby climates relate

To understand the <strong>spatial structure</strong>, we used <strong>Voronoi diagrams</strong> to define natural neighborhoods. Cities are connected if their regions share a border, creating a network that reflects true proximity — not based on arbitrary distance cutoffs, but shaped by how space is divided. This helps capture how some cities are part of dense regional clusters, while others are more isolated.

<p></p>
<h3>Temporal City Graphs</h3>
<p></p>

<p></p>
We looked at the <strong>temporal behavior</strong> of climate in each city — how daily temperatures have changed (or remained consistent) across decades. Some locations show highly stable seasonal cycles, while others exhibit more variation year to year. We constructed temporal graphs for each city, with nodes representing city - year, with a 365-value vector of daily temperatures. Graph edges we defined by pairs of nodes with cosine similarities higher than threshold. Temporal graphs represent relationships between daily temperature vectors for different years.
For each graph we added a virtual node to transform disconnected graphs into single connected components.
<p></p>
<ul>
  <li><strong>Nodes</strong> = city-year; features = daily temperature</li>
  <li><strong>Edges</strong> = high cosine similarity (year↔year)</li>
  <li><strong>Virtual nodes</strong> to ensure connectivity</li>

</ul>

<p></p>



<a href="#">
    <img src="/img/voronoi42.jpg" alt="Post Sample Image" width="555" />
</a>
<p></p>
You can see as examples city graph for Malaga, Spain with stable weather and highly similar yearly weather and Orenburg, Russia where daily temperature vectors are very different year by year.
<p></p>
<p></p>
<h2>GNN Models</h2>
<p></p>
We will use Graph Neural Networks (GNNs) to learn more from these graphs by turning each city (or each city-year) into a meaningful vector. In both cases, the GNN models help us represent each city as a learned vector, shaped by its spatial context or its climate history over time. These new vectors can then be used to compare cities, group them, or detect unusual patterns. From each model, we extract the pre-final output vectors — these are 128-dimensional embeddings that capture the learned information.

<p></p>
<h3>Temporal GNN - Graph Classification</h3>
<p></p>
To capture how each city’s climate has changed over time, we applied a GNN Graph Classification model to 1,000 city-level temporal graphs. The model learns from the structure and connections within each graph, summarizing a city’s long-term climate behavior — whether it’s stable, variable, or somewhere in between.
<p></p>
The model requires small graphs with labels. As a simple proxy, we labeled cities based on their distance from the equator, using latitude as an indicator of climate variability. The model outputs a 128-dimensional vector that represents each city’s climate history. Future work could refine these labels with more detailed, data-driven methods.
<p></p>

<p></p>

<p></p>
For classifying city graphs, we used the Graph Convolutional Network (GCNConv) model from the PyTorch Geometric Library (PyG). The GCNConv model allowed us to extract feature vectors from the graph data, enabling us to perform a binary classification to determine whether the climate for each city was 'stable' or 'unstable'.
<p></p>

<p></p>

<p></p>
<p></p>
<h3>Spatial GNN - Link Prediction</h3>
<p></p>
For the spatial analysis, we build a Voronoi-based graph that links all 1 000 cities worldwide and train a GNN link-prediction model on it. Each node is initialized with a 365-dimensional “average-temperature” vector, enabling the network to learn how climate patterns propagate among neighboring cities. The model then produces a fresh embedding for every city—one that blends its own climate signature with the influence of its Voronoi neighbors.
<p></p>

<p></p>
For spatial graphs we used GNN Link Prediction model based on GraphSAGE algorithm, which generates node embeddings based on attributes and neighbors without retraining. Our study employs a GNN Link Prediction model from the Deep Graph Library (DGL) library.

<p></p>
<h3>Joint Spatial and Temporal Modeling</h3>
<p></p>
To capture both temporal and spatial influences on climate, we apply a GNN Link Prediction model. The graph structure comes from Voronoi-based city connections, while the node features are the learned embeddings from the city-level temporal graphs produced by the GNN Classification model. This allows us to explore how geography and long-term climate behavior interact together.

<p></p>
<h2>Methods</h2>

<p></p>
The diagram below shows how we built a climate similarity model using graph neural networks. First, we connected the 1000 most populated cities using Voronoi-based geography — cities are linked if their zones share a border. Then, we used 40 years of temperature data to describe each city in two ways: one based on raw daily averages, and one using advanced GNN models that learn from how each city's climate changed over time. These feature vectors help us compare cities and uncover deep climate patterns around the world.




   <a href="#">
       <img src="/img/voronoi16b.jpg" alt="Post Sample Image" width="404" />
   </a>
Fig. 1. Overview of the proposed method combining Voronoi-based spatial graphs with GNN pipelines for climate similarity and classification.
<p></p>


<p></p>
<p></p>






<h2>Coding and Observations</h2>


<p></p>
<h3>Data Source: Climate Data</h3>
<p></p>
Our primary dataset, sourced from Kaggle, is titled:
<i><a href="
https://www.kaggle.com/hansukyang/temperature-history-of-1000-cities-1980-to-2020">"Temperature History of 1000 cities 1980 to 2020"</a></i> - daily temperature from 1980 to 2020 years for 1000 most populous cities in the world. This dataset provides a comprehensive record of average daily temperatures in Celsius for the 1000 most populous cities worldwide, spanning from 1980 to 2019.
<p></p>



<p></p>

   <a href="#">
       <img src="/img/preFinFig1.jpg" alt="Post Sample Image" width="678" />
   </a>
Fig. 1. Latitude Distribution of the 1000 Most Populous Cities.
<p></p>  

To begin our climate analysis, we created a simple but effective climate profile for each city. The dataset includes daily temperature readings for 1000 cities across multiple years. By averaging the temperatures for each day of the year across all available years, we produced a single 365-dimensional vector per city.

This average vector captures the city’s typical annual temperature pattern and serves as a foundational node feature for later graph-based models.
</p>

<p></p>

<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python">  <span class="n">df</span><span class="o">=</span><span class="n">rawData</span>
  <span class="n">daily_cols</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nf">range</span><span class="p">(</span><span class="mi">365</span><span class="p">)))</span>
  <span class="n">city_avg_vectors</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">cityInd</span><span class="sh">'</span><span class="p">)[</span><span class="n">daily_cols</span><span class="p">].</span><span class="nf">mean</span><span class="p">().</span><span class="nf">reset_index</span><span class="p">()</span>
  <span class="n">city_avg_vectors</span><span class="p">.</span><span class="n">shape</span>
  <span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">366</span><span class="p">)</span>
  </code></pre></figure>

<p></p>
<p></p>

<p></p>

<h3>Voronoi Graph Construction</h3>

<p>
To capture spatial relationships between cities, we built a <strong>Voronoi diagram</strong>, which naturally defines neighboring regions based on geographic proximity.
</p>

<p>
First, we projected the latitude and longitude of each city into a flat 2D coordinate system using the <strong>EPSG:3857 map projection</strong>, as required by the Voronoi algorithm.
</p>

<pre><code>
from pyproj import Transformer
from scipy.spatial import Voronoi
import numpy as np

# Project geographic coordinates to 2D plane
transformer = Transformer.from_crs("epsg:4326", "epsg:3857", always_xy=True)
projected = np.array([
    transformer.transform(lon, lat)
    for lon, lat in zip(cityData['lng'], cityData['lat'])
])
</code></pre>

<p>
We then computed the Voronoi diagram using SciPy:
</p>

<pre><code>
# Compute Voronoi diagram
vor = Voronoi(projected)
</code></pre>

<p>
The Voronoi output contains pairs of neighboring points via <code>vor.ridge_points</code>, which lists index pairs for cities whose regions share a border. We converted these indices into our unique city identifiers (<code>cityInd</code>) and created a DataFrame representing the edge list of our spatial graph:
</p>

<pre><code>
# Extract unique neighbor pairs
neighbors = set(tuple(sorted((p1, p2))) for p1, p2 in vor.ridge_points)

# Build edge list DataFrame
rows = []
for i, j in neighbors:
    rows.append({
        'city1': cityData.iloc[i]['cityInd'],
        'city2': cityData.iloc[j]['cityInd'],
    })
voronoi_df = pd.DataFrame(rows)
</code></pre>

<p><strong>Example of Voronoi-based neighboring city pairs:</strong></p>

<table class="compact" style="width:auto;">
  <colgroup>
    <col style="width:60px;" />
    <col style="width:60px;" />
  </colgroup>
  <thead>
    <tr><th>City_1</th><th>City_2</th></tr>
  </thead>
  <tbody>
    <tr><td>155</td><td>810</td></tr>
    <tr><td>60</td><td>801</td></tr>
    <tr><td>40</td><td>185</td></tr>
    <tr><td>874</td><td>905</td></tr>
    <tr><td>686</td><td>705</td></tr>
  </tbody>
</table>

<p>
This edge list defines the connections in our spatial graph, showing which cities are considered neighbors based on shared Voronoi borders.
</p>

<h4>Calculating Distances Between Neighboring Cities</h4>

<p>
To measure distances between neighboring cities, we used the same 2D projected coordinates:
</p>

<pre><code>
rows = []
for i, j in neighbors:
    dist_km = round(np.linalg.norm(projected[i] - projected[j]) / 1000, 5)
    rows.append({
        'city1': cityData.iloc[i]['cityInd'],
        'city2': cityData.iloc[j]['cityInd'],
        'distance_km': dist_km
    })
voronoi_distances_df = pd.DataFrame(rows)
</code></pre>

<p>
To make the results more readable, we combined city names and countries:
</p>

<pre><code>
# Create readable city labels
cityData['city_country'] = cityData['city_ascii'] + ', ' + cityData['country']
city_lookup = cityData.set_index('cityInd')['city_country']

# Add city names to distances DataFrame
voronoi_distances_df['city1_name'] = voronoi_distances_df['city1'].map(city_lookup)
voronoi_distances_df['city2_name'] = voronoi_distances_df['city2'].map(city_lookup)
</code></pre>

<p></p>
<p>Statistics on distance Between Neighboring Cities (in kilometers)</p>
<pre>
count     2983.00  
mean       638.67  
std       1170.90  
min          2.27  
25%        176.22  
50%        340.92  
75%        658.97  
max      25870.97
</pre>
<p></p>

<p>
This structure provides both the graph topology (neighbors) and distance information, forming the basis for spatial climate analysis using graph models.
</p>

<p></p>

<p></p>

<p></p>

<p></p>

<p></p>
<h3>Temporal GNN: Graph Classification</h3>
<p></p>
<p>For our analysis, each city was modeled as a graph, with nodes representing specific {city, year} pairs. These nodes encapsulate a full year of daily temperature values, allowing us to examine long-term temporal trends across time. To enable classification, each city graph was labeled as either stable or unstable, based on its geographic latitude. The assumption here is that cities located closer to the equator tend to have more stable climate patterns, with less seasonal fluctuation, while those farther from the equator generally experience greater variability.</p>
<p></p>
<p>We divided the cities into two groups using their latitude values—one closer to the equator, the other at higher latitudes—creating a binary classification task for our Graph Neural Network (GNN) model. The bar chart below shows the latitude distribution of all 1000 cities, highlighting a dense cluster between 20\textdegree{} and 60\textdegree{} in the Northern Hemisphere and a sparser spread in the Southern Hemisphere. The equator is marked by a dashed line for reference.</p>

<p></p>
<h4>Input Graph Data Preparation</h4>
<p></p>

<p>Before training our GNN for classification, we need to label each city graph as either <strong>stable</strong> or <strong>unstable</strong> in terms of climate. To do this, we sort all 1000 cities by their absolute latitude — under the assumption that cities closer to the equator (low latitude) tend to have more stable temperature patterns over time.</p>
<p></p>
<p>We assign a label of <code>0</code> to the 500 cities nearest the equator and a label of <code>1</code> to the 500 cities farther away. These labels serve as ground truth for training the graph classification model.</p>
<p></p>
<p>Here’s the code used to sort the data and assign the classification labels:</p>

<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df_sorted</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">lat</span><span class="sh">'</span><span class="p">].</span><span class="nf">abs</span><span class="p">().</span><span class="nf">sort_values</span><span class="p">().</span><span class="n">index</span><span class="p">]</span>
<span class="n">df_sorted</span><span class="p">[</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">500</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)]</span>
<span class="n">df_sorted</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df_sorted</span><span class="p">[</span><span class="sh">'</span><span class="s">labelIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_sorted</span><span class="p">.</span><span class="n">index</span>
<span class="n">cityLabels</span> <span class="o">=</span> <span class="n">df_sorted</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="sh">'</span><span class="s">cityInd</span><span class="sh">'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">cityLabels</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">min_lat</span> <span class="o">=</span> <span class="n">cityLabels</span><span class="p">[</span><span class="sh">'</span><span class="s">lat</span><span class="sh">'</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span>
<span class="n">max_lat</span> <span class="o">=</span> <span class="n">cityLabels</span><span class="p">[</span><span class="sh">'</span><span class="s">lat</span><span class="sh">'</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Minimum Latitude:</span><span class="sh">"</span><span class="p">,</span> <span class="n">min_lat</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Maximum Latitude:</span><span class="sh">"</span><span class="p">,</span> <span class="n">max_lat</span><span class="p">)</span>
<span class="n">Minimum</span> <span class="n">Latitude</span><span class="p">:</span> <span class="o">-</span><span class="mf">41.3</span>
<span class="n">Maximum</span> <span class="n">Latitude</span><span class="p">:</span> <span class="mf">64.15</span></code></pre></figure>

<p></p>

<p>After assigning stability labels to cities, we merge this information with the original temperature dataset. Each city-year pair includes a daily temperature vector (365 values), and we focus on the year 1980 as the representative graph structure for every city.</p>
<p></p>
<p>We also extract important metadata — including city name, coordinates, and region — to keep track of each graph’s identity during analysis.</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">subData</span><span class="o">=</span><span class="n">rawData</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">lineScore</span><span class="p">,</span><span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">cityInd</span><span class="sh">'</span><span class="p">,</span><span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">inner</span><span class="sh">'</span><span class="p">)</span>
<span class="n">subData</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">values1</span><span class="o">=</span><span class="n">subData</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">9</span><span class="p">:</span><span class="mi">374</span><span class="p">]</span>
<span class="n">metaGroups</span><span class="o">=</span><span class="n">subData</span><span class="p">[(</span><span class="n">subData</span><span class="p">[</span><span class="sh">'</span><span class="s">nextYear</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="mi">1980</span><span class="p">)].</span><span class="n">iloc</span><span class="p">[:,[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">374</span><span class="p">]]</span>
<span class="n">metaGroups</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">metaGroups</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">metaGroups</span><span class="p">.</span><span class="n">index</span></code></pre></figure>

<p></p>

<p>
To build graphs for each city, we first define a cosine similarity threshold. We will use this threshold to determine which years within a city are connected based on the similarity of their temperature profiles.
</p>

<p>
For example, if two years have a cosine similarity greater than <code>0.925</code>, we connect them with an edge in that city’s graph. This approach helps us capture internal climate consistency and variability over time.
</p>

<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="n">datasetTest</span><span class="o">=</span><span class="nf">list</span><span class="p">()</span>
<span class="n">cosList</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.925</span><span class="p">]</span></code></pre></figure>

<p></p>

<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="n">datasetTest</span><span class="o">=</span><span class="nf">list</span><span class="p">()</span>
<span class="n">datasetModel</span><span class="o">=</span><span class="nf">list</span><span class="p">()</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="k">for</span> <span class="n">cos</span> <span class="ow">in</span> <span class="n">cosList</span><span class="p">:</span>
  <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">cityName</span><span class="o">=</span><span class="n">metaGroups</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">g</span><span class="p">][</span><span class="sh">'</span><span class="s">city_ascii</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">country</span><span class="o">=</span><span class="n">metaGroups</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">g</span><span class="p">][</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">label</span><span class="o">=</span><span class="n">metaGroups</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">g</span><span class="p">][</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">cityInd</span><span class="o">=</span><span class="n">metaGroups</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">g</span><span class="p">][</span><span class="sh">'</span><span class="s">cityInd</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">data1</span><span class="o">=</span><span class="n">subData</span><span class="p">[(</span><span class="n">subData</span><span class="p">[</span><span class="sh">'</span><span class="s">cityInd</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">cityInd</span><span class="p">)]</span>
    <span class="n">values1</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">9</span><span class="p">:</span><span class="mi">374</span><span class="p">]</span>
    <span class="n">fXValues1</span><span class="o">=</span> <span class="n">values1</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">values</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">fXValuesPT1</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">fXValues1</span><span class="p">)</span>
    <span class="n">fXValuesPT1avg</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">fXValuesPT1</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">fXValuesPT1union</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">fXValuesPT1</span><span class="p">,</span><span class="n">fXValuesPT1avg</span><span class="p">),</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">cosine_scores1</span> <span class="o">=</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">fXValuesPT1</span><span class="p">,</span> <span class="n">fXValuesPT1</span><span class="p">)</span>
    <span class="n">cosPairs1</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">score0</span><span class="o">=</span><span class="n">cosine_scores1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">40</span><span class="p">):</span>
      <span class="n">year1</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">'</span><span class="s">nextYear</span><span class="sh">'</span><span class="p">]</span>
      <span class="n">cosPairs1</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span><span class="n">score0</span><span class="p">,</span> <span class="sh">'</span><span class="s">cityName</span><span class="sh">'</span><span class="p">:</span><span class="n">cityName</span><span class="p">,</span> <span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">:</span><span class="n">country</span><span class="p">,</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span>
          <span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">:</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">:</span><span class="mi">40</span><span class="p">,</span> <span class="sh">'</span><span class="s">year1</span><span class="sh">'</span><span class="p">:</span><span class="n">year1</span><span class="p">,</span> <span class="sh">'</span><span class="s">year2</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">XXX</span><span class="sh">'</span><span class="p">,</span>
          <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">score0</span><span class="p">})</span>
      <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">40</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">j</span><span class="p">:</span>
          <span class="n">score</span><span class="o">=</span><span class="n">cosine_scores1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
          <span class="c1"># print(cos)
</span>          <span class="k">if</span> <span class="n">score</span><span class="o">&gt;</span><span class="n">cos</span><span class="p">:</span>
            <span class="n">year2</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="sh">'</span><span class="s">nextYear</span><span class="sh">'</span><span class="p">]</span>
            <span class="n">cosPairs1</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span><span class="n">cos</span><span class="p">,</span> <span class="sh">'</span><span class="s">cityName</span><span class="sh">'</span><span class="p">:</span><span class="n">cityName</span><span class="p">,</span> <span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">:</span><span class="n">country</span><span class="p">,</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">:</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">:</span><span class="n">j</span><span class="p">,</span> <span class="sh">'</span><span class="s">year1</span><span class="sh">'</span><span class="p">:</span><span class="n">year1</span><span class="p">,</span> <span class="sh">'</span><span class="s">year2</span><span class="sh">'</span><span class="p">:</span><span class="n">year2</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">score</span><span class="p">})</span>
    <span class="n">dfCosPairs1</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">cosPairs1</span><span class="p">)</span>
    <span class="n">edge1</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">dfCosPairs1</span><span class="p">[[</span><span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">,</span>	<span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">]].</span><span class="n">T</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">dataset1</span> <span class="o">=</span> <span class="nc">Data</span><span class="p">(</span><span class="n">edge_index</span><span class="o">=</span><span class="n">edge1</span><span class="p">)</span>
    <span class="n">dataset1</span><span class="p">.</span><span class="n">y</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">label</span><span class="p">])</span>
    <span class="n">dataset1</span><span class="p">.</span><span class="n">x</span><span class="o">=</span><span class="n">fXValuesPT1union</span>
    <span class="n">datasetTest</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">dataset1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">&gt;=</span><span class="mi">0</span><span class="p">:</span>
      <span class="n">datasetModel</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">dataset1</span><span class="p">)</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">datasetTest</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">datasetModel</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>
<h4>GNN Graph Classification Model Training</h4>
<p></p>
<p>
Once our graph dataset is ready, we divide it into training and testing splits — using 888 city graphs for training and the remaining 112 for testing. Each graph represents one city, with nodes representing years and features capturing daily temperature patterns.
</p>

<p>
We use PyTorch Geometric’s <code>DataLoader</code> to batch graphs efficiently and iterate through them during training. Below, we also define a 3-layer Graph Convolutional Network (GCN) with a global pooling layer that summarizes each graph into a single embedding.
</p>

<p>
The final layer outputs a prediction for each graph: whether it represents a <strong>stable</strong> or <strong>unstable</strong> climate pattern.
</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span>  <span class="n">dataset</span><span class="p">[:</span><span class="mi">888</span><span class="p">]</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">888</span><span class="p">:]</span>
<span class="n">rom</span> <span class="n">torch_geometric</span><span class="p">.</span><span class="n">loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Step </span><span class="si">{</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s">:</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">=======</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Number of graphs in the current batch: </span><span class="si">{</span><span class="n">data</span><span class="p">.</span><span class="n">num_graphs</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">()</span>
<span class="kn">from</span> <span class="n">torch.nn</span> <span class="kn">import</span> <span class="n">Linear</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GCNConv</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">global_mean_pool</span>
<span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">GCN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="mi">365</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lin</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">return_graph_embedding</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="c1"># Node Embedding Steps
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">graph_embedding</span> <span class="o">=</span> <span class="nf">global_mean_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>  
        <span class="k">if</span> <span class="n">return_graph_embedding</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">graph_embedding</span>  
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">graph_embedding</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span></code></pre></figure>

<p></p>

<p>With the model and data loaders set up, we now train our Graph Neural Network (GCN) using a standard cross-entropy loss function. We optimize using Adam and evaluate the model’s accuracy on both training and test sets after each epoch.</p>
<p></p>
<p>The training loop runs for 76 epochs, showing how well the model is learning to classify cities based on their climate patterns over time.</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">IPython.display</span> <span class="kn">import</span> <span class="n">Javascript</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
         <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>  
         <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>  
         <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>  
         <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
         <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>  
<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">loader</span><span class="p">):</span>
     <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
     <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
     <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
         <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>
         <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
         <span class="n">correct</span> <span class="o">+=</span> <span class="nf">int</span><span class="p">((</span><span class="n">pred</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">).</span><span class="nf">sum</span><span class="p">())</span>
     <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">)</span>  
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">77</span><span class="p">):</span>
    <span class="nf">train</span><span class="p">()</span>
    <span class="n">train_acc</span> <span class="o">=</span> <span class="nf">test</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="nf">test</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="mi">03</span><span class="n">d</span><span class="si">}</span><span class="s">, Train Acc: </span><span class="si">{</span><span class="n">train_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, Test Acc: </span><span class="si">{</span><span class="n">test_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>

<p></p>

<pre>
Epoch: 061, Train Acc: 0.9110, Test Acc: 0.8750
Epoch: 062, Train Acc: 0.9392, Test Acc: 0.9107
Epoch: 063, Train Acc: 0.9291, Test Acc: 0.8839
Epoch: 064, Train Acc: 0.9110, Test Acc: 0.9196
Epoch: 065, Train Acc: 0.9471, Test Acc: 0.9107
Epoch: 066, Train Acc: 0.9448, Test Acc: 0.9286
Epoch: 067, Train Acc: 0.9279, Test Acc: 0.8929
Epoch: 068, Train Acc: 0.9392, Test Acc: 0.9107
Epoch: 069, Train Acc: 0.9032, Test Acc: 0.8661
Epoch: 070, Train Acc: 0.9414, Test Acc: 0.9286
Epoch: 071, Train Acc: 0.9426, Test Acc: 0.9018
Epoch: 072, Train Acc: 0.9448, Test Acc: 0.9196
Epoch: 073, Train Acc: 0.9448, Test Acc: 0.9107
Epoch: 074, Train Acc: 0.9448, Test Acc: 0.9107
Epoch: 075, Train Acc: 0.9448, Test Acc: 0.9196
Epoch: 076, Train Acc: 0.9414, Test Acc: 0.9196
</pre>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">Epoch</span><span class="p">:</span> <span class="mi">076</span><span class="p">,</span> <span class="n">Train</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9414</span><span class="p">,</span> <span class="n">Test</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9196</span></code></pre></figure>

<p></p>
<h4>GNN Graph Classification Model Results</h4>
<p></p>

<p>Once the model is trained, we can use it to extract vector representations (embeddings) for each city graph. These embeddings capture structural and feature-based patterns learned during training — essentially summarizing each city’s climate behavior over time.</p>
<p></p>
<p>Below, we retrieve the graph embedding for the first city in our dataset. The model outputs a 128-dimensional vector that can later be used for clustering, similarity analysis, or further graph-based tasks.</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">g</span><span class="o">=</span><span class="mi">0</span>
<span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_graph_embedding</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">out</span><span class="p">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">])</span></code></pre></figure>

<p></p>
<p>
After training our GNN classifier, we loop through all 1000 city graphs and extract their 128-dimensional embeddings using the model’s <code>return_graph_embedding=True</code> mode. These embeddings capture the climate structure of each city graph and can be used for downstream tasks such as clustering, similarity analysis, or building meta-graphs.
</p>

<p>
We collect these vectors into a unified DataFrame called <code>city_graph_vectors</code>, where each row corresponds to a single city (indexed by <code>cityInd</code>) and each column holds part of its graph embedding.
</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Softmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">graphUnion</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">graphCount</span><span class="p">):</span>
  <span class="n">label</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_graph_embedding</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="n">output</span> <span class="o">=</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">out</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">graphUnion</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">:</span><span class="n">g</span><span class="p">,</span><span class="sh">'</span><span class="s">vector</span><span class="sh">'</span><span class="p">:</span> <span class="n">out</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()})</span>
<span class="n">df</span><span class="o">=</span><span class="n">graphUnion_df</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">vector</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">vector</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="nf">flatten</span><span class="p">())</span>
<span class="n">city_graph_vectors</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">vector</span><span class="sh">'</span><span class="p">].</span><span class="nf">to_list</span><span class="p">())</span>
<span class="n">city_graph_vectors</span><span class="p">.</span><span class="nf">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="sh">'</span><span class="s">cityInd</span><span class="sh">'</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">])</span>
<span class="n">city_graph_vectors</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">cityInd</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">city_graph_vectors</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span></code></pre></figure>

<p></p>

<p></p>

<h3>Spatial GNN: Link Prediction</h3>
<p></p>
<p>We used the GNN Link Prediction model from DGL library for Voronoi graph with average vectors and Voronoi graph with city-graph embedding vectors.</p>
<p></p>
<p>We build a DGL graph where each node represents a city and edges connect Voronoi neighbors.
Node features are provided in two forms:</p>
<p></p>

<ul>
  <li><strong>Raw vectors:</strong> 365-dimensional averages of daily temperature over 40 years.</li>
  <li><strong>Embedded vectors:</strong> Learned representations from city-level temporal graphs via a GNN classification model.</li>
</ul>

<p>Graph construction steps (same for both feature types):</p>

<ol>
  <li>Load vector data and remove non-feature columns (e.g., <code>cityInd</code>).</li>
  <li>Convert Voronoi-based city pairs to PyTorch edge tensors.</li>
  <li>Create the DGL graph with nodes and Voronoi edges.</li>
  <li>Assign raw or embedded vectors as node features.</li>
</ol>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">avg_vectors</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">theAvgPath</span><span class="p">)</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">dgl</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">avg_vectors</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="sh">'</span><span class="s">cityInd</span><span class="sh">'</span><span class="p">).</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">src_nodes</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">edges</span><span class="p">[</span><span class="sh">'</span><span class="s">city1</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">dst_nodes</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">edges</span><span class="p">[</span><span class="sh">'</span><span class="s">city2</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">src_nodes</span><span class="p">,</span> <span class="n">dst_nodes</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">features</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">features</span>
<span class="n">g</span>
<span class="nc">Graph</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">num_edges</span><span class="o">=</span><span class="mi">2983</span><span class="p">,</span>
      <span class="n">ndata_schemes</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">:</span> <span class="nc">Scheme</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">365</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)}</span>
      <span class="n">edata_schemes</span><span class="o">=</span><span class="p">{})</span></code></pre></figure>

<p></p>
<p></p>

<h4>Splitting Edges for Training and Testing</h4>

<p>
For link prediction, we need both real (positive) and fake (negative) edges.
We split Voronoi edges into training and test sets, then sample an equal number
of non-connected city pairs as negatives.
</p>

<ol>
  <li>Extract and shuffle city-to-city edges; convert to PyTorch tensors.</li>
  <li>Split 90% for training, 10% for testing.</li>
  <li>Build a sparse adjacency matrix to detect missing (negative) edges.</li>
  <li>Sample negative edges with no connection or self-loop, matching positive count.</li>
</ol>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">scipy.sparse</span> <span class="k">as</span> <span class="n">sp</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="n">eids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">permutation</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_edges</span><span class="p">())</span>
<span class="n">eids</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">eids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>  
<span class="n">test_size</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">eids</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">eids</span><span class="p">)</span> <span class="o">-</span> <span class="n">test_size</span>
<span class="n">test_pos_u</span><span class="p">,</span> <span class="n">test_pos_v</span> <span class="o">=</span> <span class="n">u</span><span class="p">[</span><span class="n">eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]],</span> <span class="n">v</span><span class="p">[</span><span class="n">eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]]</span>
<span class="n">train_pos_u</span><span class="p">,</span> <span class="n">train_pos_v</span> <span class="o">=</span> <span class="n">u</span><span class="p">[</span><span class="n">eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]],</span> <span class="n">v</span><span class="p">[</span><span class="n">eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]]</span>
<span class="n">adj</span> <span class="o">=</span> <span class="n">sp</span><span class="p">.</span><span class="nf">coo_matrix</span><span class="p">((</span><span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">u</span><span class="p">)),</span> <span class="p">(</span><span class="n">u</span><span class="p">.</span><span class="nf">tolist</span><span class="p">(),</span> <span class="n">v</span><span class="p">.</span><span class="nf">tolist</span><span class="p">())),</span>
      <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">(),</span> <span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">()))</span>
<span class="n">adj_neg</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">adj</span><span class="p">.</span><span class="nf">todense</span><span class="p">()</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>
<span class="n">neg_u</span><span class="p">,</span> <span class="n">neg_v</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">adj_neg</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">neg_eids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">neg_u</span><span class="p">),</span> <span class="n">g</span><span class="p">.</span><span class="nf">number_of_edges</span><span class="p">(),</span> <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">test_neg_u</span><span class="p">,</span> <span class="n">test_neg_v</span> <span class="o">=</span> <span class="n">neg_u</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]],</span> <span class="n">neg_v</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]]</span>
<span class="n">train_neg_u</span><span class="p">,</span> <span class="n">train_neg_v</span> <span class="o">=</span> <span class="n">neg_u</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]],</span> <span class="n">neg_v</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]]</span>
<span class="n">train_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">remove_edges</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">])</span></code></pre></figure>

<p></p>
<p></p>
<h4>Building a GraphSAGE Model</h4>

<p>
To learn meaningful representations of each city in our graph, we use a two-layer GraphSAGE model. GraphSAGE (Graph Sample and Aggregate) is a popular Graph Neural Network architecture that generates node embeddings by aggregating information from a node’s neighbors.
</p>

<p>
In our model, each layer applies a <code>mean</code> aggregator to combine neighbor features and passes the result through a ReLU activation. The second layer refines the hidden representation.
</p>

<p>
Here’s the code that defines the GraphSAGE model using DGL’s built-in <code>SAGEConv</code> layer:
</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">dgl.nn</span> <span class="kn">import</span> <span class="n">SAGEConv</span>

<span class="k">class</span> <span class="nc">GraphSAGE</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_feats</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">GraphSAGE</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">SAGEConv</span><span class="p">(</span><span class="n">in_feats</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">,</span> <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">SAGEConv</span><span class="p">(</span><span class="n">h_feats</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">,</span> <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">in_feat</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">in_feat</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span></code></pre></figure>

<p></p>

<p></p>

<p>


<p>
<h4>Link Prediction: Dot Product and MLP</h4>

<p>
To predict whether two cities should be connected, we use link prediction methods that score the similarity between node embeddings.
</p>

<p>
<code>DotPredictor</code> uses a simple dot product to measure alignment between nodes, while <code>MLPPredictor</code> applies a small neural network to learn more flexible scoring patterns.
</p>

</p>
</p>

<p>

</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">dgl.function</span> <span class="k">as</span> <span class="n">fn</span>
<span class="k">class</span> <span class="nc">DotPredictor</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">g</span><span class="p">.</span><span class="nf">local_scope</span><span class="p">():</span>
            <span class="n">g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span>
            <span class="n">g</span><span class="p">.</span><span class="nf">apply_edges</span><span class="p">(</span><span class="n">fn</span><span class="p">.</span><span class="nf">u_dot_v</span><span class="p">(</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">g</span><span class="p">.</span><span class="n">edata</span><span class="p">[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="k">class</span> <span class="nc">MLPPredictor</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">W1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">h_feats</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">W2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">h_feats</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">apply_edges</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">edges</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">edges</span><span class="p">.</span><span class="n">src</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">],</span> <span class="n">edges</span><span class="p">.</span><span class="n">dst</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">]],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="nc">W2</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nc">W1</span><span class="p">(</span><span class="n">h</span><span class="p">))).</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)}</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">g</span><span class="p">.</span><span class="nf">local_scope</span><span class="p">():</span>
            <span class="n">g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span>
            <span class="n">g</span><span class="p">.</span><span class="nf">apply_edges</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">apply_edges</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">g</span><span class="p">.</span><span class="n">edata</span><span class="p">[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">]</span></code></pre></figure>

<p></p>

<p></p>
<h4>Model Setup and Evaluation</h4>

<p>
We define the full training pipeline using our GraphSAGE model and a predictor. You can easily switch between <code>DotPredictor</code> and <code>MLPPredictor</code> by updating one line.
</p>

<p>
The <code>compute_loss</code> function uses binary cross-entropy to learn from both positive and negative edges. We also use the AUC (Area Under the Curve) score to evaluate how well the model distinguishes between real and false edges.
</p>

<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="nc">GraphSAGE</span><span class="p">(</span><span class="n">train_g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="nc">DotPredictor</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">):</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">])</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">pos_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">neg_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])])</span>
    <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="nf">binary_cross_entropy_with_logits</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">compute_auc</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">):</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">]).</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span>
        <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">pos_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">neg_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]).</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="nf">roc_auc_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>
<h4>Training the Model</h4>

<p>
We optimize both the GraphSAGE encoder and the link predictor using the Adam optimizer. During each training epoch, the model generates node embeddings, computes scores for positive and negative edges, and updates its weights using binary cross-entropy loss.
</p>

<p>
The model is trained for 4000 epochs, with periodic logging of the training loss.
</p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">itertools</span><span class="p">.</span><span class="nf">chain</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">pred</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span> <span class="p">)</span>
<span class="n">all_logits</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4000</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">train_g</span><span class="p">,</span> <span class="n">train_g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">e</span> <span class="o">%</span> <span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">In epoch {}, loss: {}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span></code></pre></figure>

<p></p>
<p>Average raw vectors:</p>
<p></p>
<pre>
In epoch 0, loss: 204028.6875
In epoch 200, loss: 1625.9397
In epoch 400, loss: 558.7700
In epoch 600, loss: 291.7234
In epoch 800, loss: 179.5440
In epoch 1000, loss: 120.3145
In epoch 1200, loss: 84.1568
In epoch 1400, loss: 60.9932
In epoch 1600, loss: 44.9907
In epoch 1800, loss: 34.1410
In epoch 2000, loss: 26.5716
In epoch 2200, loss: 21.0573
In epoch 2400, loss: 16.8369
In epoch 2600, loss: 13.7170
In epoch 2800, loss: 11.2253
In epoch 3000, loss: 9.2902
In epoch 3200, loss: 7.8638
In epoch 3400, loss: 6.7238
In epoch 3600, loss: 5.7895
In epoch 3800, loss: 4.9161
</pre>
<p></p>
<p></p>
<p>City Graph embedded vectors:</p>
<p></p>
<pre>
In epoch   0, loss: 9616.3594
In epoch 200, loss:  306.7737
In epoch 400, loss:  121.4521
In epoch 600, loss:   62.3646
In epoch 800, loss:   35.9576
In epoch 1000, loss:  23.0823
In epoch 1200, loss:  16.0522
In epoch 1400, loss:  11.7496
In epoch 1600, loss:   8.9312
In epoch 1800, loss:   7.0417
In epoch 2000, loss:   5.7560
In epoch 2200, loss:   4.7962
In epoch 2400, loss:   4.0738
In epoch 2600, loss:   3.5095
In epoch 2800, loss:   3.0330
In epoch 3000, loss:   2.6442
In epoch 3200, loss:   2.3126
In epoch 3400, loss:   2.0293
In epoch 3600, loss:   1.7847
In epoch 3800, loss:   1.6135
</pre>

<p></p>
<p></p>

<h4>Evaluating the Model</h4>

<p>
To assess performance, we evaluated the trained link prediction model on a held-out test set using the
AUC (Area Under the ROC Curve) metric, which measures the model’s ability to distinguish between actual
and non-existent links — higher values indicate better predictive accuracy.
</p>

<p>The evaluation was performed using two types of node features:</p>

<ul>
  <li>Average daily temperature vectors: AUC 0.823015</li>
  <li>City graph embedded vectors: AUC 0.808995</li>
</ul>

<p>The AUC was computed using the following code:</p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">AUC</span><span class="sh">'</span><span class="p">,</span> <span class="nf">compute_auc</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">))</span></code></pre></figure>

<p></p>
<p></p>
<h4>Extracting Node Embeddings from GNN Link Prediction</h4>

<p>
Once the GNN Link Prediction model has been trained, we can extract the learned node embeddings — 128-dimensional vectors that capture both climate and geographic context. These embeddings represent how each city relates to its Voronoi-based neighbors in terms of temperature trends and spatial structure.
</p>

<p>
To make the embeddings easier to analyze and merge with other datasets, we convert them into a DataFrame format and assign each row its corresponding cityInd.
</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="n">h_numpy</span> <span class="o">=</span> <span class="n">h</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>  
<span class="n">embedding_table</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">h_numpy</span><span class="p">)</span>
<span class="n">embedding_table</span><span class="p">[</span><span class="sh">'</span><span class="s">cityInd</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">embedding_table</span><span class="p">.</span><span class="n">index</span>  </code></pre></figure>

<p></p>

<p></p>

<h2>Findings</h2>

<p></p>

<h3>Voronoi Graph Observations</h3>

<p></p>

<h4>The Biggest Triangle in the Voronoi Graph</h4>

<p>
This map shows the largest "triangle" formed by neighboring cities in our Voronoi graph.
</p>
<p></p>
<p><a href="#">
    <img src="/img/voronoi35.jpg" alt="Post Sample Image" width="876" />
</a></p>
<p></p>
<p>
<strong>Wellington, New Zealand</strong> is one corner of this triangle. Its two nearest neighbors aren’t even nearby — they’re across the ocean in <strong>Port Elizabeth, South Africa</strong> and <strong>Mar del Plata, Argentina</strong>.
</p>

<p>
This triangle highlights how the Voronoi graph connects cities based on available neighbors, not strict distance. In isolated parts of the world, cities can be far apart yet still linked — an effect that’s especially important when exploring global climate patterns.
</p>

<h4>How Cities Are Distributed in the Voronoi Graph</h4>

<p>
Through areas of Voronoi diagrams we can see how the world’s 1,000 most populated cities are distributed — and how that shapes our Voronoi graph. The map shows each city as a colored dot, where the color reflects how much space that city covers in the graph. This gives a picture of where cities are packed close together and where they’re more isolated.
<p></p>

</p>
<p></p>
<p><a href="#">
    <img src="/img/voronoi45.jpg" alt="Post Sample Image" width="876" />
</a></p>
<p></p>

<p></p>

<ul>
  <li><strong>Green = </strong>small cells (dense).</li>
  <li><strong>Yellow = </strong>medium.</li>
  <li><strong>Red = </strong>large (sparse).</li>
</ul>

<p>
</p>
<p>You can see on the map that countries with the highest population —India and China —have large green areas. In Europe it’s interesting to compare Germany and France: similar title population and similar territories, but population distribution by cities are very different.</p>
<p></p>

<p>Populated-city distribution may reflect geography and climate.</p>
<p></p>

<h3>Nearby vs. Distant Similarities</h3>

<p></p>
<p>The spatial Voronoi graph and the four types of vectors create many opportunities to explore climate patterns across cities. We can look for similarities, differences, clusters, or unexpected relationships. But including all these analyses in one blog post would make it too long and hard to follow.</p>
<p></p>
<p>In this post, we’ll share just a few simple examples to show what’s possible. More detailed results and additional patterns will be covered in separate posts.</p>
<p></p>

<p>The combination of the <strong>spatial Voronoi graph</strong> and the four types of vectors opens up many ways to explore global climate patterns. There’s an almost endless list of questions we can ask — from obvious ones like which cities have similar climate profiles, to more complex ideas like how geographic structure interacts with long-term climate change.</p>
<p></p>
<p></p>

<h4>Distant but similar: Wellington ↔ Mar del Plata (regime match) </h4>

<p></p>
<p>The tables below highlight two interesting groups of city pairs based on both their physical distance and climate similarity across different types of vectors.</p>

<p></p>
<p><a href="#">
    <img src="/img/voronoi43.jpg" alt="Post Sample Image" width="800" />
</a></p>

<p></p>
<p>Despite being thousands of kilometers apart, these cities show high climate similarity — especially when considering temporal patterns and spatial relationships together. This suggests that geographic distance alone doesn’t tell the full story when it comes to climate behavior.</p>
<p></p>
<h4>Nearby but different: New York ↔ Brooklyn (microclimate)</h4>
<p></p>
<p><a href="#">
    <img src="/img/voronoi44.jpg" alt="Post Sample Image" width="800" />
</a></p>

<p></p>
<p>In most cases, neighboring cities naturally share highly similar climates. But there are exceptions — like New York and Brooklyn, where spatial and combined similarity scores are unexpectedly low. This reflects how factors like microclimates, urban environments, or modeling limitations can produce unexpected results, even at small distances.</p>
<p></p>

<p></p>

<h3>New Graph Metrics: Closeness and Betweenness</h3>

<p>Throughout, climate similarity means cosine similarity between the indicated vectors; for path-based metrics we use edge weights 𝑤 = 1 − cosine. Each set of maps uses the same spatial backbone: edges come from the Voronoi graph, where two cities are adjacent if their cells share a border.</p>

<p></p>
<p>What changes across panels is the edge weight, derived from cosine similarity computed from one of four representations (Average, Temporal, Spatial, Spatial+Temporal), with vectors normalized prior to cosine. The topology stays fixed; the weights—and therefore any shortest- path–based measures—change with the chosen vectors. Smaller weights mean higher climate similarity.</p>
<p></p>

<p></p>
<h4>Closeness Centrality</h4>
<p></p>

<p></p>
<p><a href="#">
    <img src="/img/centrality_all.jpg" alt="Post Sample Image" width="800" />
</a></p>
<p></p>
<p>In the closeness centrality maps, cities with high closeness are, on average, at short weighted distance from many others—i.e., they are similar to many cities. Dense climate regions such as Europe and East Asia typically stand out. Differences between panels reveal how each representation defines “similar,” shifting which cities appear most central.</p>

<p></p>
<p></p>
<h4>Betweenness Centrality</h4>
<p></p>
<p></p>
<p><a href="#">
    <img src="/img/Betweenness_all.jpg" alt="Post Sample Image" width="800" />
</a></p>

<p></p>

<p>In the betweenness maps, different weightings emphasize different connectors: high-betweenness cities lie on many shortest routes. The Spatial+Temporal view surfaces more long- range intermediaries than Average (notably in Africa, South America, and the Pacific). We also observe slight polarization in Spatial and Spatial+Temporal; the reason for this requires further research.</p>

<p></p>

<h2>To Be Continued...</h2>

<p>
In future posts, we’ll dig deeper into the questions this approach opens up, like:
</p>

<ul>
  <li>How are cities clustered or isolated in the Voronoi graph — and how does that look across different parts of the world?</li>
  <li>How might those spatial patterns relate to climate stability or change?</li>
  <li>How do different types of vectors — from simple temperature averages to learned embeddings — reveal new climate connections?</li>
  <li>Where do geography and climate patterns align — and where do they tell different stories?</li>
</ul>

<p>
There’s a lot more to explore. These first examples are just a glimpse of how spatial graphs and climate data together can uncover hidden patterns.
</p>

<p></p>

<h3>Broader Impact</h3>

<p></p>
<ul>
  <li><strong>New perspective:</strong> Graph-based AI reveals hidden relationships across space and time — beyond what traditional text or image analyses capture.</li>
  <li><strong>Transferable method:</strong> The same fusion pipeline applies to cities, mobility, environmental systems, and public health.</li>
  <li><strong>Next steps — vectors:</strong> We showed only a few examples; many more applications and vector analyses remain to explore.</li>
  <li><strong>Next steps — healthcare:</strong> Extend the approach to disease-spread modeling and hospital-capacity planning.</li>
</ul>

<p></p>

<p></p>

<p></p>

<p></p>

<p></p>

<p></p>

<p></p>
<p></p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[Spatio-Temporal Graphs for Climate Patterns Here we combine time series graphs with a global spatial graph of cities to create a spatio-temporal view of climate. Decades of daily temperatures are turned into graph-based climate fingerprints for each city, then injected into a Voronoi-based world graph where neighboring regions share borders. A GNN refines this fused graph so we can see which distant cities behave almost identically, which nearby cities quietly diverge, and which “bridge cities” connect climate regions. The same method can be applied to any setting where signals evolve over time and are anchored in space—sensors, assets, patients, or networks.]]></summary></entry><entry><title type="html">Sliding Graph Neural Networks for EEG Analysis</title><link href="http://localhost:4000/2025/01/25/slidingWindowGraph-EEG/" rel="alternate" type="text/html" title="Sliding Graph Neural Networks for EEG Analysis" /><published>2025-01-25T07:00:00-05:00</published><updated>2025-01-25T07:00:00-05:00</updated><id>http://localhost:4000/2025/01/25/slidingWindowGraph%20EEG</id><content type="html" xml:base="http://localhost:4000/2025/01/25/slidingWindowGraph-EEG/"><![CDATA[<h2>Sliding Graphs: Watching Signals Change Like a Movie</h2>
<p>
  Sliding graphs are a way to let AI watch how a signal behaves over time, not just look at a
  summary. Instead of treating a long recording as one big block, we break it into many small,
  overlapping moments and let AI see which moments look alike and which don’t. Put together, these
  moments form an evolving map of the signal, showing when things are calm, when they shift, and
  when something unusual starts to happen. We illustrate this with EEG sleep vs rest, but the same
  idea works for machines, sensors, markets, climate, or any long signal—anywhere you want AI to
  say not only what is happening, but when things start to change.
</p>

<p></p>
<h2>Conference</h2>
<p>
  The work <em>“Time Aligned Sliding Graph Embeddings for Dynamic Time Series Analysis”</em>
  was presented at <strong>Brain Informatics 2025</strong> in Bari, Italy, on
  <strong>11 November 2025</strong>. The corresponding paper is not yet published
  in archival proceedings.
</p>

<p></p>

<p></p>
<h2>Exploring EEG Through Graph-Based Methods</h2>
<p></p>
<p>Over the years, we are looking to uncover the secrets of brain connectivity using EEG data.
Our work has evolved from traditional graph analysis techniques to cutting-edge Graph Neural Networks (GNNs),
each step uncovering deeper insights into neural dynamics. Let’s take a closer look at these studies.</p>

<p></p>
<p><h4>Study 1: Traditional Graph Analysis</h4></p>
<p></p>
<p>Our journey began with a traditional graph analysis approach. In this study, we constructed connectivity graphs from EEG trials using
<strong>cosine similarity</strong> between channels. Each graph’s nodes represented EEG electrodes, and the edges reflected their functional connectivity.</p>
<p></p>
<p>Key Findings:</p>
<ul>
    <li>Differences in connectivity patterns emerged between the <strong>Alcoholic</strong> and <strong>Control</strong> groups, providing insights into altered neural activity.</li>
    <li>Graph features like clustering coefficients and edge density helped highlight these differences.</li>
    <li>However, traditional methods struggled to distinguish subtle variations, particularly in <strong>single-stimulus conditions</strong>, prompting the need for more advanced techniques.</li>
</ul>
<figure>
    <img src="/img/dataSource5.jpg" alt="Traditional EEG Graph Example" style="width:75%; margin:auto;" />
    <figcaption>Figure 1: A sample connectivity graph constructed from EEG data using cosine similarity.</figcaption>
</figure>
<p></p>
<p>For a deeper dive into this work, check out our post <a href="http://sparklingdataocean.com/2020/08/19/brainGraphEeg/">“EEG Patterns by Deep Learning and Graph Mining”</a> or refer to the paper <a href="https://link.springer.com/chapter/10.1007/978-3-030-87101-7_19">Time Series Pattern Discovery by Deep Learning and Graph Mining</a>.</p>

<p></p>

<p></p>
<h4>Study 2: Graph Neural Networks for Trial Classification</h4>
<p></p>
<p>On the second study, we introduced <strong>Graph Neural Networks (GNNs)</strong> to analyze EEG data at the trial level. Each graph represented an entire EEG trial, encapsulating the connectivity across all channels.</p>
<p></p>
<p>Why GNNs? GNNs brought a new level of sophistication by enabling the model to learn spatial relationships and connectivity dynamics within the graph.</p>
<p></p>
<p>Key Findings:</p>
<ul>
    <li><strong>Improved Classification Accuracy:</strong> GNN Graph Classification models significantly outperformed traditional methods in differentiating between Alcoholic and Control groups.</li>
    <li><strong>Enhanced Connectivity Insights:</strong> Subtle variations in connectivity, previously missed, were captured.</li>
    <li><strong>Challenges:</strong> Misclassifications within the Control group highlighted the complexity of EEG connectivity patterns.</li>
</ul>

<p></p>

<p></p>
<p>This approach is detailed further in our post <a href="http://sparklingdataocean.com/2023/05/08/classGraphEeg/">“GNN Graph Classification for EEG Pattern Analysis”</a> or refer to the paper <a href="https://www.springerprofessional.de/en/enhancing-time-series-analysis-with-gnn-graph-classification-mod/26751028">Enhancing Time Series Analysis with GNN Graph Classification Models</a>.</p>

<p></p>

<h4>Study 3: Graph Neural Networks for Link Prediction</h4>
<p></p>
<p>In our third study, the focus shifted to <strong>link prediction</strong>, using GNNs to analyze node- and edge-level connectivity. A unified graph constructed from EEG electrode distances was used to predict connectivity dynamics.</p>
<p></p>
<p>Key Findings:</p>
<ul>
    <li><strong>Revealing Hidden Connectivity:</strong> GNN Link Prediction models highlighted relationships between electrodes that were previously unobserved.</li>
    <li><strong>Node Importance:</strong> Certain electrodes emerged as more central to connectivity patterns.</li>
    <li><strong>Limitations:</strong> This method focused primarily on short-term EEG segments, leaving the dynamics of long-term recordings unexplored.</li>
</ul>

<p></p>
<p>For more on this work, check out our <a href="http://sparklingdataocean.com/2024/11/09/GNN_timeSeries_EEG/">“Graph Neural Networks for EEG Connectivity Analysis”<a href="#"></a> or refer to the paper <a href="https://iwain.lucentia.es/proceedings/">Graph Neural Networks in Action: Uncovering Patterns in EEG Time Series Data.  1st International Workshop on Artificial Intelligence for Neuroscience (IWAIN’24), pp. 4–15</a>.</a></p>
<p></p>
<p></p>
<figure>
    <img src="/img/brain4.jpg" alt="Traditional EEG Graph Example" style="width:75%; margin:auto;" />
    <figcaption>Figure 2: A sample connectivity graph constructed from EEG data using cosine similarity.</figcaption>
</figure>

<p></p>
<h2>Looking Ahead: Current Study</h2>
<p></p>

<p>This study applies GNN Sliding Graph Classification to long-time EEG series, capturing evolving neural activity during sleep and rest. This approach reveals extended brain states, uncovering transitions and sustained neural processes, offering deeper insights into EEG dynamics over time.</p>
<p></p>
<p>Imagine moving a sliding window through EEG data—like watching a movie, scene by scene. Each window captures a brief moment in time. Now imagine building a graph that doesn’t just follow the timeline, but connects moments that belong to the same theme—even if they’re far apart. Like linking “research” and “presentation” as part of the same goal. That graph becomes a story—showing how different moments are connected by meaning, not just time.</p>
<p></p>
<figure>
    <img src="/img/brain41.jpg" alt="Traditional EEG Graph Example" style="width:99%; margin:auto;" />
    <figcaption>Slide from demo on conference Brain Informatics (BI 2025) in Bari, Italy.</figcaption>
</figure>
<p></p>

<p></p>

<p></p>

<h2>GNN Sliding Graph Classification: Introduction</h2>

<p></p>

<p>In our previous work, we introduced two key methods for time series analysis. The methodology consists of three key steps:</p>

<ul>
  <li>
    <strong>Sliding Graph Construction:</strong> Transform time series data into graph structures by segmenting it into overlapping windows. Each graph captures localized temporal and spatial relationships, representing distinct patterns over the chosen time frame.
  </li>
  <li>
    <strong>GNN Graph Classification:</strong> Utilize GNNs to classify these graphs, extracting high-level features from their topology while preserving the structural and temporal dependencies in the data.
  </li>
  <li>
    <strong>Pre-final Vectors:</strong> Obtain graph embeddings (pre-final vectors) from the GNN Graph Classification model during classification. These embeddings represent the learned topological features and are further analyzed to reveal temporal and structural patterns in the time series.
  </li>
</ul>

<p></p>

<p>Both methods were successfully applied to <em>climate time series data</em>, revealing complex patterns in large-scale datasets. However, these techniques have never been combined in a single study.</p>

<p></p>

<p>In this study, we integrate these approaches and apply them to <strong>EEG time series data</strong>, specifically in the context of <em>sleep studies</em>. EEG analysis presents unique challenges, requiring methods that can detect both <em>long-term trends</em> and <em>local brain connectivity changes</em>. By leveraging <strong>sliding graph construction</strong> and <strong>pre-final vector extraction</strong>, we aim to uncover <em>hidden EEG patterns</em> that traditional signal processing techniques might miss.</p>
<p></p>
<p>Objectives of This Study</p>
<p></p>
<ul>
    <li>Demonstrate the effectiveness of <strong>graph-based models</strong> for long-duration biomedical signal analysis.</li>
    <li>Validate the generalizability of <strong>GNN Sliding Graph Classification</strong> and <strong>Pre-Final Vectors</strong> beyond climate data, applying them to neuroscience.</li>
</ul>

<p>This approach bridges sliding window techniques and graph-based modeling, providing a powerful framework for analyzing complex temporal EEG data. By capturing both localized and global topological patterns, it enhances our understanding of brain activity dynamics during sleep.</p>

<p></p>
<p>For more detailed information about GNN Sliding Graphs, look at our post <a href="http://sparklingdataocean.com/2024/05/25/slidingWindowGraph/">“Sliding Window Graph in GNN Graph Classification”</a> or refer to the paper <a href="https://dl.acm.org/doi/10.1145/3674029.3674059">GNN Graph Classification for Time Series: A New Perspective on Climate Change Analysis</a>.</p>

<p></p>

<p>For information about catching embedded graphs, look at our post <a href="http://sparklingdataocean.com/2024/07/04/vectorsGNN/">“Unlocking the Power of Pre-Final Vectors in GNN Graph Classification”</a> or refer to the paper <a href="https://mlg-europe.github.io/2024/">Utilizing Pre-Final Vectors from GNN Graph Classification for Enhanced Climate Analysis</a>.</p>

<p></p>

<h2>Methods</h2>
<p></p>
<h3>Pipeline</h3>
<p></p>
<p><a href="#">
      <img src="/img/slide1b.jpg" alt="Post Sample Image" width="808" />
</a></p>
<p></p>
<p>Our pipeline for <strong>Graph Neural Network (GNN) Graph Classification</strong> consists of several stages.</p>
<ul>

    <li>The process begins with <strong>data input</strong>, where EEG data representing brain activity during sleep and rest states is collected.</li>
    <li><strong>Graph construction:</strong>
        <ul>
            <li><strong>Sliding window method:</strong> Segments time series data into overlapping graphs to maintain temporal structure.</li>
            <li><strong>Virtual nodes:</strong> Act as central hubs, improving model accuracy and information flow.</li>
        </ul>
    </li>
    <li>The <strong>GNN model</strong> classifies these graphs based on detected patterns.</li>
    <li>To enhance interpretability, <strong>pre-final vectors</strong> are extracted from the model, capturing deeper structural information before classification.</li>
    <li><strong>Linear algebra analysis</strong> applies cosine similarity computations to these embeddings, uncovering connectivity trends over time.</li>
    <li>This approach enables effective modeling of long-duration EEG dynamics by integrating graph-based learning with temporal analysis techniques.</li>
</ul>

<p></p>
<p></p>

<p></p>
<p></p>

<p></p>

<h3>Sliding Graph Construction</h3>
<p></p>

<p>In our previous study, <a href="https://dl.acm.org/doi/10.1145/3674029.3674059">GNN Graph Classification for Time Series: A New Perspective on Climate Change Analysis</a>, we introduced an approach to constructing graphs using the
<em>Sliding Window Method</em>.</p>

<p></p>
<p><a href="#">
      <img src="/img/slide3.jpg" alt="Post Sample Image" width="600" />
</a></p>
<p></p>
<p></p>
<h4>Sliding Window Method</h4>
<ul>
    <li>
      <strong>Nodes</strong>: Represent data points within each sliding window, with features reflecting their respective values.
    </li>
    <li>
      <strong>Edges</strong>: Connect pairs of points to preserve the temporal sequence and structure.
    </li>
    <li>
      <strong>Labels</strong>: Assigned to detect and analyze patterns within the time series.
    </li>
  </ul>
<p></p>

<h3>Methodology for Sliding Window Graph Construction</h3>
<p></p>
<h4>Data to Graph Transformation</h4>
<p></p>
<p>Time series data is segmented into overlapping windows using the sliding
window technique. Each segment forms a unique graph, allowing for the analysis of local temporal dynamics.</p>
<p></p>
<p>In these graphs:</p>

<ul>
    <li>
      <strong>Nodes</strong>: Represent data points within the window, with features derived from their values.
    </li>
    <li>
      <strong>Edges</strong>: Connect pairs of nodes to maintain temporal relationships.
    </li>
  </ul>
<p></p>
<p>Key Parameters:</p>
<ul>
    <li>
      <strong>Window Size (W)</strong>: Determines the size of each segment.
    </li>
    <li>
      <strong>Shift Size (S)</strong>: Defines the degree of overlap between windows.
    </li>
    <li>
      <strong>Edge Definitions</strong>: Tailored to the specific characteristics of the time series, helping detect meaningful
      patterns.
    </li>
  </ul>

<p></p>
<p></p>
<h4>Node Calculation</h4>
<p></p>
<p>For a dataset with N data points, we apply a sliding window of size W with a shift of S to create nodes. The number of nodes, N<sub>nodes</sub>, is calculated as:
    <math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
            <msub>
                <mi>N</mi>
                <mi>nodes</mi>
            </msub>
            <mo>=</mo>
            <mrow>
                <mo>&lfloor;</mo>
                <mfrac>
                    <mrow>
                        <mi>N</mi>
                        <mo>-</mo>
                        <mi>W</mi>
                    </mrow>
                    <mi>S</mi>
                </mfrac>
                <mo>&rfloor;</mo>
            </mrow>
            <mo>+</mo>
            <mn>1</mn>
        </mrow>
    </math></p>
<p></p>
<p></p>
<p></p>

<p></p>
<h4>Graph Calculation</h4>
<p></p>
<p>With the nodes determined, we construct graphs, each comprising G nodes, with a shift of S<sub>g</sub> between successive graphs. The number of graphs, N<sub>graphs</sub>, is calculated by:
    <math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
            <msub>
                <mi>N</mi>
                <mi>graphs</mi>
            </msub>
            <mo>=</mo>
            <mrow>
                <mo>&lfloor;</mo>
                <mfrac>
                    <mrow>
                        <msub>
                            <mi>N</mi>
                            <mi>nodes</mi>
                        </msub>
                        <mo>-</mo>
                        <mi>G</mi>
                    </mrow>
                    <msub>
                        <mi>S</mi>
                        <mi>g</mi>
                    </msub>
                </mfrac>
                <mo>&rfloor;</mo>
            </mrow>
            <mo>+</mo>
            <mn>1</mn>
        </mrow>
    </math></p>
<p></p>
<p></p>
<h4>Graph Construction</h4>
<p></p>
<p>Cosine similarity matrices are generated from the time series data and transformed into graph adjacency matrices.</p>
<p></p>
<ul>
    <li>
      <strong>Edge Creation</strong>: Edges are established for vector pairs with cosine values above a defined threshold.
    </li>
    <li>
      <strong>Virtual Nodes</strong>: Added to ensure network connectivity, enhancing graph representation.
    </li>
  </ul>
<p></p>

<p></p>
<p></p>
<p>This framework effectively captures both local and global patterns within the time series, yielding valuable insights into temporal dynamics.</p>
<p></p>

<p></p>
<h4>Graph Classification</h4>
<p></p>
<p>We employ the <em>GCNConv</em> model from the PyTorch Geometric Library for GNN Graph Classification tasks. This model performs convolutional operations, leveraging edges, node attributes, and graph labels to extract features and analyze graph structures comprehensively.</p>
<p></p>
<p>By combining the sliding window technique with Graph Neural Networks, our approach offers a robust framework for analyzing time series data. It captures intricate temporal dynamics and provides actionable insights into both local and global patterns, making it particularly well-suited for applications such as EEG data analysis. This method allows us to analyze time series data effectively by capturing both local and global patterns, providing valuable insights into temporal dynamics.</p>
<p></p>

<h3>Pairwise GNN Sliding Graph Classification</h3>
<p></p>
<p><a href="#">
      <img src="/img/slide2b.jpg" alt="Post Sample Image" width="717" />
</a></p>
<p></p>

<p>This figure illustrates the process of pairwise GNN Sliding Graph Classification, where pairs of long time series are analyzed using graph-based methods to capture dynamic connectivity patterns. Channels F3-F4 during sleep are used as an illustrative example. Below is a breakdown of the methodology:</p>
<p></p>
<ul>
      <li><strong>Input Time Series as Pairs:</strong> Two long time series (e.g., Sleep F3 and Sleep F4) are taken as input, each representing continuous data points over time.</li>
      <li><strong>Sliding Graph Construction:</strong> Each time series is segmented into overlapping windows, and graphs are created from these segments. These graphs are labeled according to their respective time series (e.g., F3 and F4).</li>
      <li><strong>GNN Graph Classification:</strong> The sliding graphs are processed by a GNN Graph Classification model. The model learns pairwise relationships between the graph labels, capturing interactions between the time series.</li>
      <li><strong>Pre-Final Vector Extraction:</strong> The GNN generates pre-final vectors (graph embeddings) for each segment. These embeddings are aligned with the time points of the original time series.</li>
      <li><strong>Cosine Similarity Computation:</strong> For each pair of embeddings at corresponding time points, cosine similarity is calculated to measure the relationship between the time series.</li>
      <li><strong>Temporal Analysis of Similarities:</strong> The cosine similarity values are plotted over time, revealing how the connectivity between the time series evolves dynamically.</li>
  </ul>
<p>
  This approach bridges time series analysis and graph theory, offering a robust method to study pairwise relationships in applications like EEG connectivity or multi-channel sensor data.
  </p>

<p></p>

<p></p>
<h2>Experiments Overview</h2>
<p></p>
<h3>Data Source: EEG Data</h3>
<p></p>
<p>For this study, we utilized EEG data from the
<i><a href="https://github.com/OpenNeuroDatasets/ds003768/tree/master/sub-01/eeg" target="_blank">OpenNeuroDatasets</a></i>.</p>
<p></p>
<p>This dataset includes EEG data collected from 33 healthy participants using a 32-channel MR-compatible EEG system (Brain Products, Munich, Germany). The EEG data were recorded during two 10-minute resting-state sessions (before and after a visual-motor adaptation task) and multiple 15-minute sleep sessions.</p>
<p></p>
<p>For our analysis, we specifically focused on data from one resting-state session and one sleep session, using the raw EEG data for processing and comparative analysis of activity patterns during rest and sleep states.</p>

<p></p>

<p>We used the <code>mne</code> Python library to process EEG data. The dataset includes recordings in the BrainVision format, which were preloaded for analysis. Below is the Python code used for this preprocessing step:</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">mne</span>
<span class="kn">import</span> <span class="n">mne</span>
<span class="n">vhdr_file_path1</span> <span class="o">=</span> <span class="n">filePath</span><span class="o">+</span><span class="sh">'</span><span class="s">sub-01_task-rest_run-1_eeg.vhdr</span><span class="sh">'</span>
<span class="n">vhdr_file_path2</span> <span class="o">=</span> <span class="n">filePath</span><span class="o">+</span><span class="sh">'</span><span class="s">sub-01_task-sleep_run-3_eeg.vhdr</span><span class="sh">'</span>
<span class="n">raw1</span> <span class="o">=</span> <span class="n">mne</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="nf">read_raw_brainvision</span><span class="p">(</span><span class="n">vhdr_file_path1</span><span class="p">,</span> <span class="n">preload</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">raw2</span> <span class="o">=</span> <span class="n">mne</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="nf">read_raw_brainvision</span><span class="p">(</span><span class="n">vhdr_file_path2</span><span class="p">,</span> <span class="n">preload</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>
<p>We specifically extracted EEG data from one resting-state session (<code>sub-01_task-rest_run-1_eeg.vhdr</code>) and one sleep session (<code>sub-01_task-sleep_run-3_eeg.vhdr</code>), which were recorded using a 32-channel MR-compatible EEG system (Brain Products, Munich, Germany). These raw EEG signals were prepared for further analysis and sliding graph construction.</p>

<p></p>
<p>After loading the EEG data, we transformed the raw signals into structured pandas DataFrames for ease of analysis. The following code snippet demonstrates this step:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">eeg_data1</span><span class="p">,</span> <span class="n">times1</span> <span class="o">=</span> <span class="n">raw1</span><span class="p">.</span><span class="nf">get_data</span><span class="p">(</span><span class="n">return_times</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">eeg_df1</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">eeg_data1</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">channel_names1</span><span class="p">)</span>
<span class="n">eeg_df1</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">times1</span>
<span class="n">eeg_data2</span><span class="p">,</span> <span class="n">times2</span> <span class="o">=</span> <span class="n">raw2</span><span class="p">.</span><span class="nf">get_data</span><span class="p">(</span><span class="n">return_times</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">eeg_df2</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">eeg_data2</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">channel_names1</span><span class="p">)</span>
<span class="n">eeg_df2</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">times2</span>
<span class="n">eeg_df1</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span><span class="n">eeg_df2</span><span class="p">.</span><span class="n">shape</span>
<span class="p">((</span><span class="mi">4042800</span><span class="p">,</span> <span class="mi">33</span><span class="p">),</span> <span class="p">(</span><span class="mi">4632500</span><span class="p">,</span> <span class="mi">33</span><span class="p">))</span></code></pre></figure>

<p></p>

<p>The EEG signals from both the rest and sleep sessions were converted into DataFrames. Each DataFrame contains 32 EEG channels and a corresponding <code>Time</code> column, enabling a clear representation of time series data for further processing. The shapes of the resulting DataFrames are as follows:
  &lt;/p&gt;</p>
<ul>
    <li><strong>Rest session:</strong> 4,042,800 rows × 33 columns</li>
    <li><strong>Sleep session:</strong> 4,632,500 rows × 33 columns</li>
  </ul>

<p>This structured format facilitates segmentation, feature extraction, and the eventual construction of sliding graphs.</p>

<p></p>

<p>Given the large size of the EEG datasets, we applied downsampling to reduce the number of rows while retaining the temporal structure of the signals. Specifically, every 20th row from each DataFrame was selected, effectively reducing the data size by a factor of 20.</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">eeg_df1</span> <span class="o">=</span> <span class="n">eeg_df1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[::</span><span class="mi">20</span><span class="p">,</span> <span class="p">:].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">eeg_df2</span> <span class="o">=</span> <span class="n">eeg_df2</span><span class="p">.</span><span class="n">iloc</span><span class="p">[::</span><span class="mi">20</span><span class="p">,</span> <span class="p">:].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">eeg_df1</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">eeg_df2</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="p">(</span><span class="mi">202140</span><span class="p">,</span> <span class="mi">33</span><span class="p">)</span> <span class="p">(</span><span class="mi">231625</span><span class="p">,</span> <span class="mi">33</span><span class="p">)</span></code></pre></figure>

<p></p>

<ul>
    <li><strong>Rest session:</strong> 202,140 rows × 33 columns</li>
    <li><strong>Sleep session:</strong> 231,625 rows × 33 columns</li>
  </ul>
<p>
This step significantly reduced the computational overhead for subsequent processing steps while preserving meaningful patterns in the data.
<p></p>

To ensure compatibility during analysis, both EEG DataFrames were truncated to have the same number of rows. This step is essential to facilitate pairwise comparisons and maintain consistency across the datasets.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="n">min_rows</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">eeg_df1</span><span class="p">),</span> <span class="nf">len</span><span class="p">(</span><span class="n">eeg_df2</span><span class="p">))</span>
<span class="n">eeg1df</span> <span class="o">=</span> <span class="n">eeg_df1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">min_rows</span><span class="p">]</span>
<span class="n">eeg2df</span> <span class="o">=</span> <span class="n">eeg_df2</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">min_rows</span><span class="p">]</span>
<span class="n">eeg1df</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span><span class="n">eeg2df</span><span class="p">.</span><span class="n">shape</span>
<span class="p">((</span><span class="mi">202140</span><span class="p">,</span> <span class="mi">33</span><span class="p">),</span> <span class="p">(</span><span class="mi">202140</span><span class="p">,</span> <span class="mi">33</span><span class="p">))</span></code></pre></figure>

<p></p>

After truncation, both DataFrames contain:

<ul>
  <li><strong>Row count:</strong> 202,140</li>
  <li><strong>Column count:</strong> 33 EEG channels</li>
</ul>
<p></p>
This ensures that subsequent operations, such as similarity calculations or graph-based analysis, can be performed without inconsistencies in data alignment.

<p></p>

To prepare the EEG data for analysis, numerical columns were normalized to ensure consistent scaling across features. The 'Time' column was excluded during normalization and re-added afterward. This step helps improve the performance of subsequent analytical methods by standardizing the data.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">eeg1_features</span> <span class="o">=</span> <span class="n">eeg1df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">])</span>
<span class="n">eeg2_features</span> <span class="o">=</span> <span class="n">eeg2df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">])</span>
<span class="n">eeg1</span> <span class="o">=</span> <span class="p">(</span><span class="n">eeg1_features</span> <span class="o">-</span> <span class="n">eeg1_features</span><span class="p">.</span><span class="nf">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">eeg1_features</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">)</span>
<span class="n">eeg2</span> <span class="o">=</span> <span class="p">(</span><span class="n">eeg2_features</span> <span class="o">-</span> <span class="n">eeg2_features</span><span class="p">.</span><span class="nf">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">eeg2_features</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">)</span>
<span class="n">eeg1</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">eeg1df</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span>
<span class="n">eeg2</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">eeg2df</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span></code></pre></figure>

<p></p>

To enhance data tracking and processing, the 'Time' column was renamed, formatted as a string, and additional metadata columns were added:

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">eeg1</span><span class="o">=</span><span class="n">eeg1</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">})</span>
<span class="n">eeg2</span><span class="o">=</span><span class="n">eeg2</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">})</span>
<span class="n">eeg1</span><span class="p">[</span><span class="sh">'</span><span class="s">dateStr</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>  <span class="sh">'</span><span class="s">~</span><span class="sh">'</span> <span class="o">+</span> <span class="n">eeg1</span><span class="p">[</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">eeg2</span><span class="p">[</span><span class="sh">'</span><span class="s">dateStr</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>  <span class="sh">'</span><span class="s">~</span><span class="sh">'</span> <span class="o">+</span> <span class="n">eeg2</span><span class="p">[</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">eeg1</span><span class="p">[</span><span class="sh">'</span><span class="s">rowIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">eeg1</span><span class="p">))</span>
<span class="n">eeg2</span><span class="p">[</span><span class="sh">'</span><span class="s">rowIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">eeg2</span><span class="p">))</span></code></pre></figure>

<p></p>

These steps ensure that the data is not only normalized but also organized with clear metadata, facilitating downstream analysis and visualization tasks.



<p></p>
<h3>Raw Data Analysis</h3>
<p></p>
This step of data analysis focuses on comparing the cosine similarity between EEG channels during sleep and rest states. The top bar chart visualizes the channel-wise differences, highlighting which brain regions exhibit notable variations in activity patterns. The bottom chart aggregates these comparisons region-wise (e.g., Central, Occipital, Temporal), providing a high-level view of how different brain regions behave in sleep versus rest.
<p></p>
<a href="#">
    <img src="/img/eegSlide1.jpg" alt="Post Sample Image" width="678" />
</a>
<p></p>
<p></p>
<a href="#">
    <img src="/img/eegSlide2.jpg" alt="Post Sample Image" width="600" />
</a>
<p></p>
Since time measures in separate sections do not overlap, this comparison offers a broad overview, serving as a basis for more detailed studies on individual sessions.

<p></p>
<h4>Normalization and Preprocessing</h4>
<p></p>
In this step, we normalized the EEG data to ensure consistency across different sessions and reduce the impact of varying scales. The following processes were carried out:

<ul>
  <li>
    <strong>Numerical Column Selection:</strong>
    Excluded the 'Time' column to focus only on the numerical EEG data for normalization.
  </li>
  <li>
    <strong>Data Normalization:</strong>
    Each feature was normalized using z-score normalization:
    <br />
    <code>Normalized Value = (Value - Mean) / (Standard Deviation + 1e-5)</code>
    <br />
    This ensures the data has a mean of 0 and a standard deviation of 1, improving the stability of subsequent analyses.
  </li>
  <li>
    <strong>Reintegrating the Time Column:</strong>
    The 'Time' column was added back to the normalized dataset and renamed to <code>date</code> for easier readability and alignment with temporal analyses.
  </li>
  <li>
    <strong>String Representation for Dates:</strong>
    Created a <code>dateStr</code> column by prefixing the time values with a tilde (<code>~</code>), providing a textual representation of the timestamps.
  </li>
  <li>
    <strong>Index Assignment:</strong>
    Added a <code>rowIndex</code> column to assign a unique index to each row for tracking during further analysis.
  </li>
</ul>
<p></p>
This normalization step prepared the data for sliding window segmentation and graph construction, ensuring consistency and improving the robustness of the subsequent analyses.


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">eeg1_features</span> <span class="o">=</span> <span class="n">eeg1df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">])</span>
<span class="n">eeg2_features</span> <span class="o">=</span> <span class="n">eeg2df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">])</span>
<span class="n">eeg1</span> <span class="o">=</span> <span class="p">(</span><span class="n">eeg1_features</span> <span class="o">-</span> <span class="n">eeg1_features</span><span class="p">.</span><span class="nf">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">eeg1_features</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">)</span>
<span class="n">eeg2</span> <span class="o">=</span> <span class="p">(</span><span class="n">eeg2_features</span> <span class="o">-</span> <span class="n">eeg2_features</span><span class="p">.</span><span class="nf">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">eeg2_features</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">)</span>
<span class="n">eeg1</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">eeg1df</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span>
<span class="n">eeg2</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">eeg2df</span><span class="p">[</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">]</span>
<span class="n">eeg1</span><span class="o">=</span><span class="n">eeg1</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">})</span>
<span class="n">eeg2</span><span class="o">=</span><span class="n">eeg2</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">Time</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">})</span>
<span class="n">eeg1</span><span class="p">[</span><span class="sh">'</span><span class="s">dateStr</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>  <span class="sh">'</span><span class="s">~</span><span class="sh">'</span> <span class="o">+</span> <span class="n">eeg1</span><span class="p">[</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">eeg2</span><span class="p">[</span><span class="sh">'</span><span class="s">dateStr</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>  <span class="sh">'</span><span class="s">~</span><span class="sh">'</span> <span class="o">+</span> <span class="n">eeg2</span><span class="p">[</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">eeg1</span><span class="p">[</span><span class="sh">'</span><span class="s">rowIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">eeg1</span><span class="p">))</span>
<span class="n">eeg2</span><span class="p">[</span><span class="sh">'</span><span class="s">rowIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">eeg2</span><span class="p">))</span></code></pre></figure>

<p></p>

<h4>Channel Grouping by Brain Regions</h4>
<p></p>
To organize the EEG channels for our study, we grouped them based on their prefixes. This grouping helps us focus on specific brain regions for analysis and simplifies the selection process. Below are the steps and results of this process:
<p></p>
<ul>
  <li>
    <strong>Grouping Channels:</strong>
    Each EEG channel was categorized by its prefix, which corresponds to the brain region it represents. Channels ending with <code>'z'</code> were treated as central and grouped by removing the trailing <code>'z'</code>. For all other channels, their alphabetical prefix was used for grouping.
  </li>
  <li>
    <strong>Code Implementation:</strong>
    The grouping was performed programmatically using a dictionary structure where the keys represent brain region prefixes, and the values contain the corresponding EEG channels.
  </li>
</ul>
<p></p>
Below is the Python implementation used for channel grouping:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="n">channel_groups</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="k">for</span> <span class="n">channel</span> <span class="ow">in</span> <span class="n">eeg1</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">channel</span><span class="p">.</span><span class="nf">endswith</span><span class="p">(</span><span class="sh">'</span><span class="s">z</span><span class="sh">'</span><span class="p">):</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="n">channel</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="sh">''</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="n">char</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">channel</span> <span class="k">if</span> <span class="n">char</span><span class="p">.</span><span class="nf">isalpha</span><span class="p">()])</span>
    <span class="n">channel_groups</span><span class="p">[</span><span class="n">prefix</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">channel</span><span class="p">)</span>
<span class="k">for</span> <span class="n">group</span><span class="p">,</span> <span class="n">channels</span> <span class="ow">in</span> <span class="n">channel_groups</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">group</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">channels</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span></code></pre></figure>

<p></p>

<h4>Grouped Channels</h4>
<p></p>
The resulting channel groups are as follows:
<ul>
  <li><strong>Fp:</strong> ['Fp1', 'Fp2']</li>
  <li><strong>F:</strong> ['F3', 'F4', 'F7', 'F8', 'Fz']</li>
  <li><strong>C:</strong> ['C3', 'C4', 'Cz']</li>
  <li><strong>P:</strong> ['P3', 'P4', 'P7', 'P8', 'Pz']</li>
  <li><strong>O:</strong> ['O1', 'O2', 'Oz']</li>
  <li><strong>T:</strong> ['T7', 'T8']</li>
  <li><strong>FC:</strong> ['FC1', 'FC2', 'FC5', 'FC6']</li>
  <li><strong>CP:</strong> ['CP1', 'CP2', 'CP5', 'CP6']</li>
  <li><strong>TP:</strong> ['TP9', 'TP10']</li>
  <li><strong>EOG:</strong> ['EOG']</li>
  <li><strong>ECG:</strong> ['ECG']</li>
  <li><strong>Time:</strong> ['Time']</li>
</ul>
<p></p>
These groups will guide our selection of brain regions and EEG channels for further analysis in the study.

<p></p>

<h3>Computing Cosine Similarities Within EEG Channel Groups</h3>
<p></p>
As part of our EEG analysis, we calculated cosine similarities between channel pairs within the same group. This step focuses on understanding relationships between channels in specific brain regions. Below are the details of the process and implementation:
<p></p>
<h4>Steps in Analysis</h4>
<p></p>
<ol>
  <li><strong>Channel Grouping:</strong> EEG channels were grouped based on their prefixes, corresponding to specific brain regions. Channels ending with <code>'z'</code> were adjusted by removing the trailing <code>'z'</code>, and other channels were grouped by their letter prefixes.</li>
  <li><strong>Sorting Channels:</strong> Channels within each group were sorted alphabetically to ensure consistent pairwise comparisons.</li>
  <li><strong>Cosine Similarity Calculation:</strong> Cosine similarities were computed for all possible pairs within each group using their numerical feature vectors.</li>
  <li><strong>Sorting Results:</strong> The cosine similarity pairs were sorted alphabetically for easy interpretation and analysis.</li>
</ol>
<p></p>
The following Python code was used to perform the analysis:

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="n">channel_groups</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="k">for</span> <span class="n">channel</span> <span class="ow">in</span> <span class="n">eeg_df1_truncated</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">channel</span><span class="p">.</span><span class="nf">endswith</span><span class="p">(</span><span class="sh">'</span><span class="s">z</span><span class="sh">'</span><span class="p">):</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="n">channel</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="sh">''</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="n">char</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">channel</span> <span class="k">if</span> <span class="n">char</span><span class="p">.</span><span class="nf">isalpha</span><span class="p">()])</span>
    <span class="n">channel_groups</span><span class="p">[</span><span class="n">prefix</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">channel</span><span class="p">)</span>
<span class="n">cosine_similarities</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">group</span><span class="p">,</span> <span class="n">channels</span> <span class="ow">in</span> <span class="n">channel_groups</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
    <span class="n">channels</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">channels</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">channel1</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">channels</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">channel2</span> <span class="ow">in</span> <span class="n">channels</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]:</span>
            <span class="n">vector1</span> <span class="o">=</span> <span class="n">eeg_df1_truncated</span><span class="p">[</span><span class="n">channel1</span><span class="p">].</span><span class="nf">to_numpy</span><span class="p">().</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">vector2</span> <span class="o">=</span> <span class="n">eeg_df1_truncated</span><span class="p">[</span><span class="n">channel2</span><span class="p">].</span><span class="nf">to_numpy</span><span class="p">().</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">similarity</span> <span class="o">=</span> <span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="n">vector2</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">cosine_similarities</span><span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">channel1</span><span class="si">}</span><span class="s">-</span><span class="si">{</span><span class="n">channel2</span><span class="si">}</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">similarity</span>
<span class="n">sorted_cosine_similarities</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="nf">sorted</span><span class="p">(</span><span class="n">cosine_similarities</span><span class="p">.</span><span class="nf">items</span><span class="p">()))</span></code></pre></figure>

<p></p>


<ul>
  <li>Cosine similarities provide insights into the relationships between EEG channels within the same brain region.</li>
  <li>The sorted similarity pairs offer a clear view of which channels are most or least correlated within each group.</li>
</ul>

<p></p>
This method helps isolate patterns within specific brain regions, contributing to our understanding of channel interactions during rest and sleep sessions.

<p></p>
<figure>
    <img src="/img/eegSlide5.jpg" alt="Data Analysis: Cosine Similarities" style="width:50%; margin:auto;" />
    <figcaption>The table summarizes cosine similarity values for EEG channel pairs during sleep and rest states, alongside the difference between these states (Sleep - Rest).</figcaption>
</figure>

<p></p>
<p></p>
<a href="#">
    <img src="/img/eegSlide7.jpg" alt="Post Sample Image" width="600" />
</a>
<p></p>
<p></p>
<a href="#">
    <img src="/img/eegSlide8.jpg" alt="Post Sample Image" width="600" />
</a>
<p></p>
<ul>
  <li><strong>Channel Pairs</strong>: EEG channel pairs analyzed for similarity.</li>
  <li><strong>Sleep Cos</strong>: Cosine similarity during the sleep session.</li>
  <li><strong>Rest Cos</strong>: Cosine similarity during the rest session.</li>
  <li><strong>Sleep-Rest</strong>: Difference in similarity between sleep and rest, showing how connectivity changes across states.</li>
</ul>
<p></p>
<a href="#">
    <img src="/img/eegSlide9.jpg" alt="Post Sample Image" width="600" />
</a>
<p></p>
<p></p>
<a href="#">
    <img src="/img/eegSlide10.jpg" alt="Post Sample Image" width="600" />
</a>
<p></p>
<p></p>

For our analysis, we selected the EEG channel pairs C4-Cz, F3-F4, and O1-O2. These pairs were chosen based on their relevance to brain region interactions and their notable differences in connectivity between sleep and rest states. These channels represent central, frontal, and occipital brain regions, providing a comprehensive view of neural activity across different areas of the brain.

<p></p>
<h3>Sliding Graph</h3>
<p></p>
This function, <code>create_segments_df</code>, is designed to process a time series DataFrame by creating overlapping segments for a specified column. It helps prepare data for sliding window analysis, which is essential for studying temporal patterns in EEG signals. Below is a high-level description of its workflow:

<ul>
  <li><strong>Inputs:</strong> The function takes the following parameters:
    <ul>
      <li><code>df</code>: The DataFrame containing the data.</li>
      <li><code>column_name</code>: The column to segment.</li>
      <li><code>window_size</code>: The size of each sliding window.</li>
      <li><code>shift</code>: The step size for sliding the window.</li>
      <li><code>columnLabel</code>: A label to annotate the segments.</li>
    </ul>
  </li>

  <li>Process:
    <ul>
      <li>Iterates over the DataFrame to extract overlapping windows of the specified size.</li>
      <li>Transposes each window to arrange its data as a single row for easier concatenation.</li>
      <li>Adds metadata to each segment, including:
        <ul>
          <li><code>start_date</code>: The start time of the segment.</li>
          <li><code>rowIndex</code>: The row index of the original DataFrame.</li>
          <li><code>theColumn</code>: The name of the column being segmented.</li>
          <li><code>columnLabel</code>: A label for the segment.</li>
        </ul>
      </li>
      <li>Appends each processed segment to a list.</li>
    </ul>
  </li>
  <li><strong>Output:</strong> Combines all segments into a single DataFrame for downstream analysis.</li>
</ul>
<p></p>
This function is particularly useful in EEG studies, enabling the division of continuous signals into manageable segments for sliding graph or time-series analysis.
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">create_segments_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">column_name</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span><span class="n">columnLabel</span><span class="p">):</span>
    <span class="n">segments</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">-</span> <span class="n">window_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">shift</span><span class="p">):</span>
        <span class="n">segment</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">window_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
          <span class="p">[</span><span class="n">column_name</span><span class="p">]].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">segment</span> <span class="o">=</span> <span class="n">segment</span><span class="p">.</span><span class="n">T</span>  
        <span class="n">segment</span><span class="p">[</span><span class="sh">'</span><span class="s">start_date</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
        <span class="n">segment</span><span class="p">[</span><span class="sh">'</span><span class="s">rowIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">rowIndex</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
        <span class="n">segment</span><span class="p">[</span><span class="sh">'</span><span class="s">theColumn</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">column_name</span>
        <span class="n">segment</span><span class="p">[</span><span class="sh">'</span><span class="s">columnLabel</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">columnLabel</span>
        <span class="n">segments</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">segment</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">segments</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>
The function <code>group_segments</code> is designed to group smaller data segments into larger groups for graph-based analysis. This process is crucial for aggregating segments in sliding window studies, particularly for EEG analysis. Here’s a detailed explanation:

<ul>
  <li><strong>Inputs:</strong> The function takes the following parameters:
    <ul>
      <li><code>segments_df</code>: The DataFrame containing individual segments.</li>
      <li><code>group_size</code>: The number of segments in each group.</li>
      <li><code>group_shift</code>: The step size for sliding between groups.</li>
    </ul>
  </li>
<p></p>
  <li>Process:
    <ul>
      <li>Iterates over the DataFrame to extract overlapping groups of the specified size.</li>
      <li>Resets the index for each group to maintain consistent indexing.</li>
      <li>Adds a new column, <code>graphIndex</code>, to assign a unique identifier to each group.</li>
      <li>Appends each grouped segment to a list for aggregation.</li>
      <li>Increments the <code>group_index</code> after each group to ensure unique identifiers.</li>
    </ul>
  </li>
  <li><strong>Output:</strong> Combines all grouped segments into a single DataFrame for further analysis or graph construction.</li>
</ul>

<p></p>
This function facilitates efficient grouping of sliding window segments, enabling robust graph-based analysis for temporal patterns in EEG data.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">group_segments</span><span class="p">(</span><span class="n">segments_df</span><span class="p">,</span> <span class="n">group_size</span><span class="p">,</span> <span class="n">group_shift</span><span class="p">):</span>
    <span class="n">grouped_segments</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">group_index</span> <span class="o">=</span> <span class="mi">0</span>  
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">segments_df</span><span class="p">)</span> <span class="o">-</span> <span class="n">group_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">group_shift</span><span class="p">):</span>
        <span class="n">group</span> <span class="o">=</span> <span class="n">segments_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">group_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">group</span><span class="p">[</span><span class="sh">'</span><span class="s">graphIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">group_index</span>  
        <span class="n">grouped_segments</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">group</span><span class="p">)</span>
        <span class="n">group_index</span> <span class="o">+=</span> <span class="mi">1</span>  
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">grouped_segments</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>

<h4>Preprocessing and Sliding Window Preparation</h4>

<p></p>
Parameters for Sliding Window and Grouping:
<p></p>
We defined the following parameters for creating sliding windows and grouping segments:
<p></p>
<ul>
  <li><em>Window size (W):</em> 32 data points per segment.</li>
  <li><em>Shift (S):</em> 16 data points between segments.</li>
  <li><em>Group size (G):</em> 32 segments per group.</li>
  <li><em>Group shift (S<sub>g</sub>):</em> 16 segments between groups.</li>
</ul>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">window_size</span><span class="o">=</span><span class="mi">32</span>
<span class="n">shift</span><span class="o">=</span><span class="mi">16</span>
<span class="n">group_size</span><span class="o">=</span><span class="mi">32</span>
<span class="n">group_shift</span><span class="o">=</span><span class="mi">16</span></code></pre></figure>

<p></p>
Data Scaling and Handling Missing Values:
<p></p>
We selected EEG channels (e.g., <code>O1</code> and <code>O2</code>) for analysis and processed them as follows:
<ul>
  <li>Missing values were replaced with the mean of the respective column.</li>
  <li>Min-Max Scaling was applied to normalize the data for consistency across features.</li>
</ul>
<p></p>
Sliding Window Segmentation and Grouping:
<p></p>
Using the defined parameters, sliding windows were created for each channel (e.g., <code>O1</code> and <code>O2</code>), with each segment assigned a unique node index. Segments were then grouped into larger units for graph analysis.

<p></p>
Dataset Creation:
<p></p>
The grouped segments for both channels were concatenated into a single dataset. Each group was assigned a unique graph index, resulting in a dataset with 787 graph groups, ready for graph-based processing and analysis.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="n">pairColumns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">O1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">O2</span><span class="sh">'</span><span class="p">]</span>
<span class="n">col1</span> <span class="o">=</span> <span class="n">pairColumns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">col2</span> <span class="o">=</span> <span class="n">pairColumns</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="nc">MinMaxScaler</span><span class="p">()</span>
<span class="n">fx_data</span><span class="o">=</span><span class="n">df</span>
<span class="k">if</span> <span class="n">col1</span> <span class="ow">in</span> <span class="n">fx_data</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">fx_data</span><span class="p">[</span><span class="n">col1</span><span class="p">]</span> <span class="o">=</span> <span class="n">fx_data</span><span class="p">[</span><span class="n">col1</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">fx_data</span><span class="p">[</span><span class="n">col1</span><span class="p">].</span><span class="nf">mean</span><span class="p">())</span>
    <span class="n">fx_data</span><span class="p">[</span><span class="n">col1</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">fx_data</span><span class="p">[[</span><span class="n">col1</span><span class="p">]])</span>
<span class="k">if</span> <span class="n">col2</span> <span class="ow">in</span> <span class="n">fx_data</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">fx_data</span><span class="p">[</span><span class="n">col2</span><span class="p">]</span> <span class="o">=</span> <span class="n">fx_data</span><span class="p">[</span><span class="n">col2</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">fx_data</span><span class="p">[</span><span class="n">col2</span><span class="p">].</span><span class="nf">mean</span><span class="p">())</span>
    <span class="n">fx_data</span><span class="p">[</span><span class="n">col2</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">fx_data</span><span class="p">[[</span><span class="n">col2</span><span class="p">]])</span>
<span class="n">columnLabel</span><span class="o">=</span><span class="mi">0</span>
<span class="n">segments1</span> <span class="o">=</span> <span class="nf">create_segments_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">col1</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span> <span class="n">columnLabel</span><span class="p">)</span>
<span class="n">columnLabel</span><span class="o">=</span><span class="mi">1</span>
<span class="n">segments2</span> <span class="o">=</span> <span class="nf">create_segments_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">col2</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span> <span class="n">columnLabel</span><span class="p">)</span>  
<span class="n">segments1</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIndex</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">segments1</span><span class="p">.</span><span class="n">index</span>
<span class="n">segments2</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIndex</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">segments2</span><span class="p">.</span><span class="n">index</span>
<span class="n">grouped_segments1</span> <span class="o">=</span> <span class="nf">group_segments</span><span class="p">(</span><span class="n">segments1</span><span class="p">,</span> <span class="n">group_size</span><span class="p">,</span> <span class="n">group_shift</span><span class="p">)</span>
<span class="n">grouped_segments2</span> <span class="o">=</span> <span class="nf">group_segments</span><span class="p">(</span><span class="n">segments2</span><span class="p">,</span> <span class="n">group_size</span><span class="p">,</span> <span class="n">group_shift</span><span class="p">)</span>
<span class="n">dataSet</span><span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">grouped_segments1</span><span class="p">,</span> <span class="n">grouped_segments2</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">graphMax</span> <span class="o">=</span> <span class="n">dataSet</span><span class="p">[</span><span class="sh">'</span><span class="s">graphIndex</span><span class="sh">'</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span>
<span class="n">graphMax</span>
<span class="mi">787</span>  </code></pre></figure>

<p></p>


<p></p>

<p></p>

<p></p>
<h4>Sliding Window Graph as Input for GNN Graph Classification</h4>
<p></p>
In this stage of our analysis, we prepared sliding window graphs as input for a Graph Neural Network (GNN) classification task. Below is a high-level description of the process:
<p></p>
Process Overview:
<p></p>
We iteratively constructed graphs for EEG data using the predefined sliding windows and grouped segments. Each graph corresponds to a unique segment of the EEG data, capturing temporal relationships within the window. For each graph:
<ul>
  <li>Features (<code>x</code>): Derived from EEG signal values within the segment, including the average of node features to enhance representation.</li>
  <li>Edges (<code>edge_index</code>): Created based on cosine similarity between node pairs, using a threshold (<code>cos &gt; 0.9</code>) to establish connections between nodes.</li>
  <li>Labels (<code>y</code>): Assigned based on the channel being analyzed (e.g., <code>O1</code> or <code>O2</code>).</li>
</ul>
<p></p>
Cosine Similarity Calculation:
<p></p>
Cosine similarity was computed for all node pairs within each graph to determine connectivity. Node pairs exceeding the threshold of 0.9 were added as edges. This ensures that only significant relationships within the EEG signals are represented in the graph structure.
<p></p>
DataLoader Preparation:
<p></p>
The resulting graphs were packaged into datasets for model training and testing:
<ul>
  <li><em>DatasetTest:</em> Contains graphs prepared for evaluation.</li>
  <li><em>DatasetModel:</em> Contains graphs ready for training the GNN model.</li>
</ul>
<p></p>
These datasets were loaded into PyTorch Geometric's <code>DataLoader</code> for efficient batch processing during model training and evaluation.

<p></p>
Outcome:
The constructed sliding window graphs provide a structured and efficient way to capture temporal EEG patterns for graph-based classification. This approach highlights the power of combining sliding window analysis with GNNs to study EEG signals.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="n">cos</span><span class="o">=</span><span class="mf">0.9</span>
<span class="n">datasetTest</span><span class="o">=</span><span class="nf">list</span><span class="p">()</span>
<span class="n">datasetModel</span><span class="o">=</span><span class="nf">list</span><span class="p">()</span>
<span class="n">cosPairsUnion</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">):</span>
  <span class="n">column</span><span class="o">=</span><span class="n">pairColumns</span><span class="p">[</span><span class="n">label</span><span class="p">]</span>
  <span class="k">for</span> <span class="n">graphIdx</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">graphMax</span><span class="p">):</span>
    <span class="n">data1</span><span class="o">=</span><span class="n">dataSet</span><span class="p">[(</span><span class="n">dataSet</span><span class="p">[</span><span class="sh">'</span><span class="s">graphIndex</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">graphIdx</span><span class="p">)</span>
      <span class="o">&amp;</span> <span class="p">(</span><span class="n">dataSet</span><span class="p">[</span><span class="sh">'</span><span class="s">theColumn</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">column</span><span class="p">)]</span>
    <span class="n">values1</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">7</span><span class="p">]</span>
    <span class="n">fXValues1</span><span class="o">=</span> <span class="n">values1</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">values</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">fXValuesPT1</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">fXValues1</span><span class="p">)</span>
    <span class="n">fXValuesPT1avg</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">fXValuesPT1</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">fXValuesPT1union</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">fXValuesPT1</span><span class="p">,</span><span class="n">fXValuesPT1avg</span><span class="p">),</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">cosine_scores1</span> <span class="o">=</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">fXValuesPT1</span><span class="p">,</span> <span class="n">fXValuesPT1</span><span class="p">)</span>
    <span class="n">cosPairs1</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">score0</span><span class="o">=</span><span class="n">cosine_scores1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">group_size</span><span class="p">):</span>
      <span class="n">date1</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">'</span><span class="s">start_date</span><span class="sh">'</span><span class="p">]</span>
      <span class="n">datasetIdx</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">]</span>
      <span class="n">cosPairs1</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span><span class="n">score0</span><span class="p">,</span> <span class="sh">'</span><span class="s">graphIdx</span><span class="sh">'</span><span class="p">:</span><span class="n">graphIdx</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span><span class="sh">'</span><span class="s">theColumn</span><span class="sh">'</span><span class="p">:</span><span class="n">column</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">:</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">:</span><span class="n">window_size</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">date1</span><span class="sh">'</span><span class="p">:</span><span class="n">date1</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">date2</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">XXX</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">:</span> <span class="n">datasetIdx</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">score0</span><span class="p">})</span>
      <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">group_size</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">j</span><span class="p">:</span>
          <span class="n">score</span><span class="o">=</span><span class="n">cosine_scores1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
          <span class="k">if</span> <span class="n">score</span><span class="o">&gt;</span><span class="n">cos</span><span class="p">:</span>
            <span class="n">date2</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="sh">'</span><span class="s">start_date</span><span class="sh">'</span><span class="p">]</span>
            <span class="n">datasetIdx</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">]</span>
            <span class="n">cosPairs1</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span><span class="n">cos</span><span class="p">,</span> <span class="sh">'</span><span class="s">graphIdx</span><span class="sh">'</span><span class="p">:</span><span class="n">graphIdx</span><span class="p">,</span>
                              <span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span><span class="n">score0</span><span class="p">,</span> <span class="sh">'</span><span class="s">graphIdx</span><span class="sh">'</span><span class="p">:</span><span class="n">graphIdx</span><span class="p">,</span>
                              <span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span><span class="sh">'</span><span class="s">theColumn</span><span class="sh">'</span><span class="p">:</span><span class="n">column</span><span class="p">,</span>
                              <span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">:</span><span class="n">i</span><span class="p">,</span>
                              <span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">:</span><span class="n">j</span><span class="p">,</span>
                              <span class="sh">'</span><span class="s">date1</span><span class="sh">'</span><span class="p">:</span><span class="n">date1</span><span class="p">,</span>
                              <span class="sh">'</span><span class="s">date2</span><span class="sh">'</span><span class="p">:</span><span class="n">date2</span><span class="p">,</span>
                              <span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">:</span> <span class="n">datasetIdx</span><span class="p">,</span>
                              <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">score</span><span class="p">})</span>
    <span class="n">dfCosPairs1</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">cosPairs1</span><span class="p">)</span>
    <span class="n">edge1</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">dfCosPairs1</span><span class="p">[[</span><span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">,</span>	<span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">]].</span><span class="n">T</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">dataset1</span> <span class="o">=</span> <span class="nc">Data</span><span class="p">(</span><span class="n">edge_index</span><span class="o">=</span><span class="n">edge1</span><span class="p">)</span>
    <span class="n">dataset1</span><span class="p">.</span><span class="n">y</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">label</span><span class="p">])</span>
    <span class="n">dataset1</span><span class="p">.</span><span class="n">x</span><span class="o">=</span><span class="n">fXValuesPT1union</span>
    <span class="n">datasetTest</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">dataset1</span><span class="p">)</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">datasetTest</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">datasetModel</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">cosPairsUnion</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">cosPairsUnion</span><span class="p">,</span> <span class="n">dfCosPairs1</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>   
<h4>GNN Graph Classification: Model Training.</h4>
<p></p>  

To classify EEG data using a graph neural network (GNN), we implemented a training pipeline that incorporates data splitting, model definition, and training steps. Below is an overview of the process:



<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.17</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span>
  <span class="nf">train_test_split</span><span class="p">(</span><span class="n">graphInput</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></figure>

<p></p>
<strong>Dataset Splitting:</strong> The dataset was split into training and testing sets with a 17% test size. The data was prepared for training using PyTorch Geometric's DataLoader, ensuring efficient batch processing.

<p></p>

<strong>Model Architecture:</strong> A Graph Convolutional Network (GCN) was designed for EEG graph classification. The model includes:
<ul>
<li><strong>Node Embedding Steps:</strong> Three graph convolutional layers process node-level information.</li>
<li><strong>Graph Embedding Step:</strong> A global mean pooling layer aggregates node-level embeddings into graph-level embeddings.</li>
<li><strong>Classification Step:</strong> A fully connected layer classifies graphs into two categories.</li>
</ul>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch.nn</span> <span class="kn">import</span> <span class="n">Linear</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GCNConv</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">global_mean_pool</span>
<span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">GCN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">window_size</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lin</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">return_graph_embedding</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">graph_embedding</span> <span class="o">=</span> <span class="nf">global_mean_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>  
        <span class="k">if</span> <span class="n">return_graph_embedding</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">graph_embedding</span>  
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">graph_embedding</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span></code></pre></figure>

<p></p>
The model is now ready for training and evaluation using the prepared data loaders. This architecture leverages node-level and graph-level features for effective classification.

<p></p>
<h3>Model Training and Evaluation</h3>
<p></p>

The training and evaluation process for the GNN model involves key steps to optimize the parameters and assess performance. Below is an overview of the methodology:
<p></p>
<strong>Training Process:</strong>
<ul>
  <li>Perform a single forward pass over batches in the training dataset.</li>
  <li>Compute the loss using the cross-entropy loss function.</li>
  <li>Derive gradients using backpropagation.</li>
  <li>Update model parameters based on the computed gradients.</li>
  <li>Clear gradients after each step to prevent accumulation.</li>
</ul>
<p></p>
<strong>Evaluation Process:</strong>
<ul>
  <li>Iterate over the test dataset in batches.</li>
  <li>Perform forward passes to compute predictions.</li>
  <li>Use the class with the highest probability as the predicted label.</li>
  <li>Compare predictions with ground-truth labels to compute the accuracy.</li>
  <li>Return the ratio of correct predictions as the evaluation metric.</li>
</ul>
<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">IPython.display</span> <span class="kn">import</span> <span class="n">Javascript</span>
<span class="nf">display</span><span class="p">(</span><span class="nc">Javascript</span><span class="p">(</span><span class="sh">'''</span><span class="s">google.colab.output.setIframeHeight(0, true, {maxHeight: 300})</span><span class="sh">'''</span><span class="p">))</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
         <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>  
         <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>  
         <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>  
         <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>  
         <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>  
<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">loader</span><span class="p">):</span>
     <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
     <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
     <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>  
         <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>
         <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
         <span class="n">correct</span> <span class="o">+=</span> <span class="nf">int</span><span class="p">((</span><span class="n">pred</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">).</span><span class="nf">sum</span><span class="p">())</span>
     <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">)</span>  </code></pre></figure>

<p></p>


This section details the training and evaluation process of the graph neural network (GNN) model for the EEG channel pair F3-F4 during the sleep session. The model was trained over 16 epochs, with accuracy metrics computed for both the training and test datasets at each epoch.


<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">17</span><span class="p">):</span>
    <span class="nf">train</span><span class="p">()</span>
    <span class="n">train_acc</span> <span class="o">=</span> <span class="nf">test</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="nf">test</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="mi">03</span><span class="n">d</span><span class="si">}</span><span class="s">,
      Train Acc: </span><span class="si">{</span><span class="n">train_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">,
      Test Acc: </span><span class="si">{</span><span class="n">test_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>

<a href="#">
    <img src="/img/eegSlide6.jpg" alt="Post Sample Image" width="445" />
</a>
<p></p>
<ul>
  <li><b>Training Accuracy:</b> Indicates the model's ability to learn patterns from the training dataset. Accuracy steadily increased across epochs, reaching a peak of <strong>0.9502</strong>.</li>
  <li><b>Test Accuracy:</b> Reflects the model's performance on unseen test data, gradually improving and achieving a high value of <strong>0.9366</strong> by the final epoch.</li>
</ul>
<p></p>
The consistent improvement in both training and test accuracy demonstrates the model's capability to generalize well. This highlights its effectiveness in classifying EEG data based on sliding window graphs for the F3-F4 channel pair during sleep.

<p></p>

<p></p>
<p></p>
The table summarizes cosine similarity values and graph neural network (GNN) performance for selected EEG channel pairs across sleep and rest sessions. It provides insights into how these pairs interact during different states and how well the GNN model captures these patterns.



<p></p>
<h4>Analysis of Cosine Similarity and GNN Performance for Selected EEG Pairs</h4>
<p></p>


<p></p>
<a href="#">
    <img src="/img/eegSlide11.jpg" alt="Post Sample Image" width="657" />
</a>
<p></p>

This table presents cosine similarity values and GNN Graph Classification performance for selected EEG channel pairs across sleep and rest states, offering insights into connectivity patterns and classification accuracy.

<p></p>
<ul>


    <li>Cosine Similarity &amp; Channel Interactions:
        <ul>
            <li><strong>F3-F4 (Frontal Lobe):</strong> Moderate similarity in both states with the highest training and test accuracy, indicating strong differentiation between sleep and rest.</li>
            <li><strong>C4-Cz (Central Region):</strong> Higher similarity during sleep, suggesting stronger functional connectivity in this state. However, its stable patterns across conditions resulted in moderate classification accuracy.</li>
            <li><strong>O1-O2 (Occipital Lobe):</strong> Consistently high similarity across both states, limiting classification performance due to minimal variation.</li>
        </ul>
    </li>

    <li>Brain Regions &amp; Functional Roles:
        <ul>
            <li><strong>Frontal Activity (F3-F4):</strong> Notable differences in similarity between sleep and rest align with the frontal lobe’s role in cognitive processing, which decreases during sleep.</li>
            <li><strong>Visual Processing (O1-O2):</strong> The occipital lobe pair maintained stable interactions across states, reflecting consistent neural activity in visual regions.</li>
        </ul>
    </li>

    <li>Model Performance &amp; Interpretation:
        <ul>
            <li><strong>Training Accuracy:</strong> The GNN effectively learned EEG patterns, with F3-F4 achieving the highest accuracy, reinforcing its distinct connectivity changes across states.</li>
            <li><strong>Test Accuracy:</strong> Performance varied across pairs; F3-F4 demonstrated strong generalization, while others showed moderate accuracy shifts.</li>
            <li><strong>High Similarity &amp; Lower Accuracy:</strong> While strong cosine similarity suggests stable EEG interactions, it can reduce variability needed for classification. This is evident in O1-O2, where consistently high similarity limited the model’s ability to distinguish between sleep and rest.</li>
        </ul>
    </li>


</ul>

<p></p>
<p></p>
These findings highlight the complex dynamics of EEG signal relationships and the challenges of analyzing highly correlated data. The results also demonstrate how GNN-based approaches can capture distinct neural patterns, offering a powerful framework for studying sleep-state transitions and functional connectivity.
<p></p>
<p></p>
<h4>Note on O1-O2 Analysis</h4>
<p></p>
Although <strong>O1-O2</strong> was initially included as part of the analysis, its results have been excluded from the figures and detailed discussion due to the very low model training and testing accuracy observed for this channel pair. This suggests that the model failed to capture meaningful patterns or dynamics for O1-O2, likely due to insufficient signal quality or inherent limitations in the data for this pair.


<p></p>
<p></p>



<p></p>


<p></p>
<p></p>

<p></p>   

<p></p>
<p></p>   
<h3>Model Results Interpretation</h3>
<p></p>

The results interpretation phase analyzed the predictions and embeddings from the GNN Graph Classification model. A softmax function transformed the model’s outputs into probabilities, making classification predictions more interpretable. This process helped identify the most likely labels for each graph.

Process:
<ul>
  <li><i>Softmax Transformation:</i> The raw outputs of the GNN model were passed through a softmax function to convert them into probability distributions over the possible classes.</li>
  <li><i>Prediction Extraction:</i> The predicted labels for each graph were determined by identifying the class with the highest probability.</li>
  <li><i>Graph Embeddings:</i> The GNN model also generated graph-level embeddings for each graph, providing a compact vector representation of the patterns captured within the graph.</li>
  <li><i>Data Storage:</i> These embeddings, along with the predicted labels and probabilities, were stored in a structured DataFrame for further analysis and visualization.</li>
</ul>
<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Softmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">graphUnion</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">graphCount</span><span class="p">):</span>
  <span class="n">label</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_graph_embedding</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="n">output</span> <span class="o">=</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">out</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">graphUnion</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">:</span><span class="n">g</span><span class="p">,</span><span class="sh">'</span><span class="s">vector</span><span class="sh">'</span><span class="p">:</span> <span class="n">out</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()})</span></code></pre></figure>

<p></p>


The resulting DataFrame contains each graph's index, embedding vectors, and prediction results. The embeddings serve as high-dimensional representations of the EEG data, enabling further analysis of the underlying patterns and relationships identified by the GNN model.


<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">graphUnion_df</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">graphUnion</span><span class="p">)</span>
<span class="n">graphUnion_df</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span>
      <span class="n">index</span>	<span class="n">vector</span>
<span class="mi">1569</span>	<span class="mi">1569</span>	<span class="p">[[</span><span class="mf">0.17810732</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.19235992</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.16263075</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.167</span><span class="bp">...</span>
<span class="mi">1570</span>	<span class="mi">1570</span>	<span class="p">[[</span><span class="mf">0.2913107</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.073132396</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.09579194</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.039</span><span class="bp">...</span>
<span class="mi">1571</span>	<span class="mi">1571</span>	<span class="p">[[</span><span class="mf">0.030929727</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.10722159</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.040990006</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0</span><span class="bp">...</span>
<span class="mi">1572</span>	<span class="mi">1572</span>	<span class="p">[[</span><span class="mf">0.3690454</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.014458519</span><span class="p">,</span> <span class="mf">0.03268631</span><span class="p">,</span> <span class="mf">0.04397</span><span class="bp">...</span>
<span class="mi">1573</span>	<span class="mi">1573</span>	<span class="p">[[</span><span class="mf">0.123519175</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.23811509</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.22812074</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.16</span><span class="p">.</span></code></pre></figure>

<p></p>
This step bridges the gap between model training and interpretability, allowing for a deeper understanding of how the GNN processes and classifies EEG-based sliding window graphs.
<p></p>
<h4>Cosine Similarity Analysis for Graph Embeddings</h4>
<p></p>
This step evaluates the similarity between pre-final embedding vectors generated by the GNN model for sliding window graphs. By calculating cosine similarity, we gain insights into the relationships and connectivity patterns captured by the model.
<p></p>
Key Steps:
<ul>
    <li><strong>Graph Embedding Vectors:</strong> Each graph is represented by a vector derived from the GNN's pre-final embedding layer, summarizing temporal and spatial relationships within the EEG signal.</li>
    <li><strong>Middle Point Calculation:</strong> For each pair of graph embeddings, the middle point between their corresponding time windows is calculated to align temporal information with similarity analysis.</li>
    <li><strong>Cosine Similarity:</strong> Cosine similarity is computed between graph embedding vectors to quantify the relationship between graphs. This metric reveals how closely related the patterns in the two time segments are.</li>
    <li><strong>Result Compilation:</strong> The results include cosine similarity scores and metadata like the middle point of time windows. These scores provide a basis for exploring the relationships in EEG data.</li>
</ul>


<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cosine_sim_pairs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">graphList_1</span><span class="p">)):</span>
    <span class="n">datasetIdx_0</span><span class="o">=</span><span class="n">graphList_0</span><span class="p">[</span><span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>   
    <span class="n">datasetIdx_1</span><span class="o">=</span><span class="n">graphList_1</span><span class="p">[</span><span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
    <span class="nb">min</span> <span class="o">=</span> <span class="n">graphList_0</span><span class="p">[</span><span class="sh">'</span><span class="s">min</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
    <span class="nb">max</span> <span class="o">=</span> <span class="n">graphList_1</span><span class="p">[</span><span class="sh">'</span><span class="s">max</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
    <span class="n">middle_point</span> <span class="o">=</span> <span class="p">(</span><span class="nb">min</span><span class="o">+</span><span class="nb">max</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
    <span class="c1"># cos_sim_value = cos_sim(datasetIdx_0, datasetIdx_1).numpy().flatten
</span>    <span class="n">vector_0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">graphUnion_df</span><span class="p">[</span><span class="sh">'</span><span class="s">vector</span><span class="sh">'</span><span class="p">][</span><span class="n">datasetIdx_0</span><span class="p">])</span>
    <span class="n">vector_1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">graphUnion_df</span><span class="p">[</span><span class="sh">'</span><span class="s">vector</span><span class="sh">'</span><span class="p">][</span><span class="n">datasetIdx_1</span><span class="p">])</span>
    <span class="n">cos_sim_value</span> <span class="o">=</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">vector_0</span><span class="p">,</span> <span class="n">vector_1</span><span class="p">).</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">flatten</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">cosine_sim_pairs</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span>            
            <span class="sh">'</span><span class="s">middle_point</span><span class="sh">'</span><span class="p">:</span><span class="n">middle_point</span><span class="p">,</span>            
            <span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span> <span class="n">cos_sim_value</span>
        <span class="p">})</span></code></pre></figure>

<p></p>

This analysis bridges the gap between model outputs and interpretability, offering a clearer understanding of how the GNN captures and distinguishes temporal patterns. By identifying regions of high and low similarity, this step enables further exploration of brain dynamics during sleep and rest states, paving the way for advanced graph-based analyses.
<p></p>




<p></p>
<h3>Analysis of Embedded Graphs: Statistics</h3>
<p></p>
<figure>
    <img src="/img/slide4.jpg" alt="Cosine Similarity Statistics for Channel Pairs F3-F4 and C4-Cz" style="width:90%; margin:auto;" />
    <figcaption>Cosine similarity statistics for EEG channel pairs F3-F4 and C4-Cz during sleep and rest sessions, highlighting shifts in connectivity patterns and variability across states.</figcaption>
</figure>

<p></p>
This process aligns embeddings with their corresponding time points, enabling a structured temporal analysis. Cosine similarity is computed between paired embeddings (e.g., F3 and F4) at each time point, generating a dynamic connectivity profile that reveals evolving relationships within the time series.
<p></p>
Table 2 presents cosine similarity statistics for EEG channel pairs F3-F4 and C4-Cz across sleep and rest sessions, highlighting shifts in connectivity behavior. The mean similarity for F3-F4 shifts from negative during sleep (-0.1529) to positive in rest (0.1522), indicating a state-dependent connectivity change. In contrast, C4-Cz remains positive in both sleep (0.1069) and rest (0.2889), suggesting stable connectivity with an increase in rest.
<p></p>
Higher standard deviations in rest for both pairs reflect greater variability, demonstrating that neural interactions fluctuate more during wakeful rest than in sleep. These findings further emphasize the distinct temporal dynamics of frontal and central brain regions across different states.

<p></p>
<h3>Temporal Analysis of Connectivity Within Sleep and Rest</h3>
<p></p>
Understanding how connectivity evolves within each state requires a detailed temporal analysis. While statistical comparisons provide an overview of differences between sleep and rest, examining connectivity patterns over time within each session offers deeper insights. Figures below present a time-resolved views of cosine similarities for F3-F4 and C4-Cz, capturing fluctuations in connectivity as they unfold. This approach helps identify transient changes, sustained trends, and potential transitions in neural activity, providing a more nuanced understanding of brain dynamics in sleep and rest.
<p></p>
<h4>Transforming Time Points</h4>
<p></p>
First, we converted the middle points of each sliding window into minutes and seconds to provide a clear temporal context. This was achieved by calculating the integer division and modulo of the middle points by 60 to derive minutes and seconds, respectively. These were then formatted into readable time labels (e.g., "12m 34.5s") for enhanced interpretability in our plots.
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cosine_sim_pairs_df</span><span class="p">[</span><span class="sh">'</span><span class="s">minutes</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cosine_sim_pairs_df</span><span class="p">[</span><span class="sh">'</span><span class="s">middle_point</span><span class="sh">'</span><span class="p">]</span> <span class="o">//</span> <span class="mi">60</span>
<span class="n">cosine_sim_pairs_df</span><span class="p">[</span><span class="sh">'</span><span class="s">seconds</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cosine_sim_pairs_df</span><span class="p">[</span><span class="sh">'</span><span class="s">middle_point</span><span class="sh">'</span><span class="p">]</span> <span class="o">%</span> <span class="mi">60</span>
<span class="n">cosine_sim_pairs_df</span><span class="p">[</span><span class="sh">'</span><span class="s">time_label</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cosine_sim_pairs_df</span><span class="p">[</span><span class="sh">'</span><span class="s">minutes</span><span class="sh">'</span><span class="p">]</span>
  <span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span> <span class="sh">'</span><span class="s">m </span><span class="sh">'</span> <span class="o">+</span> <span class="n">cosine_sim_pairs_df</span><span class="p">[</span><span class="sh">'</span><span class="s">seconds</span><span class="sh">'</span><span class="p">]</span>
  <span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span> <span class="sh">'</span><span class="s">s</span><span class="sh">'</span></code></pre></figure>

<p></p>
<p></p>

<p></p>



<p></p>

<h4>Smoothing Cosine Similarity Values</h4>
<p></p>

Next, to reduce noise and highlight meaningful trends, we applied a Gaussian smoothing filter to the cosine similarity values. This technique helps clarify patterns by averaging adjacent points in the time series, resulting in smoother curves that better represent the underlying data.
<p></p>
<h4>Creating the Plot</h4>
<p></p>
The smoothed cosine similarity values for both channel pairs were plotted against their corresponding time points. Key details of the plot include:
<ul>
    <li><strong>X-axis:</strong> Time in minutes and seconds, with custom ticks to reduce clutter, ensuring a clear and focused visualization.</li>
    <li><strong>Y-axis:</strong> Cosine similarity values, representing the strength of connectivity between the selected EEG channels.</li>
    <li><strong>Curves:</strong> Separate lines for each channel pair (F3-F4 and C4-Cz) to allow for direct comparison of their temporal dynamics.</li>
</ul>
<p></p>
<h4>Insights and Observations</h4>
<p></p>
The resulting plot showcases how connectivity between specific brain regions changes over time. The F3-F4 pair, for instance, might exhibit distinct patterns compared to C4-Cz, reflecting differences in activity across these regions. This visualization provides a foundation for deeper analyses, such as correlating these dynamics with behavioral or physiological states.

<p></p>
<h4>Technical Details</h4>
<p></p>
The plot was created using Python libraries, including <code>matplotlib</code> for visualization and <code>scipy.ndimage</code> for smoothing. The data preparation involved grouping cosine similarity values, aligning them temporally, and ensuring consistency in the time axis for both channel pairs. This ensures an accurate and visually compelling comparison of the EEG data's temporal features.
<p></p>
By transforming, smoothing, and plotting the cosine similarity values, this analysis offers a detailed view of temporal connectivity dynamics in EEG data. It provides a vital step in understanding the intricate relationships between brain regions and their changes across different states, such as sleep and rest.

<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">scipy.ndimage</span> <span class="kn">import</span> <span class="n">gaussian_filter1d</span>
<span class="n">cos_smoothed_sleep</span> <span class="o">=</span> <span class="nf">gaussian_filter1d</span><span class="p">(</span><span class="n">cosine_sim_pairs_df1</span><span class="p">[</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">],</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">cos_smoothed_rest</span> <span class="o">=</span> <span class="nf">gaussian_filter1d</span><span class="p">(</span><span class="n">cosine_sim_pairs_df2</span><span class="p">[</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">],</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">time_labels</span> <span class="o">=</span> <span class="n">cosine_sim_pairs_df1</span><span class="p">[</span><span class="sh">'</span><span class="s">time_label</span><span class="sh">'</span><span class="p">]</span>  
<span class="n">step_size</span> <span class="o">=</span> <span class="mi">60</span>
<span class="n">x_ticks</span> <span class="o">=</span> <span class="n">cosine_sim_pairs_df1</span><span class="p">[</span><span class="sh">'</span><span class="s">middle_point</span><span class="sh">'</span><span class="p">][::</span><span class="n">step_size</span><span class="p">]</span>
<span class="n">x_labels</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="nf">int</span><span class="p">(</span><span class="n">m</span><span class="p">)</span><span class="si">}</span><span class="s">:</span><span class="si">{</span><span class="n">s</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span> <span class="k">for</span> <span class="n">m</span><span class="p">,</span>
  <span class="n">s</span> <span class="ow">in</span> <span class="n">cosine_sim_pairs_df1</span><span class="p">[[</span><span class="sh">'</span><span class="s">minutes</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">seconds</span><span class="sh">'</span><span class="p">]].</span><span class="n">iloc</span><span class="p">[::</span><span class="n">step_size</span><span class="p">].</span><span class="n">values</span><span class="p">]</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span>
    <span class="n">cosine_sim_pairs_df1</span><span class="p">[</span><span class="sh">'</span><span class="s">middle_point</span><span class="sh">'</span><span class="p">],</span> <span class="n">cos_smoothed_sleep</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">F3-F4</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">brown</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span>
<span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span>
    <span class="n">cosine_sim_pairs_df2</span><span class="p">[</span><span class="sh">'</span><span class="s">middle_point</span><span class="sh">'</span><span class="p">],</span> <span class="n">cos_smoothed_rest</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">C4-Cz</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span>
<span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">x_ticks</span><span class="p">,</span> <span class="n">x_labels</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Time (minutes:seconds)</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Cosine Similarity</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Cosine Similarity at Rest Time: F3-F4 vs. C4-Cz</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure>

<p></p>

<p></p>

<p></p>
<h4>Cosine Similarity at Sleep Time: F3-F4 vs. C4-Cz</h4>
<p></p>
This figure illustrates the temporal dynamics of cosine similarity for two EEG channel pairs, <strong>F3-F4</strong> and <strong>C4-Cz</strong>, during sleep. The x-axis represents time in minutes and seconds, while the y-axis shows the cosine similarity values. The red line corresponds to the F3-F4 channel pair, and the green line corresponds to the C4-Cz channel pair. The fluctuations in similarity values over time highlight differences in connectivity between these brain regions during sleep. This visualization offers a detailed view of how specific brain areas interact dynamically during sleep, capturing subtle connectivity changes.

<p></p>

<figure>
    <img src="/img/eegSlide12.jpg" alt="Traditional EEG Graph Example" style="width:90%; margin:auto;" />
    <figcaption>Temporal dynamics of cosine similarity during sleep for EEG channel pairs F3-F4 and C4-Cz, showcasing distinct connectivity patterns in brain regions associated with motor and sensory processing..</figcaption>
</figure>

<p></p>
<h4>Cosine Similarity at Rest Time: F3-F4 vs. C4-Cz</h4>
<p></p>
This figure depicts the cosine similarity for the same EEG channel pairs, <strong>F3-F4</strong> and <strong>C4-Cz</strong>, during rest. Similar to the sleep plot, the x-axis indicates time in minutes and seconds, and the y-axis represents cosine similarity values. The trends for F3-F4 (red) and C4-Cz (green) reveal distinct patterns of connectivity during rest, differing from the sleep state. These patterns reflect how brain activity and connectivity are modulated across different states.


<p></p>
<figure>
    <img src="/img/eegSlide13.jpg" alt="Traditional EEG Graph Example" style="width:90%; margin:auto;" />
    <figcaption>Temporal dynamics of cosine similarity during rest for EEG channel pairs F3-F4 and C4-Cz, highlighting connectivity differences in brain regions compared to the sleep state.</figcaption>
</figure>
<p></p>








<p></p>
<p></p>









<p></p>
<h2>Conclusion</h2>
<p></p>
<p>This study explores how <strong>sliding graph neural networks</strong> can help analyze <strong>EEG time series</strong>, capturing <strong>shifting connectivity patterns</strong> in the brain. By transforming EEG signals into overlapping graphs, <strong>GNN Graph Classification</strong> not only tracks how brain activity changes over time but also provides deeper insights into neural interactions beyond simple classification.</p>

<p>Our findings highlight clear differences between <strong>sleep and rest</strong>, especially in the <strong>frontal (F3-F4) and central (C4-Cz) regions</strong>. <strong>Cosine similarity analysis</strong> shows that while <strong>C4-Cz remains strongly connected during rest</strong>, <strong>F3-F4 shifts more between states</strong>, reflecting how different brain areas behave across conditions.</p>

<p>Bringing <strong>neuroscience and graph theory</strong> together opens exciting possibilities. <strong>Sliding graphs</strong> give neuroscientists a fresh way to uncover EEG patterns that might go unnoticed with traditional methods, while <strong>graph-based techniques</strong> gain new applications in sleep research. This collaboration isn’t just about analyzing data—it’s about connecting disciplines and discovering new ways to study the brain.</p>

<p>Beyond EEG, <strong>GNN Sliding Graph Classification</strong> has potential in many fields, from <strong>tracking climate trends</strong> to <strong>understanding financial markets</strong>. With opportunities to <strong>scale, improve interpretability, and tackle real-world challenges</strong>, this approach could offer fresh insights into complex systems far beyond neuroscience.</p>




<!-- This study demonstrates the effectiveness of sliding graph neural networks for EEG time series analysis. By transforming EEG signals into overlapping graph structures, GNN Graph Classification captures dynamic connectivity patterns over time, while pre-final vector embeddings provide deeper insights into neural interactions beyond classification.
<p></p>
Our analysis reveals distinct connectivity differences between rest and sleep states, particularly in the frontal (F3-F4) and central (C4-Cz) regions. Cosine similarity analysis shows that while C4-Cz exhibits stronger connectivity during rest, F3-F4 varies more across states, aligning with neurophysiological patterns.
<p></p>
Bridging neuroscience and graph theory presents both challenges and opportunities. Sliding graphs offer neuroscientists a new lens to uncover EEG patterns that conventional methods may miss, while graph experts see their tools applied to real-world challenges like sleep research. By merging these perspectives, we go beyond data analysis—building connections between disciplines and demonstrating how graph-based techniques can reshape brain research.
<p></p>
These findings suggest sliding graph-based GNNs as a powerful framework for modeling long-duration EEG dynamics. Future work will focus on scalability to larger datasets, clinical validation, and enhanced interpretability for sleep research and neurodiagnostics.
<p></p> -->







<p></p>

<p></p>

<p></p>
<p></p>
</p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[Sliding Graphs: Watching Signals Change Like a Movie Sliding graphs are a way to let AI watch how a signal behaves over time, not just look at a summary. Instead of treating a long recording as one big block, we break it into many small, overlapping moments and let AI see which moments look alike and which don’t. Put together, these moments form an evolving map of the signal, showing when things are calm, when they shift, and when something unusual starts to happen. We illustrate this with EEG sleep vs rest, but the same idea works for machines, sensors, markets, climate, or any long signal—anywhere you want AI to say not only what is happening, but when things start to change.]]></summary></entry><entry><title type="html">Exploring Geo-Connectivity and Multi-Feature Graphs with GNNs</title><link href="http://localhost:4000/2025/01/20/vectors2gafGNN/" rel="alternate" type="text/html" title="Exploring Geo-Connectivity and Multi-Feature Graphs with GNNs" /><published>2025-01-20T07:00:00-05:00</published><updated>2025-01-20T07:00:00-05:00</updated><id>http://localhost:4000/2025/01/20/vectors2gafGNN</id><content type="html" xml:base="http://localhost:4000/2025/01/20/vectors2gafGNN/"><![CDATA[<p><h2> Introduction</h2>
<p></p>
Graphs are everywhere in our lives. They represent molecules in chemistry, roads in navigation, and our social networks like Facebook. From molecules to city maps and social network graphs, graphs allow us to model complex relationships in ways that are easy to analyze and visualize.
<p></p>
<p></p>
<a href="#">
    <img src="/img/gkgSlide1.jpg" alt="Post Sample Image" width="765" />
</a>
<p></p>

People don’t think sequentially, especially when solving complex problems. Instead, our brains rely on networks of connections, enabling dynamic and non-linear thinking. Graph Neural Networks (GNNs) replicate this process by modeling data as graphs, helping uncover hidden relationships and patterns in everything from neuroscience to social networks.
<p></p>


<p></p>
<p>
    Building on this, we explore how <strong>multi-feature graphs</strong> can capture the complexity of real-world systems by representing countries as nodes and their relationships (like borders) as edges. Nodes aren't just static entities—they hold rich features, which might be time series, text, images, or other data that can be represented as vectors. For this study, we focus on <strong>time series features</strong>, such as life expectancy, GDP, and CO₂ emissions, where each feature may follow a different format.
</p>
<p>
    Using a <strong>country geo graph</strong>, where edges represent shared borders (land or sea) and nodes represent countries with diverse features, we leverage <strong>GNNs for link prediction</strong> to embed these features into consistent vector representations. Borders in this graph act as connections that influence cross-country relationships, akin to synapses between neurons. The quality of these connections, such as the openness or type of borders, can provide meaningful insights into the dynamics of international relationships.
</p>
<p>
    This approach allows us to harmonize diverse datasets into a single unified graph, which can then be analyzed for clustering, classification, and prediction tasks. By incorporating details like border types and shared attributes, we aim to better understand how spatial relationships shape global patterns in health, economy, and environment.
</p>
<p>
    Our study highlights the potential of multi-feature graphs in uncovering hidden connections and patterns in global data. By combining spatial relationships, detailed node features, and advanced GNN techniques, we provide a robust framework for analyzing international dynamics and their impact on socio-economic outcomes.
</p>
<p></p>



<h2>Methods</h2>


<p></p>
<a href="#">
    <img src="/img/graphBorders13c.jpg" alt="Post Sample Image" width="711" />
</a>
<p></p>

<h3>Pipeline Overview</h3>
<p>The methodology integrates country features and border information to construct a unified graph, enabling comprehensive analysis of global relationships:</p>

<ul>
    <li><strong>Country-Feature Subgraphs:</strong> Edges are based on land and sea borders, representing geographical connections. Subgraphs were enriched with attributes such as life expectancy, GDP, and internet usage, combining spatial relationships with socio-economic and health data.</li>
    <li><strong>Unified Dual-Layer Graph:</strong> Subgraphs were combined into a dual-layer graph by adding intra-country edges that link nodes corresponding to the same country across different features.</li>
    <li><strong>Final Embeddings:</strong> A second GNN was applied to the dual-layer graph to generate final embeddings. These embeddings integrate the combined graph structure and relationships across all features and borders.</li>
    <li><strong>Country-Level Aggregation:</strong> Node embeddings were aggregated at the country level, creating average vectors that summarize each country’s overall profile, incorporating its socio-economic features and geographic relationships.</li>
    <li><strong>GNN Link Prediction:</strong> A Graph Neural Network (GNN) was applied to each subgraph using the GraphSAGE Link Prediction model, embedding time-series features of varying lengths into fixed-size vectors. The Deep Graph Library (DGL) framework was used for efficient training and evaluation, capturing both feature-based and structural relationships.</li>
</ul>


<h3>Graph Construction</h3>
    <p>
        We began by constructing a graph where countries were represented as nodes, and edges corresponded to borders between countries. Nodes were identified using country codes, and edges were created for countries sharing either land or sea borders. This foundational graph structure captures geographic connectivity and serves as the basis for modeling socio-economic relationships between countries.
    </p>

    <h3>Node Features</h3>
    <p>
        Each node (country) was enriched with features derived from publicly available time series datasets, including indicators such as life expectancy, GDP, population, and internet usage rates. These features were preprocessed and normalized to ensure comparability across countries. The inclusion of these diverse node features enabled us to capture multiple aspects of country dynamics and facilitate meaningful graph analysis.
    </p>

    <h3>Multiple Feature Sets</h3>
    <p>
        To capture the unique influence of each node feature, we constructed separate subgraphs for each feature type. For example, one subgraph was based on life expectancy, while another was based on GDP. Each subgraph retained the same graph structure but focused on a single feature set. We applied GNNs independently to these subgraphs, generating feature-specific embeddings for each country. These embeddings reflected the specific relationships and patterns associated with individual features, such as health, economy, or technology.
    </p>

    <h3>GNN Link Prediction</h3>
    <p>
        To reveal hidden connections and enrich the graph's structure, we employed <em>GNN Link Prediction</em> as a core component of our methodology. By leveraging the graph’s structure and node features, this approach allowed us to uncover previously unobserved relationships and enhance the graph's utility for analysis.
    </p>
    <p>
        For this task, we used the <em>GraphSAGE Link Prediction</em> model, implemented via the <em>Deep Graph Library (DGL)</em>. GraphSAGE generates robust node embeddings by aggregating information from neighboring nodes and their attributes, with the added advantage of generalizing to unseen nodes without requiring retraining. Our implementation utilized two GraphSAGE layers, progressively refining node representations by combining details from nearby nodes.
    </p>
    <p>
        The embeddings generated through this process not only captured the individual node features but also the relationships inferred from the graph structure. This methodology facilitated the discovery of hidden connections between countries, which were represented as additional edges in the graph. Similar techniques have been successfully applied to datasets such as the Enron email dataset, demonstrating the effectiveness of GNN-based models in uncovering complex relationships.
    </p>

    <h3>Unified Graph Representation</h3>
    <p>
        To integrate multiple feature-specific embeddings into a single framework, we constructed a unified graph representation. This involved either aggregating embeddings (e.g., averaging across features) or adding new edges to represent feature-based connections between the same nodes across subgraphs. The unified graph enables a holistic view of country relationships by combining diverse aspects such as health, economy, and connectivity into a single, cohesive structure.
    </p>
    <p>
        We further propose extending this approach to <em>multi-domain knowledge graphs</em> by linking subgraphs through shared entities. For example, in our study, country nodes are shared across subgraphs representing different domains (e.g., health, economic, and environmental indicators). This linking process enhances the graph's expressiveness and enables the modeling of inter-domain relationships.
    </p>

    <h3>Applications and Challenges</h3>
    <p>
        The unified graph representation opens up possibilities for various tasks, such as clustering, link prediction, and scenario analysis. By leveraging GNNs, this approach offers flexible and interpretable models for analyzing complex international relationships.
    </p>
    <p>
        However, constructing knowledge graphs for diverse domains presents challenges, particularly in defining graph structures. For spatial data, graph structures can be based on geographic coordinates. For countries, neighbors are defined by shared borders. Other domains, however, may require unique criteria to establish connections.
    </p>
    <p>
        By combining embeddings from multiple subgraphs and linking them through shared nodes, we create a scalable framework for multi-domain knowledge graphs. This framework enables comprehensive analyses of interconnected systems and uncovers patterns across diverse datasets, making it a robust tool for addressing complex, real-world challenges.
    </p>



<p></p>
<h2>Experiments</h2>

<p></p>

<p></p>
<p></p>
<h3>Graph Edges: Data Sources and Data Preparation </h3>
<p></p>

Borders between countries can be compared to synapses between neurons, serving as points of connection or division. The nature and quality of these connections evolve over time: open borders foster stronger connections and collaboration between countries, while closed borders often signify increased tension or conflict. This dynamic makes borders a critical factor in understanding international relationships.
<p></p>
To define neighboring countries, we rely on information about shared borders. Identifying pairs of countries that share borders is particularly valuable, especially when enriched with data about the type and quality of these borders—such as how easily people or goods can cross them. This additional context provides deeper insights into cross-country interactions and their socio-political implications.
<p></p>
There are two primary types of country borders: land borders and sea borders. Each type offers unique insights into the nature of geographic and economic connectivity, making them essential elements in analyzing global relationships.
<p></p>
<p></p>


<p></p>
<p></p>
<h4>Data Sources for Country Land Borders</h4>
<p></p>

<p></p>
<p>
        For this study, we utilized the <em>Natural Earth Admin 0 - Countries dataset</em>, version 5.0.1 (2023), as the primary source for country boundaries and metadata. This dataset provides comprehensive information about country borders, including land boundaries, and includes associated metadata such as GDP, population, and administrative classifications. The data is publicly available under the <em>CC0 1.0 Public Domain Dedication</em>, ensuring accessibility for research and analysis.
    </p>
    <p>
        This dataset was instrumental in constructing the graph structure for land borders, where countries are represented as nodes and shared land boundaries as edges. By leveraging this dataset, we ensured the accuracy and reliability of the geographic connectivity in the graph representation.
    </p>
    <p>
        <strong>Reference:</strong> Natural Earth. "Admin 0 - Countries." Version 5.0.1, Natural Earth, 2023.
        <a href="https://www.naturalearthdata.com" target="_blank">https://www.naturalearthdata.com</a>
    </p>
<p></p>
<p></p>


<p></p>
<p></p>

Land Borders:
<p></p>
<a href="#">
    <img src="/img/gkgMap1.jpg" alt="Post Sample Image" width="700" />
</a>

<p></p>
<p></p>
<p>
    To use datasets stored in Google Drive, we often needed to extract compressed files. Below is an outline of how we unzipped files directly within a Python environment using the zipfile library. This process involved specifying the path to our zip file and the destination directory where the files would be extracted.
</p>
<p>
    Steps we followed:
    <ul>
        <li>Path to the zip file: We located the compressed file in our Google Drive and specified its path.</li>
        <li>Path to extract the files: We chose a destination directory where the contents of the zip file would be extracted.</li>
        <li>Unzip the file: We used Python's zipfile module to extract the contents efficiently.</li>
    </ul>
</p>

<p>
    Below is code for unzipping a file in Google Drive:
</p>

<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">zipfile</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="n">zip_file_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/Geo/ne_10m_admin_0_countries.zip</span><span class="sh">"</span>
<span class="n">extract_to_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/Geo/</span><span class="sh">"</span>
<span class="k">with</span> <span class="n">zipfile</span><span class="p">.</span><span class="nc">ZipFile</span><span class="p">(</span><span class="n">zip_file_path</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
    <span class="n">zip_ref</span><span class="p">.</span><span class="nf">extractall</span><span class="p">(</span><span class="n">extract_to_path</span><span class="p">)</span></code></pre></figure>

<p></p>
<p>
    This approach allows to handle large datasets directly within Google Colab, ensuring seamless integration with your data processing workflow.
</p>
<p></p>
<h4>Data Source for Country Sea Borders</h4>
<p></p>
<p>
    Sea boundaries and Exclusive Economic Zones (EEZs) were obtained from
    <em>Marineregions.org's World EEZ v12 dataset</em>, version 12 (2023). This dataset provides detailed information on sea boundaries and EEZs and is licensed under the Creative Commons Attribution 4.0 International License (CC BY 4.0). The dataset was used to construct the graph's sea boundaries, where edges represent countries sharing maritime boundaries.
</p>
<p>
    <strong>Reference:</strong> Marineregions.org. (2023). World EEZ v12 [Dataset]. Version 12.
    <a href="https://www.marineregions.org/" target="_blank">https://www.marineregions.org/</a>.
</p>

<p></p>
<p></p>

<p></p>
<p></p>
<p>
    To work with the World EEZ v12 dataset, we started by locating the ZIP file containing the data. This file was stored in a directory, such as Google Drive, for easy access. Once the file path was identified, a directory was specified for extracting the contents of the ZIP file.
</p>
<p>
    After unzipping the file, the contents of the extracted directory were listed to verify that all necessary files were successfully extracted. This step ensured that the dataset was prepared and ready for further processing and analysis.
</p>


<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">zipfile</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="n">zip_file_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/Geo/World_EEZ_v12_20231025_gpkg.zip</span><span class="sh">"</span>
<span class="n">extract_to_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/Geo/World_EEZ_v12_20231025_gpkg/</span><span class="sh">"</span>
<span class="k">with</span> <span class="n">zipfile</span><span class="p">.</span><span class="nc">ZipFile</span><span class="p">(</span><span class="n">zip_file_path</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
    <span class="n">zip_ref</span><span class="p">.</span><span class="nf">extractall</span><span class="p">(</span><span class="n">extract_to_path</span><span class="p">)</span>
<span class="n">extracted_files</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">extract_to_path</span><span class="p">)</span></code></pre></figure>

<p></p>

<p>
    By following these steps, we ensured a seamless workflow for preparing the dataset to incorporate sea boundary data into the graph structure and analysis.
</p>

<p></p>
</p>
<p>
Sea Borders:
<p></p>
<a href="#">
    <img src="/img/gkgMap2.jpg" alt="Post Sample Image" width="700" />
</a>



<p></p>
<p></p>

<p></p>

<p></p>

<p></p>

<p></p>
<h4>Land Neighbors Graph</h4>
<p>
    When integrating multiple datasets with potentially different country naming conventions, it's essential to standardize country names systematically. As part of this process, we used ISO_A3 codes as country indicators instead of country names to ensure consistency across datasets.
</p>
<p>
    To extract land borders as connections (edges) in a graph, we first read the shapefile containing the geographic information. This involves loading the dataset, inspecting its contents, and identifying the relationships between neighboring countries.
</p>
<p>
    For this step, we used the Natural Earth Admin 0 dataset, which provides detailed information about country boundaries. After ensuring the shapefile was loaded correctly, we began processing the data to extract meaningful connections for the graph.
</p>

<p></p>
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">geopandas</span> <span class="k">as</span> <span class="n">gpd</span>
<span class="n">shapefile_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/natural_earth/ne_110m_admin_0_countries.shp</span><span class="sh">"</span>
<span class="n">world</span> <span class="o">=</span> <span class="n">gpd</span><span class="p">.</span><span class="nf">read_file</span><span class="p">(</span><span class="n">shapefile_path</span><span class="p">)</span></code></pre></figure>

<p></p>
<p></p>
<p></p>
<p></p>
<p>
    Next, we extracted unique country names from the dataset and printed the total number of countries along with their names. This step helped us understand the scope of the dataset and ensured we were working with accurate geographic entities.
</p>
<p>
    To streamline the dataset, we focused on the essential columns required for constructing the graph. These included:
</p>
<ul>
    <li><strong>Country Name:</strong> Typically represented by columns like <code>NAME</code>, <code>SOVEREIGNT</code>, or similar.</li>
    <li><strong>Geometry:</strong> Contains polygon data defining country borders.</li>
</ul>
<p>
    We simplified the dataset by selecting only these columns and renaming the country column for consistency and ease of use in subsequent processing steps. This approach ensured that the dataset remained clean and manageable while retaining all necessary information for building the graph.
</p>

<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">world</span> <span class="o">=</span> <span class="n">world</span><span class="p">[[</span><span class="sh">'</span><span class="s">NAME</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">geometry</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">world</span> <span class="o">=</span> <span class="n">world</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">NAME</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">})</span></code></pre></figure>
<p></p>
<p></p>
<p></p>
<p></p>
<p>
    To identify neighboring countries, we used GeoPandas spatial operations to determine which countries share borders. This step was crucial for defining the edges in our graph, where each edge represents a land border between two countries.
</p>
<p>
    The process involved iterating through each country in the dataset and finding all other countries whose borders touch the geometry of the current country. A dictionary was created to store these relationships, with each country as a key and its list of neighbors as the corresponding value.
</p>
<p>
    To ensure the geometric integrity of the dataset, we first corrected any invalid geometries using a buffer operation, which fixes potential issues with polygon shapes. This step ensured accurate results when performing spatial queries.
</p>

<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">world</span><span class="p">[</span><span class="sh">'</span><span class="s">geometry</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">world</span><span class="p">[</span><span class="sh">'</span><span class="s">geometry</span><span class="sh">'</span><span class="p">].</span><span class="nf">buffer</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">neighbors</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">country</span> <span class="ow">in</span> <span class="n">world</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
    <span class="n">touching</span> <span class="o">=</span> <span class="n">world</span><span class="p">[</span><span class="n">world</span><span class="p">.</span><span class="n">geometry</span><span class="p">.</span><span class="nf">touches</span><span class="p">(</span><span class="n">country</span><span class="p">.</span><span class="n">geometry</span><span class="p">)][</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
    <span class="n">neighbors</span><span class="p">[</span><span class="n">country</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]]</span> <span class="o">=</span> <span class="n">touching</span></code></pre></figure>

<p></p>
<p>
    The resulting dictionary of neighboring countries provided the foundational structure for building the graph’s edges, capturing the geographic connectivity between nodes (countries).
</p>
<p></p>
<p>
    After identifying neighboring countries, the next step was to create the graph representation. Using the dictionary of neighbors, we constructed a graph where nodes represent countries and edges represent shared borders between them.
</p>
<p>
    The process involved initializing an empty graph and iterating through the dictionary. For each country, edges were added to connect it with its neighbors, effectively capturing the geographic relationships between countries.
</p>


<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="k">for</span> <span class="n">country</span><span class="p">,</span> <span class="n">neighbor_list</span> <span class="ow">in</span> <span class="n">neighbors</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="n">neighbor_list</span><span class="p">:</span>
        <span class="n">G</span><span class="p">.</span><span class="nf">add_edge</span><span class="p">(</span><span class="n">country</span><span class="p">,</span> <span class="n">neighbor</span><span class="p">)</span></code></pre></figure>
<p></p>
<p></p>
<p>
    This graph structure forms the backbone of our analysis, providing a flexible framework to integrate additional data, such as node features and edge attributes. By visualizing and inspecting the graph, we ensured that the structure accurately reflected the underlying geographic connectivity.
</p>
<p></p>
<h4>Sea Neighbors Graph</h4>
<p>
    To construct the Sea Neighbors Graph, we first prepared the dataset by extracting the World EEZ v12 files. This dataset provides detailed information about Exclusive Economic Zones (EEZs) and maritime boundaries, making it ideal for identifying sea-based relationships between countries.
</p>
<p>
    The steps included locating the ZIP file containing the dataset, specifying the directory for extraction, and unzipping the file. Once the files were extracted, the directory was inspected to ensure that all necessary components were available for further processing.
</p>


<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">zipfile</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="n">zip_file_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/Geo/World_EEZ_v12_20231025_gpkg.zip</span><span class="sh">"</span>
<span class="n">extract_to_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/Geo/World_EEZ_v12_20231025_gpkg/</span><span class="sh">"</span>
<span class="k">with</span> <span class="n">zipfile</span><span class="p">.</span><span class="nc">ZipFile</span><span class="p">(</span><span class="n">zip_file_path</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
    <span class="n">zip_ref</span><span class="p">.</span><span class="nf">extractall</span><span class="p">(</span><span class="n">extract_to_path</span><span class="p">)</span>
<span class="n">extracted_files</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">extract_to_path</span><span class="p">)</span></code></pre></figure>


<p></p>
<p>
    These steps ensured that the dataset was ready for use in building the Sea Neighbors Graph, where edges represent shared maritime boundaries between countries.
</p>
<p></p>
<p>
    When working with geographic data, it is essential to ensure that all geometries are valid to avoid issues during spatial operations. Invalid geometries, such as self-intersecting polygons, can lead to errors or inaccurate results when analyzing spatial relationships.
</p>
<p>
    To address this, we corrected any invalid geometries in the dataset by applying a buffer operation with a distance of zero. This operation is a common technique for fixing minor geometric inconsistencies without altering the overall shape of the polygons.
</p>

<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">eez</span><span class="p">[</span><span class="sh">'</span><span class="s">geometry</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">eez</span><span class="p">[</span><span class="sh">'</span><span class="s">geometry</span><span class="sh">'</span><span class="p">].</span><span class="nf">buffer</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span></code></pre></figure>
<p></p>
<p></p>
<p>
    After applying the buffer operation, we confirmed the validity of the geometries. Ensuring valid geometries was a crucial step in preparing the data for constructing the Sea Neighbors Graph and performing reliable spatial queries.
</p>
<p></p>
<p>
    To identify sea neighbors, we analyzed overlapping Exclusive Economic Zones (EEZs) using spatial operations. This process determined which countries share maritime boundaries based on their EEZ polygons.
</p>
<p>
    The method involved iterating through each EEZ polygon in the dataset and checking for intersections with other polygons. For every overlap, we recorded pairs of countries sharing the boundary, ensuring that duplicate pairs were avoided by sorting and storing them uniquely.
</p>
<p>
    This approach allowed us to construct a comprehensive list of sea neighbors, which served as the foundation for creating the Sea Neighbors Graph. Each pair in this list represents a connection (edge) between countries based on their shared maritime boundaries.
</p>

<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">country_pairs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">country</span> <span class="ow">in</span> <span class="n">eez_sea</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
    <span class="n">overlapping_countries</span> <span class="o">=</span> <span class="n">eez_sea</span><span class="p">[</span><span class="n">eez_sea</span><span class="p">.</span><span class="n">geometry</span><span class="p">.</span><span class="nf">intersects</span><span class="p">(</span><span class="n">country</span><span class="p">.</span><span class="n">geometry</span><span class="p">)][</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
    <span class="n">overlapping_countries</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">overlapping_countries</span> <span class="k">if</span> <span class="n">c</span> <span class="o">!=</span> <span class="n">country</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]]</span>
    <span class="k">for</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="n">overlapping_countries</span><span class="p">:</span>
        <span class="n">pair</span> <span class="o">=</span> <span class="nf">tuple</span><span class="p">(</span><span class="nf">sorted</span><span class="p">([</span><span class="n">country</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">],</span> <span class="n">neighbor</span><span class="p">]))</span>
        <span class="k">if</span> <span class="n">pair</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">country_pairs</span><span class="p">:</span>
            <span class="n">country_pairs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">pair</span><span class="p">)</span></code></pre></figure>

<p></p>
<p>
    To construct the Sea Neighbors Graph, we converted the list of overlapping EEZ country pairs into a graph structure using NetworkX. Each country was represented as a node, and shared maritime boundaries were represented as edges between the nodes.
</p>
<p>
    The process began by initializing an empty graph and iterating through the list of country pairs. For each pair, an edge was added to the graph, capturing the maritime connection between the two countries. To ensure a clean graph structure, isolated nodes—countries without any maritime neighbors—were identified and removed from the graph.
</p>


<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">sea_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">country_pairs</span><span class="p">:</span>
    <span class="n">sea_graph</span><span class="p">.</span><span class="nf">add_edge</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>  
<span class="n">isolated_nodes</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">nx</span><span class="p">.</span><span class="nf">isolates</span><span class="p">(</span><span class="n">sea_graph</span><span class="p">))</span>
<span class="n">sea_graph</span><span class="p">.</span><span class="nf">remove_nodes_from</span><span class="p">(</span><span class="n">isolated_nodes</span><span class="p">)</span></code></pre></figure>

<p></p>
<p>
    This graph representation forms the basis for analyzing sea-based relationships between countries, enabling visualization and further exploration of maritime connectivity. By incorporating only connected nodes, we ensured that the graph was well-suited for downstream tasks such as clustering, classification, and link prediction.
</p>
<p></p>

<h4>Combine Land and Sea Graphs</h4>
<p>
    To create a unified representation of geographic relationships, we combined the Land Neighbors Graph and the Sea Neighbors Graph. This unified graph includes all connections based on both land and sea borders, enabling a holistic analysis of country relationships.
</p>
<p>
    The process began by annotating edges in each graph with attributes that indicate the type of connection. For the Land Neighbors Graph, all edges were marked with the attribute <code>'type': 'land'</code>. Similarly, for the Sea Neighbors Graph, all edges were labeled with <code>'type': 'sea'</code>.
</p>



<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">land_graph</span><span class="p">.</span><span class="n">edges</span><span class="p">:</span>
    <span class="n">land_graph</span><span class="p">[</span><span class="n">u</span><span class="p">][</span><span class="n">v</span><span class="p">][</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">land</span><span class="sh">'</span></code></pre></figure>

<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">sea_graph</span><span class="p">.</span><span class="n">edges</span><span class="p">:</span>
    <span class="n">sea_graph</span><span class="p">[</span><span class="n">u</span><span class="p">][</span><span class="n">v</span><span class="p">][</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">sea</span><span class="sh">'</span></code></pre></figure>

<p></p>

<p></p>
<p>
    Next, the two graphs were combined using NetworkX's composition operation. If an edge existed in both the land and sea graphs, it was marked as <code>'type': 'both'</code> to indicate that the connection represents both land and sea borders.
</p>
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">combined_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nf">compose</span><span class="p">(</span><span class="n">land_graph</span><span class="p">,</span> <span class="n">sea_graph</span><span class="p">)</span>
<span class="k">for</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">combined_graph</span><span class="p">.</span><span class="n">edges</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">land_graph</span><span class="p">.</span><span class="nf">has_edge</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">and</span> <span class="n">sea_graph</span><span class="p">.</span><span class="nf">has_edge</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="n">combined_graph</span><span class="p">[</span><span class="n">u</span><span class="p">][</span><span class="n">v</span><span class="p">][</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">both</span><span class="sh">'</span>  <span class="c1"># Mark as both land and sea</span></code></pre></figure>

<p></p>

<p>
    The resulting combined graph captures the complexity of geographic relationships by integrating both land and maritime connectivity into a single structure. Each node in the graph corresponds to a country, labeled with its ISO 3166-1 alpha-3 code for easy identification. This unified graph serves as a foundation for analyzing various aspects of international relationships and their influence on socio-economic and environmental factors.
</p>

This image represents the combined graph of countries connected by both land and sea borders. Each node in the graph corresponds to a country, labeled with its ISO 3166-1 alpha-3 code for easy identification.
<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">nx</span><span class="p">.</span><span class="nf">draw</span><span class="p">(</span><span class="n">Gedges</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span><span class="n">node_color</span><span class="o">=</span><span class="sh">'</span><span class="s">lightgrey</span><span class="sh">'</span><span class="p">,</span> <span class="n">font_size</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure>

<p></p>
<p></p>
<a href="#">
    <img src="/img/graphBorders4.jpg" alt="Post Sample Image" width="900" />
</a>
<p></p>

<p></p>
<h3>Graph Nodes: Data Sources and Preparation</h3>
<p></p>

<p>We constructed graph nodes by incorporating socio-economic and health data from the World Bank:</p>
<ul>
    <li><strong>Life Expectancy:</strong> Extracted from the World Development Indicators (WDI) dataset, capturing the average years a newborn is expected to live.</li>
    <li><strong>Poverty Levels:</strong> Percentage of the population living below $2.15 a day (2017 PPP), reflecting economic disparities.</li>
    <li><strong>GDP Per Capita:</strong> Measuring economic performance and living standards.</li>
    <li><strong>Internet Usage:</strong> Percentage of individuals using the Internet, indicating global connectivity.</li>
</ul>


<p></p>
The World Bank provides comprehensive time-series data on various global indicators, including life expectancy. This dataset includes the average number of years a newborn is expected to live under current mortality rates. The data is categorized by country, year, and additional metadata, ensuring broad applicability for global analyses. It is part of the World Development Indicators (WDI) and is publicly accessible, supporting studies in health, socio-economic development, and policy-making.





<p></p>

<h4>World Bank Data Sources for Graph Nodes</h4>
<p></p>
The life expectancy dataset was used to create node features in our graph, representing time-series data for each country. This data was cleaned, normalized, and integrated into the graph structure, providing meaningful inputs for predictive modeling and analysis.
<p></p>

The life expectancy data was sourced from the World Bank's World Development Indicators (WDI). This dataset provides annual life expectancy figures for countries worldwide, representing the average number of years a newborn is expected to live under current mortality conditions.
More information and access to the dataset are available on the <a href="https://data.worldbank.org/indicator/SP.DYN.LE00.IN" target="_blank">World Bank: Life Expectancy</a>.
<p></p>
The dataset "Poverty headcount ratio at $2.15 a day (2017 PPP) (% of population)" is sourced from the World Bank's World Development Indicators. It provides data on the percentage of the population living below the international poverty line of $2.15 per day (adjusted for 2017 purchasing power parity). This dataset is publicly available and offers insights into global poverty trends. More information and access to the dataset are available on the <a href="https://data.worldbank.org/indicator/SI.POV.DDAY" target="_blank">World Bank: Poverty</a>.
<p></p>
The dataset "GDP per capita (current US$)" is sourced from the World Bank's World Development Indicators. It provides data on the gross domestic product divided by the midyear population, expressed in current U.S. dollars. This dataset is a key indicator for analyzing economic performance and living standards across countries. More information and access to the dataset are available on the <a href="https://data.worldbank.org/indicator/NY.GDP.PCAP.CD" target="_blank">World Bank: GDP per capita</a>.
<p></p>
The dataset "Individuals using the Internet (% of population)" is sourced from the World Bank Open Data platform. It provides the percentage of individuals in a country who use the Internet and is a valuable resource for analyzing global digital connectivity trends. More information and access to the dataset are available on the
<a href="https://data.worldbank.org/indicator/IT.NET.USER.ZS" target="_blank">World Bank: Individuals using the Internet</a>.
<p></p>

<p></p>

<p></p>

<p></p>

<p></p>

<h4>Data Process for Country Life Expectancy</h4>
<p>
    The life expectancy data, sourced from the World Bank's World Development Indicators (WDI), provides life expectancy at birth for countries worldwide across multiple years. This publicly accessible dataset is widely used for analyzing health trends and socio-economic development.
</p>
<p>
    The first step was loading and inspecting the dataset to identify relevant columns for analysis. We then filtered and reshaped the data into a usable format for graph-based modeling by:
</p>
<ul>
    <li>Keeping relevant columns, such as country name, country code, and life expectancy values.</li>
    <li>Reshaping the dataset into a long format, with years as variables, for easier integration into the graph structure.</li>
</ul>
<p>
    The loading process included skipping the first 4 rows (containing metadata), using a comma as the delimiter, and employing the Python engine for parsing flexibility. These preprocessing steps ensured the dataset was clean, structured, and ready for integration into the graph model.
</p>

<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">file_path</span> <span class="o">=</span><span class="sh">'</span><span class="s">/content/drive/My Drive/Geo/API_SP.DYN.LE00.IN_DS2_en_csv_v2_99.csv</span><span class="sh">'</span>
<span class="n">data</span><span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span>
    <span class="n">file_path</span><span class="p">,</span>
    <span class="n">skiprows</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>          
    <span class="n">delimiter</span><span class="o">=</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">,</span>       
    <span class="n">engine</span><span class="o">=</span><span class="sh">"</span><span class="s">python</span><span class="sh">"</span>      
<span class="p">)</span></code></pre></figure>

<p></p>
<p></p>


<p></p>
<p>
    For our study, we manually preprocessed life expectancy data to ensure compatibility with the graph structure. This preprocessing was essential for aligning country-level data with the nodes in the graph and maintaining data integrity.
</p>
<p>
    We handled missing values by filling them with zeros, ensuring a complete dataset for integration. Next, we aligned the country codes between the dataset and the graph nodes. This involved extracting nodes from the graph and standardizing country codes to remove inconsistencies.
</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">file_path</span> <span class="o">=</span><span class="sh">'</span><span class="s">/content/drive/My Drive/Geo/WorldBank/Life_expectancy.csv</span><span class="sh">'</span>
<span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span></code></pre></figure>


<p>
    Then we performed an inner join on the 'Country Code' column to merge the graph nodes with the life expectancy data. This step connected node features to the graph structure, allowing for meaningful analysis and modeling in subsequent stages.
</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">nodes_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">Gedges</span><span class="p">.</span><span class="n">nodes</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">])</span>
<span class="n">nodes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">nodes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span>
<span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span>
<span class="n">merged_data</span> <span class="o">=</span> <span class="n">nodes_df</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">inner</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>


<p></p>
<p>
    In our data preprocessing, we addressed the issue of missing values represented as zeros in the dataset. To ensure continuity in the time series data, we replaced all 0.0 values in a row with the closest non-zero value in the same row.
</p>
<p>
    The process involved checking each row for non-zero values. For rows with zeros, we filled these values by propagating the nearest valid data point forward and backward along the row. If an entire row consisted of zeros, it remained unchanged. This approach ensured that gaps in the data were minimized without introducing biases or arbitrary values.
</p>


<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="k">def</span> <span class="nf">replace_zeros_with_closest_nonzero</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="n">non_zero_indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">row</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">non_zero_indices</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">row</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">row</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">row</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="k">else</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">row</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">row</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="k">else</span> <span class="mf">0.0</span>
    <span class="k">return</span> <span class="n">row</span>
<span class="n">columns_to_process</span> <span class="o">=</span> <span class="n">merged_data</span><span class="p">.</span><span class="nf">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">number</span><span class="p">]).</span><span class="n">columns</span>
<span class="n">merged_data</span><span class="p">[</span><span class="n">columns_to_process</span><span class="p">]</span> <span class="o">=</span> <span class="n">merged_data</span><span class="p">[</span><span class="n">columns_to_process</span><span class="p">]</span>
  <span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">replace_zeros_with_closest_nonzero</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code></pre></figure>

<p></p>
<p>
    This step was applied to all numerical columns in the dataset, resulting in a cleaned and more consistent dataset that could be effectively used for graph-based analysis and modeling.
</p>

<p></p>
<p>
    After handling missing values, we proceeded to clean the dataset further by dropping rows containing NaN values. This step ensured that the dataset was fully prepared for graph-based analysis, free of incomplete data entries.
</p>
<p>
    Next, we reshaped and normalized the data to enhance its comparability and suitability for cosine similarity computations. The time series data, excluding identifiers like country codes and names, underwent L2 normalization. This technique scales each row to have a unit norm, emphasizing relative patterns over absolute magnitudes.
</p>


<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">normalize</span>
<span class="n">time_series_data</span> <span class="o">=</span> <span class="n">merged_data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:].</span><span class="n">values</span>  
<span class="n">normalized_data</span> <span class="o">=</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">time_series_data</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="sh">'</span><span class="s">l2</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">merged_data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">=</span> <span class="n">normalized_data</span></code></pre></figure>


<p></p>
<p>
    By replacing the original columns with the normalized data, we created a consistent dataset optimized for similarity calculations and embedding processes in the graph model.
</p>
<p></p>
<p>
    After preprocessing the dataset, we filtered the graph nodes to include only those with corresponding time series data. This step ensured that the graph structure and the dataset were fully aligned for analysis.
</p>
<p>
    We identified valid nodes by matching country codes in the graph with those in the processed dataset. Using this information, a subgraph was created from the original graph, retaining only the nodes with associated time series data.
</p>
<p>
    For each valid node in the filtered graph, we added its corresponding time series data as a node attribute. This enriched the graph structure, embedding meaningful data into the nodes for downstream tasks such as clustering, classification, and link prediction.
</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">valid_nodes</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">merged_data</span><span class="p">[</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">])</span>
<span class="n">filtered_graph</span> <span class="o">=</span> <span class="n">Gedges</span><span class="p">.</span><span class="nf">subgraph</span><span class="p">(</span><span class="n">valid_nodes</span><span class="p">).</span><span class="nf">copy</span><span class="p">()</span>
<span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">filtered_graph</span><span class="p">.</span><span class="n">nodes</span><span class="p">:</span>
    <span class="n">node_data</span> <span class="o">=</span> <span class="n">merged_data</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">merged_data</span><span class="p">[</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">node</span><span class="p">].</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:].</span><span class="n">values</span>
    <span class="n">filtered_graph</span><span class="p">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">node</span><span class="p">][</span><span class="sh">'</span><span class="s">time_series</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">node_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  </code></pre></figure>



<p></p>
<p>
To integrate node features effectively into the graph, we first extracted country codes and created a mapping table linking node identifiers to their respective country codes. This process ensures that each node in the graph is associated with its corresponding country.
</p>
<p>
The steps involved include:
</p>
<ul>
    <li>Extracting country codes from the graph nodes. This step checks whether the node contains a 'Country Code' attribute, ensuring accurate alignment between the graph and the dataset.</li>
    <li>Preparing a mapping table that connects each node ID to its country code. This mapping serves as a crucial link between the graph structure and external data.</li>
    <li>Adding a 'Feature' column to the mapping table. In this case, we associated the literal value "Life expectancy" to signify the feature type being analyzed for the nodes.</li>
</ul>
<p>
This mapping table not only links the graph structure to external data sources but also helps streamline the integration of additional node features for future analysis.
</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="n">country_code_mapping</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">node</span><span class="p">:</span> <span class="n">filtered_graph</span><span class="p">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">node</span><span class="p">][</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">]</span>
    <span class="k">if</span> <span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">filtered_graph</span><span class="p">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
    <span class="k">else</span> <span class="n">node</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">filtered_graph</span><span class="p">.</span><span class="n">nodes</span>
<span class="p">}</span>
<span class="n">mapping_table</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span>
    <span class="sh">'</span><span class="s">Node ID</span><span class="sh">'</span><span class="p">:</span> <span class="nf">list</span><span class="p">(</span><span class="n">country_code_mapping</span><span class="p">.</span><span class="nf">keys</span><span class="p">()),</span>
    <span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">:</span> <span class="nf">list</span><span class="p">(</span><span class="n">country_code_mapping</span><span class="p">.</span><span class="nf">values</span><span class="p">())</span>
<span class="p">})</span>
<span class="n">mapping_table</span><span class="p">[</span><span class="sh">'</span><span class="s">Feature</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Life expectancy</span><span class="sh">"</span>
<span class="n">mapping_table</span><span class="o">=</span><span class="n">mapping_table</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">mapping_table</span><span class="p">[</span><span class="sh">'</span><span class="s">countryIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">mapping_table</span><span class="p">.</span><span class="n">index</span></code></pre></figure>

<p></p>
<p></p>
<a href="#">
    <img src="/img/graphBorders5.jpg" alt="Post Sample Image" width="404" />
</a>
<p></p>
<p></p>
<p></p>
<p>
The prepared mapping table was saved as a CSV file for future reference and analysis. This ensures that the relationship between nodes, country codes, and their associated features is preserved and can be reused in subsequent steps.
</p>
<p>
Saving the mapping table provides a convenient way to link graph nodes to external datasets, enabling seamless integration of node features into the graph structure.
</p>

<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">filePath</span><span class="o">=</span><span class="sh">"</span><span class="s">/content/drive/My Drive/GEO/</span><span class="sh">"</span>
<span class="n">mapping_table</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="n">filePath</span><span class="o">+</span><span class="sh">'</span><span class="s">Life_expectancy_node_mapping.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></figure>


<p></p>
<p></p>

<h3>Prepare Input Data and Train GNN Link Prediction Model</h3>

<p>
The model training phase involves preparing the input graph with enriched node features and converting it into a suitable format for processing with Graph Neural Networks (GNNs). The steps include ensuring that the graph nodes are equipped with meaningful attributes, such as time series data, and converting the graph into the Deep Graph Library (DGL) format.
</p>
<p>
For this study, we assigned the processed time series data as the 'feat' attribute for each node in the filtered graph. This feature represents the life expectancy values or other relevant node features. Each node's feature was converted into a tensor to make it compatible with GNN frameworks.
</p>
<p>
The enriched NetworkX graph was then converted into a DGL graph using the `from_networkx` method. This step preserved the graph structure and node attributes, ensuring the data was ready for GNN training. The resulting DGL graph structure included 200 nodes, 776 edges, and a feature vector of size 63 for each node, making it suitable for tasks such as link prediction.
</p>

<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">dgl</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">filtered_graph</span><span class="p">.</span><span class="n">nodes</span><span class="p">:</span>
    <span class="n">time_series</span> <span class="o">=</span> <span class="n">filtered_graph</span><span class="p">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">node</span><span class="p">].</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">time_series</span><span class="sh">'</span><span class="p">,</span> <span class="p">[])</span>
    <span class="n">filtered_graph</span><span class="p">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">node</span><span class="p">][</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">time_series</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">dgl_graph_nodes</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">from_networkx</span><span class="p">(</span><span class="n">filtered_graph</span><span class="p">,</span> <span class="n">node_attrs</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">])</span>
<span class="n">g</span><span class="o">=</span><span class="n">dgl_graph_nodes</span>
<span class="n">g</span>
<span class="nc">Graph</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">num_edges</span><span class="o">=</span><span class="mi">776</span><span class="p">,</span>
      <span class="n">ndata_schemes</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">:</span> <span class="nc">Scheme</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">63</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)}</span>
      <span class="n">edata_schemes</span><span class="o">=</span><span class="p">{})</span></code></pre></figure>

    <p></p>



    <p></p>               

    <p></p>
    <p>
    The model training phase leveraged code templates from the Deep Graph Library (DGL). These templates streamlined the process of preparing datasets and implementing the Graph Neural Network (GNN) architecture.
    </p>
    <p>
    The use of DGL's resources ensured a consistent and efficient approach to building and training the model on our multi-feature country graph.
    </p>


<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">g</span><span class="p">.</span><span class="nf">edges</span><span class="p">()</span>
<span class="n">eids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_edges</span><span class="p">())</span>
<span class="n">eids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">permutation</span><span class="p">(</span><span class="n">eids</span><span class="p">)</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">eids</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="n">g</span><span class="p">.</span><span class="nf">number_of_edges</span><span class="p">()</span> <span class="o">-</span> <span class="n">test_size</span>
<span class="n">test_pos_u</span><span class="p">,</span> <span class="n">test_pos_v</span> <span class="o">=</span> <span class="n">u</span><span class="p">[</span><span class="n">eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]],</span> <span class="n">v</span><span class="p">[</span><span class="n">eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]]</span>
<span class="n">train_pos_u</span><span class="p">,</span> <span class="n">train_pos_v</span> <span class="o">=</span> <span class="n">u</span><span class="p">[</span><span class="n">eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]],</span> <span class="n">v</span><span class="p">[</span><span class="n">eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]]</span>

<span class="n">adj</span> <span class="o">=</span> <span class="n">sp</span><span class="p">.</span><span class="nf">coo_matrix</span><span class="p">((</span><span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">u</span><span class="p">)),</span> <span class="p">(</span><span class="n">u</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">v</span><span class="p">.</span><span class="nf">numpy</span><span class="p">())))</span>
<span class="n">adj_neg</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">adj</span><span class="p">.</span><span class="nf">todense</span><span class="p">()</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>
<span class="n">neg_u</span><span class="p">,</span> <span class="n">neg_v</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">adj_neg</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">neg_eids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">neg_u</span><span class="p">),</span> <span class="n">g</span><span class="p">.</span><span class="nf">number_of_edges</span><span class="p">())</span>
<span class="n">test_neg_u</span><span class="p">,</span> <span class="n">test_neg_v</span> <span class="o">=</span> <span class="n">neg_u</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]],</span> <span class="n">neg_v</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]]</span>
<span class="n">train_neg_u</span><span class="p">,</span> <span class="n">train_neg_v</span> <span class="o">=</span> <span class="n">neg_u</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]],</span> <span class="n">neg_v</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]]</span>
<span class="n">train_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">remove_edges</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">])</span>
<span class="kn">from</span> <span class="n">dgl.nn</span> <span class="kn">import</span> <span class="n">SAGEConv</span>

<span class="k">class</span> <span class="nc">GraphSAGE</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_feats</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">GraphSAGE</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">SAGEConv</span><span class="p">(</span><span class="n">in_feats</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">,</span> <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">SAGEConv</span><span class="p">(</span><span class="n">h_feats</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">,</span> <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">in_feat</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">in_feat</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span>
<span class="n">train_pos_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">train_pos_u</span><span class="p">,</span> <span class="n">train_pos_v</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>
<span class="n">train_neg_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">train_neg_u</span><span class="p">,</span> <span class="n">train_neg_v</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>
<span class="n">test_pos_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">test_pos_u</span><span class="p">,</span> <span class="n">test_pos_v</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>
<span class="n">test_neg_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">test_neg_u</span><span class="p">,</span> <span class="n">test_neg_v</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>

<span class="kn">import</span> <span class="n">dgl.function</span> <span class="k">as</span> <span class="n">fn</span>
<span class="k">class</span> <span class="nc">DotPredictor</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">g</span><span class="p">.</span><span class="nf">local_scope</span><span class="p">():</span>
            <span class="n">g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span>
            <span class="n">g</span><span class="p">.</span><span class="nf">apply_edges</span><span class="p">(</span><span class="n">fn</span><span class="p">.</span><span class="nf">u_dot_v</span><span class="p">(</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">g</span><span class="p">.</span><span class="n">edata</span><span class="p">[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">MLPPredictor</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">W1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">h_feats</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">W2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">h_feats</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">apply_edges</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">edges</span><span class="p">):</span>
      <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">edges</span><span class="p">.</span><span class="n">src</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">],</span> <span class="n">edges</span><span class="p">.</span><span class="n">dst</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">]],</span> <span class="mi">1</span><span class="p">)</span>
      <span class="k">return</span> <span class="p">{</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="nc">W2</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nc">W1</span><span class="p">(</span><span class="n">h</span><span class="p">))).</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)}</span>

<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
  <span class="k">with</span> <span class="n">g</span><span class="p">.</span><span class="nf">local_scope</span><span class="p">():</span>
    <span class="n">g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span>
    <span class="n">g</span><span class="p">.</span><span class="nf">apply_edges</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">apply_edges</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">g</span><span class="p">.</span><span class="n">edata</span><span class="p">[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">model</span> <span class="o">=</span> <span class="nc">GraphSAGE</span><span class="p">(</span><span class="n">train_g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">64</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="nc">DotPredictor</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">):</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">])</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">pos_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
      <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">neg_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])])</span>
    <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="nf">binary_cross_entropy_with_logits</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compute_auc</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">):</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">]).</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="n">abels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span>
        <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">pos_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
            <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">neg_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]).</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="nf">roc_auc_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">itertools</span><span class="p">.</span><span class="nf">chain</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span>
    <span class="n">pred</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span> <span class="p">)</span>  </code></pre></figure>



<p></p>
<p>
The training process iteratively refined the model's parameters through a series of epochs. During each epoch, the model computed embeddings for nodes, predicted scores for positive and negative edges, and calculated the loss function based on these predictions.
</p>
<p>
An optimizer was employed to minimize the loss by adjusting model parameters through backpropagation. Progress was monitored by printing the loss at regular intervals, providing insight into the model's convergence over time.
</p>
<p></p>            

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">all_logits</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4000</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">train_g</span><span class="p">,</span> <span class="n">train_g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">e</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">In epoch {}, loss: {}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span></code></pre></figure>


<a href="#">
    <img src="/img/graphBorders6.jpg" alt="Post Sample Image" width="333" />
</a>
<p></p>
<p></p>
<p></p>
<p>
To evaluate the model's performance, we computed the Area Under the Receiver Operating Characteristic Curve (AUC) score. Using the predictions for positive and negative edges on the test dataset, the AUC score measures the model's ability to distinguish between actual connections and non-connections in the graph.
</p>
<p>
In this case, the model achieved an AUC of 0.787, indicating a strong predictive capability for link prediction tasks within the country graph.
</p>

<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">AUC</span><span class="sh">'</span><span class="p">,</span> <span class="nf">compute_auc</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">))</span>
<span class="n">AUC</span> <span class="mf">0.7874852420306966</span></code></pre></figure>

<p></p>

<p></p>

<p></p>

<h4>Getting Embedding Vectors from GNN Link Prediction Model</h4>
<p>
To extract and save the learned embedding vectors from the trained Graph Neural Network (GNN) Link Prediction model, we followed these steps:
</p>
<p>
First, the embeddings, stored as a PyTorch tensor (`h`), were converted to a NumPy array for easier handling. The resulting embedding table was structured as a DataFrame, with each row representing the embedding vector for a corresponding node.
</p>
<p>
An additional column, `countryIndex`, was added to the embedding table, linking each vector to its respective node identifier. This table was then merged with the previously created mapping table, which contains country codes and node details, ensuring that each embedding vector was correctly associated with its corresponding country.
</p>
<p>
The final table, containing country codes and their respective embedding vectors, was saved as a CSV file for further analysis and integration into downstream tasks.
</p>

<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="n">h_numpy</span> <span class="o">=</span> <span class="n">h</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>  
<span class="n">embedding_table</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">h_numpy</span><span class="p">)</span>
<span class="n">embedding_table</span><span class="p">[</span><span class="sh">'</span><span class="s">countryIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">embedding_table</span><span class="p">.</span><span class="n">index</span>  
<span class="n">final_table</span> <span class="o">=</span> <span class="n">mapping_table</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">embedding_table</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">countryIndex</span><span class="sh">'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">inner</span><span class="sh">'</span><span class="p">)</span>
<span class="n">final_table</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="n">filePath</span><span class="o">+</span><span class="sh">'</span><span class="s">Life_expectancy_embeddings.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></figure>

<p></p>
<a href="#">
    <img src="/img/graphBorders7.jpg" alt="Post Sample Image" width="734" />
</a>
<p></p>

<h4>Unified Graph of Subgraphs</h4>
<p>
To create a unified graph that integrates multiple subgraphs based on different features, we started by combining node data from various datasets. Each dataset represents a specific feature, such as life expectancy, GDP per capita, or poverty levels. These datasets were merged to establish a common structure for the graph.
</p>
<p>
We concatenated the feature-specific data files into a single DataFrame, ensuring that all relevant attributes were retained. To uniquely identify each node, we created a composite identifier by combining the country code and feature type into a new column, <code>country_feature</code>. This ensures that nodes from different features are distinctly represented, even if they share the same country code.
</p>
<p>
Additionally, a <code>globalIndex</code> column was introduced, assigning a unique index to every node in the combined dataset. This index simplifies the process of creating edges and constructing the unified graph.
</p>
<p>

</p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">data1</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">filePath</span><span class="o">+</span><span class="sh">'</span><span class="s">Life_expectancy_embeddings.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">data2</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">filePath</span><span class="o">+</span><span class="sh">'</span><span class="s">GDP_per_capita_embeddings.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">data3</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">filePath</span><span class="o">+</span><span class="sh">'</span><span class="s">Poor_embeddings.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">data4</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">filePath</span><span class="o">+</span><span class="sh">'</span><span class="s">Internet_embeddings.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">dataNodes</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">,</span> <span class="n">data3</span><span class="p">,</span> <span class="n">data4</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">dataNodes</span><span class="p">[</span><span class="sh">'</span><span class="s">country_feature</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataNodes</span><span class="p">[</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="sh">"</span><span class="s">~</span><span class="sh">"</span> <span class="o">+</span> <span class="n">dataNodes</span><span class="p">[</span><span class="sh">'</span><span class="s">Feature</span><span class="sh">'</span><span class="p">]</span>
<span class="n">dataNodes</span><span class="p">[</span><span class="sh">'</span><span class="s">globalIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataNodes</span><span class="p">.</span><span class="n">index</span></code></pre></figure>

<p></p>

By unifying the data from multiple subgraphs, we established a robust framework for analyzing relationships and patterns across different features, paving the way for multi-feature graph modeling and analysis.
<p></p>

<p></p>  

<p></p>               
<p></p>
<p>
To integrate the edges of different subgraphs into a unified graph, we processed the relationships for each feature independently. By iterating over the feature-specific data, we linked the nodes within the graph structure based on their corresponding edges.
</p>
<p>
For each feature (e.g., "Poor", "GDP per capita", "Internet", and "Life expectancy"), the following steps were performed:
</p>
<ul>
    <li>
        Filtered the combined node dataset to isolate nodes associated with the current feature.
    </li>
    <li>
        Created a mapping from country codes to their respective <code>globalIndex</code>.
    </li>
    <li>
        Iterated through the edges of the initial graph (<code>Gedges</code>) and identified valid connections where both nodes were present in the current feature dataset.
    </li>
    <li>
        Stored the identified edges for each feature in a separate list.
    </li>
</ul>
<p>
This approach ensured that the relationships specific to each feature were preserved while preparing for the construction of the unified graph. The resulting lists of edges will be used to represent the connections within the multi-feature graph model.
</p>

<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Poor</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">GDP per capita</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Life expectancy</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Internet</span><span class="sh">'</span><span class="p">]</span>
<span class="n">edges_for_global</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features</span><span class="p">:</span>
    <span class="n">filtered_data</span> <span class="o">=</span> <span class="n">dataNodes</span><span class="p">[</span><span class="n">dataNodes</span><span class="p">[</span><span class="sh">'</span><span class="s">Feature</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">feature</span><span class="p">]</span>
    <span class="n">country_to_index</span> <span class="o">=</span>
      <span class="n">filtered_data</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">)[</span><span class="sh">'</span><span class="s">globalIndex</span><span class="sh">'</span><span class="p">].</span><span class="nf">to_dict</span><span class="p">()</span>
    <span class="n">edges_for_feature</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">Gedges</span><span class="p">.</span><span class="n">edges</span><span class="p">:</span>
        <span class="n">left</span><span class="p">,</span> <span class="n">right</span> <span class="o">=</span> <span class="n">edge</span>
        <span class="n">left_index</span> <span class="o">=</span> <span class="n">country_to_index</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">left</span><span class="p">)</span>
        <span class="n">right_index</span> <span class="o">=</span> <span class="n">country_to_index</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">right</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">left_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">right_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">edges_for_feature</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">left_index</span><span class="p">,</span> <span class="n">right_index</span><span class="p">))</span>
    <span class="n">edges_for_global</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">edges_for_feature</span><span class="p">)</span></code></pre></figure>

<p></p>
<p></p>
<p>
To further enrich the unified graph, we established edges between nodes that shared the same country code. This step aimed to capture intrinsic relationships between features within the same country.
</p>
<p>
The process involved:
</p>
<ul>
    <li>
        Grouping <code>globalIndex</code> values by country codes using the combined dataset (<code>dataNodes</code>).
    </li>
    <li>
        Iterating through each group of <code>globalIndex</code> values and adding edges between all possible pairs of indices within the same group.
    </li>
</ul>
<p>
The generated edges capture the multi-feature connections for each country, enhancing the unified graph's structure. These new edges were combined with the previously identified feature-specific edges to form a comprehensive representation of the graph.
</p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">global_index_mapping</span> <span class="o">=</span> <span class="n">dataNodes</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">)[</span><span class="sh">'</span><span class="s">globalIndex</span><span class="sh">'</span><span class="p">]</span>
  <span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="nb">list</span><span class="p">).</span><span class="nf">to_dict</span><span class="p">()</span>
<span class="n">edges_with_equal_country_codes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">country_code</span><span class="p">,</span> <span class="n">global_indices</span> <span class="ow">in</span> <span class="n">global_index_mapping</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">global_indices</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">global_indices</span><span class="p">)):</span>
<span class="n">edges_for_global</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">edges_with_equal_country_codes</span><span class="p">)</span></code></pre></figure>




<p></p>
<p>
To finalize the unified graph, we flattened the list of edges derived from feature-specific and country code-based connections. This step ensures that all edges are combined into a single, cohesive structure.
</p>
<p>
The process involved:
</p>
<ul>
    <li>
        Flattening <code>edges_for_global</code>, which contains edges grouped by features, into a single list of edges.
    </li>
    <li>
        Initializing a new graph and adding all edges to it using the <code>add_edges_from</code> method from NetworkX.
    </li>
</ul>
<p>
The resulting unified graph incorporates both inter-feature relationships and intra-country connections, providing a robust framework for further analysis.
</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="n">all_edges</span> <span class="o">=</span> <span class="p">[</span><span class="n">edge</span> <span class="k">for</span> <span class="n">feature_edges</span> <span class="ow">in</span> <span class="n">edges_for_global</span> <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">feature_edges</span><span class="p">]</span>
<span class="n">new_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="n">new_graph</span><span class="p">.</span><span class="nf">add_edges_from</span><span class="p">(</span><span class="n">all_edges</span><span class="p">)</span></code></pre></figure>

<p></p>
New graph was created with 765 nodes and 2571 edges.

<h3>GNN Link Prediction and Cross-Country Analysis</h3>

<p>
In our study, we created a <strong>unified graph</strong> that combines multiple perspectives of country relationships. Each node in the graph represents a unique combination of a country and one of its features, such as life expectancy, GDP per capita, or poverty levels. Edges in the graph capture two types of connections: shared borders between countries and relationships where features belong to the same country. This dual-layer graph structure allows us to explore both geographical and intra-country relationships simultaneously, offering a comprehensive view of global dynamics.
</p>

<p>
The next phase involves leveraging this unified graph for deeper insights. Using a <strong>Graph Neural Network (GNN) Link Prediction model</strong>, we aim to uncover hidden connections and patterns within the graph. The GNN will generate <strong>embedded vectors</strong> for each node, capturing both the node's individual features and its position in the graph structure.
</p>

<p>
Once the embeddings are generated, we will <strong>aggregate the vectors</strong> at the country level. This step ensures that the diverse feature representations for each country are unified into a single vector, encapsulating the country's overall profile. By applying linear algebra techniques to these aggregated vectors, we will measure <strong>similarities between countries</strong>, enabling a data-driven comparison of global trends in health, economy, and connectivity.
</p>

<p>
This approach highlights the potential of GNNs in analyzing multi-faceted relationships and provides a robust framework for comparing countries based on diverse and complex data. It is a step forward in understanding global patterns and uncovering insights from interconnected datasets.
</p>


<p>
Using the <code>dgl.from_networkx</code> method, the NetworkX graph was converted to the DGL format. This transformation preserved the graph structure and enriched each node with a 64-dimensional feature vector, preparing the graph for GNN-based link prediction and analysis tasks.
</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">nodes_with_edges</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">index</span> <span class="k">for</span> <span class="n">feature_edges</span>
    <span class="ow">in</span> <span class="n">edges_for_global</span> <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">feature_edges</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">edge</span><span class="p">)</span>
<span class="n">filtered_dataNodes</span> <span class="o">=</span> <span class="n">dataNodes</span><span class="p">[</span><span class="n">dataNodes</span><span class="p">[</span><span class="sh">'</span><span class="s">globalIndex</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">nodes_with_edges</span><span class="p">)]</span>
<span class="n">dgl_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="n">all_edges</span> <span class="o">=</span> <span class="p">[</span><span class="n">edge</span> <span class="k">for</span> <span class="n">feature_edges</span> <span class="ow">in</span> <span class="n">edges_for_global</span> <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">feature_edges</span><span class="p">]</span>
<span class="n">dgl_graph</span><span class="p">.</span><span class="nf">add_edges_from</span><span class="p">(</span><span class="n">all_edges</span><span class="p">)</span>
<span class="n">node_features</span> <span class="o">=</span> <span class="n">filtered_dataNodes</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">4</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">to_numeric</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="sh">'</span><span class="s">coerce</span><span class="sh">'</span><span class="p">)</span>
<span class="n">node_features</span> <span class="o">=</span> <span class="n">node_features</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">values</span>
<span class="n">new_graph_dgl</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">from_networkx</span><span class="p">(</span><span class="n">dgl_graph</span><span class="p">)</span>
<span class="n">new_graph_dgl</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">features</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">node_features</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">new_graph_dgl</span>
<span class="nc">Graph</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">765</span><span class="p">,</span> <span class="n">num_edges</span><span class="o">=</span><span class="mi">5142</span><span class="p">,</span>
      <span class="n">ndata_schemes</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">features</span><span class="sh">'</span><span class="p">:</span> <span class="nc">Scheme</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)}</span>
      <span class="n">edata_schemes</span><span class="o">=</span><span class="p">{})</span></code></pre></figure>

<p></p>
<p>
The GNN Link Prediction model was trained as described earlier, achieving an impressive AUC score of 0.8720. This result highlights the model's strong capability to predict connections within the unified graph, reflecting the underlying relationships between country-feature pairs.
</p>

<p>
Using the trained model, positive and negative edge scores were evaluated on the test set. The Area Under the Receiver Operating Characteristic Curve (AUC) was calculated, providing a robust measure of the model's performance.
</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">AUC</span><span class="sh">'</span><span class="p">,</span> <span class="nf">compute_auc</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">))</span>
<span class="n">AUC</span> <span class="mf">0.8720230434980092</span></code></pre></figure>

<p></p>
<p></p>
The node embeddings generated by the GNN model were converted from a PyTorch tensor to a NumPy array and organized into a DataFrame. A globalIndex column was added to align these embeddings with the original node data (dataNodes). By merging the embeddings with Country Code and Feature columns from the original data, we created a unified table (h_nodes) for further analysis and visualization.
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="n">h_numpy</span> <span class="o">=</span> <span class="n">h</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
<span class="n">h_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">h_numpy</span><span class="p">)</span>
<span class="n">h_df</span><span class="p">[</span><span class="sh">'</span><span class="s">globalIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">h_df</span><span class="p">.</span><span class="n">index</span>  
<span class="n">nodes</span><span class="o">=</span><span class="n">nodes</span><span class="p">[[</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Feature</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">globalIndex</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">h_nodes</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">h_df</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">globalIndex</span><span class="sh">'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">inner</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>



<p></p>
<h4>Aggregating Node Embeddings by Country</h4>
<p></p>

To analyze the data at the country level, we calculated the average embedding vectors for each <code>Country Code</code>. This process involved grouping the unified table (<code>h_nodes</code>) by <code>Country Code</code>, computing the mean for all embedding columns, and resetting the index to ensure <code>Country Code</code> remained a visible column. The resulting <code>average_vectors</code> table provides a single, unified vector for each country, capturing multidimensional relationships across features.
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">embedding_columns</span> <span class="o">=</span> <span class="n">h_nodes</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">3</span><span class="p">:]</span>  
<span class="n">average_vectors</span> <span class="o">=</span> <span class="n">h_nodes</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">)[</span><span class="n">embedding_columns</span><span class="p">].</span><span class="nf">mean</span><span class="p">()</span>
<span class="n">average_vectors</span> <span class="o">=</span> <span class="n">average_vectors</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">()</span></code></pre></figure>


<p></p>

<p>
To make the dataset more interpretable, we enriched the <code>average_vectors</code> table by mapping each <code>Country Code</code> to its corresponding <code>Country Name</code>. This was accomplished using the <code>pycountry</code> library, which provides reliable mappings between ISO 3166-1 alpha-3 country codes and their official country names. The resulting table now includes country names alongside the country codes and embedding vectors, enhancing clarity and usability for further analysis.
</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">pycountry</span>
<span class="k">def</span> <span class="nf">get_country_name</span><span class="p">(</span><span class="n">iso_code</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">country</span> <span class="o">=</span> <span class="n">pycountry</span><span class="p">.</span><span class="n">countries</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">alpha_3</span><span class="o">=</span><span class="n">iso_code</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">country</span><span class="p">.</span><span class="n">name</span> <span class="k">if</span> <span class="n">country</span> <span class="k">else</span> <span class="bp">None</span>
    <span class="k">except</span> <span class="nb">Exception</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">None</span>
<span class="n">average_vectors</span><span class="p">[</span><span class="sh">'</span><span class="s">Country Name</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">average_vectors</span><span class="p">[</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">get_country_name</span><span class="p">)</span></code></pre></figure>

<p></p>




<p></p>
<h4>Interpreting Model Results: Cosine Similarity</h4>
<p></p>



<p>Using node embeddings, we calculated cosine similarities to explore relationships between countries. This method captures similarities across various dimensions, such as health, economy, and connectivity.
Cosine similarity analysis serves as a basis for comparative studies, helping to identify shared challenges or opportunities and informing policy-making decisions.</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="kn">from</span> <span class="n">itertools</span> <span class="kn">import</span> <span class="n">combinations</span>
<span class="n">vectors</span> <span class="o">=</span> <span class="n">average_vectors</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">values</span>  
<span class="n">countries_info</span> <span class="o">=</span> <span class="n">average_vectors</span><span class="p">[[</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Country Name</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="nf">for </span><span class="p">(</span><span class="n">idx1</span><span class="p">,</span> <span class="n">row1</span><span class="p">),</span> <span class="p">(</span><span class="n">idx2</span><span class="p">,</span> <span class="n">row2</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">combinations</span><span class="p">(</span><span class="n">countries_info</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">(),</span> <span class="mi">2</span><span class="p">):</span>
    <span class="n">cos_sim</span> <span class="o">=</span> <span class="nf">cosine_similarity</span><span class="p">([</span><span class="n">vectors</span><span class="p">[</span><span class="n">idx1</span><span class="p">]],</span> <span class="p">[</span><span class="n">vectors</span><span class="p">[</span><span class="n">idx2</span><span class="p">]])[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">results</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span>
        <span class="sh">'</span><span class="s">Country Code 1</span><span class="sh">'</span><span class="p">:</span> <span class="n">row1</span><span class="p">[</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">Country Code 2</span><span class="sh">'</span><span class="p">:</span> <span class="n">row2</span><span class="p">[</span><span class="sh">'</span><span class="s">Country Code</span><span class="sh">'</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">Country Name 1</span><span class="sh">'</span><span class="p">:</span> <span class="n">row1</span><span class="p">[</span><span class="sh">'</span><span class="s">Country Name</span><span class="sh">'</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">Country Name 2</span><span class="sh">'</span><span class="p">:</span> <span class="n">row2</span><span class="p">[</span><span class="sh">'</span><span class="s">Country Name</span><span class="sh">'</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">Cosine Similarity</span><span class="sh">'</span><span class="p">:</span> <span class="n">cos_sim</span>
    <span class="p">})</span>
<span class="n">cosine_similarity_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span></code></pre></figure>

<p></p>

We added border type information to the cosine similarity analysis, identifying whether countries shared land, sea, both, or no borders.This inclusion provides geographical context, enabling comparisons between countries with and without direct geographical connections.



<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">get_border_type</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">graph</span><span class="p">.</span><span class="nf">has_edge</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">graph</span><span class="p">[</span><span class="n">source</span><span class="p">][</span><span class="n">target</span><span class="p">].</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">unknown</span><span class="sh">'</span><span class="p">)</span>    
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">no border</span><span class="sh">'</span>
<span class="n">cosine_similarity_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Border Type</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cosine_similarity_df</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">row</span><span class="p">:</span>
        <span class="nf">get_border_type</span><span class="p">(</span><span class="n">Gedges</span><span class="p">,</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">Country Code 1</span><span class="sh">'</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">Country Code 2</span><span class="sh">'</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span></code></pre></figure>

<p></p>

<p>
<strong>High Similarity Countries Without Borders:</strong> This analysis identifies country pairs with high cosine similarity (&gt; 0.78) but no shared borders. These pairs reveal strong feature-based relationships, such as economic or health similarities, independent of geographical proximity. Such insights highlight potential partnerships or shared challenges among geographically distant nations.
</p>


<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">high_similarity_no_border</span> <span class="o">=</span> <span class="n">cosine_similarity_df</span><span class="p">[</span>
    <span class="p">(</span><span class="n">cosine_similarity_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Cosine Similarity</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.77</span><span class="p">)</span>
       <span class="o">&amp;</span> <span class="p">(</span><span class="n">cosine_similarity_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Border Type</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">no border</span><span class="sh">'</span><span class="p">)</span>
<span class="p">]</span></code></pre></figure>

<p></p>
<a href="#">
    <img src="/img/graphBorders10.jpg" alt="Post Sample Image" width="734" />
</a>
<p></p>
<p></p>
<p>
<strong>Low Similarity Countries With Borders:</strong> This analysis explores neighboring countries with low cosine similarity (e.g., &lt;0.1). These pairs highlight geographical neighbors that exhibit distinct socio-economic or cultural differences, offering insights into contrasts despite shared borders.
</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">low_similarity_with_border</span> <span class="o">=</span> <span class="n">cosine_similarity_df</span><span class="p">[</span>
    <span class="p">(</span><span class="n">cosine_similarity_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Cosine Similarity</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="o">&amp;</span> <span class="p">(</span><span class="n">cosine_similarity_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Border Type</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">land</span><span class="sh">'</span><span class="p">)</span>
<span class="p">]</span></code></pre></figure>

<p></p>
<a href="#">
    <img src="/img/graphBorders9.jpg" alt="Post Sample Image" width="734" />
</a>
<p></p>
<p></p>
<p></p>
<p>To identify the most similar country pairs first, the DataFrame is sorted by the Cosine Similarity column in descending order:</p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cosine_similarity_df</span> <span class="o">=</span>
    <span class="n">cosine_similarity_df</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">'</span><span class="s">Cosine Similarity</span><span class="sh">'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></figure>

<p></p>
<a href="#">
    <img src="/img/graphBorders11.jpg" alt="Post Sample Image" width="734" />
</a>
<p></p>
<p></p>
<p>
To understand the average relationship strength between countries for each border type, we calculated the mean cosine similarity grouped by "Border Type." This provides an aggregate view of how geographical and feature-based connections correlate across different border categories.
</p>

<ul>
    <li><strong>Cosine Similarity by Border Type:</strong></li>
    <ul>
        <li><strong>Both:</strong> 0.429409</li>
        <li><strong>Land:</strong> 0.428523</li>
        <li><strong>No Border:</strong> -0.009745</li>
        <li><strong>Sea:</strong> 0.412243</li>
    </ul>
</ul>


To analyze the distribution of cosine similarities by border type, we ensured that the "Border Type" column in the <code>cosine_similarity_df</code> DataFrame was ordered. By setting it as a categorical variable with the specified order ('both,' 'land,' 'sea,' 'no border'), we maintained a consistent and meaningful arrangement in the boxplot.
<p></p>
The resulting boxplot illustrates the distribution of cosine similarities grouped by border types. This visualization highlights relationships between countries based on their geographic and feature-based connections. The plot's title, labels, and removal of the default subtitle enhance its clarity and readability.


<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">cosine_similarity_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Border Type</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Categorical</span><span class="p">(</span>
    <span class="n">cosine_similarity_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Border Type</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">categories</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">both</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">land</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">sea</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">no border</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">ordered</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>
<span class="n">cosine_similarity_df</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="sh">'</span><span class="s">Cosine Similarity</span><span class="sh">'</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="sh">'</span><span class="s">Border Type</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Cosine Similarity by Border Type</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">suptitle</span><span class="p">(</span><span class="sh">''</span><span class="p">)</span>  <span class="c1"># Removes the default subtitle
</span><span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Border Type</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Cosine Similarity</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure>

<p></p>
<a href="#">
    <img src="/img/graphBorders8.jpg" alt="Post Sample Image" width="567" />
</a>
<p></p>

<p>
Countries with shared borders, whether by land, sea, or both, tend to have higher cosine similarity, suggesting stronger connections influenced by their geographic proximity. On the other hand, countries without borders show much lower or even negative similarity, emphasizing their distinct differences in socio-economic and other multidimensional features.
</p>

<p></p>



<h2>Conclusion</h2>
<p></p>

<p></p>    


This study explores a novel way of analyzing global relationships using graph-based methodologies, specifically GNN Link Prediction models. By representing countries as nodes and their shared borders as edges, we combined geographic connections with diverse indicators, including economic, health, and cultural dimensions. This approach helps capture the complexity of global relationships in a meaningful way.
<p></p>
Our findings suggest that shared borders often correspond to stronger similarities between countries, while differences within border groups point to the influence of other factors, such as cultural or economic systems. This method provides a flexible framework for understanding international relationships and uncovering new insights.
<p></p>
Looking ahead, these techniques could be applied to a wide range of scenarios involving multi-modal graph data. By transforming diverse features into unified vectors, the GNN Link Prediction model offers a way to analyze relationships in a cohesive space. There is great potential to expand this approach further by incorporating new data, evolving trends, and additional dimensions to deepen our understanding of global connections.
<p></p>


<p></p>
</p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[Introduction Graphs are everywhere in our lives. They represent molecules in chemistry, roads in navigation, and our social networks like Facebook. From molecules to city maps and social network graphs, graphs allow us to model complex relationships in ways that are easy to analyze and visualize.]]></summary></entry><entry><title type="html">Connecting Art and Data: Building a Unified Knowledge Graph</title><link href="http://localhost:4000/2025/01/01/knowledgeGraph4artPaintings/" rel="alternate" type="text/html" title="Connecting Art and Data: Building a Unified Knowledge Graph" /><published>2025-01-01T07:00:00-05:00</published><updated>2025-01-01T07:00:00-05:00</updated><id>http://localhost:4000/2025/01/01/knowledgeGraph4artPaintings</id><content type="html" xml:base="http://localhost:4000/2025/01/01/knowledgeGraph4artPaintings/"><![CDATA[<h2>Unified Knowledge Graph for Artists and Paintings</h2>
<p>
  Think of this project as one map of the art world, where artists and paintings are dots and
  their relationships form the lines between them. We turn biographies and images into a single
  unified knowledge graph, then use Graph AI to see which artists and works are close, far, or
  unexpectedly linked. Instead of scrolling through lists, you can explore art as a connected
  network and discover relationships you wouldn’t notice from text or images alone. The same
  pattern extends far beyond art: this pipeline can fuse text, images, time series, and other data
  into a unified knowledge graph in any domain, keeping everything analyzable with one Graph AI
  workflow.
</p>

<h2>Conference &amp; Publication</h2>
<p>
  This work was presented at <strong>CVIT 2025</strong> in Florence, Italy, on
  <strong>June 20, 2025</strong>, and published as:

  <em>Romanova, A. (2025). “Rewiring Multi-Modal Knowledge Graphs with GNN Link
  Prediction: Insights from Art History.”
  doi: <a href="https://doi.org/10.1117/12.3078062" target="_blank" rel="noopener">
  10.1117/12.3078062</a>.</em>
</p>

<p><h2>Introduction: Knowledge Graphs Exploration</h2>

Art and artists are deeply connected, reflecting creativity, culture, and history. Graphs provide a powerful way to explore these relationships by representing artists, artworks, and movements as nodes, and their connections as edges. This helps us uncover patterns, find hidden links, and better understand the evolution of art. With advanced tools like Graph Neural Networks (GNNs), we can predict new connections, group related ideas, and gain even deeper insights into the art world.
<p></p>
<p><h3>Building on Our Previous Research</h3>
<p></p>
<p>
The first study, titled <strong>"Building Knowledge Graph in Spark without SPARQL"</strong>, was presented at the DEXA 2020 online conference. It explored non-traditional methods for constructing and analyzing knowledge graphs, moving beyond SPARQL-based semantic web approaches. The study demonstrated how the Spark GraphFrames library could be leveraged to efficiently build and mine knowledge graphs. Focusing on modern art artists, it highlighted the versatility and scalability of knowledge graph techniques.
</p>
<p>
For more details, visit: <a href="http://sparklingdataocean.com/2020/02/02/knowledgeGraphIntegration/" target="_blank">Building Knowledge Graph in Spark without SPARQL</a><br />
<strong>Reference:</strong> Romanova, A. (2020). <em>Building knowledge graph in spark without SPARQL</em>. CCIS, vol. 1285, pp 96–102.
</p>
<i><a href="https://www.researchgate.net/publication/344329097_Building_Knowledge_Graph_in_Spark_Without_SPARQL">
paper</a></i>
where we showed how to build knowledge graph in Spark without SPARQL and how conceptually knowledge graph builds a bridge between logical thinking and graph thinking for data mining.
<p></p>
<p>
The second study was presented at <strong>ICAART 2023: 22-24 February, 2023 in Lisbon</strong>. It focused on methods for rewiring knowledge graphs to uncover hidden relationships between nodes using GNN link prediction models. The experiments analyzed semantic similarities and dissimilarities between the biographies of modern art artists by utilizing Wikipedia articles. A traditional method used the full text of articles and cosine similarities between re-embedded nodes, while a novel method examined the distribution of co-located words within and across articles. Output vectors from the GNN link prediction model were aggregated by artist, and link predictions were calculated based on cosine similarities.
</p>
<p>
The study highlighted the importance of both highly connected and highly disconnected node pairs in graph mining. Disconnected pairs offered unique insights, revealing the knowledge graph's overall coverage and serving as indicators for validating community detection. Additionally, the study demonstrated practical applications for rewired knowledge graphs in recommender systems. High-similarity node pairs suggested related artists or movements, while high-dissimilarity pairs encouraged users to explore contrasting art movements, enhancing the diversity of recommendations.
</p>
<p>
For more details, visit: <a href="http://sparklingdataocean.com/2022/07/23/knowledgeGraph4GNN/" target="_blank">Rewiring Knowledge Graphs by Graph Neural Network Link Predictions</a><br />
<strong>Reference:</strong> Romanova, A. <em>Rewiring Knowledge Graphs by Graph Neural Network Link Predictions</em>. International Conference on Agents and Artificial Intelligence (2023). doi:10.5220/0011664400003393.

<p></p>

<p></p>



<p></p>
<p><h3>This Study</h3>
<p></p>



<p></p>

The dataset, <i><a href="https://www.kaggle.com/datasets/ikarus777/best-artworks-of-all-time">
'Best Artworks of All Time'</a></i>, was taken from Kaggle. It features information and artwork images from 50 of the most influential artists in history. The dataset includes detailed artist metadata sourced from Wikipedia, as well as a collection of high-resolution images scraped from artchallenge.ru.
<p></p>

This study focuses on the <strong>Construction of a Unified Knowledge Graph</strong> to analyze the relationships between artists and their works. Starting with raw data comprising artist biographies and painting images, two separate graphs are created: an <strong>Artist Graph</strong> and a <strong>Painting Graph</strong>.
<p></p>
Textual data from artist biographies is transformed into vectors using Large Language Models (LLMs), while visual data from painting images is processed into vectors using Convolutional Neural Networks (CNNs). These initial embeddings are further refined through Graph Neural Networks (GNNs) to produce consistent, high-quality representations for the nodes in both graphs.
<p></p>
The final step involves combining the Artist Graph and Painting Graph into a single <strong>Unified Knowledge Graph</strong>, where links represent the connections between artists and their respective works. This integrated graph provides a robust framework for exploring the intricate relationships within the art world, enabling tasks such as classification, clustering, and link prediction.


<p></p>

<p></p>
<figure>
    <img src="/img/artPaint15.jpg" alt="Traditional EEG Graph Example" style="width:77%; margin:auto;" />
    <figcaption>This figure represents construction of a Unified Knowledge Graph. Raw data of artist biographies and painting images are transformed into an Artist Graph and a Painting Graph. Text and image data are converted into vectors using LLMs and CNNs, respectively, followed by GNN-based embedding. The graphs are then combined into a Unified Knowledge Graph, linking artists to their works.</figcaption>
</figure>
<p></p>

</p><p>


<p><h2>Methods</h2>
<p></p>
<h3>Graph Construction for Artists</h3>

<p>
The process of constructing a graph to represent artist relationships begins with defining nodes for each artist and creating edges based on shared attributes such as genre and nationality.
</p>

<p>
Each artist is represented as a node in the graph, with attributes like the artist's index and name. To capture relationships:
</p>

<ul>
  <li><strong>Genre-Based Edges:</strong> Edges are added between all pairs of artists who share the same genre, reflecting thematic or stylistic connections.</li>
  <li><strong>Nationality-Based Edges:</strong> Edges are created between artists who share the same nationality, representing cultural or geographical ties.</li>
</ul>

<p>
To enable analysis, the graph’s edges are converted into a DataFrame, organized with columns for source nodes, target nodes, and edge attributes. If the edge attributes are stored as dictionaries, these are expanded into individual columns for easier interpretation. The resulting DataFrame is reviewed to confirm its accuracy and structure.
</p>

<h4>Transforming Text to Vectors for Node Features</h4>

<p>
Artist biographies are transformed into vector embeddings to enrich the graph with semantic information. Using the Hugging Face <i><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2">'all-MiniLM-L6-v2'</a></i> model, the text is encoded into a 384-dimensional vector space, producing a tensor of size <code>[50, 384]</code>, where each row represents an artist.
</p>

<p>
These embeddings are assigned as node features in the graph using the <code>ndata['feat']</code> attribute. This enables:
</p>

<ul>
  <li>Using vectors as input for GNN link prediction models.</li>
  <li>Generating additional graph edges by calculating a cosine similarity matrix and selecting highly connected vector pairs.</li>
</ul>

<p>
This approach provides a robust foundation for graph-based analysis, capturing both semantic relationships and potential hidden connections between artists.
</p>

</p><p>

</p><p>
<p><h4>Run GNN Link Prediction Model</h4>
</p><p>

As Graph Neural Networks link prediction we used a model from Deep Graph Library (DGL). The model is built on two GrapgSAGE layers  and computes node representations by averaging neighbor information.

We used the code provided by DGL tutorial <i><a href="https://docs.dgl.ai/en/0.8.x/tutorials/blitz/4_link_predict.html">DGL Link Prediction using Graph Neural Networks</a></i>.

</p><p>

The results of this code are embedded nodes that can be used for further analysis such as node classification, k-means clustering, link prediction and so on. In this study we used it for link prediction by estimating cosine similarities between embedded nodes.
<p></p>

<h3>Building the Painting Graph</h3>
<p>
To construct a graph representing paintings, artwork files are processed to link paintings to their respective artists and prepare the data for graph creation. Each painting is assigned a unique <code>File Index</code>, and artist names extracted from file names are mapped to their corresponding <code>Artist Index</code> using <code>artists_df</code>. This information—<code>File Name</code>, <code>Artist Name</code>, <code>File Index</code>, and <code>Artist Index</code>—is combined into a structured DataFrame.
</p>
<p>
The Painting Graph is created where nodes represent paintings and edges connect paintings by the same artist. Using NetworkX, nodes are added with their <code>File Index</code> as identifiers and <code>File Name</code> as attributes. Edges are added between paintings that share the same <code>Artist Index</code>, capturing relationships based on shared creators.
</p>

<h4>Image Features for Node Embeddings</h4>
<p>
Painting images are processed to generate visual embeddings using a pre-trained CNN, such as ResNet. Images are resized, normalized, and passed through the model to extract high-dimensional feature vectors. These embeddings are stored as node features, enriching the graph with visual content for machine learning tasks.
</p>

<h4>Transforming the Painting Graph to DGL Format</h4>
<p>
The Painting Graph is converted into DGL format to facilitate efficient processing and modeling using DGL's graph-based machine learning tools. The edges from <code>painting_graph_edges</code> are transformed into a PyTorch tensor, defining the graph's structure. Self-loops are added to ensure each node is connected to itself, which can enhance the performance of GNN models.
</p>
<p>
Image feature vectors, previously saved and loaded from storage, are assigned as node features in the graph. These embeddings are converted into a PyTorch tensor and set using the <code>ndata['feat']</code> attribute, enriching the graph with meaningful visual data for each painting node.
</p>

<h4>GNN Link Prediction Model Training for the Painting Graph</h4>
<p>
The GNN model is trained for link prediction on the Painting Graph using the constructed graph and its visual embeddings. Similar to the Artist Graph, the training process involves predicting links by leveraging the node features, allowing the model to identify relationships between paintings based on shared visual or contextual patterns. This tailored approach reveals hidden connections and enhances the understanding of painting relationships within the graph.
</p>

<h3>Unified Knowledge Graph</h3>


<p>
To analyze relationships between artists and their works, we created a Unified Knowledge Graph by combining the Artist graph and Painting graph. This integration enables consistent multi-modal data embedding and analysis.
</p>

<p>
Artist biographies were transformed into 384-dimensional vectors using a transformer model, then reduced to 128-dimensional embeddings through GNN link prediction. Paintings were similarly represented as 2048-dimensional vectors using a pre-trained CNN model, which were also reduced to 128-dimensional embeddings.
</p>

<p>
To unify the graphs, unique indices ensured no overlap between artist and painting nodes, with artist nodes offset by 1000. Painting file names were processed to map each painting to its corresponding artist, and edges were added to represent these relationships.
</p>

<p>
The resulting Unified Knowledge Graph integrates artist and painting data into a single structure, providing a foundation for advanced graph-based analysis.
</p>

<h4>GNN Link Prediction Model for the Unified Graph</h4>
<p>
<p>We applied the GNN Link Prediction model three times across different stages of the study:</p>

<p><strong>1. Artist Graph:</strong> The model was used to process artist biographies, initially embedded as 384-dimensional vectors derived from text data. The GNN Link Prediction model reduced these embeddings to a consistent size of 128 dimensions, capturing semantic relationships between artists effectively.</p>

<p><strong>2. Painting Graph:</strong> For paintings, visual features extracted via a CNN model were initially represented as 2048-dimensional vectors. The GNN Link Prediction model was applied to reduce these high-dimensional embeddings to 128 dimensions, emphasizing meaningful stylistic or thematic connections between paintings.</p>

<p><strong>3. Unified Knowledge Graph:</strong> After merging the Artist and Painting graphs into a single structure, the GNN Link Prediction model was run again on the unified graph. This step refined the node embeddings, ensuring consistent 128-dimensional representations across all nodes while integrating multi-modal relationships between artists and their works.</p>

<p>By running the model at each stage, we achieved consistent embeddings that facilitate advanced graph-based analysis, uncovering complex patterns and relationships within the unified framework.</p>

</p>




<h2>Experiments</h2>
<p></p>
<h3>Data Source Analysis</h3>
<p></p>
As data source we used text data from kaggle.com: <i><a href="https://www.kaggle.com/datasets/ikarus777/best-artworks-of-all-time">
'Best Artworks of All Time'</a></i>.



<p></p>
<h4>Metadata Overview</h4>
<p>This dataset provides the following key files:</p>
<ul>
  <li>
    <strong><code>artists.csv</code></strong>:
    <ul>
      <li>Contains metadata for 50 influential artists, including:</li>
      <li><strong>Name</strong>, <strong>Genre</strong>, <strong>Nationality</strong>, <strong>Biography</strong>, and <strong>Years</strong> (lifespan or active period).</li>
    </ul>
  </li>
  <li>
    <strong><code>resized.zip</code></strong>:
    <ul>
      <li>A collection of resized artwork images, optimized for faster processing and reduced storage.</li>
      <li>Ideal for machine learning workflows requiring efficient model training and testing.</li>
    </ul>
  </li>
</ul>
<p>These files provide a compact yet comprehensive resource for analyzing and classifying artworks.</p>


<p></p>
<h4>Raw Data Processing</h4>
<p></p>

The code loads the artist metadata from a CSV file, selects relevant columns (name, genre, nationality, bio, years), sorts the data alphabetically by name, resets the index, and assigns a sequential artistIndex based on the new order.
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">artists</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/drive/My Drive/Art/artists.csv</span><span class="sh">"</span><span class="p">)</span>
<span class="n">artists_dff</span> <span class="o">=</span> <span class="n">artists</span><span class="p">[[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">genre</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">nationality</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">bio</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">years</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">artists_df</span><span class="o">=</span> <span class="n">artists_dff</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">).</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">artists_df</span><span class="p">[</span><span class="sh">'</span><span class="s">artistIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">artists_df</span><span class="p">.</span><span class="n">index</span></code></pre></figure>




<p>Split the standardized 'years' column into 'start_year' and 'end_year': </p>
<p></p>
<ul>
  <li>
    The <code>years</code> column is cleaned to replace special characters (e.g., em-dash) with a hyphen and split into <code>start_year</code> and <code>end_year</code>.
  </li>
  <li>
    The <code>genre</code> column is exploded, creating separate rows for each genre associated with an artist, and the DataFrame is reset to include <code>artistIndex</code>, <code>name</code>, <code>start_year</code>, <code>end_year</code>, and <code>genre</code>.
  </li>
  <li>
    A new DataFrame, <code>artist2nationality</code>, is created by splitting the <code>nationality</code> column into multiple entries, exploding it into separate rows, and resetting the index to include <code>artistIndex</code>, <code>name</code>, <code>start_year</code>, <code>end_year</code>, and <code>nationality</code>.
  </li>
</ul>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">artists_df</span><span class="p">[</span><span class="sh">'</span><span class="s">years</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">artists_df</span><span class="p">[</span><span class="sh">'</span><span class="s">years</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">[–—]</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">-</span><span class="sh">'</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="n">artists_df</span><span class="p">[[</span><span class="sh">'</span><span class="s">start_year</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">end_year</span><span class="sh">'</span><span class="p">]]</span> <span class="o">=</span> <span class="n">artists_df</span><span class="p">[</span><span class="sh">'</span><span class="s">years</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s"> - </span><span class="sh">'</span><span class="p">,</span> <span class="n">expand</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">explode</span><span class="p">(</span><span class="sh">'</span><span class="s">genre</span><span class="sh">'</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)[[</span><span class="sh">'</span><span class="s">artistIndex</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">start_year</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">end_year</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">genre</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">artist2nationality</span> <span class="o">=</span> <span class="n">artists_df</span><span class="p">.</span><span class="nf">assign</span><span class="p">(</span><span class="n">nationality</span><span class="o">=</span><span class="n">artists_df</span><span class="p">[</span><span class="sh">'</span><span class="s">nationality</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="p">))</span> \
<span class="p">.</span><span class="nf">explode</span><span class="p">(</span><span class="sh">'</span><span class="s">nationality</span><span class="sh">'</span><span class="p">)</span>
<span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)[[</span><span class="sh">'</span><span class="s">artistIndex</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">start_year</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">end_year</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">nationality</span><span class="sh">'</span><span class="p">]]</span></code></pre></figure>


<p></p>

<p></p>
<p></p>
<a href="#">
    <img src="/img/artPaint1.jpg" alt="Post Sample Image" width="777" />
</a>
<p></p>
<h3>Artist Graph</h3>
<p></p>
<h4>Building Graph on Artists</h4>
<p>To construct a graph where nodes represent artists and edges are created based on shared attributes, follow these steps:</p>
<ul>
  <li>
    <strong>Create nodes:</strong> Add a node for each artist using their <code>artistIndex</code> and <code>name</code>.
  </li>
  <li>
    <strong>Create genre-based edges:</strong> For each genre, add edges between all pairs of artists who share that genre.
  </li>
  <li>
    <strong>Create nationality-based edges:</strong> Similarly, for each nationality, add edges between all pairs of artists who share that nationality.
  </li>
</ul>
<p></p>


<p></p>
Below is the Python code used to implement this graph:

<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">artist2genre</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
    <span class="n">G</span><span class="p">.</span><span class="nf">add_node</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">artistIndex</span><span class="sh">'</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">])</span><span class="c1"># !pip install torch
</span><span class="k">for</span> <span class="n">genre</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">artist2genre</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">genre</span><span class="sh">'</span><span class="p">):</span>
    <span class="n">artist_indices</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="sh">'</span><span class="s">artistIndex</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">artist_indices</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">artist_indices</span><span class="p">)):</span>
            <span class="n">G</span><span class="p">.</span><span class="nf">add_edge</span><span class="p">(</span><span class="n">artist_indices</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">artist_indices</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">genre</span><span class="o">=</span><span class="n">genre</span><span class="p">)</span>
<span class="k">for</span> <span class="n">nationality</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">artist2nationality</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">nationality</span><span class="sh">'</span><span class="p">):</span>
    <span class="n">artist_indices</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="sh">'</span><span class="s">artistIndex</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">artist_indices</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">artist_indices</span><span class="p">)):</span>
            <span class="n">G</span><span class="p">.</span><span class="nf">add_edge</span><span class="p">(</span><span class="n">artist_indices</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">artist_indices</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">nationality</span><span class="o">=</span><span class="n">nationality</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Number of nodes: </span><span class="si">{</span><span class="n">G</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">()</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Number of edges: </span><span class="si">{</span><span class="n">G</span><span class="p">.</span><span class="nf">number_of_edges</span><span class="p">()</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Average degree: </span><span class="si">{</span><span class="n">nx</span><span class="p">.</span><span class="nf">density</span><span class="p">(</span><span class="n">G</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">G</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="n">Number</span> <span class="n">of</span> <span class="n">nodes</span><span class="p">:</span> <span class="mi">50</span>
<span class="n">Number</span> <span class="n">of</span> <span class="n">edges</span><span class="p">:</span> <span class="mi">218</span>
<span class="n">Average</span> <span class="n">degree</span><span class="p">:</span> <span class="mf">8.72</span></code></pre></figure>


<p></p>

<p></p>
<p>The following steps describe how to convert graph edges into a DataFrame for analysis:</p>
<ul>
  <li><strong>Convert edges to a DataFrame:</strong> Extract the edges from the graph <code>G</code> and organize them into a DataFrame with columns for source nodes, target nodes, and edge attributes.</li>
  <li><strong>Expand edge attributes:</strong> If the edge attributes are stored as dictionaries, expand these into separate columns to make them more accessible.</li>
  <li><strong>Display the edges DataFrame:</strong> View the resulting DataFrame to verify its structure and content.</li>
</ul>
<p>The Python code snippet below demonstrates these steps:</p>
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">edges_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="n">G</span><span class="p">.</span><span class="nf">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="bp">True</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Source</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Target</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Attributes</span><span class="sh">'</span><span class="p">])</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">edges_df</span><span class="p">.</span><span class="n">empty</span> <span class="ow">and</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">edges_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Attributes</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">dict</span><span class="p">):</span>
    <span class="n">attributes_df</span> <span class="o">=</span> <span class="n">edges_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Attributes</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">)</span>
    <span class="n">edges_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">edges_df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Attributes</span><span class="sh">'</span><span class="p">]),</span> <span class="n">attributes_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code></pre></figure>


<p></p>
Convert edges to dgl format:
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">dgl</span>
<span class="kn">import</span> <span class="n">dgl.nn</span> <span class="k">as</span> <span class="n">dglnn</span>
<span class="kn">import</span> <span class="n">dgl.data</span>
<span class="kn">from</span> <span class="n">dgl.data</span> <span class="kn">import</span> <span class="n">DGLDataset</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="n">itertools</span>
<span class="n">unpickEdges</span><span class="o">=</span><span class="n">edges_df</span>
<span class="n">edge_index</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">unpickEdges</span><span class="p">[[</span><span class="sh">'</span><span class="s">Source</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Target</span><span class="sh">'</span><span class="p">]].</span><span class="n">T</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="o">=</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">g</span><span class="o">=</span><span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="p">))</span>
<span class="n">g</span><span class="o">=</span><span class="n">dgl</span><span class="p">.</span><span class="nf">add_self_loop</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
<span class="n">g</span>
<span class="nc">Graph</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">num_edges</span><span class="o">=</span><span class="mi">268</span><span class="p">,</span>
      <span class="n">ndata_schemes</span><span class="o">=</span><span class="p">{}</span>
      <span class="n">edata_schemes</span><span class="o">=</span><span class="p">{})</span></code></pre></figure>

<p></p>

<h4>Transform Text to Vectors</h4>
<p></p>

<p>This section describes how text data, specifically the artist biographies, is transformed into vector embeddings to be used as node features in a graph. We utilized the <code>'all-MiniLM-L6-v2'</code> model from Hugging Face for this purpose, which generates high-quality sentence embeddings.</p>
<ul>
  <li>
    <strong>Model Selection:</strong> The <code>'all-MiniLM-L6-v2'</code> model, a lightweight yet powerful transformer, was used for efficient text-to-vector translation.
  </li>
  <li>
    <strong>Embedding Creation:</strong> Artist biographies from the DataFrame are encoded into a tensor of size <code>[50, 384]</code>, where each row represents a 384-dimensional vector for an artist.
  </li>
  <li>
    <strong>Assigning Features:</strong> These embeddings are assigned as node features to the graph using the <code>ndata['feat']</code> attribute.
  </li>
</ul>

<p></p>
The Python code below demonstrates the embedding process and assignment to the graph:
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="nc">SentenceTransformer</span><span class="p">(</span><span class="sh">'</span><span class="s">all-MiniLM-L6-v2</span><span class="sh">'</span><span class="p">)</span>
<span class="n">node_embeddings</span> <span class="o">=</span> <span class="n">modelST</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">artists_df</span><span class="p">[</span><span class="sh">'</span><span class="s">bio</span><span class="sh">'</span><span class="p">],</span><span class="n">convert_to_tensor</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">node_embeddings</span> <span class="o">=</span> <span class="n">node_embeddings</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">))</span>
<span class="n">gNew</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">node_embeddings</span>
<span class="n">node_embeddings</span><span class="p">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">384</span><span class="p">])</span></code></pre></figure>

<p></p>

Input graph
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">g</span>
<span class="nc">Graph</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">num_edges</span><span class="o">=</span><span class="mi">268</span><span class="p">,</span>
      <span class="n">ndata_schemes</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">:</span> <span class="nc">Scheme</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">384</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)}</span>
      <span class="n">edata_schemes</span><span class="o">=</span><span class="p">{})</span></code></pre></figure>

<p></p>

<p></p>
<h4>GNN Link Prediction Model Training</h4>
<p>This subsection describes the process of training a GNN link prediction model, using code adapted from the DGL library. The focus is on leveraging the built-in functionalities for implementing and training GNN-based link prediction tasks.</p>
<p>The training pipeline includes constructing positive and negative edge graphs for the training and testing phases, defining the GNN architecture, and training the model using standard techniques. The training concludes with an evaluation of the model's performance using the AUC (Area Under the Curve) metric.</p>

<p></p>



<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">g</span><span class="p">.</span><span class="nf">edges</span><span class="p">()</span>
<span class="n">eids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_edges</span><span class="p">())</span>
<span class="n">eids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">permutation</span><span class="p">(</span><span class="n">eids</span><span class="p">)</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">eids</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="n">g</span><span class="p">.</span><span class="nf">number_of_edges</span><span class="p">()</span> <span class="o">-</span> <span class="n">test_size</span>
<span class="n">test_pos_u</span><span class="p">,</span> <span class="n">test_pos_v</span> <span class="o">=</span> <span class="n">u</span><span class="p">[</span><span class="n">eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]],</span> <span class="n">v</span><span class="p">[</span><span class="n">eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]]</span>
<span class="n">train_pos_u</span><span class="p">,</span> <span class="n">train_pos_v</span> <span class="o">=</span> <span class="n">u</span><span class="p">[</span><span class="n">eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]],</span> <span class="n">v</span><span class="p">[</span><span class="n">eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]]</span>
<span class="n">adj</span> <span class="o">=</span> <span class="n">sp</span><span class="p">.</span><span class="nf">coo_matrix</span><span class="p">((</span><span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">u</span><span class="p">)),</span> <span class="p">(</span><span class="n">u</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">v</span><span class="p">.</span><span class="nf">numpy</span><span class="p">())))</span>
<span class="n">adj_neg</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">adj</span><span class="p">.</span><span class="nf">todense</span><span class="p">()</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>
<span class="n">neg_u</span><span class="p">,</span> <span class="n">neg_v</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">adj_neg</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">neg_eids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">neg_u</span><span class="p">),</span> <span class="n">g</span><span class="p">.</span><span class="nf">number_of_edges</span><span class="p">())</span>
<span class="n">test_neg_u</span><span class="p">,</span> <span class="n">test_neg_v</span> <span class="o">=</span> <span class="n">neg_u</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]],</span> <span class="n">neg_v</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]]</span>
<span class="n">train_neg_u</span><span class="p">,</span> <span class="n">train_neg_v</span> <span class="o">=</span> <span class="n">neg_u</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]],</span> <span class="n">neg_v</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]]</span>
<span class="n">train_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">remove_edges</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">])</span></code></pre></figure>

<p></p>


<p></p>

<p></p>

<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">dgl.nn</span> <span class="kn">import</span> <span class="n">SAGEConv</span>
<span class="k">class</span> <span class="nc">GraphSAGE</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_feats</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">GraphSAGE</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">SAGEConv</span><span class="p">(</span><span class="n">in_feats</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">,</span> <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">SAGEConv</span><span class="p">(</span><span class="n">h_feats</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">,</span> <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">in_feat</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">in_feat</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span></code></pre></figure>

<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">dgl.function</span> <span class="k">as</span> <span class="n">fn</span>
<span class="n">train_pos_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">train_pos_u</span><span class="p">,</span> <span class="n">train_pos_v</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>
<span class="n">train_neg_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">train_neg_u</span><span class="p">,</span> <span class="n">train_neg_v</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>
<span class="n">test_pos_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">test_pos_u</span><span class="p">,</span> <span class="n">test_pos_v</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>
<span class="n">test_neg_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">test_neg_u</span><span class="p">,</span> <span class="n">test_neg_v</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>
<span class="k">class</span> <span class="nc">DotPredictor</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">g</span><span class="p">.</span><span class="nf">local_scope</span><span class="p">():</span>
            <span class="n">g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span>
            <span class="n">g</span><span class="p">.</span><span class="nf">apply_edges</span><span class="p">(</span><span class="n">fn</span><span class="p">.</span><span class="nf">u_dot_v</span><span class="p">(</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">g</span><span class="p">.</span><span class="n">edata</span><span class="p">[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">]</span></code></pre></figure>


<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">MLPPredictor</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">W1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">h_feats</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">W2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">h_feats</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">apply_edges</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">edges</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">edges</span><span class="p">.</span><span class="n">src</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">],</span> <span class="n">edges</span><span class="p">.</span><span class="n">dst</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">]],</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="nc">W2</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nc">W1</span><span class="p">(</span><span class="n">h</span><span class="p">))).</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)}</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">g</span><span class="p">.</span><span class="nf">local_scope</span><span class="p">():</span>
            <span class="n">g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span>
            <span class="n">g</span><span class="p">.</span><span class="nf">apply_edges</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">apply_edges</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">g</span><span class="p">.</span><span class="n">edata</span><span class="p">[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">]</span></code></pre></figure>


<p></p>
<p></p>



<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="nc">GraphSAGE</span><span class="p">(</span><span class="n">train_g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="nc">MLPPredictor</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">):</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">])</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">pos_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">neg_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])])</span>
    <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="nf">binary_cross_entropy_with_logits</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">compute_auc</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">):</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">]).</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span>
        <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">pos_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">neg_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]).</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="nf">roc_auc_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">itertools</span><span class="p">.</span><span class="nf">chain</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">pred</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span></code></pre></figure>


<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">all_logits</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">train_g</span><span class="p">,</span> <span class="n">train_g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">].</span><span class="nf">float</span><span class="p">())</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">e</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">In epoch {}, loss: {}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span></code></pre></figure>


<p></p>
<a href="#">
    <img src="/img/artPaint2.jpg" alt="Post Sample Image" width="333" />
</a>

<p></p>
<p></p>
Final evaluation:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">AUC</span><span class="sh">'</span><span class="p">,</span> <span class="nf">compute_auc</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">))</span>
<span class="n">AUC</span> <span class="mf">0.9171597633136095</span></code></pre></figure>

<p></p>

<p>To ensure the embedded vectors are preserved and accessible across sessions, they are saved to Google Drive as PyTorch tensors. This allows seamless reuse without recomputing the embeddings, saving time and computational resources.</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="sh">'</span><span class="s">/content/drive/My Drive/Art/artists_h.pt</span><span class="sh">'</span><span class="p">)</span>
<span class="n">load_h</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">/content/drive/My Drive/Art/artists_h.pt</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>

<p></p>
<h3>Paintings Graph</h3>
<p></p>
<h4>Create a Graph on Paintings</h4>
<p>In this subsection, we process artwork files to build a DataFrame that links paintings to their respective artists and prepares data for graph construction.</p>
<p>The following steps outline the workflow:</p>
<ul>
  <li>
    <strong>Process files in the directory:</strong> Iterate through the files in the specified directory, extract the painting's file name, artist's name, and assign a unique <code>File Index</code> to each painting.
  </li>
  <li>
    <strong>Match artist names to indices:</strong> The artist names extracted from the file names are mapped to their corresponding <code>Artist Index</code> using a sorted version of the <code>artists_df</code>.
  </li>
  <li>
    <strong>Create the paintings DataFrame:</strong> Combine the extracted file data, including <code>File Name</code>, <code>Artist Name</code>, <code>File Index</code>, and the mapped <code>Artist Index</code>, into a structured DataFrame for further analysis and graph creation.
  </li>
</ul>

<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">paintings_dir</span> <span class="o">=</span> <span class="sh">'</span><span class="s">/content/drive/My Drive/Art/paintings/</span><span class="sh">'</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">file_data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">file_index</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="n">paintings_dir</span><span class="p">):</span>
    <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">paintings_dir</span><span class="p">)):</span>  
        <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">isfile</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">paintings_dir</span><span class="p">,</span> <span class="nb">file</span><span class="p">)):</span>
            <span class="n">artist_name</span> <span class="o">=</span> <span class="nb">file</span><span class="p">.</span><span class="nf">rsplit</span><span class="p">(</span><span class="sh">'</span><span class="s">_</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">_</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="p">)</span>
            <span class="n">file_data</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="nb">file</span><span class="p">,</span> <span class="n">artist_name</span><span class="p">,</span> <span class="n">file_index</span><span class="p">))</span>
            <span class="n">file_index</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">File Name</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Artist Name</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">File Index</span><span class="sh">'</span><span class="p">]</span>
<span class="n">file_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">file_data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>
<span class="n">artists_sorted</span> <span class="o">=</span> <span class="n">artists_df</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">).</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  
<span class="n">artist_name_to_index</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">artists_sorted</span><span class="p">[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">])}</span>  
<span class="n">file_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Artist Index</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">file_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Artist Name</span><span class="sh">'</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="n">artist_name_to_index</span><span class="p">)</span>
<span class="n">file_df</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span></code></pre></figure>

<p></p>


<a href="#">
    <img src="/img/artPaint3.jpg" alt="Post Sample Image" width="444" />
</a>
<p></p>
<h4>Initialize and Build the Painting Graph</h4>
<p>This subsection describes the creation of a graph where nodes represent paintings, and edges connect paintings created by the same artist. The graph is then analyzed and converted to DGL format for use in machine learning tasks.</p>
<p>The following steps outline the workflow:</p>
<ul>
  <li>
    <strong>Initialize the graph:</strong> Use NetworkX to create an undirected graph.
  </li>
  <li>
    <strong>Add nodes with attributes:</strong> Each painting is added as a node, with its <code>File Index</code> as the identifier and <code>File Name</code> as a node attribute.
  </li>
  <li>
    <strong>Add edges:</strong> Paintings created by the same artist are connected. Edges are added between all pairs of paintings that share the same <code>Artist Index</code>.
  </li>
</ul>
<p>The Python code below demonstrates the implementation:</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">file_df</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
    <span class="n">G</span><span class="p">.</span><span class="nf">add_node</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">File Index</span><span class="sh">'</span><span class="p">],</span> <span class="n">file_name</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">File Name</span><span class="sh">'</span><span class="p">])</span>
<span class="n">artist_groups</span> <span class="o">=</span> <span class="n">file_df</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">Artist Index</span><span class="sh">'</span><span class="p">)[</span><span class="sh">'</span><span class="s">File Index</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">artist_groups</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">group</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">group</span><span class="p">)):</span>
            <span class="n">G</span><span class="p">.</span><span class="nf">add_edge</span><span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">group</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Number of nodes: </span><span class="si">{</span><span class="n">G</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">()</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Number of edges: </span><span class="si">{</span><span class="n">G</span><span class="p">.</span><span class="nf">number_of_edges</span><span class="p">()</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Average degree: </span><span class="si">{</span><span class="n">nx</span><span class="p">.</span><span class="nf">density</span><span class="p">(</span><span class="n">G</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">G</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="n">Number</span> <span class="n">of</span> <span class="n">nodes</span><span class="p">:</span> <span class="mi">1000</span>
<span class="n">Number</span> <span class="n">of</span> <span class="n">edges</span><span class="p">:</span> <span class="mi">9500</span>
<span class="n">Average</span> <span class="n">degree</span><span class="p">:</span> <span class="mf">177.781</span></code></pre></figure>


<p></p>
We extract nodes and edges from the graph and save them as DataFrames in Google Drive for future use.
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">nodes_data</span> <span class="o">=</span> <span class="p">[{</span><span class="sh">'</span><span class="s">Node</span><span class="sh">'</span><span class="p">:</span> <span class="n">n</span><span class="p">,</span> <span class="o">**</span><span class="n">G2</span><span class="p">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">n</span><span class="p">]}</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">G2</span><span class="p">.</span><span class="n">nodes</span><span class="p">]</span>
<span class="n">nodes_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">nodes_data</span><span class="p">)</span>
<span class="n">nodes_df</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">/content/drive/My Drive/Art/painting_graph_nodes.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">edges_data</span> <span class="o">=</span> <span class="p">[{</span><span class="sh">'</span><span class="s">Source</span><span class="sh">'</span><span class="p">:</span> <span class="n">u</span><span class="p">,</span> <span class="sh">'</span><span class="s">Target</span><span class="sh">'</span><span class="p">:</span> <span class="n">v</span><span class="p">,</span> <span class="o">**</span><span class="n">G2</span><span class="p">.</span><span class="n">edges</span><span class="p">[</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">]}</span> <span class="k">for</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">G2</span><span class="p">.</span><span class="n">edges</span><span class="p">]</span>
<span class="n">edges_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">edges_data</span><span class="p">)</span>
<span class="n">edges_df</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">/content/drive/My Drive/Art/painting_graph_edges.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></figure>

<p></p>

<h4>Image Features for Node Embeddings</h4>
<p>In this section, we use a pre-trained Convolutional Neural Network (CNN) to extract feature embeddings from the painting images. These features serve as node embeddings for the graph, enabling the model to capture meaningful visual patterns.</p>
<p><strong>Workflow:</strong></p>
<ul>
  <li>
    <strong>Image Preprocessing:</strong> Images are resized to <code>224x224</code> pixels, converted to tensors, and normalized using standard ImageNet mean and standard deviation values. This ensures compatibility with the pre-trained CNN model.
  </li>
  <li>
    <strong>Feature Extraction:</strong> Each preprocessed image is passed through the CNN (e.g., ResNet) to extract a high-dimensional feature vector. These vectors represent the visual content of the paintings.
  </li>
  <li>
    <strong>Embedding Storage:</strong> The extracted feature vector for each image is flattened, converted to a NumPy array, and stored in a dictionary with the file name as the key. This allows easy mapping between the image and its corresponding feature representation.
  </li>
</ul>
<p>This process generates a rich set of visual embeddings that can be used as input features for graph-based learning tasks.</p>


<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torchvision</span> <span class="kn">import</span> <span class="n">models</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="n">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="p">.</span><span class="nc">Resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)),</span>
    <span class="n">transforms</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
<span class="p">])</span>
<span class="n">image_vectors</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">file_names</span><span class="p">:</span>
    <span class="n">img_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">paintings_dir</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">).</span><span class="nf">convert</span><span class="p">(</span><span class="sh">'</span><span class="s">RGB</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">img_tensor</span> <span class="o">=</span> <span class="nf">transform</span><span class="p">(</span><span class="n">img</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="n">features</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">img_tensor</span><span class="p">).</span><span class="nf">flatten</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="n">image_vectors</span><span class="p">[</span><span class="n">file_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">features</span></code></pre></figure>


<p></p>

<p></p>

Save extracted vectors to Google Drive and validate:
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">vectors_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">image_vectors</span><span class="p">)</span>
<span class="n">vectors_df</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">/content/drive/My Drive/Art/image_vectors.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">loaded_image_vectors_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">/content/drive/My Drive/Art/image_vectors.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">loaded_image_vectors_df</span><span class="p">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span></code></pre></figure>


<p></p>
<h4>Transforming the Painting Graph to DGL Format</h4>
<p>This subsection describes the process of transforming the painting graph into DGL format, including edge and node feature assignments. This transformation enables efficient processing and modeling using DGL's graph-based machine learning tools.

<p></p>
The previously saved image feature vectors are loaded from the CSV file stored on Google Drive
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">image_vectors</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/drive/My Drive/Art/image_vectors.csv</span><span class="sh">"</span><span class="p">)</span>
<span class="n">image_vectors</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span></code></pre></figure>


<p></p>
<a href="#">
    <img src="/img/artPaint4.jpg" alt="Post Sample Image" width="900" />
</a>
<p></p>

<p>Workflow:</p>
<ul>
  <li>
    <strong>Create the DGL graph:</strong> The edges from <code>painting_graph_edges</code> are converted into a PyTorch tensor and used to define the graph structure. Self-loops are added to ensure every node has a connection to itself, which can enhance model performance.
  </li>
  <li>
    <strong>Assign node features:</strong> The image embeddings are transformed into a PyTorch tensor and assigned to the graph as node features using the <code>ndata['feat']</code> attribute. This allows the graph to carry meaningful data for each node.
  </li>
</ul>

<p></p>
<p>The following code demonstrates the transformation process:</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">unpickEdges</span><span class="o">=</span><span class="n">painting_graph_edges</span>
<span class="n">edge_index</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">unpickEdges</span><span class="p">[[</span><span class="sh">'</span><span class="s">Source</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Target</span><span class="sh">'</span><span class="p">]].</span><span class="n">T</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="o">=</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">gPaintings</span><span class="o">=</span><span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="p">))</span>
<span class="n">gPaintings</span><span class="o">=</span><span class="n">dgl</span><span class="p">.</span><span class="nf">add_self_loop</span><span class="p">(</span><span class="n">gPaintings</span><span class="p">)</span>
<span class="n">gPaintings</span>
<span class="nc">Graph</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">num_edges</span><span class="o">=</span><span class="mi">10500</span><span class="p">,</span>
      <span class="n">ndata_schemes</span><span class="o">=</span><span class="p">{}</span>
      <span class="n">edata_schemes</span><span class="o">=</span><span class="p">{})</span></code></pre></figure>


<p></p>

Next, the node features are assigned to the graph:
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">image_vectors_T</span> <span class="o">=</span> <span class="n">image_vectors</span><span class="p">.</span><span class="n">T</span>
<span class="n">image_vectors_T_df</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">image_vectors_T</span><span class="p">).</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="n">image_vectors_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">image_vectors_T_df</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span>
<span class="n">gPaintings</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_vectors_tensor</span>
<span class="n">gPaintings</span>
<span class="nc">Graph</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">num_edges</span><span class="o">=</span><span class="mi">10500</span><span class="p">,</span>
      <span class="n">ndata_schemes</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">:</span> <span class="nc">Scheme</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2048</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)}</span>
      <span class="n">edata_schemes</span><span class="o">=</span><span class="p">{})</span></code></pre></figure>


<p></p>
<p>The resulting graph <code>gPaintings</code> includes 1000 nodes, 10,500 edges, and node features of shape <code>(2048,)</code>. It is now ready for use in graph-based machine learning tasks.</p>
<p></p>

<h4>GNN Link Prediction Model Training for the Painting Graph</h4>
<p></p>
In this subsection, we focus on training a GNN model for link prediction on the painting graph, utilizing the graph and node features constructed in the previous steps. This process is similar to the training conducted for the artist graph but specifically tailored to predict links between paintings based on their visual embeddings.
<p></p>

<ul>
  <li>
    <strong>Forward pass:</strong> The node features (image embeddings) are passed through the GNN model to compute embeddings for each painting. Positive and negative edge scores are calculated using the model's prediction function.
  </li>
  <li>
    <strong>Loss computation:</strong> A loss function compares the predicted scores against the ground truth, guiding the model's optimization.
  </li>
  <li>
    <strong>Backward pass and optimization:</strong> Gradients are calculated with respect to the loss, and the optimizer updates the model's parameters to minimize the loss.
  </li>
</ul>
The training process iterates for 100 epochs, logging the loss every 5 epochs:


<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">all_logits</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="c1"># forward
</span>    <span class="n">h</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">train_g</span><span class="p">,</span> <span class="n">train_g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">].</span><span class="nf">float</span><span class="p">())</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">)</span>
    <span class="c1"># backward
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">e</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">In epoch {}, loss: {}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span></code></pre></figure>


<p></p>
<a href="#">
    <img src="/img/artPaint5.jpg" alt="Post Sample Image" width="321" />
</a>

<p></p>



<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">AUC</span><span class="sh">'</span><span class="p">,</span> <span class="nf">compute_auc</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">))</span>
<span class="n">AUC</span> <span class="mf">0.9827046611570248</span></code></pre></figure>

<p></p>
<p></p>
Save embedded vectors
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="sh">'</span><span class="s">/content/drive/My Drive/Art/paintings_h.pt</span><span class="sh">'</span><span class="p">)</span>
<span class="n">load_h</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">/content/drive/My Drive/Art/paintings_h.pt</span><span class="sh">'</span><span class="p">)</span>
<span class="n">load_h</span><span class="p">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">128</span><span class="p">])</span></code></pre></figure>


<p></p>
<h3>Unified Knowledge Graph</h3>
<p></p>
<h4>Combining Artist and Painting Graphs into a Unified Knowledge Graph</h4>
<p>We started by constructing two separate graphs:</p>
<ul>
  <li>
    <strong>Artist Graph:</strong> Artist biographies were converted into vectors of size <code>384</code> using a transformer model, followed by GNN link prediction, which transformed these embeddings into vectors of size <code>128</code>.
  </li>
  <li>
    <strong>Painting Graph:</strong> Paintings were represented as vectors of size <code>2048</code> using a pre-trained CNN model, followed by GNN link prediction, which transformed these embeddings into vectors of size <code>128</code>.
  </li>
</ul>
<p><strong>Next Step:</strong> We will combine the Artist graph and Painting graph into a unified Knowledge Graph. This Knowledge Graph (suggested name: <code>ArtKnowledgeGraph</code>) will map painting nodes to their corresponding artist nodes. The node features for this unified graph will be represented by vectors of size <code>128</code>, ensuring a consistent embedding space across all node types.</p>

<p></p>

<p></p>
<p></p>

<p>To create a unified Knowledge Graph, we need to ensure that nodes from both the Artist graph and the Painting graph have unique indices. This adjustment is achieved by offsetting the indices of the Artist nodes:</p>
<ul>
  <li>
    <strong>Unique indexing:</strong> Since the Painting graph contains 1000 nodes (indexed from <code>0</code> to <code>999</code>), we add an offset of <code>1000</code> to the indices of the Artist nodes. This ensures that Artist node indices start from <code>1000</code> and do not overlap with Painting node indices.
  </li>
  <li>
    <strong>Prepare adjusted Artist nodes:</strong> After offsetting the indices, the Artist nodes are prepared with the updated <code>nodeIdx</code> and their corresponding names. These are then included in the unified Knowledge Graph.
  </li>
</ul>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">artist_graph_nodes</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/drive/My Drive/Art/artist_graph_nodes.csv</span><span class="sh">"</span><span class="p">)</span>
<span class="n">artist_graph_edges</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/drive/My Drive/Art/artist_graph_edges.csv</span><span class="sh">"</span><span class="p">)</span>
<span class="n">artist_graph_nodes</span><span class="p">[</span><span class="sh">'</span><span class="s">Node</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">artist_graph_nodes</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1000</span>
<span class="n">artist_graph_nodes</span> <span class="o">=</span> <span class="n">artist_graph_nodes</span><span class="p">[[</span><span class="sh">'</span><span class="s">Node</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">artist_graph_edges</span><span class="p">[</span><span class="sh">'</span><span class="s">Source</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">artist_graph_edges</span><span class="p">[</span><span class="sh">'</span><span class="s">Source</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1000</span>
<span class="n">artist_graph_edges</span><span class="p">[</span><span class="sh">'</span><span class="s">Target</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">artist_graph_edges</span><span class="p">[</span><span class="sh">'</span><span class="s">Target</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1000</span></code></pre></figure>

<p></p>

<p></p>
Knowledge Graph nodes: head and tail
<a href="#">
    <img src="/img/artPaint8.jpg" alt="Post Sample Image" width="499" />
</a>
<p></p>


Painting nodes are prepared for the unified Knowledge Graph by mapping each painting to its corresponding artist and assigning unique artist indices.
<p></p>
<ul>
  <li>
    Load painting nodes:The painting graph nodes are loaded from a CSV file, and the column <code>file_name</code> is renamed to <code>name</code> for consistency.
  </li>
  <li>
    Map paintings to artists: A new column, <code>artist_name</code>, is created by extracting the artist's name from the painting's file name. This assumes the artist's name is the first two words in the file name, separated by underscores.
  </li>
  <li>
    Assign unique artist indices: An <code>artist_index</code> column is created by dividing the painting node index (<code>Node</code>) by 20 (integer division) and adding an offset of <code>1000</code>. This ensures unique indexing for artists across the graph.
  </li>
</ul>
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">painting_graph_nodes</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/drive/My Drive/Art/painting_graph_nodes.csv</span><span class="sh">"</span><span class="p">)</span>
<span class="n">painting_graph_nodes</span> <span class="o">=</span> <span class="n">painting_graph_nodes</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">file_name</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">})</span>
<span class="n">painting_artist_graph_nodes</span><span class="o">=</span><span class="n">painting_graph_nodes</span>
<span class="n">painting_artist_graph_nodes</span><span class="p">[</span><span class="sh">'</span><span class="s">artist_name</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">painting_graph_nodes</span><span class="p">[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">]</span>
   <span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">_</span><span class="sh">'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="o">+</span><span class="n">x</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">_</span><span class="sh">'</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>
<span class="n">painting_artist_graph_nodes</span><span class="p">[</span><span class="sh">'</span><span class="s">artist_index</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">painting_graph_nodes</span><span class="p">[</span><span class="sh">'</span><span class="s">Node</span><span class="sh">'</span><span class="p">]</span>
   <span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span> <span class="o">//</span> <span class="mi">20</span><span class="p">)</span><span class="o">+</span><span class="mi">1000</span><span class="p">)</span></code></pre></figure>


<p></p>


<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">xxx</span></code></pre></figure>

<p></p>
<p></p>

In this post we demonstrated how to use transformers and GNN link predictions to rewire knowledge graphs.
<p></p>
<a href="#">
    <img src="/img/artPaint11.jpg" alt="Post Sample Image" width="234" height="314" />
</a>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">artist_graph_nodes</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">artist_graph_nodes</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1000</span>
<span class="n">artist_graph_nodes</span> <span class="o">=</span> <span class="n">artist_graph_nodes</span><span class="p">[[</span><span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">]]</span></code></pre></figure>

<p></p>
<a href="#">
    <img src="/img/artPaint12.jpg" alt="Post Sample Image" width="234" height="314" />
</a>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">artist_graph_edges</span><span class="p">[</span><span class="sh">'</span><span class="s">Source</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">artist_graph_edges</span><span class="p">[</span><span class="sh">'</span><span class="s">Source</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1000</span>
<span class="n">artist_graph_edges</span><span class="p">[</span><span class="sh">'</span><span class="s">Target</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">artist_graph_edges</span><span class="p">[</span><span class="sh">'</span><span class="s">Target</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1000</span>
<span class="n">artist_graph_edges</span> <span class="o">=</span> <span class="n">artist_graph_edges</span><span class="p">[[</span><span class="sh">'</span><span class="s">Source</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Target</span><span class="sh">'</span><span class="p">]]</span></code></pre></figure>

<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">painting_artist_graph_nodes</span><span class="o">=</span><span class="n">painting_graph_nodes</span>
<span class="n">painting_artist_graph_nodes</span><span class="p">[</span><span class="sh">'</span><span class="s">artist_name</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>
    <span class="n">painting_graph_nodes</span><span class="p">[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">_</span><span class="sh">'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="o">+</span><span class="n">x</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">_</span><span class="sh">'</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>
<span class="n">painting_artist_graph_nodes</span><span class="p">[</span><span class="sh">'</span><span class="s">artist_index</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>
    <span class="n">painting_graph_nodes</span><span class="p">[</span><span class="sh">'</span><span class="s">Node</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span> <span class="o">//</span> <span class="mi">20</span><span class="p">)</span><span class="o">+</span><span class="mi">1000</span><span class="p">)</span>

<span class="n">painting_graph_nodes</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span></code></pre></figure>

<p></p>

<p></p>
<a href="#">
    <img src="/img/artPaint13.jpg" alt="Post Sample Image" width="444" height="500" />
</a>

<p>To establish connections between painting nodes and their corresponding artist nodes, edges are created by matching paintings to artists based on their indices:</p>
<ul>
  <li><strong>Find matching artist nodes:</strong> For each painting node, the <code>artist_index</code> is used to identify the matching artist node in <code>artist_graph_nodes</code>.</li>
  <li><strong>Create edges:</strong> For each match, an edge is added between the painting node and the artist node. These edges represent the relationship between a painting and its creator.</li>
  <li><strong>Convert edges to DataFrame:</strong> The resulting edges are stored in a DataFrame with <code>Source</code> and <code>Target</code> columns, representing the painting and artist nodes, respectively.</li>
</ul>
<p>The following code implements this process:</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">edges</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">painting_row</span> <span class="ow">in</span> <span class="n">painting_artist_graph_nodes</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
    <span class="n">artist_matches</span> <span class="o">=</span> <span class="n">artist_graph_nodes</span><span class="p">[</span><span class="n">artist_graph_nodes</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span>
        <span class="n">painting_row</span><span class="p">[</span><span class="sh">'</span><span class="s">artist_index</span><span class="sh">'</span><span class="p">]]</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">artist_row</span> <span class="ow">in</span> <span class="n">artist_matches</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
    <span class="n">edges</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">painting_row</span><span class="p">[</span><span class="sh">'</span><span class="s">Node</span><span class="sh">'</span><span class="p">],</span> <span class="n">artist_row</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">]))</span>
<span class="n">painting_artist_graph_edges</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Source</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Target</span><span class="sh">'</span><span class="p">])</span></code></pre></figure>


<p></p>
The unified Knowledge Graph is created by combining nodes and edges from the Painting and Artist graphs. Painting nodes and Artist nodes are concatenated into a single DataFrame, ensuring all nodes are represented. Similarly, edges between paintings and their artists (painting_artist_graph_edges) and edges within the Artist graph (artist_graph_edges) are concatenated into a single DataFrame of edges. The resulting Knowledge Graph contains 1218 edges, ready for further graph-based processing and analysis.
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">knowledge_graph_nodes</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">painting_nodes</span><span class="p">,</span> <span class="n">artist_nodes</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">knowledge_graph_edges</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">painting_artist_graph_edges</span><span class="p">,</span> <span class="n">artist_graph_edges</span><span class="p">],</span>
    <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">knowledge_graph_edges</span><span class="p">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">1218</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span></code></pre></figure>

<p></p>


<h4>Transforming the Unified Graph to DGL Format</h4>
<p></p>
<p></p>
<p></p>
The Knowledge Graph is constructed as a DGL graph object. The edges from knowledge_graph_edges are transformed into a PyTorch tensor to define the connections between nodes. These edges are used to create a DGL graph, and self-loops are added to ensure that each node is connected to itself, which can improve GNN performance. The node features are represented by knowledge_graph_embeddings, with each node having a 128-dimensional feature vector. The resulting graph contains 1050 nodes and 2268 edges, making it ready for graph-based learning tasks.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">unpickEdges</span><span class="o">=</span><span class="n">knowledge_graph_edges</span>
<span class="n">edge_index</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">unpickEdges</span><span class="p">[[</span><span class="sh">'</span><span class="s">Source</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Target</span><span class="sh">'</span><span class="p">]].</span><span class="n">T</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="o">=</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">gKG</span><span class="o">=</span><span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="p">))</span>
<span class="n">gKG</span><span class="o">=</span><span class="n">dgl</span><span class="p">.</span><span class="nf">add_self_loop</span><span class="p">(</span><span class="n">gKG</span><span class="p">)</span>
<span class="n">gKG</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">knowledge_graph_embeddings</span>
<span class="n">gKG</span>
<span class="nc">Graph</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">1050</span><span class="p">,</span> <span class="n">num_edges</span><span class="o">=</span><span class="mi">2268</span><span class="p">,</span>
      <span class="n">ndata_schemes</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">:</span> <span class="nc">Scheme</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">128</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)}</span>
      <span class="n">edata_schemes</span><span class="o">=</span><span class="p">{})</span></code></pre></figure>

<p></p>

<p></p>
<h4>GNN Link Prediction Model for Unified Knowledge Graph</h4>

<p></p>
<p>The final phase of training involves running the GNN link prediction model for 2000 epochs. During each epoch, the model performs a forward pass to compute node embeddings, calculates scores for positive and negative edges, and computes the loss. Gradients are backpropagated to update model parameters, optimizing the model for link prediction. Progress is logged every 100 epochs, showing the loss to monitor convergence.</p>
<p>After training, the model's performance is evaluated on the test set. Positive and negative edge scores are computed, and the AUC (Area Under the Curve) metric is used to assess the model's ability to distinguish between true and false links. The final AUC score achieved is <code>0.9007</code>, indicating strong predictive performance.</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">all_logits</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">):</span>
    <span class="c1"># forward
</span>    <span class="n">h</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">train_g</span><span class="p">,</span> <span class="n">train_g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">].</span><span class="nf">float</span><span class="p">())</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">)</span>
    <span class="c1"># backward
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">e</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">In epoch {}, loss: {}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span></code></pre></figure>

<p></p>
<a href="#">
    <img src="/img/artPaint10.jpg" alt="Post Sample Image" width="374" />
</a>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">AUC</span><span class="sh">'</span><span class="p">,</span> <span class="nf">compute_auc</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">))</span>
<span class="n">AUC</span> <span class="mf">0.9007130791642577</span></code></pre></figure>

<p></p>
<p></p>
<p>The node embeddings for the unified Knowledge Graph are saved and reloaded to enable persistent storage and reuse:</p>
<ul>
  <li><strong>Save embeddings:</strong> The node embeddings, represented by the variable <code>h</code>, are saved to Google Drive as a PyTorch tensor using <code>torch.save</code>. This ensures that the embeddings can be preserved for later use.</li>
  <li><strong>Load embeddings:</strong> The saved embeddings are reloaded from Google Drive using <code>torch.load</code>. This allows for seamless reuse of the computed embeddings without requiring recomputation.</li>
</ul>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="sh">'</span><span class="s">/content/drive/My Drive/Art/artist_knowledge_graph_h.pt</span><span class="sh">'</span><span class="p">)</span>
<span class="n">load_h</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">/content/drive/My Drive/Art/artist_knowledge_graph_h.pt</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>

<p></p>
<h2>Interpreting GNN Link Prediction Model Results</h2>

<p>The results of the GNN Link Prediction (LP) model go beyond merely predicting links; they generate <em>embedded vectors</em> for each node in the Unified Knowledge Graph. These vectors, consistent in size, provide high-dimensional representations of the nodes, capturing both contextual and relational information. Such embeddings enable advanced analysis using techniques like <em>cosine similarity</em>, <em>clustering</em>, and <em>building new graph layers</em>, offering deeper insights into the structure and relationships within the graph.</p>

<p>The Unified Knowledge Graph in this study consists of <strong>50 artist nodes</strong> and <strong>1000 painting nodes</strong>, all encoded as vectors of size 128. The GNN LP model ensures a consistent embedding space across all nodes, enabling seamless analysis and comparisons between different node types.</p>

<p>In this section, we explore two main areas of interpretation:</p>
<ul>
    <li><strong>Artist-artist relationships:</strong> Examining similarities in the embedded vectors to identify shared themes, influences, or overlapping artistic philosophies.</li>
    <li><strong>Painting-painting connections:</strong> Analyzing stylistic or contextual similarities between paintings through their embeddings.</li>
</ul>

By focusing on embeddings rather than direct link predictions, this study highlights the ability of GNN models to uncover nuanced patterns and provide a deeper understanding of the complex relationships within the art world.

<p></p>
<h3>Model Results Analysis</h3>
<p></p>
In this step, we calculate the cosine similarity between all pairs of nodes in the Unified Knowledge Graph using their embedded vectors. The similarity scores, generated by a PyTorch function, quantify the relationships between nodes based on their high-dimensional embeddings.
<p></p>
The result is stored in a DataFrame containing 1,102,500 rows, representing all possible pairs of 1,050 nodes (50 artists and 1,000 paintings). Each row includes the indices of the two nodes and their corresponding similarity score, which serves as the foundation for analyzing relationships between nodes in the graph.
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cosine_scores_gnn</span> <span class="o">=</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">load_h</span><span class="p">,</span> <span class="n">load_h</span><span class="p">)</span>
<span class="n">pairs_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span> <span class="nf">len</span><span class="p">(</span><span class="n">cosine_scores_gnn</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">cosine_scores_gnn</span><span class="p">)):</span>  
        <span class="n">pairs_scores</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span>
            <span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">:</span> <span class="n">j</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">cosine_scores_gnn</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="nf">item</span><span class="p">()</span>  <span class="c1"># Use `.item()` for scalar tensors
</span>        <span class="p">})</span>

<span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">pairs_scores</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">1102500</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span></code></pre></figure>

<p></p>
<p></p>
<p>This step enhances the similarity DataFrame by joining node information from the Unified Knowledge Graph. For each pair of indices (<code>idx1</code> and <code>idx2</code>), node metadata such as names and types are added, providing contextual information about the nodes involved in each similarity computation.</p>

<p>Key steps include:</p>
<ul>
    <li><strong>Joining node information:</strong> The <code>idx1</code> and <code>idx2</code> columns are matched with the <code>nodeIdx</code> column in the Knowledge Graph nodes DataFrame, adding relevant details about each node.</li>
    <li><strong>Renaming columns:</strong> After the join, node metadata (<code>nodeName</code> and <code>nodeType</code>) is renamed to <code>node1_name</code>, <code>node1_type</code>, <code>node2_name</code>, and <code>node2_type</code> for clarity.</li>
    <li><strong>Dropping redundant columns:</strong> Extra columns from the join (<code>nodeIdx_x</code> and <code>nodeIdx_y</code>) are removed, keeping the DataFrame clean and focused on relevant information.</li>
</ul>

<p>The resulting DataFrame includes enriched details about each pair of nodes, laying the groundwork for deeper analysis of relationships within the graph.</p>


<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">knowledge_graph_nodes</span><span class="p">,</span> <span class="n">left_on</span><span class="o">=</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">,</span> <span class="n">right_on</span><span class="o">=</span><span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">nodeName</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">node1_name</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">nodeType</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">node1_type</span><span class="sh">'</span><span class="p">})</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">knowledge_graph_nodes</span><span class="p">,</span> <span class="n">left_on</span><span class="o">=</span><span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">,</span> <span class="n">right_on</span><span class="o">=</span><span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">nodeName</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">node2_name</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">nodeType</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">node2_type</span><span class="sh">'</span><span class="p">})</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIdx_x</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">nodeIdx_y</span><span class="sh">'</span><span class="p">])</span>
<span class="n">graph_pairs</span> <span class="o">=</span> <span class="n">df</span></code></pre></figure>

<p></p>

<p></p>
<a href="#">
    <img src="/img/artPaint20.jpg" alt="Post Sample Image" width="555" />
</a>
<p></p>

<h4>Cosine Similarity Score Distributions</h4>

<p>The GNN Link Prediction model generates similarity scores for each pair of nodes in the Unified Knowledge Graph. These scores represent the relationships between nodes and provide insights into the structure and connections within the graph.</p>


<p>For all node pairs, excluding self-loops, scores range from -0.515 to 1.000, with a mean of approximately 0.460. This indicates that many pairs exhibit moderate similarity, while higher scores highlight stronger relationships.</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">filtered_graph_pairs</span> <span class="o">=</span> <span class="n">graph_pairs</span><span class="p">[</span><span class="n">graph_pairs</span><span class="p">[</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">]</span> <span class="o">!=</span> <span class="n">graph_pairs</span><span class="p">[</span><span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">overall_scores</span> <span class="o">=</span> <span class="n">filtered_graph_pairs</span><span class="p">[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">]</span>
<span class="n">overall_stats</span> <span class="o">=</span> <span class="n">overall_scores</span><span class="p">.</span><span class="nf">describe</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Overall Score Distribution:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">overall_stats</span><span class="p">)</span>
<span class="n">Overall</span> <span class="n">Score</span> <span class="n">Distribution</span><span class="p">:</span>
 <span class="n">count</span>   <span class="mf">1101450.000000</span>
<span class="n">mean</span>          <span class="mf">0.460064</span>
<span class="n">std</span>           <span class="mf">0.337415</span>
<span class="nb">min</span>          <span class="o">-</span><span class="mf">0.515314</span>
<span class="mi">25</span><span class="o">%</span>           <span class="mf">0.217390</span>
<span class="mi">50</span><span class="o">%</span>           <span class="mf">0.471504</span>
<span class="mi">75</span><span class="o">%</span>           <span class="mf">0.744774</span>
<span class="nb">max</span>           <span class="mf">1.000000</span></code></pre></figure>

<p></p>
<p>Artist-artist pairs show a higher mean score of 0.621, reflecting strong semantic relationships such as shared influences or overlapping styles.
<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">artist_artist_pairs</span> <span class="o">=</span> <span class="n">filtered_graph_pairs</span><span class="p">[</span>
    <span class="p">(</span><span class="n">filtered_graph_pairs</span><span class="p">[</span><span class="sh">'</span><span class="s">node1_type</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">artist</span><span class="sh">'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">filtered_graph_pairs</span><span class="p">[</span><span class="sh">'</span><span class="s">node2_type</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">artist</span><span class="sh">'</span><span class="p">)</span>
<span class="p">]</span>
<span class="n">artist_artist_scores</span> <span class="o">=</span> <span class="n">artist_artist_pairs</span><span class="p">[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">]</span>
<span class="n">artist_stats</span> <span class="o">=</span> <span class="n">artist_artist_scores</span><span class="p">.</span><span class="nf">describe</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Artist-Artist Score Distribution:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">artist_stats</span><span class="p">)</span>
<span class="n">Artist</span><span class="o">-</span><span class="n">Artist</span> <span class="n">Score</span> <span class="n">Distribution</span><span class="p">:</span>
 <span class="n">count</span>    <span class="mf">2450.000000</span>
<span class="n">mean</span>        <span class="mf">0.621267</span>
<span class="n">std</span>         <span class="mf">0.291015</span>
<span class="nb">min</span>        <span class="o">-</span><span class="mf">0.281765</span>
<span class="mi">25</span><span class="o">%</span>         <span class="mf">0.455145</span>
<span class="mi">50</span><span class="o">%</span>         <span class="mf">0.688079</span>
<span class="mi">75</span><span class="o">%</span>         <span class="mf">0.860471</span>
<span class="nb">max</span>         <span class="mf">0.992316</span></code></pre></figure>

<p></p>



In contrast, painting-painting pairs have a mean score of 0.477, demonstrating diverse visual and contextual connections between artworks.</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">painting_painting_pairs</span> <span class="o">=</span> <span class="n">filtered_graph_pairs</span><span class="p">[</span>
    <span class="p">(</span><span class="n">filtered_graph_pairs</span><span class="p">[</span><span class="sh">'</span><span class="s">node1_type</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">painting</span><span class="sh">'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">filtered_graph_pairs</span><span class="p">[</span><span class="sh">'</span><span class="s">node2_type</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">painting</span><span class="sh">'</span><span class="p">)</span>
<span class="p">]</span>
<span class="n">painting_scores</span> <span class="o">=</span> <span class="n">painting_painting_pairs</span><span class="p">[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">]</span>
<span class="n">painting_stats</span> <span class="o">=</span> <span class="n">painting_scores</span><span class="p">.</span><span class="nf">describe</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Painting-Painting Score Distribution:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">painting_stats</span><span class="p">)</span>
<span class="n">Painting</span><span class="o">-</span><span class="n">Painting</span> <span class="n">Score</span> <span class="n">Distribution</span><span class="p">:</span>
 <span class="n">count</span>    <span class="mf">999000.000000</span>
<span class="n">mean</span>          <span class="mf">0.477173</span>
<span class="n">std</span>           <span class="mf">0.338798</span>
<span class="nb">min</span>          <span class="o">-</span><span class="mf">0.515314</span>
<span class="mi">25</span><span class="o">%</span>           <span class="mf">0.232907</span>
<span class="mi">50</span><span class="o">%</span>           <span class="mf">0.492818</span>
<span class="mi">75</span><span class="o">%</span>           <span class="mf">0.769807</span>
<span class="nb">max</span>           <span class="mf">1.000000</span></code></pre></figure>

<p></p>


<p>These distributions reveal the model's ability to capture meaningful relationships across different types of nodes, setting the stage for deeper analysis of highly connected and less connected nodes. Such insights are valuable for exploring relationships in art and uncovering hidden patterns.</p>
<p></p>
<p></p>
<p></p>
<a href="#">
    <img src="/img/artPaint21.jpg" alt="Post Sample Image" width="711" />
</a>
<p></p>
<p>This analysis explores the distribution of cosine similarity scores for painting-painting pairs. The scores are grouped into intervals ranging from -1.0 to 1.0 in steps of 0.1. Data is filtered to include only painting-painting connections, and a histogram visualizes the frequency of pairs within each interval. The results highlight a concentration of pairs in higher intervals (e.g., <code>0.9-1.0</code>), suggesting strong stylistic or thematic similarities between many paintings. In contrast, lower intervals reveal fewer connections, emphasizing weaker or negative correlations.</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">bins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">bins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.001</span>
<span class="n">painting_painting_pairs</span> <span class="o">=</span> <span class="n">filtered_graph_pairs</span><span class="p">[</span>
    <span class="p">(</span><span class="n">filtered_graph_pairs</span><span class="p">[</span><span class="sh">'</span><span class="s">node1_type</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">painting</span><span class="sh">'</span><span class="p">)</span> <span class="o">&amp;</span>
    <span class="p">(</span><span class="n">filtered_graph_pairs</span><span class="p">[</span><span class="sh">'</span><span class="s">node2_type</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">painting</span><span class="sh">'</span><span class="p">)</span>
<span class="p">]</span>
<span class="n">frequency</span><span class="p">,</span> <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">histogram</span><span class="p">(</span><span class="n">painting_painting_pairs</span><span class="p">[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">)</span>
<span class="n">intervals</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="n">bin_edges</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s">-</span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="n">bin_edges</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">bin_edges</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
<span class="n">freq_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">'</span><span class="s">Interval</span><span class="sh">'</span><span class="p">:</span> <span class="n">intervals</span><span class="p">,</span> <span class="sh">'</span><span class="s">Frequency</span><span class="sh">'</span><span class="p">:</span> <span class="n">frequency</span><span class="p">})</span>
<span class="n">freq_df</span> <span class="o">=</span> <span class="n">freq_df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nf">print</span><span class="p">(</span><span class="n">freq_df</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">bar</span><span class="p">(</span><span class="n">freq_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Interval</span><span class="sh">'</span><span class="p">],</span> <span class="n">freq_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Frequency</span><span class="sh">'</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">skyblue</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Cosine Similarity Distribution for Painting-Painting Pairs</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Cosine Similarity Intervals</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Frequency</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">().</span><span class="nf">invert_xaxis</span><span class="p">()</span>  <span class="c1"># Invert x-axis for descending order
</span><span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure>

<p></p>
<p></p>
<p></p>
<a href="#">
    <img src="/img/artPaint24.jpg" alt="Post Sample Image" width="500" />
</a>
<p></p>
<p></p>
<a href="#">
    <img src="/img/artPaint22.jpg" alt="Post Sample Image" width="654" />
</a>
<p></p>
<p></p>
<a href="#">
    <img src="/img/artPaint23.jpg" alt="Post Sample Image" width="654" />
</a>
<p></p>

<p></p><p></p>


<p></p><p></p>


<p></p>

<p></p>
<h3>Painting-Painting Connections</h3>
<p>This section focuses on analyzing connections between paintings based on their similarity scores, emphasizing relationships that span across different artists. By filtering and enriching the DataFrame, we can better understand how paintings from various artists relate to one another.</p>

<p>Key steps include:</p>
<ul>
    <li><strong>Filtering painting-painting pairs:</strong> Rows where both nodes are of type <code>painting</code> are extracted, creating a subset of the data that exclusively examines relationships between paintings.</li>
    <li><strong>Extracting artist names:</strong> For each painting, the artist’s name is derived from the file name by splitting the string and capturing the relevant segment. The artist names are stored in new columns <code>artist1</code> and <code>artist2</code>.</li>
    <li><strong>Cross-artist connections:</strong> Connections between paintings created by different artists are identified by filtering for pairs where <code>artist1</code> is not equal to <code>artist2</code>. Additionally, only unique pairs are retained by ensuring <code>idx1 &lt; idx2</code>.</li>
</ul>
<p></p>
The resulting DataFrame highlights cross-artist painting relationships, providing insights into stylistic or thematic similarities between works by different creators.</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">painting_pairs</span><span class="o">=</span><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">node1_type</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="sh">'</span><span class="s">painting</span><span class="sh">'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">node2_type</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="sh">'</span><span class="s">painting</span><span class="sh">'</span><span class="p">)]</span>
<span class="n">painting_pairs</span><span class="p">[</span><span class="sh">'</span><span class="s">artist1</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">painting_pairs</span><span class="p">[</span><span class="sh">'</span><span class="s">node1_name</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">_</span><span class="sh">'</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span class="n">painting_pairs</span><span class="p">[</span><span class="sh">'</span><span class="s">artist2</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">painting_pairs</span><span class="p">[</span><span class="sh">'</span><span class="s">node2_name</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">_</span><span class="sh">'</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span class="n">dfp</span><span class="o">=</span><span class="n">painting_pairs</span></code></pre></figure>

<p></p>
<p></p>
<h4>Cross-Artist Painting Connections Analysis</h4>
<p>
The analysis focuses on identifying connections between paintings created by different artists, highlighting stylistic or thematic similarities. By filtering pairs of paintings where the creators are distinct, and ensuring unique combinations, we analyzed a total of <strong>490,000 cross-artist connections</strong>. The top-scoring pairs based on cosine similarity are presented below, offering insights into overlapping influences and shared artistic elements.
</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">diffArtistPaintings</span><span class="o">=</span> <span class="n">dfp</span><span class="p">[(</span><span class="n">dfp</span><span class="p">[</span><span class="sh">'</span><span class="s">artist1</span><span class="sh">'</span><span class="p">]</span><span class="o">!=</span><span class="n">dfp</span><span class="p">[</span><span class="sh">'</span><span class="s">artist2</span><span class="sh">'</span><span class="p">])</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">dfp</span><span class="p">[</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">dfp</span><span class="p">[</span><span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">])]</span>
<span class="n">diffArtistPaintings</span><span class="p">.</span><span class="n">shape</span> <span class="p">:</span> <span class="p">(</span><span class="mi">490000</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="n">diffArtistPaintings</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">).</span><span class="nf">tail</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span></code></pre></figure>

<p></p>
<a href="#">
    <img src="/img/artPaint16.jpg" alt="Post Sample Image" width="555" />
</a>
<p></p>
Observations:
<ul>
  <li><strong>Stylistic Overlaps:</strong> High similarity scores suggest shared stylistic elements or thematic connections between paintings, even from different movements.</li>
  <li><strong>Artistic Influence:</strong> These links may indicate underlying inspirations or techniques shared across eras or artistic philosophies.</li>
  <li><strong>Applications:</strong> The insights can support art recommendations, historical analyses, or new narratives in understanding artistic relationships.</li>
</ul>
<p></p>
<p></p>
<a href="#">
    <img src="/img/artPaint19.jpg" alt="Post Sample Image" width="777" />
</a>
<p></p>
<h4>Exploring Painting-Painting Connections Within the Same Artist</h4>
<p>This table highlights painting-painting connections within the works of the same artist, showcasing the least similar pairs based on cosine similarity scores derived from the GNN embeddings.</p>

<p></p>
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">artistPaintings</span><span class="o">=</span> <span class="n">dfp</span><span class="p">[(</span><span class="n">dfp</span><span class="p">[</span><span class="sh">'</span><span class="s">artist1</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">dfp</span><span class="p">[</span><span class="sh">'</span><span class="s">artist2</span><span class="sh">'</span><span class="p">])</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">dfp</span><span class="p">[</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">dfp</span><span class="p">[</span><span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">])]</span>
<span class="n">artistPaintings</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">).</span><span class="nf">head</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span></code></pre></figure>

<p></p>
<p></p>
<a href="#">
    <img src="/img/artPaint17b.jpg" alt="Post Sample Image" width="555" />
</a>
<p></p>
Key Observations
<ul>
  <li><strong>Low Cosine Similarity Within Same Artist's Works:</strong>
    <ul>
      <li><em>Hieronymus Bosch</em> has the lowest similarity score (0.2722), indicating significant variation between the chosen paintings, likely due to differences in themes or styles.</li>
      <li><em>Pierre-Auguste Renoir</em> and <em>Edouard Manet</em> also have scores near 0.29, reflecting diversity in artistic elements.</li>
    </ul>
  </li>
  <p></p>
  <a href="#">
      <img src="/img/artPaint18.jpg" alt="Post Sample Image" width="777" />
  </a>
  <p></p>
  <li><strong>Mikhail Vrubel Dominates:</strong> The table features multiple pairs from <em>Mikhail Vrubel</em>, with scores ranging from 0.2952 to 0.3195, highlighting his stylistic versatility.</li>
  <p></p>
  <a href="#">
      <img src="/img/artPaint31.jpg" alt="Post Sample Image" width="579" />
  </a>
  This visualization highlights the painting "Lilac" by Mikhail Vrubel, which exhibits a low cosine similarity (&lt;0.32) to his other works. This deviation offers insight into how specific pieces can stand apart from an artist's typical style, enriching our understanding of their creative range and versatility.
  <p></p>
</ul>




<p></p>
<p>The low similarity scores between paintings of the same artist emphasize <strong>stylistic versatility</strong> or exploration within their body of work. These results provide valuable insights into the evolution and experimentation of individual artists, offering a deeper understanding of their creative journeys.</p>



<p></p>
<h3>Artist-Artist Connections</h3>

<p></p>
This analysis explores the relationships between artists by categorizing their connections based on cosine similarity scores and metadata such as shared genres or nationalities.

<p></p>
First, pairs of artist nodes were isolated and merged with existing edge data to identify relationships such as shared genres or nationalities. Missing values in the <code>genre</code> and <code>nationality</code> columns were replaced with "None" to standardize the dataset for further processing.</p>


<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">artist_pairs</span><span class="o">=</span><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">node1_type</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="sh">'</span><span class="s">artist</span><span class="sh">'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">node2_type</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="sh">'</span><span class="s">artist</span><span class="sh">'</span><span class="p">)]</span>
<span class="n">combined_df</span><span class="p">[</span><span class="sh">'</span><span class="s">genre</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">combined_df</span><span class="p">[</span><span class="sh">'</span><span class="s">genre</span><span class="sh">'</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="sh">'</span><span class="s">None</span><span class="sh">'</span><span class="p">)</span>
<span class="n">combined_df</span><span class="p">[</span><span class="sh">'</span><span class="s">nationality</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">combined_df</span><span class="p">[</span><span class="sh">'</span><span class="s">nationality</span><span class="sh">'</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="sh">'</span><span class="s">None</span><span class="sh">'</span><span class="p">)</span>
<span class="n">combined_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span>
    <span class="n">artist_pairs</span><span class="p">,</span>
    <span class="n">artist_edges</span><span class="p">,</span>
    <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span>
<span class="p">)</span></code></pre></figure>

<p></p>
<p></p>
<p></p>

<p>To better understand the nature of artist connections, a new column, <code>edge_type</code>, was introduced to classify relationships into the following categories:</p>
<ul>
  <li><strong>Genre:</strong> When artists share a common artistic style or movement.</li>
  <li><strong>Nationality:</strong> When artists belong to the same country.</li>
  <li><strong>Both:</strong> When artists share both genre and nationality.</li>
  <li><strong>None:</strong> When no direct connection exists in the provided metadata.</li>
</ul>

<p>This categorization offers valuable insights into the nature of artist-artist relationships, helping uncover patterns and anomalies within the graph.</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">determine_edge_type</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">genre</span><span class="sh">'</span><span class="p">]</span> <span class="o">!=</span> <span class="sh">'</span><span class="s">None</span><span class="sh">'</span> <span class="ow">and</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">nationality</span><span class="sh">'</span><span class="p">]</span> <span class="o">!=</span> <span class="sh">'</span><span class="s">None</span><span class="sh">'</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">both</span><span class="sh">'</span>
    <span class="k">elif</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">genre</span><span class="sh">'</span><span class="p">]</span> <span class="o">!=</span> <span class="sh">'</span><span class="s">None</span><span class="sh">'</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">genre</span><span class="sh">'</span>
    <span class="k">elif</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">nationality</span><span class="sh">'</span><span class="p">]</span> <span class="o">!=</span> <span class="sh">'</span><span class="s">None</span><span class="sh">'</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">nationality</span><span class="sh">'</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">none</span><span class="sh">'</span>
<span class="n">combined_df</span><span class="p">[</span><span class="sh">'</span><span class="s">edge_type</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">combined_df</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">determine_edge_type</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">combined_df</span><span class="p">[</span><span class="n">combined_df</span><span class="p">[</span><span class="sh">'</span><span class="s">edge_type</span><span class="sh">'</span><span class="p">]</span><span class="o">!=</span><span class="sh">'</span><span class="s">none</span><span class="sh">'</span><span class="p">].</span><span class="nf">tail</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span></code></pre></figure>

<p></p>
<p></p>
<a href="#">
    <img src="/img/artPaint25.jpg" alt="Post Sample Image" width="734" />
</a>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">stats</span> <span class="o">=</span> <span class="n">combined_df</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">edge_type</span><span class="sh">'</span><span class="p">)[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">]</span>
  <span class="p">.</span><span class="nf">agg</span><span class="p">([</span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">median</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">min</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">max</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">std</span><span class="sh">'</span><span class="p">]).</span><span class="nf">reset_index</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Statistics by Edge Type:</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">stats</span><span class="p">)</span>
<span class="n">Statistics</span> <span class="n">by</span> <span class="n">Edge</span> <span class="n">Type</span><span class="p">:</span>
     <span class="n">edge_type</span>      <span class="n">mean</span>    <span class="n">median</span>       <span class="nb">min</span>       <span class="nb">max</span>       <span class="n">std</span>
<span class="mi">0</span>         <span class="n">both</span>  <span class="mf">0.751972</span>  <span class="mf">0.790473</span>  <span class="mf">0.345487</span>  <span class="mf">0.989279</span>  <span class="mf">0.210772</span>
<span class="mi">1</span>        <span class="n">genre</span>  <span class="mf">0.817520</span>  <span class="mf">0.864702</span>  <span class="mf">0.260232</span>  <span class="mf">0.978745</span>  <span class="mf">0.149252</span>
<span class="mi">2</span>  <span class="n">nationality</span>  <span class="mf">0.719641</span>  <span class="mf">0.791969</span>  <span class="mf">0.052798</span>  <span class="mf">0.992316</span>  <span class="mf">0.245162</span>
<span class="mi">3</span>         <span class="n">none</span>  <span class="mf">0.617343</span>  <span class="mf">0.685730</span> <span class="o">-</span><span class="mf">0.281765</span>  <span class="mf">1.000000</span>  <span class="mf">0.296322</span></code></pre></figure>

<p></p>
To better understand the relationship between edge types and their corresponding similarity scores, we use a boxplot. The plot is arranged in the following order: both, genre, nationality, and none, ensuring consistency and clarity. A uniform light gray color is applied to all boxes for a clean and professional appearance.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">order</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">both</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">genre</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">nationality</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">none</span><span class="sh">'</span><span class="p">]</span>  <span class="c1"># Specify the desired order
</span><span class="n">sns</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">'</span><span class="s">edge_type</span><span class="sh">'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">combined_df</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">lightgray</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># Use single color
</span><span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Score Distribution by Edge Type</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Edge Type</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Score</span><span class="sh">"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure>

<p></p>

This visualization provides insights into how different edge types (e.g., genre-based or nationality-based connections) influence the similarity scores among artists in the graph.

<a href="#">
    <img src="/img/artPaint26.jpg" alt="Post Sample Image" width="474" />
</a>
<p></p>

<p>In this analysis, we focus on understanding the relationships between artist nodes by exploring similarity scores for different edge types. By examining both high and low scores, we gain insights into hidden connections and variations among artists.</p>


<p></p>

<h4>Low Scores with 'Both'</h4>
<p>Even when artists share both genre and nationality, low similarity scores reveal nuanced differences. These pairs demonstrate the diversity that can exist even within closely related artistic and cultural contexts.</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">=</span><span class="n">combined_df</span>
<span class="n">low_scores_both</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">edge_type</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">both</span><span class="sh">'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">])]</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Low scores with </span><span class="sh">'</span><span class="s">genre</span><span class="sh">'</span><span class="s"> edge type:</span><span class="sh">"</span><span class="p">)</span>
<span class="n">low_scores_both</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">).</span><span class="nf">head</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span></code></pre></figure>

<p></p>
<a href="#">
    <img src="/img/artPaint30.jpg" alt="Post Sample Image" width="579" />
</a>
<p></p>
With the exception of Titian and Leonardo da Vinci, all pairs are French artists from Impressionism or Post-Impressionism, yet their low cosine similarity scores highlight nuanced stylistic differences within these closely related movements.

<p></p>


<p></p>
<h4>Low Scores with 'Nationality'</h4>
<p>Artists sharing the same nationality but exhibiting weak similarities highlight diversity within a shared cultural framework. These cases may represent unique interpretations or individualistic approaches despite shared backgrounds.</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">low_scores_nationality</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">edge_type</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">nationality</span><span class="sh">'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">])]</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Low scores with </span><span class="sh">'</span><span class="s">nationality</span><span class="sh">'</span><span class="s"> edge type:</span><span class="sh">"</span><span class="p">)</span>
<span class="n">low_scores_nationality</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">).</span><span class="nf">head</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span></code></pre></figure>


<p></p>
<a href="#">
    <img src="/img/artPaint29.jpg" alt="Post Sample Image" width="579" />
</a>
<p></p>
The low cosine similarity scores between artists of the same nationality often reflect differences in time periods and artistic movements. For example, Rembrandt and Piet Mondrian represent vastly different eras—17th-century Baroque and 20th-century Abstract art—while Camille Pissarro and Eugene Delacroix belong to distinct movements like Impressionism and Romanticism. These temporal and stylistic disparities highlight the diversity within shared cultural backgrounds.
<p></p>


<p></p>
<h4>Low Scores with 'Genre'</h4>
<p>For artist pairs connected by the same genre but showing low similarity scores, we explore how artists within a single genre can differ significantly in their styles, techniques, or approaches to art.</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">low_scores_genre</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">edge_type</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">genre</span><span class="sh">'</span><span class="p">)</span> <span class="o">&amp;</span>  <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">])]</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Low scores with </span><span class="sh">'</span><span class="s">genre</span><span class="sh">'</span><span class="s"> edge type:</span><span class="sh">"</span><span class="p">)</span>
<span class="n">low_scores_genre</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">).</span><span class="nf">head</span><span class="p">()</span></code></pre></figure>

<p></p>
<p></p>

<p></p>
<a href="#">
    <img src="/img/artPaint28.jpg" alt="Post Sample Image" width="579" />
</a>
<p></p>
For artists connected by the same genre, even the lowest cosine similarity scores are relatively high, indicating a baseline level of shared characteristics. However, these pairs still highlight stylistic diversity within the same genre, such as the contrasting approaches of Eugene Delacroix and William Turner in Romanticism or the differences between Albrecht Dürer and Hieronymus Bosch in the Northern Renaissance.


<p></p>

<h4>High Scores with 'None'</h4>
<p>Artists with no shared genre or nationality but high similarity scores reveal unexpected connections. These relationships may indicate shared influences, overlapping themes, or stylistic similarities that are not captured by explicit attributes.</p>


<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">high_scores_none</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">edge_type</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">none</span><span class="sh">'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">])]</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">High scores with </span><span class="sh">'</span><span class="s">none</span><span class="sh">'</span><span class="s"> edge type:</span><span class="sh">"</span><span class="p">)</span>
<span class="n">high_scores_none</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="nf">head</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>
<a href="#">
    <img src="/img/artPaint27.jpg" alt="Post Sample Image" width="579" />
</a>
<p></p>
These high scores, despite no overlaps in genre or nationality, suggest deeper, unrecognized influences or thematic and stylistic parallels that transcend traditional classifications, warranting further exploration. One such connection is between Pablo Picasso (1881–1973), the Spanish pioneer of Cubism, and Mikhail Vrubel (1856–1910), a Russian Symbolist painter. Although they lived in different periods and represented contrasting artistic movements, a historical link bridges their work. In 1906, Sergey Diaghilev brought Vrubel’s works to Paris, where they captured the admiration of a young Pablo Picasso.
<p></p>

<p></p>








<h2>Conclusion</h2>

<p>
This study presented a Unified Knowledge Graph framework that combines text and image data to explore artistic relationships. By utilizing Graph Neural Networks (GNNs) for embedding and link prediction, we uncovered meaningful connections within and across artist and painting nodes, revealing both expected patterns and surprising insights.
</p>

<p>
<strong>Key findings include:</strong>
</p>

<ul>
  <li><strong>Cross-Artist Painting Connections:</strong> Identified thematic overlaps and stylistic diversity between works created by different artists.</li>
  <li><strong>Artist-Specific Variations:</strong> Highlighted the evolution and experimentation within individual artists' portfolios, showcasing their creative range.</li>
  <li><strong>Unexpected Influences:</strong> Discovered surprising connections, such as historical links between Pablo Picasso and Mikhail Vrubel, demonstrating the broader potential of this approach.</li>
</ul>

<p>
The Unified Knowledge Graph provides a powerful tool for analyzing complex datasets, offering fresh perspectives on art history. It also paves the way for applications in recommendation systems, classification tasks, and cultural analysis. Future work will focus on expanding the graph with additional data types and improving model interpretability.
</p>
</p></p></p></p></p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[Unified Knowledge Graph for Artists and Paintings Think of this project as one map of the art world, where artists and paintings are dots and their relationships form the lines between them. We turn biographies and images into a single unified knowledge graph, then use Graph AI to see which artists and works are close, far, or unexpectedly linked. Instead of scrolling through lists, you can explore art as a connected network and discover relationships you wouldn’t notice from text or images alone. The same pattern extends far beyond art: this pipeline can fuse text, images, time series, and other data into a unified knowledge graph in any domain, keeping everything analyzable with one Graph AI workflow.]]></summary></entry><entry><title type="html">Graph Neural Networks for EEG Connectivity Analysis</title><link href="http://localhost:4000/2024/11/09/GNN_timeSeries_EEG/" rel="alternate" type="text/html" title="Graph Neural Networks for EEG Connectivity Analysis" /><published>2024-11-09T07:00:00-05:00</published><updated>2024-11-09T07:00:00-05:00</updated><id>http://localhost:4000/2024/11/09/GNN_timeSeries_EEG</id><content type="html" xml:base="http://localhost:4000/2024/11/09/GNN_timeSeries_EEG/"><![CDATA[<h2>Brain Graphs with Time Series Signals</h2>
<p>
  In this project, we model the brain as a <strong>spatial graph</strong>: each node is an EEG
  electrode on the scalp, and edges connect nearby positions in the standard montage. The time
  series data are used as <strong>node features</strong> for each trial, so every channel carries
  its full signal while staying embedded in the brain’s geometry. A GNN link prediction model then
  learns how these nodes connect under different conditions, revealing changes in functional
  connectivity and highlighting which regions act as key connectors in Control vs Alcohol groups.
</p>

<h2>Conference &amp; Workshop</h2>
<p>
  The work <em>“Graph Neural Networks in Action: Uncovering Patterns in EEG Time Series Data”</em>
  was presented at the <strong>1st International Workshop on Artificial Intelligence for Neuroscience (IWAIN’24)</strong>
  in Alicante, Spain, on <strong>26 November 2024</strong>. The contribution is currently available as
  a conference paper via ResearchGate and is associated with the IWAIN’24 workshop program. The full
  paper can be accessed by visiting the author’s profile or the paper page on ResearchGate and
  downloading the PDF directly from there.
</p>

<h2>Introduction</h2>

<p>
    Electroencephalography (EEG) is a widely used non-invasive neuroimaging technique that captures electrical activity in the brain. By recording voltage fluctuations across the scalp, EEG enables researchers to monitor real-time brain activity, providing insights into cognitive processes, mental states, and neurological disorders. It is a valuable tool for understanding how different brain regions coordinate to support functions such as attention, memory, and motor control, making EEG essential for studying neural connectivity.
</p>

<p>
    Traditional methods for analyzing EEG data, such as feature extraction, spectral analysis, and machine learning models like Support Vector Machines (SVM) or Convolutional Neural Networks (CNN), often process channels independently or in predefined groups. While these approaches have achieved moderate success, they struggle to fully model the complex, non-linear spatial and temporal dependencies present in EEG signals. This limitation often results in the loss of crucial information about brain network dynamics.
</p>

<p>
    The graph-like nature of EEG data, where electrode positions can be represented as nodes and interactions as edges, has led to the adoption of Graph Neural Networks (GNNs) for more advanced analysis. GNNs capture the intricate spatial relationships and temporal dependencies in EEG signals, offering a powerful framework for understanding neural dynamics. This capability makes GNNs highly effective for applications such as cognitive state monitoring, emotion recognition, and neurological disorder diagnosis. Recent studies have demonstrated that GNN-based models can provide deeper insights into brain activity compared to traditional methods by revealing subtle connectivity patterns.
</p>

<h4>Current Study Overview</h4>

<p>
    This study utilizes the publicly available <em>EEG-Alcohol</em> dataset from Kaggle, which includes EEG recordings from subjects exposed to visual stimuli. Trials involved either a single picture stimulus or two picture stimuli, with the latter being either matched (identical) or non-matched (different). This dataset serves as a basis for exploring the impact of alcohol on brain connectivity and cognitive processing.
</p>

<h4>Building on Prior Work</h4>
<p>
    Our previous studies analyzed this dataset using different methodologies:
</p>
<ul>
    <li>
        <i>Study 1:</i> Used CNNs and time series analysis to classify EEG signals, showing higher accuracy with Gramian Angular Field (GAF) transformations but limited success in distinguishing Alcoholic and Control groups for single-stimulus trials.
    </li>
    <p></p>
    <a href="#">
        <img src="/img/dataSource5.jpg" alt="Figure 1: Connectivity Patterns from Previous Study" width="404" />
    </a>
    <p></p>
    <p>
        This figure from our previous study shows how connectivity patterns were analyzed using traditional graph mining, revealing stronger and weaker similarities between EEG positions. We found that single-image trials were not effective for distinguishing Alcoholic and Control groups. In this study, we extend these findings by using GNN Link Prediction models.
    </p>

    <li>
        <i>Study 2:</i> Employed GNN Graph Classification models, representing each trial as a graph with EEG channels as nodes. While this approach improved classification accuracy, it struggled with single-stimulus trials and highlighted the need for more detailed connectivity analysis.
    </li>
</ul>

<p>
    Building on these findings, this study introduces a unified graph structure where edges represent spatial relationships between EEG channels. This new framework provides a consistent basis for analyzing brain-trial combinations at a granular level, capturing both spatial and temporal dependencies in EEG data.
</p>

<h4>Significance of the Unified Graph Approach</h4>
<p>
    In contrast to earlier studies that created separate graphs for each trial, this approach integrates all EEG signals into a unified graph structure. Nodes represent EEG channels, while edges reflect spatial proximity, ensuring consistency across analyses. Each trial contributes to a subgraph within the unified structure, capturing both local and global dependencies. The unified graph serves as input for the GNN Link Prediction model, enabling us to detect subtle variations in connectivity across experimental conditions.
</p>

<p>
    By transforming EEG signals into high-dimensional embeddings, this method provides a deeper exploration of spatial and temporal relationships, revealing interactions that conventional techniques could not capture. The study contributes to the growing field of AI-driven neuroscience by offering a versatile framework for analyzing EEG connectivity patterns and improving our understanding of neural dynamics.
</p>

<h3>Methods</h3>

<h4>EEG Channel Position Mapping and Graph Construction</h4>

<p>
    This section outlines the process of mapping EEG channel positions in 3D space and constructing an initial graph to capture spatial relationships between the electrodes. The goal was to create a graph where nodes represent EEG channels, and edges reflect their spatial proximity, forming the foundation for subsequent analysis.
</p>

<h5>EEG Channel Position Extraction</h5>
<ul>
    <li>We loaded the standard EEG montage (<code>'standard_1005'</code>) using the <strong>mne</strong> library.</li>
    <li>Channel positions were retrieved as (x, y, z) coordinates, representing each EEG channel in 3D space.</li>
    <li>Pairwise Euclidean distances between channels were calculated using <b>scipy.spatial.distance</b>, capturing the spatial proximity between electrodes.</li>
</ul>

<h5>Distance Matrix Construction</h5>
<ul>
    <li>The computed distances were used to create a distance matrix that encapsulates the spatial relationships between EEG channels.</li>
    <li>This matrix was formatted into a structured dataset, making it suitable for graph-based modeling.</li>
</ul>

<h5>Minimum Distance Filtering and Graph Creation</h5>
<ul>
    <li>To ensure no channel was isolated, we identified the shortest distance for each channel.</li>
    <li>A distance threshold was applied, defined as the maximum of these minimum distances, to retain only the closest pairs of channels.</li>
    <li>The final graph was constructed with nodes representing EEG channels and edges indicating spatial proximity, ensuring the graph was fully connected for analysis.</li>
</ul>

<h5>Initial EEG Graph Construction</h5>
<ul>
    <li>We built an initial graph representing the spatial configuration of the EEG channels.</li>
    <li>In this graph:
        <ul>
            <li><i>Nodes:</i> Represent EEG channels.</li>
            <li><i>Edges:</i> Represent spatial proximity between channels.</li>
        </ul>
    </li>
    <li>Time-series EEG signals for each channel were incorporated as node features, capturing both spatial and temporal dependencies within the EEG data.</li>
</ul>

<p>
    Figure 2: An overview of the EEG graph analysis pipeline. The initial graph (left) is built using spatial and temporal EEG data. The GNN Link Prediction model (center) processes the graph to learn node connections, generating embedded vectors (right) that capture complex relationships within the EEG signals for further analysis.
</p>
<p></p>
<p><a href="#">
    <img src="/img/pipeline2.jpg" alt="EEG Graph Analysis Pipeline" width="888" />
</a></p>
<p></p>

<p></p>
<h3>Experiments </h3>

<p></p>
<p>Using the EEG-Alcohol dataset from Kaggle, we preprocessed data from 61 EEG channels across multiple trials. The GNN model trained on this graph data demonstrated high accuracy, achieving an 81.45% AUC in distinguishing connectivity patterns between control and alcohol groups. Key differences emerged between experimental conditions, with the control group displaying stronger connectivity in visual processing areas compared to the alcohol group​</p>
<p></p>

<h4>Data Source</h4>

<p>In our study on brain connectivity, we used the publicly available <a href="https://www.kaggle.com/datasets/nnair25/Alcoholics">EEG-Alcohol dataset</a> from Kaggle (Kaggle.com, EEG-Alcohol Data Set, 2017). This dataset contains EEG recordings collected to explore how genetic predisposition to alcoholism might affect neural responses. Each participant was exposed to visual stimuli, either as a single image or two consecutive images. In trials with two images, the stimuli could either be identical (matched) or different (non-matched). The images used were selected from the well-known Snodgrass and Vanderwart picture set, created in 1980, which is commonly used in psychological studies.</p>

<p>The dataset includes EEG data from 8 participants in each group—those with and without alcohol exposure. EEG activity was recorded using 64 electrodes placed across the scalp, capturing brain signals at a high sampling rate of 256 Hz over short, 1-second trials. Due to quality issues in some channels, we focused on data from 61 out of the 64 electrodes, resulting in a total of 61 person-trial pairs included in our analysis.</p>

<p>Our data preparation approach was partly inspired by <a href="https://www.kaggle.com/code/ruslankl/eeg-data-analysis">Ruslan Klymentiev's Kaggle notebook</a> on EEG Data Analysis, which provided a foundation for processing the raw EEG data into a structured format. Building on Klymentiev’s work, we implemented additional transformations to convert these EEG recordings into a structured time series format for each electrode, making the data suitable for graph-based modeling.</p>

<p>To organize the raw sensor data, we categorized it by sensor position and trial number, then created a structured dataset where each row represents a single time point, and each column shows the sensor value from a specific EEG channel at that moment. This transformation was essential for enabling our subsequent graph-based analysis, laying the groundwork for understanding connectivity patterns in the brain. For a more detailed look at our data transformation process, check out our related blog post.</p>

<p>This preprocessing step was crucial as it prepared the dataset for our deeper analysis, allowing us to model brain connectivity patterns effectively. Through this structured data, we could dive into the fascinating world of neural dynamics and uncover insights into how alcohol exposure might influence brain connectivity.</p>

<h4>Prepare Input Data for GNN Link Prediction Model</h4>
<p>
The initial graph structure was created by calculating pairwise Euclidean distances between EEG channels, as outlined in the EEG Channel Position Mapping and Graph Construction subsection of the Methods section. These distances capture the spatial relationships between electrodes based on their physical positions on the scalp. The maximum of the minimum distances between EEG channels was calculated to be 0.038, and to prevent isolated nodes, a slightly higher threshold of 0.04 was used to filter and retain the closest channel pairs. This process resulted in a consistent graph structure with 61 nodes and 108 edges, representing the spatial layout of EEG channels across all subjects and trials. This shared graph provides a uniform topology for all subsequent subject-trial graphs, facilitating comparative analysis.
</p>
<p>
After establishing the graph structure, we defined graph nodes and their features for each subject-trial combination. Each node corresponds to one of the 61 EEG channels, while node features are derived from the time series signals recorded at these positions during the trials. The data was grouped by type (Alcohol and Control), subject, trial, and channel position, forming structured datasets that capture both spatial and temporal characteristics of the EEG signals. While the spatial configuration of the graph remains constant, node features vary based on each subject and trial, enabling the GNN Link Prediction model to detect connectivity patterns specific to different experimental conditions. For further details on the data preparation process, refer to our related blog post [18].

</p>

<h4>Data Preparation: Building the Initial Graph Structure</h4>

<p>To analyze EEG connectivity patterns effectively, we constructed an initial graph structure that represents the spatial relationships between EEG channels. This process involved calculating pairwise Euclidean distances based on the physical positions of electrodes on the scalp. Using these distances, we created a graph where nodes correspond to EEG channels and edges represent spatial proximity. To ensure no isolated nodes, a distance threshold was set slightly above the maximum of the minimum distances between channels, calculated to be <code>0.038</code>. A threshold of <code>0.04</code> was applied to retain the closest channel pairs, resulting in a connected graph with 61 nodes.</p>

<p>The following Python code demonstrates the steps to build the graph structure, including calculating distances and filtering edges based on the threshold:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">mne</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">pdist</span><span class="p">,</span> <span class="n">squareform</span>

<span class="c1"># Load EEG channel positions using MNE's standard montage
</span>
<span class="n">montage</span> <span class="o">=</span> <span class="n">mne</span><span class="p">.</span><span class="n">channels</span><span class="p">.</span><span class="nf">make_standard_montage</span><span class="p">(</span><span class="sh">'</span><span class="s">standard_1005</span><span class="sh">'</span><span class="p">)</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">montage</span><span class="p">.</span><span class="nf">get_positions</span><span class="p">()[</span><span class="sh">'</span><span class="s">ch_pos</span><span class="sh">'</span><span class="p">]</span>
<span class="n">uppercase_pos</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">.</span><span class="nf">upper</span><span class="p">():</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">pos</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>

<span class="c1"># Filter positions to retain only the relevant EEG channels
</span>
<span class="n">filtered_positions</span> <span class="o">=</span> <span class="p">[</span><span class="n">ch</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">positions</span> <span class="k">if</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">uppercase_pos</span><span class="p">]</span>

<span class="nf">len</span><span class="p">(</span><span class="n">filtered_positions</span><span class="p">)</span>
<span class="mi">61</span></code></pre></figure>

<p></p>

<p>The coordinates of the EEG channels were extracted, and a pairwise distance matrix was calculated:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Extract coordinates for the filtered EEG channels
</span>
<span class="n">coordinates</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">uppercase_pos</span><span class="p">[</span><span class="n">ch</span><span class="p">]</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">filtered_positions</span><span class="p">])</span>
<span class="n">distance_matrix</span> <span class="o">=</span> <span class="nf">squareform</span><span class="p">(</span><span class="nf">pdist</span><span class="p">(</span><span class="n">coordinates</span><span class="p">))</span>

<span class="c1"># Calculate pairwise distances and store them in a list
</span>
<span class="n">distance_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">pos1</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">filtered_positions</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">pos2</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">filtered_positions</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">:</span>  
            <span class="n">distance</span> <span class="o">=</span> <span class="n">distance_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">distance_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">pos1</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">pos2</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">distance</span><span class="si">:</span><span class="p">.</span><span class="mi">6</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="nf">len</span><span class="p">(</span><span class="n">distance_list</span><span class="p">)</span>
<span class="mi">3660</span></code></pre></figure>

<p></p>

<p>To organize the distances, a DataFrame was created, and the minimum distance for each EEG channel was identified:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># Split distance data into a structured DataFrame
</span>
<span class="n">split_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">distance_list</span><span class="p">]</span>
<span class="n">distance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">split_data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">left</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">right</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">distance</span><span class="sh">"</span><span class="p">])</span>
<span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

<span class="n">distance_df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
<span class="c1"># Example output
# left    right    distance
# AF1     AF2      0.038294
# AF1     AF7      0.057702
# AF1     AF8      0.086636
# AF1     AFZ      0.018912
# AF1     C1       0.107897
</span>
<span class="c1"># Calculate the maximum of the minimum distances
</span>
<span class="n">min_distances</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">position</span> <span class="ow">in</span> <span class="nf">set</span><span class="p">(</span><span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">]).</span><span class="nf">union</span><span class="p">(</span><span class="nf">set</span><span class="p">(</span><span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">])):</span>
    <span class="n">filtered_df</span> <span class="o">=</span> <span class="n">distance_df</span><span class="p">[(</span><span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">position</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">position</span><span class="p">)]</span>
    <span class="n">min_distance</span> <span class="o">=</span> <span class="n">filtered_df</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span>
    <span class="n">min_distances</span><span class="p">[</span><span class="n">position</span><span class="p">]</span> <span class="o">=</span> <span class="n">min_distance</span>

<span class="n">max_of_min_distances</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">min_distances</span><span class="p">.</span><span class="nf">values</span><span class="p">())</span>

<span class="n">max_of_min_distances</span>
<span class="mf">0.038043</span></code></pre></figure>

<p></p>

<p>Using the calculated maximum of the minimum distances (<code>0.038043</code>), we applied a slightly higher threshold (<code>0.04</code>) to retain only the closest channel pairs. This ensured that the graph remained fully connected, providing a robust structure for subsequent analysis.</p>

<p><a href="#">
    <img src="/img/distanceEEG.jpg" alt="Post Sample Image" width="567" />
</a></p>
<p></p>

<p>This data preparation step was critical for constructing a meaningful graph structure that captures the spatial relationships between EEG channels. By incorporating both node positions and proximity-based edge definitions, this graph provides a solid foundation for analyzing connectivity patterns using Graph Neural Networks.</p>

<p>The distribution of distances between electrode positions was analyzed to verify the spatial relationships used for graph construction. Below is a histogram illustrating the distance distribution:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Distribution of Distances Between Electrode Positions</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Distance</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Frequency</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Print basic statistics
</span>
<span class="nf">print</span><span class="p">(</span><span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">].</span><span class="nf">describe</span><span class="p">())</span></code></pre></figure>

<p></p>

<p>Basic statistics of the distances:</p>
<ul>
    <li><i>Count:</i> 3660</li>
    <li><i>Mean:</i> 0.119815</li>
    <li><i>Standard Deviation:</i> 0.045156</li>
    <li><i>Min:</i> 0.018912</li>
    <li><i>Max:</i> 0.206672</li>
</ul>

<p>Filtered edges below the threshold distance (<code>0.04</code>) were selected to ensure a fully connected graph. The following code demonstrates the construction of the graph:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>

<span class="c1"># Filter pairs below the threshold
</span>
<span class="n">filtered_pairs</span> <span class="o">=</span> <span class="n">distance_df</span><span class="p">[</span><span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.04</span><span class="p">]</span>

<span class="c1"># Create the graph and add edges with weights
</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">filtered_pairs</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
    <span class="n">G</span><span class="p">.</span><span class="nf">add_edge</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">],</span> <span class="n">weight</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">])</span>

<span class="c1"># Visualize the graph
</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nf">kamada_kawai_layout</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">nx</span><span class="p">.</span><span class="nf">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="sh">'</span><span class="s">white</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure>

<p></p>

<p><a href="#">
    <img src="/img/eegLandscape.jpg" alt="Post Sample Image" width="404" />
</a></p>
<p></p>

<p>The resulting graph represents the spatial relationships between EEG electrodes, as shown in the visualization above. This consistent graph topology is used for all subsequent analyses, with the node features varying based on subject-trial combinations. This approach enables the model to explore dynamic connectivity patterns, providing insights into brain network interactions under different conditions.</p>

<p>For further details on the data preparation and modeling process, refer to our related <a href="#">blog post</a>.</p>

<h4>Pre-Training Data Preparation for EEG Graph Neural Network</h4>

<p>Following the construction of the initial graph with 61 nodes and 108 edges based on spatial distances between EEG channels, we defined node features for each subject-trial combination. This graph structure provided a uniform topology, enabling the detection of connectivity patterns that varied across different experimental conditions, such as Alcohol and Control groups.</p>

<p>Each node in the graph represents one of the 61 EEG channels, with node features derived from the time series signals recorded during trials. By grouping the data by type (Alcohol and Control), subject, trial, and channel position, we captured both spatial and temporal aspects of the EEG signals. While the graph's spatial configuration remains constant, node features vary across subject-trial combinations, allowing the Graph Neural Network (GNN) Link Prediction model to identify connectivity patterns specific to different conditions.</p>

<p>We started by creating a DataFrame of edges that represents the connections between nodes (EEG channels). This involved combining metadata and filtering edges based on group matching. Here’s the code for constructing the edges:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>

<span class="c1"># Create an edges DataFrame from the graph's edges
</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">G</span><span class="p">.</span><span class="n">edges</span><span class="p">)</span>
<span class="n">edges</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Separate feature and metadata columns
</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">rawData</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">6</span><span class="p">:</span><span class="mi">262</span><span class="p">]</span>
<span class="n">metavalues1</span> <span class="o">=</span> <span class="n">rawData</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">6</span><span class="p">]</span>
<span class="n">metavalues2</span> <span class="o">=</span> <span class="n">rawData</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">262</span><span class="p">:]</span>
<span class="n">metavalues</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">metavalues1</span><span class="p">,</span> <span class="n">metavalues2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Drop unnecessary metadata columns and merge with edges
</span>
<span class="n">metaData</span> <span class="o">=</span> <span class="n">metavalues</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">'</span><span class="s">trial</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">match</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">channel</span><span class="sh">'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">edges_left</span> <span class="o">=</span> <span class="n">metaData</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">left_on</span><span class="o">=</span><span class="sh">'</span><span class="s">positionIdx</span><span class="sh">'</span><span class="p">,</span> <span class="n">right_on</span><span class="o">=</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">).</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">edges_left</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">left_index</span><span class="sh">'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">edges_right</span> <span class="o">=</span> <span class="n">edges_left</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">metaData</span><span class="p">,</span> <span class="n">left_on</span><span class="o">=</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">,</span>
   <span class="n">right_on</span><span class="o">=</span><span class="sh">'</span><span class="s">positionIdx</span><span class="sh">'</span><span class="p">).</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">edges_right</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">right_index</span><span class="sh">'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Filter edges by group matching and reset index
</span>
<span class="n">filtered_edges</span> <span class="o">=</span> <span class="n">edges_right</span><span class="p">[</span><span class="n">edges_right</span><span class="p">[</span><span class="sh">'</span><span class="s">group_x</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">edges_right</span><span class="p">[</span><span class="sh">'</span><span class="s">group_y</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">edges_final</span> <span class="o">=</span> <span class="n">filtered_edges</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">'</span><span class="s">group_y</span><span class="sh">'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">edges_final</span><span class="p">[</span><span class="sh">'</span><span class="s">index_final</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">edges_final</span><span class="p">.</span><span class="n">index</span>  <span class="c1"># Add final index as a column
</span>
<span class="c1"># Create the final NetworkX graph from the processed edges DataFrame
</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nf">from_pandas_edgelist</span><span class="p">(</span><span class="n">edges_final</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="sh">'</span><span class="s">left_index</span><span class="sh">'</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="sh">'</span><span class="s">right_index</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>

<p></p>

<p>After defining the edges and nodes, we used the Deep Graph Library (DGL) to convert the NetworkX graph into a DGL graph. We then added the node features (time series signals) as tensors, which the model will use to analyze connectivity patterns. Here’s the code for preparing the DGL graph and adding features:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">dgl</span>
<span class="kn">import</span> <span class="n">torch</span>

<span class="c1"># Convert NetworkX graph to DGL graph
</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">from_networkx</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>

<span class="c1"># Convert EEG time series data to a tensor and add it as node features
</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">rawData</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">6</span><span class="p">:</span><span class="mi">262</span><span class="p">]</span>
<span class="n">features_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">values</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">features_tensor</span>

<span class="c1"># Display the graph summary
</span>
<span class="n">g</span>
<span class="nc">Graph</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">3721</span><span class="p">,</span> <span class="n">num_edges</span><span class="o">=</span><span class="mi">13176</span><span class="p">,</span>
      <span class="n">ndata_schemes</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">:</span> <span class="nc">Scheme</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)}</span>
      <span class="n">edata_schemes</span><span class="o">=</span><span class="p">{})</span></code></pre></figure>

<p></p>

<p>This data preparation stage established a robust graph-based representation of EEG data, where each node (EEG channel) has unique features based on time series signals across trials. The resulting graph, with 3721 nodes and 13176 edges, serves as input to the GNN model, allowing it to explore complex connectivity patterns across experimental conditions. This setup lays the groundwork for effective pre-training and connectivity analysis.</p>

<p>For more information on the data preparation process and detailed GNN modeling steps, refer to our related <a href="#">blog post</a>.</p>

<h4>Train the Model</h4>

<p>We utilized the GraphSAGE link prediction model, implemented with the Deep Graph Library (DGL), to train our model on the EEG graph data. GraphSAGE employs two layers to aggregate information from neighboring nodes, enabling the model to capture complex connectivity patterns and interactions between EEG channels.</p>

<ul>
    <li><i>Total Nodes:</i> 3,721</li>
    <li><i>Total Edges:</i> 13,176</li>
    <li><i>Node Feature Size:</i> 256</li>
</ul>

<p>The model’s performance was evaluated using the Area Under the Curve (AUC) metric, achieving an accuracy of <strong>81.45%</strong>. This high AUC score demonstrates the model’s effectiveness in predicting connectivity patterns and capturing the underlying signal dependencies within the EEG data.</p>

<p>We implemented our model using code from the tutorial "<a href="https://www.dgl.ai">Deep Graph Library (DGL): Link Prediction Using Graph Neural Networks</a>," published in 2018. This resource provided a foundational framework for building and optimizing our GraphSAGE-based link prediction model.</p>

<h4>EEG Connectivity Analysis: GNN Link Prediction and Statistical Calculations</h4>

<p>
    The foundation of our connectivity analysis stems from the results of a Graph Neural Network (GNN) link prediction model. This model generates a matrix, <code>h</code>, where each row represents an embedded vector corresponding to a graph node. In our context, these nodes represent EEG channels, and the embedded vectors capture the spatial and temporal relationships between signals from different brain regions.
</p>
<p>
    These embeddings provide a powerful, compressed representation of connectivity patterns, allowing us to measure the relationships between nodes through cosine similarity.
</p>

<p>
    To evaluate the strength of connections between EEG nodes, we calculated pairwise cosine similarity scores between their embedded vectors. Cosine similarity measures the cosine of the angle between two vectors, producing a value between -1 (completely opposite) and 1 (completely identical).
</p>
<p>Below is the PyTorch-based implementation for calculating cosine similarity:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>

<span class="c1"># Define a function to calculate cosine similarity using PyTorch
</span>
<span class="k">def</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>

<span class="c1"># Ensure inputs are PyTorch tensors
</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

<span class="c1"># Adjust dimensions for single-row tensors
</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Normalize the vectors
</span>
    <span class="n">a_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Compute cosine similarity
</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">a_norm</span><span class="p">,</span> <span class="n">b_norm</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>

<span class="c1"># Example usage: compute cosine similarity for matrix `h`
</span>
<span class="n">cosine_scores</span> <span class="o">=</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span></code></pre></figure>

<p></p>

<h5>Statistical Analysis Using Self-Join Cosine Similarity</h5>
<p>
    Once the cosine similarity matrix (<code>cosine_scores</code>) is computed, we perform statistical calculations by grouping the data and applying self-join operations. This allows us to analyze the pairwise connectivity patterns within specific experimental groups (e.g., Alcohol and Control) and conditions (e.g., Single Stimulus, Two Stimuli).
</p>
<p>The self-join operation systematically computes pairwise statistics within each group, focusing on unique connections between EEG channels. Below is the implementation:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">group_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Iterate over each unique group in the 'group' column
</span>
<span class="k">for</span> <span class="n">group_idx</span> <span class="ow">in</span> <span class="n">metaRawData</span><span class="p">[</span><span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">].</span><span class="nf">unique</span><span class="p">():</span>

<span class="c1"># Filter rows that belong to the current group
</span>
    <span class="n">group_data</span> <span class="o">=</span> <span class="n">metaRawData</span><span class="p">[</span><span class="n">metaRawData</span><span class="p">[</span><span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">group_idx</span><span class="p">]</span>

<span class="c1"># Extract `type`, `match`, and `name` for the group (assuming they are the same for the group)
</span>
    <span class="n">group_type</span> <span class="o">=</span> <span class="n">group_data</span><span class="p">[</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">group_match</span> <span class="o">=</span> <span class="n">group_data</span><span class="p">[</span><span class="sh">'</span><span class="s">match</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">group_name</span> <span class="o">=</span> <span class="n">group_data</span><span class="p">[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Get the indices of the rows for the current group
</span>
    <span class="n">group_indices</span> <span class="o">=</span> <span class="n">group_data</span><span class="p">.</span><span class="n">index</span>

<span class="c1"># Calculate self-join cosine similarity within the group
</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row_i</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">group_indices</span><span class="p">):</span>
        <span class="n">position_i</span> <span class="o">=</span> <span class="n">metaRawData</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">row_i</span><span class="p">,</span> <span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">]</span>

<span class="c1"># Start from the next index to avoid duplicate pairs (i, j) and (j, i)
</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">row_j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">group_indices</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:],</span> <span class="n">start</span><span class="o">=</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">position_j</span> <span class="o">=</span> <span class="n">metaRawData</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">row_j</span><span class="p">,</span> <span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">]</span>

<span class="c1"># Retrieve cosine similarity score from cosine_scores array
</span>
            <span class="n">cos</span> <span class="o">=</span> <span class="n">cosine_scores</span><span class="p">[</span><span class="n">row_i</span><span class="p">][</span><span class="n">row_j</span><span class="p">].</span><span class="nf">item</span><span class="p">()</span>

<span class="c1"># Append the results to the list
</span>
            <span class="n">group_scores</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span>
                <span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">:</span> <span class="n">group_idx</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">:</span> <span class="n">group_type</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">match</span><span class="sh">'</span><span class="p">:</span> <span class="n">group_match</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">:</span> <span class="n">group_name</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">position_i</span><span class="sh">'</span><span class="p">:</span> <span class="n">position_i</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">position_j</span><span class="sh">'</span><span class="p">:</span> <span class="n">position_j</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">left_idx</span><span class="sh">'</span><span class="p">:</span> <span class="n">row_i</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">right_index</span><span class="sh">'</span><span class="p">:</span> <span class="n">row_j</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">cosine_similarity</span><span class="sh">'</span><span class="p">:</span> <span class="n">cos</span>
            <span class="p">})</span></code></pre></figure>

<p></p>

<p>
    The result of this process is a structured dataset where each row represents a unique connection between two EEG channels, along with the computed cosine similarity and group-level metadata. An example entry might look like this:
</p>
<pre>
<code>
{
    "group": "Alcohol",
    "type": "Experimental",
    "match": "Two Stimuli - Matched",
    "name": "Subject 1",
    "position_i": "Cz",
    "position_j": "Pz",
    "left_idx": 5,
    "right_index": 10,
    "cosine_similarity": 0.76
}
</code>
</pre>

<p>Key Insights and Applications</p>
<ul>
    <li>Condition-Wise Connectivity Analysis: Aggregating cosine similarity scores allows us to compare connectivity strength between experimental groups (e.g., Alcohol vs. Control) under various conditions (e.g., Single Stimulus, Two Stimuli).</li>

    <li>Node-Level Connectivity Patterns: The <code>position_i</code> and <code>position_j</code> fields enable spatial mapping of connectivity patterns across the brain.</li>

    <li>Group Comparisons: By grouping the results, we can identify statistically significant differences in connectivity patterns between conditions.</li>
</ul>

<p>
    The combination of GNN embeddings, cosine similarity, and statistical grouping enables a robust and scalable approach to analyzing EEG connectivity. By leveraging self-join matrices, we quantify pairwise relationships between EEG channels, uncovering patterns that provide valuable insights into the neural effects of experimental conditions such as alcohol exposure.
</p>

<h3>Interpreting Model Results</h3>

<h4>Condition-wise Analysis of Cosine Similarities</h4>

<p>To compare connectivity patterns between the Alcohol and Control groups, we computed the average cosine similarities from the embedded vectors generated by the model. These cosine similarities represent the strength of connectivity between brain regions, with higher values indicating stronger connections. The computed values were aggregated by condition type and match status to assess differences across the experimental groups.</p>

<p>As shown in Table 1, the <strong>‘Single stimulus’</strong> condition revealed minimal differences between the Alcohol and Control groups. This finding aligns with results from our previous studies [2, 3]. Since the <strong>‘Single stimulus’</strong> condition did not show significant variation in connectivity patterns, it was excluded from further analysis.</p>

<p>We instead focused on the <strong>‘Two stimuli - matched’</strong> and <strong>‘Two stimuli - non-matched’</strong> conditions, where clearer distinctions between the groups were observed:</p>

<ul>
    <li><i>Alcohol group:</i> Average cosine similarity of 0.546.</li>
    <li><i>Control group:</i> Average cosine similarity of 0.645.</li>
</ul>

<p>The higher average cosine similarity in the Control group suggests stronger overall connectivity compared to the Alcohol group. This finding may reflect differences in the efficiency or robustness of neural communication between the two groups. These variations could be indicative of the impact of alcohol on brain connectivity.</p>

<p>In the following sections, we will delve deeper into these patterns at the node level, highlighting specific regions of the brain with both high and low signal correlations between the groups.</p>

<p>This table shows average cosine similarities by condition and group:</p>
<p></p>
<p><a href="#">
    <img src="/img/eegTable1.jpg" alt="Post Sample Image" width="471" />
</a></p>
<p></p>

<h4>Strongly Connected Positions</h4>

<p>
    Our analysis utilized a GNN Link Prediction model to explore the EEG connectivity patterns in both the Alcohol and Control groups. This model was specifically designed to capture the intricate spatial relationships and temporal dependencies present in EEG data. By analyzing connectivity patterns at a granular level, the GNN Link Prediction model provided critical insights into how different brain regions interact under various experimental conditions.
</p>

<p>
    The GNN Link Prediction model generated embedded vectors, which were used to calculate edge weights based on the initial graph structure. Node-level cosine similarities were then computed by combining left and right node positions, grouping them by type and position, and averaging the values to evaluate overall connectivity strength.
</p>

<p>
    Tables 2 and 3 highlight the top highly connected node pairs and nodes, respectively. In the Control group, the strongest connections are concentrated in the occipital and parietal regions. These regions play a vital role in visual processing and sensory integration, showcasing a stable and efficient brain network organization. The occipital region's dominance in the Control group suggests healthy neural patterns without significant disruptions. This enables consistent and efficient communication within the brain, particularly in areas essential for interpreting visual input.
</p>

<p>
    On the other hand, the Alcohol group displays more disruptions, characterized by lower overall connectivity values. Although connections are observed in the parietal and occipital regions, they are weaker compared to the Control group. This indicates a less organized and consistent brain network in the Alcohol group, likely reflecting the effects of alcohol on neural connectivity. Interestingly, the parietal region's dominance in the Alcohol group might suggest a compensatory mechanism, where the brain attempts to enhance connectivity in regions responsible for sensory processing and spatial awareness to counterbalance alcohol-induced disruptions.
</p>

<p>
    Table 2 highlights the top connected node pairs based on cosine similarity for the Alcohol and Control groups. The analysis reveals that the Alcohol group exhibits strong connectivity in the parietal and occipital regions, which are associated with sensory processing and spatial awareness. However, the Control group demonstrates even stronger connections within the occipital area, a region crucial for visual processing and sensory integration.
</p>
<p></p>
<p><a href="#">
    <img src="/img/eegTable2.jpg" alt="Top Connected Node Pairs" width="471" />
</a></p>
<p></p>
<p>
    These findings suggest that the Control group has a more stable and efficient brain network organization, enabling robust communication between regions involved in visual and sensory information processing. In contrast, the Alcohol group's connectivity, while present, appears less stable, potentially reflecting the impact of alcohol on neural communication pathways.
</p>

<p>
    Table 3 showcases the nodes with the highest cosine similarity values for both the Alcohol and Control groups. In the Alcohol group, the strongest connectivity is observed in the parietal region, suggesting a focus on regions responsible for sensory processing and spatial awareness. This pattern could indicate a compensatory mechanism in response to disruptions caused by alcohol.
</p>
<p></p>
<p><a href="#">
    <img src="/img/eegTable3.jpg" alt="Top Nodes with Highest Cosine Similarity" width="333" />
</a></p>
<p></p>
<p>
    Conversely, the Control group shows dominance in the occipital region, which reflects consistent and efficient neural communication critical for interpreting visual information. This occipital region dominance highlights the Control group's more organized and robust brain network, supporting efficient sensory and visual information processing. The contrast between the two groups underscores differences in how the brain processes sensory and visual stimuli under varying conditions.
</p>

<h4>Weakly Connected Positions</h4>

<p>
    As shown in Tables 4 and 5, the nodes and node pairs with the lowest cosine similarity values for both the Alcohol and Control groups are concentrated in the central brain regions, such as <strong>CZ</strong>, <strong>C1</strong>, and <strong>C2</strong>. These regions are primarily associated with motor functions and are not expected to exhibit high connectivity in trials focused on visual stimuli. This finding aligns with the task's emphasis on visual processing rather than motor activity.
</p>

<p>
    In the Control group, these motor-related regions display low connectivity, which is consistent with the visual nature of the task. However, in the Alcohol group, the connectivity in these regions is even weaker, indicating that alcohol exposure may lead to broader disruptions across brain networks, even in areas not directly involved in the experimental task. This suggests that alcohol may impair not only task-relevant connectivity but also overall neural network stability.
</p>

<p>
    Table 4 highlights node pairs with the lowest cosine similarity values in both the Alcohol and Control groups. These weakly connected regions are particularly concentrated in central areas associated with motor function. While both groups show reduced connectivity in these regions, the Alcohol group exhibits more pronounced disruptions, indicating a broader impact of alcohol on neural networks.
</p>
<p></p>
<p><a href="#">
    <img src="/img/eegTable4.jpg" alt="Table 4: Lowest Connected Node Pairs" width="471" />
</a></p>
<p></p>

<p>
    Table 5 identifies individual nodes with the lowest cosine similarity values in both groups, primarily located in central regions such as CZ, C1, and C2. The Control group maintains slightly higher connectivity in these areas, aligning with the task's visual focus. In contrast, the Alcohol group demonstrates more pronounced disruptions, further reflecting the potential impact of alcohol on overall brain network stability.
</p>
<p></p>
<p><a href="#">
    <img src="/img/eegTable5.jpg" alt="Table 5: Lowest Connected Nodes" width="333" />
</a></p>
<p></p>

<h4>Graphical Representation of High and Low Connectivity Nodes</h4>

<p>
    The figure displays a topographical map of EEG channels, highlighting nodes based on their overall cosine similarity values for the Alcohol and Control groups. Nodes with the highest connectivity are shown in <strong>turquoise</strong> for the Alcohol group and in <strong>blue</strong> for the Control group, while those with the lowest connectivity are represented in <strong>yellow</strong> for the Alcohol group and <strong>orange</strong> for the Control group. This visualization offers a clear comparison of connectivity patterns, identifying regions of stronger and weaker signal correlations.
</p>
<p></p>
<div style="text-align: center; border: 2px solid #ccc; padding: 10px; width: fit-content; margin: auto;">

    <a href="#">
        <img src="/img/brain4.jpg" alt="Graphical Representation of Connectivity Nodes" width="598" />
    </a>
</div>
<p></p>
<p></p>

<p></p>
<p>
    In the Control group, the high-connectivity nodes are primarily located in the occipital region, which is responsible for visual processing. This stable neural interaction is expected during visual trials, indicating efficient brain network organization in response to visual stimuli. In contrast, the Alcohol group exhibits stronger connections in the parietal region, with fewer occipital nodes involved. This shift in connectivity may indicate how alcohol alters brain activity, possibly disrupting normal visual processing and causing compensatory activity in other regions.
</p>

<p>
    Both groups demonstrate low connectivity in the central region, which is typically linked to motor and sensorimotor processing. The lower activity in these areas during visual trials suggests they are not heavily engaged, aligning with their expected limited role in visual perception and processing tasks.
</p>

<h3>In Conclusion</h3>

<p>
    This study highlights the potential of GNN Link Prediction models to uncover subtle variations in EEG connectivity, providing a deeper understanding of neural dynamics. By developing a unified graph structure based on spatial distances between EEG electrodes, we successfully applied these models to analyze and interpret brain connectivity patterns in both Alcohol and Control groups.
</p>

<p>
    Our findings reveal that GNN Link Prediction models offer unique insights into connectivity patterns that traditional methods might miss. In the Control group, high-connectivity nodes were predominantly found in the occipital region, which is crucial for visual processing, reflecting stable and efficient neural responses. In contrast, the Alcohol group exhibited stronger connectivity in the parietal region, suggesting compensatory mechanisms to address disruptions caused by alcohol exposure. This shift highlights how alcohol may alter typical brain activity, particularly in regions linked to sensory and cognitive functions.
</p>

<p>
    Beyond EEG analysis, this framework is adaptable to other types of time series data, making it a versatile tool for studying connectivity patterns and uncovering underlying physiological dynamics. By integrating AI with neuroscience, this work demonstrates how GNN Link Prediction models can enhance our understanding of brain connectivity and open new avenues for research and clinical applications.
</p>

<p></p>
<h3>Workshop</h3>

<p></p>

<p>This study was presented in <i><a href="https://iwain.lucentia.es/programme/">“2024 International Workshop on Artificial Intelligence for Neuroscience”</a></i> - workshop in Alicante, Spain on November 26, 2024. Here are some slides from the presentation that are not in this poster.</p>
<p></p>
<p>We started with explaining people that graphs are everywhere in our lives. They represent molecules in chemistry, roads in navigation, and even our social networks like Facebook as molecule graphs, traffic graph, and social network graph.</p>

<p></p>
<p><a href="#">
    <img src="/img/alicante1.jpg" alt="Top Connected Node Pairs" width="711" />
</a></p>
<p></p>
<p>Then we showed that perhaps the most important graph of all is the one inside us: the network of neurons and synapses that forms our brain and for neuroscience, understanding graphs is key to unraveling how our brains process information, learn, and adapt.</p>
<p></p>
<p><a href="#">
    <img src="/img/alicante2.jpg" alt="Top Connected Node Pairs" width="711" />
</a></p>
<p></p>
<p>Then we introduced deep learning history, how GNN was created and what is the most important to know about GGN models.</p>
<p></p>
<p><a href="#">
    <img src="/img/alicante3.jpg" alt="Top Connected Node Pairs" width="711" />
</a></p>
<p></p>
<p>Finally, we discussed why for neuroscience graph thinking is really important and how neuroscientists can start thinking in that direction.</p>
<p></p>
<p><a href="#">
    <img src="/img/alicante4.jpg" alt="Top Connected Node Pairs" width="711" />
</a></p>
<p></p>

<p></p>
<p></p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[Brain Graphs with Time Series Signals In this project, we model the brain as a spatial graph: each node is an EEG electrode on the scalp, and edges connect nearby positions in the standard montage. The time series data are used as node features for each trial, so every channel carries its full signal while staying embedded in the brain’s geometry. A GNN link prediction model then learns how these nodes connect under different conditions, revealing changes in functional connectivity and highlighting which regions act as key connectors in Control vs Alcohol groups.]]></summary></entry><entry><title type="html">Unlocking the Power of Pre-Final Vectors in GNN Graph Classification</title><link href="http://localhost:4000/2024/07/04/vectorsGNN/" rel="alternate" type="text/html" title="Unlocking the Power of Pre-Final Vectors in GNN Graph Classification" /><published>2024-07-04T08:00:00-04:00</published><updated>2024-07-04T08:00:00-04:00</updated><id>http://localhost:4000/2024/07/04/vectorsGNN</id><content type="html" xml:base="http://localhost:4000/2024/07/04/vectorsGNN/"><![CDATA[<h2>Graph-Level Embeddings</h2>
<p>
  Graph-level embeddings are the <strong>pre-final vectors</strong> produced by a GNN graph
  classification model, giving one compact fingerprint for each graph—whether it represents a
  city’s climate, an EEG trial, a machine, or a document. Once we have these embeddings, we can
  use simple vector-space tools (similarity, clustering, thresholds) to compare graphs, group
  similar cases, spot outliers, and even build a “graph of graphs” on top of them. In other words,
  graph-level embeddings turn single GNN predictions into a reusable layer for deeper analysis
  across many small graphs.
</p>

<h2>Conference &amp; Poster</h2>
<p>
  This work, <em>“Utilizing Pre-Final Vectors from GNN Graph Classification for Enhanced Climate Analysis”</em>,
  was presented as a peer-reviewed poster at the 21st International Workshop on Mining and Learning with Graphs (MLG 2024),
  co-located with <strong>ECML-PKDD 2024</strong> in Vilnius, Lithuania, on <strong>9 September 2024</strong>.
  The paper appears in the non-archival online workshop proceedings and is available via the MLG 2024 website.
</p>

<p></p>
<p><h2> Introduction</h2>

<p></p>
Linear algebra plays a crucial role in machine learning and artificial intelligence by providing efficient ways to represent and manipulate data. Whether dealing with matrices or vectors, these mathematical structures help model complex problems in a manageable form. The rise of deep learning models has shown just how versatile linear algebra can be across various fields.
<p></p>
Converting different types of data—like images, audio, text, and social network information—into a uniform vector format is essential for deep learning. This standardization makes it easier for deep learning algorithms to process and analyze data, paving the way for innovative AI applications that work across multiple domains. Linear algebra supports many machine learning methods, including clustering, classification, and regression, by enabling data manipulation and analysis within neural network pipelines. Each step in these pipelines often involves vector operations, highlighting the critical role of linear algebra in advancing deep learning technology.
<p></p>

<p></p>



In this post, we explore how to capture pre-final vectors from GNN processes and apply these intermediate vectors to various techniques beyond their primary tasks. GNNs are used for key tasks like node classification, link prediction, and graph classification. Node classification and link prediction rely on node embeddings, while graph classification uses whole graph embeddings. These pre-final vectors, which represent embedded node features, can be utilized for tasks like node classification, regression, clustering, finding closest members, and triangle analysis.
<p></p>
For example, the GraphSAGE link prediction model in the Deep Graph Library (DGL) produces pre-final vectors, or embeddings, for each node instead of direct link predictions. These embeddings capture the nodes’ features and relationships within the graph. Previous studies have used these pre-final vectors for tasks like node classification, clustering, regression, and graph triangle analysis.
<p></p>
While the potential of pre-final vectors from link prediction models has been studied, our research shows that no studies currently look into capturing embedded whole graphs from GNN Graph Classification models. These models capture graph structures through both individual nodes and overall topology, using both attribute and relational information in small graphs. This makes GNN Graph Classification models powerful for specific challenges in fields like social networks, biological networks, and knowledge graphs. In this study, we will show how to capture embedded vectors of entire 'small graphs' from such models and use them for further graph data analysis.
<p></p>


<p></p>


GNN Graph Classification models use many labeled small graphs as input data. Traditionally used in chemistry and biology, these models can also be applied to small graphs from other domains. For instance, in social networks, these techniques analyze the surroundings of points of interest identified by high centrality metrics, including their friends and friends of friends. Time series data can be segmented into small graphs using sliding window techniques, effectively capturing short-term variability and rapid changes for dynamic data analysis.
<p></p>
In our study, we will use climate time series data from a Kaggle dataset containing daily temperature data for 40 years in the 1000 most populous cities worldwide. For each city, we will create a graph where nodes represent combinations of cities and years, and node features are daily temperature vectors for each city-year node. To define graph edges, we will select pairs of vectors with cosine similarities higher than a threshold.
<p></p>
We will validate the methods for capturing pre-final vectors and demonstrate their effectiveness in managing and analyzing dynamic datasets. By capturing these embedded vectors and applying similarity measures to them, we will extend beyond graph classification to apply methods like clustering, finding the closest neighbors for any graph, or even using small graphs as nodes to create meta-graphs on top of small graphs.
<p></p>


<p></p>

<p></p>



<p><h3> Related Work</h3>
<p></p>

<p></p>
<p></p>


In 2012, deep learning and knowledge graphs experienced a significant breakthrough. The introduction of Convolutional Neural Network (CNN) image classification through AlexNet demonstrated its superiority over previous machine learning techniques in various domains. Around the same time, Google introduced knowledge graphs, which enabled machines to understand relationships between entities and revolutionized data integration and management, enhancing products with intelligent capabilities.
<p></p>
For years, deep learning and knowledge graphs grew simultaneously, with CNNs excelling at tasks involving grid-structured data but struggling with graph-structured data. Conversely, graph techniques thrived on graph-structured data but lacked the sophisticated capabilities of deep learning. In the late 2010s, Graph Neural Networks (GNNs) emerged, combining deep learning with graph processing. This innovation revolutionized the handling of graph-structured data by enabling complex data analysis and predictions through the effective capture of relationships between graph nodes.
<p></p>
Starting in 2022, Large Language Models (LLMs) became prominent in the deep learning landscape, capturing much of the research attention. However, the potential of GNNs continues to be recognized, and we remain optimistic that GNN research and applications will continue to grow and expand.
<p></p>



<p></p>
<a href="#">
    <img src="/img/climateGnnGc1.jpg" alt="Post Sample Image" width="479" />
</a>
<p></p>
(Picture from a book: Bronstein, M., Bruna, J., Cohen, T., and Velickovic ́, P.
“Geometric deep learning: Grids, groups, graphs, geodesics, and gauges”, 2021)
</p><p>

<p></p>
The "Geometric Deep Learning" paper was written in 2021 when Convolutional Neural Networks (CNNs) were the leading models in the deep learning world. If that paper were written in 2023-2024, Large Language Models (LLMs) would undoubtedly be at the forefront. It's exciting to think about what might be the biggest breakthrough in deep learning in the next 2-3 years.
<p></p>

<p></p>

<h3>Methods</h3>
<p></p>

<h4>Graph Construction and Climate Labeling</h4>
<p></p>

In this study, we utilized GNN Graph Classification models to analyze small labeled graphs created from nodes and edges. We constructed graphs for each city, with nodes representing specific city-year pairs and edges defined by pairs of nodes with cosine similarities higher than threshold values. Each graph was labeled as either 'stable' or 'unstable' based on the city's geographical latitude.
<p></p>
<h4>Implementation of GCNConv for Graph Classification</h4>

<p></p>
For classifying these graphs, we used the Graph Convolutional Network (GCNConv) model from the PyTorch Geometric Library (PyG). The GCNConv model allowed us to extract feature vectors from the graph data, enabling us to perform a binary classification to determine whether the climate for each city was 'stable' or 'unstable'.
<p></p>

<h4>Python Code for Extracting Pre-Final Vectors: Graph Embedding</h4>
<p></p>
This function defines a custom Graph Convolutional Network (GCN) model using the PyTorch Geometric (PyG) library. The model is designed for classifying graphs, such as determining the climate stability of cities based on their temperature data. Here's a detailed breakdown of the function:
<p></p>
<p></p>  

<p></p>

<p></p>


<ul>
  <li>Node Embedding:
    <ul>
      <li>Input features are processed through multiple graph convolutional layers.</li>
      <li>ReLU activation is applied to enhance node embeddings.</li>
    </ul>
  </li>
  <li>Aggregation:
    <ul>
      <li>Node embeddings are pooled into a single graph embedding using global mean pooling.</li>
      <li>This aggregation creates a vector representing the entire graph.</li>
    </ul>
  </li>
  <li>Returning Graph Embedding:
    <ul>
      <li>If a specific parameter is set, the function returns these graph embeddings as pre-final vectors.</li>
      <li>These intermediate vectors can then be used for further analysis, such as climate data analysis, clustering, or other tasks.</li>
    </ul>
  </li>
</ul>

<p></p>  





<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch.nn</span> <span class="kn">import</span> <span class="n">Linear</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GCNConv</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">global_mean_pool</span>
<span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">GCN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="mi">365</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lin</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">return_graph_embedding</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="c1"># Node Embedding Steps
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="c1"># Graph Embedding Step
</span>        <span class="n">graph_embedding</span> <span class="o">=</span> <span class="nf">global_mean_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>  <span class="c1"># [num_graphs, hidden_channels]
</span>        <span class="k">if</span> <span class="n">return_graph_embedding</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">graph_embedding</span>  <span class="c1"># Return graph-level embedding here
</span>        <span class="c1"># Classification Step
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">graph_embedding</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span></code></pre></figure>



<p></p>

After training the Graph Convolutional Network (GCN) model, this code snippet extracts the graph embedding for a specific graph in the dataset:
The graph embedding is stored in <code><span style="color: blue;">out</span></code>, capturing the structural and feature information of the entire graph.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">g</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_graph_embedding</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">out</span><span class="p">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">])</span></code></pre></figure>

<p></p>
<ul>
    <li><em>dataset[g].x.float()</em>: Node features as floating-point tensor.</li>
    <li><em>dataset[g].edge_index</em>: Edge list of the graph.</li>
    <li><em>dataset[g].batch</em>: Batch assignment for nodes.</li>
    <li><em>return_graph_embedding=True</em>: Requests the graph-level embedding instead of classification.</li>
</ul>

<p></p>
The following code processes a series of graphs using a GCN model, applies a softmax function to the outputs, extracts predictions and graph embeddings, and stores the embeddings along with graph indices in a list for further analysis.
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Softmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">graphUnion</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">graphCount</span><span class="p">):</span>
  <span class="n">label</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_graph_embedding</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="n">output</span> <span class="o">=</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">out</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">graphUnion</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">:</span><span class="n">g</span><span class="p">,</span><span class="sh">'</span><span class="s">vector</span><span class="sh">'</span><span class="p">:</span> <span class="n">out</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()})</span></code></pre></figure>

<p></p>
<p></p>
Cosine similarity function:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch.nn.functional</span> <span class="kn">import</span> <span class="n">normalize</span>
<span class="k">def</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">a_norm</span> <span class="o">=</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b_norm</span> <span class="o">=</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">a_norm</span><span class="p">,</span> <span class="n">b_norm</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span></code></pre></figure>

<p></p>
This code calculates the cosine similarity between pairs of graph embeddings stored in <code><span style="color: blue;">graphUnion</span></code> and appends the results, along with their corresponding graph indices, to the <code><span style="color: blue;">cosine_similarities</span></code> list.
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cosine_similarities</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">graphUnion</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">graphUnion</span><span class="p">)):</span>  
        <span class="n">vector_i</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">graphUnion</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">'</span><span class="s">vector</span><span class="sh">'</span><span class="p">])</span>
        <span class="n">vector_j</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">graphUnion</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="sh">'</span><span class="s">vector</span><span class="sh">'</span><span class="p">])</span>
        <span class="n">cos_sim_value</span> <span class="o">=</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">vector_i</span><span class="p">,</span> <span class="n">vector_j</span><span class="p">).</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">flatten</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>  
        <span class="n">cosine_similarities</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span>
            <span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">:</span> <span class="n">graphUnion</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">],</span>
            <span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">:</span> <span class="n">graphUnion</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">],</span>
            <span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span> <span class="n">cos_sim_value</span>
        <span class="p">})</span></code></pre></figure>

<p></p>
<p></p>

<p></p>
<p></p>

<p></p>

<p></p>

<p></p>

<h3>Experiments Overview</h3>
<p></p>
<h4>Data Source: Climate Data</h4>
<p></p>
Our primary dataset, sourced from Kaggle, is titled:
<i><a href="
https://www.kaggle.com/hansukyang/temperature-history-of-1000-cities-1980-to-2020">"Temperature History of 1000 cities 1980 to 2020"</a></i> - daily temperature from 1980 to 2020 years for 1000 most populous cities in the world. This dataset provides a comprehensive record of average daily temperatures in Celsius for the 1000 most populous cities worldwide, spanning from 1980 to 2019. Using this extensive dataset, we developed a Graph Neural Network (GNN) Graph Classification model to analyze and interpret the climatic behaviors of these urban centers.
<p></p>
For our analysis, each city was represented as an individual graph, with nodes corresponding to specific city-year pairs. These nodes encapsulate the temperature data for their respective years, facilitating a detailed examination of temporal climatic patterns within each city.
<p></p>
The graphs were labeled as 'stable' or 'unstable' based on the latitude of the cities. We assumed that cities closer to the equator exhibit less temperature variability and hence more stability. This assumption aligns with observed climatic trends, where equatorial regions generally experience less seasonal variation compared to higher latitudes. To categorize the cities, we divided the 1000 cities into two groups based on their latitude, with one group consisting of cities nearer to the equator and the other group comprising cities at higher latitudes.


<p></p>
<p></p>

   <p></p>
  <p></p>

   <a href="#">
       <img src="/img/preFinFig1.jpg" alt="Post Sample Image" width="678" />
   </a>
Fig. 1. Latitude Distribution of the 1000 Most Populous Cities.
   <p></p>
   The bar chart on this picture shows the latitude distribution of the 1000 most populous cities, highlighting a higher concentration of cities in the Northern Hemisphere, particularly between 20 and 60 degrees latitude, with fewer cities in the Southern Hemisphere. The equator is marked by a dashed line.
   <p></p>


    <p></p>

        <h4>Data Preparation and Model Training</h4>
  <p></p>
In our project, we developed a Graph Neural Network (GNN) Graph Classification model to analyze climate data. We created individual graphs for each city, labeling them as 'stable' or 'unstable' based on their latitude. Edges in these graphs were defined by high cosine similarities between node pairs, indicating similar temperature trends. To ensure consistency across all graphs, we introduced virtual nodes, which improved connectivity and helped the model generalize across different urban climates.
  <p></p>
For our analysis, we used the GCNConv model from the PyTorch Geometric (PyG) library. This model is excellent for extracting important feature vectors from graphs before making final classification decisions, which are essential for a detailed analysis of climate patterns.


<p></p>

 <a href="#">
     <img src="/img/preFinalVector1.jpg" alt="Post Sample Image" width="678" />
 </a>
 <p></p>
  <p></p>
The GCNConv model performed very well, with accuracy rates of around 94% on training data and 92% on test data. These results highlight the model’s ability to effectively detect and classify unusual climate trends using daily temperature data represented in graph form.
  <p></p>   

<h4>Application of Graph Embedded Vectors: Cosine Similarity Analysis</h4>
<p></p>

  After training the GNN Graph Classification model, we transformed each city graph into an embedded vector. These vectors became the foundation for our subsequent data analyses.
<p></p>
<h5>Cosine Similarity Matrix Analysis of Graph-Embedded Vectors</h5>
<p></p>
  We constructed a cosine similarity matrix for 1000 cities to identify closely related climate profiles. This matrix allows for detailed comparisons and clustering based on the embedded vector data.
<p></p>
  To illustrate, we examined the closest neighbors of the graph vectors for Tokyo, Japan (the largest city in our dataset), and Gothenburg, Sweden (the smallest city in our dataset). Tokyo’s closest neighbors are primarily major Asian cities, indicating strong climatic and geographical similarities. Similarly, Gothenburg’s nearest neighbors are predominantly European cities, reflecting similar weather patterns across Northern and Central Europe.
<p></p>
  We also identified vector pairs with the lowest cosine similarity, specifically -0.543011, between Ulaanbaatar, Mongolia, and Shaoguan, China. This negative similarity suggests stark climatic differences. Additionally, the pair with a cosine similarity closest to 0.0 (-0.000047), indicating orthogonality, is between Nanchang, China, and N’Djamena, Chad. This near-zero similarity underscores the lack of a significant relationship between these cities’ climatic attributes.
<p></p>




    <p></p>    

<p></p>    
Table 1. Closest Neighbors of Tokyo, Japan (Lat 35.69, Long 139.69). Based on Cosine
Similarity
     <a href="#">
         <img src="/img/preFinTab1.jpg" alt="Post Sample Image" width="404" />
     </a>

<p></p>
<p></p>

Table 2. Closest Neighbors of Gothenburg, Sweden (Lat 57.71, Long 12.00). Based on Cosine Similarity
      <a href="#">
          <img src="/img/preFinTab2.jpg" alt="Post Sample Image" width="383" />
      </a>
<p></p>
Code to identify the top 5 closest neighbors to a specific node (node 0) based on cosine similarity values:
<p></p>
<ul>
    <li>Select neighbors where node 0 is either the 'left' or 'right' node from the DataFrame <em>dfCosSim</em>.</li>
    <li>Concatenate these rows into a single DataFrame <em>neighbors</em>.</li>
    <li>Sort the combined DataFrame by cosine similarity in descending order to prioritize the closest neighbors.</li>
    <li>Add a 'neighbor' column to identify the neighboring node, adjusting between 'left' and 'right' as needed.</li>
    <li>Select the top 5 rows with the highest cosine similarity and keep only the 'neighbor' and 'cos' columns.</li>
</ul>

    <p></p>

    
<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="n">neighbors_left</span> <span class="o">=</span> <span class="n">dfCosSim</span><span class="p">[</span><span class="n">dfCosSim</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">neighbors_right</span> <span class="o">=</span> <span class="n">dfCosSim</span><span class="p">[</span><span class="n">dfCosSim</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">neighbors</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">neighbors_left</span><span class="p">,</span> <span class="n">neighbors_right</span><span class="p">])</span>
    <span class="n">neighbors</span> <span class="o">=</span> <span class="n">neighbors</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">neighbors</span><span class="p">[</span><span class="sh">'</span><span class="s">neighbor</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">neighbors</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">]</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">top_5_neighbors</span> <span class="o">=</span> <span class="n">neighbors</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">top_5_neighbors</span> <span class="o">=</span> <span class="n">top_5_neighbors</span><span class="p">[[</span><span class="sh">'</span><span class="s">neighbor</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">]]</span>
    </code></pre></figure>



    </p><p>  

<h5>Analyzing Climate Profiles with Cosine Similarity Matrix</h5>
<p></p>


The cosine similarity matrix distribution from the embedded city graphs reveals distinct clustering patterns, with notable peaks for values over 0.9 and between -0.4 to -0.2. These peaks indicate clusters of cities with nearly identical climates and those with shared but less pronounced features. This skewed distribution highlights areas with the highest concentration of values, providing essential insights into the relational dynamics and clustering patterns of the cities based on their climate data. The bar chart clearly illustrates how cities with similar climate profiles group together.

<p></p>
Table 3. Distribution of Cosine Similarities.
      <a href="#">
          <img src="/img/preFinTab3.jpg" alt="Post Sample Image" width="256" />
      </a>

<p></p>
<p></p>

 <a href="#">
     <img src="/img/preFinFig2.jpg" alt="Post Sample Image" width="678" />
 </a>
<p></p>
Code for distribution of cosine similarities
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>  <span class="c1"># Adjust the size of the figure, swapped dimensions for vertical orientation
</span><span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">dfCosSim</span><span class="p">[</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span>
         <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">CornflowerBlue</span><span class="sh">'</span><span class="p">,</span>
         <span class="n">orientation</span><span class="o">=</span><span class="sh">'</span><span class="s">horizontal</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># Set orientation to horizontal
</span><span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Distribution of Cosine Similarities</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Cosine Similarity</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># Now y-axis is cosine similarity
</span><span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Frequency</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># And x-axis is frequency
</span><span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure>


<p></p>
<h4>Application of Graph Embedded Vectors: Graphs Derived from Cosine Similarity Thresholds</h4>
<p></p>
Based on the observed distribution of cosine similarities, we generated three distinct graphs for further analysis, each using different cosine similarity thresholds to explore their impact on city pair distances.


<p></p>
To calculate distances between cities we used the following code:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">math</span> <span class="kn">import</span> <span class="n">sin</span><span class="p">,</span> <span class="n">cos</span><span class="p">,</span> <span class="n">sqrt</span><span class="p">,</span> <span class="n">atan2</span><span class="p">,</span> <span class="n">radians</span>
<span class="k">def</span> <span class="nf">dist</span><span class="p">(</span><span class="n">lat1</span><span class="p">,</span><span class="n">lon1</span><span class="p">,</span><span class="n">lat2</span><span class="p">,</span><span class="n">lon2</span><span class="p">):</span>
  <span class="n">rlat1</span> <span class="o">=</span> <span class="nf">radians</span><span class="p">(</span><span class="nf">float</span><span class="p">(</span><span class="n">lat1</span><span class="p">))</span>
  <span class="n">rlon1</span> <span class="o">=</span> <span class="nf">radians</span><span class="p">(</span><span class="nf">float</span><span class="p">(</span><span class="n">lon1</span><span class="p">))</span>
  <span class="n">rlat2</span> <span class="o">=</span> <span class="nf">radians</span><span class="p">(</span><span class="nf">float</span><span class="p">(</span><span class="n">lat2</span><span class="p">))</span>
  <span class="n">rlon2</span> <span class="o">=</span> <span class="nf">radians</span><span class="p">(</span><span class="nf">float</span><span class="p">(</span><span class="n">lon2</span><span class="p">))</span>
  <span class="n">dlon</span> <span class="o">=</span> <span class="n">rlon2</span> <span class="o">-</span> <span class="n">rlon1</span>
  <span class="n">dlat</span> <span class="o">=</span> <span class="n">rlat2</span> <span class="o">-</span> <span class="n">rlat1</span>
  <span class="n">a</span> <span class="o">=</span> <span class="nf">sin</span><span class="p">(</span><span class="n">dlat</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="nf">cos</span><span class="p">(</span><span class="n">rlat1</span><span class="p">)</span> <span class="o">*</span> <span class="nf">cos</span><span class="p">(</span><span class="n">rlat2</span><span class="p">)</span> <span class="o">*</span> <span class="nf">sin</span><span class="p">(</span><span class="n">dlon</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
  <span class="n">c</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="nf">atan2</span><span class="p">(</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="nf">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a</span><span class="p">))</span>
  <span class="n">R</span><span class="o">=</span><span class="mf">6371.0</span>
  <span class="k">return</span> <span class="n">R</span> <span class="o">*</span> <span class="n">c</span>

  <span class="k">def</span> <span class="nf">cityDist</span><span class="p">(</span><span class="n">city1</span><span class="p">,</span><span class="n">country1</span><span class="p">,</span><span class="n">city2</span><span class="p">,</span><span class="n">country2</span><span class="p">):</span>
    <span class="n">lat1</span><span class="o">=</span><span class="n">cityMetadata</span><span class="p">[(</span><span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">city_ascii</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">city1</span><span class="p">)</span>
      <span class="o">&amp;</span> <span class="p">(</span><span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">country1</span><span class="p">)][</span><span class="sh">'</span><span class="s">lat</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">lat2</span><span class="o">=</span><span class="n">cityMetadata</span><span class="p">[(</span><span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">city_ascii</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">city2</span><span class="p">)</span>
      <span class="o">&amp;</span> <span class="p">(</span><span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">country2</span><span class="p">)][</span><span class="sh">'</span><span class="s">lat</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">lon1</span><span class="o">=</span><span class="n">cityMetadata</span><span class="p">[(</span><span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">city_ascii</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">city1</span><span class="p">)</span>
      <span class="o">&amp;</span> <span class="p">(</span><span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">country1</span><span class="p">)][</span><span class="sh">'</span><span class="s">lng</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">lon2</span><span class="o">=</span><span class="n">cityMetadata</span><span class="p">[(</span><span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">city_ascii</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">city2</span><span class="p">)</span>
      <span class="o">&amp;</span> <span class="p">(</span><span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">country2</span><span class="p">)][</span><span class="sh">'</span><span class="s">lng</span><span class="sh">'</span><span class="p">]</span>
    <span class="k">return</span> <span class="nf">dist</span><span class="p">(</span><span class="n">lat1</span><span class="p">,</span><span class="n">lon1</span><span class="p">,</span><span class="n">lat2</span><span class="p">,</span><span class="n">lon2</span><span class="p">)</span>  </code></pre></figure>

<p></p>


The following function filters a DataFrame for high cosine similarity values, creates a graph, and adds edges between nodes with high similarities, ready for further analysis or visualization.
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">df</span><span class="o">=</span><span class="n">dfCosSim</span>
<span class="n">high_cos_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.9</span><span class="p">]</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">high_cos_df</span><span class="p">.</span><span class="n">empty</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">high_cos_df</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
        <span class="n">G</span><span class="p">.</span><span class="nf">add_edge</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">],</span> <span class="n">weight</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">])</span></code></pre></figure>


<p></p>

<p></p>


The following code enriches the edges of the graph <em>G</em> with distance information and then collects all the distance values into a list for further analysis:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">distData</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
  <span class="k">if</span> <span class="n">G</span><span class="p">.</span><span class="nf">has_edge</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">]):</span>
    <span class="n">G</span><span class="p">[</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">]][</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">]][</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">]</span>

<span class="n">distances</span> <span class="o">=</span> <span class="p">[</span><span class="n">attr</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">G</span><span class="p">.</span><span class="nf">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="bp">True</span><span class="p">)]</span>
<span class="n">mean_distance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
<span class="n">median_distance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">median</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
<span class="n">std_deviation</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">std</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
<span class="n">min_distance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">min</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
<span class="n">max_distance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span></code></pre></figure>

<p></p>
This code iterates through the <em>distData</em> DataFrame, checks for existing edges in the graph <em>G</em>, and adds distance attributes to these edges. It then calculates the mean, median, standard deviation, minimum, and maximum of the distance values.
<p></p>
<b>For the first graph</b>, we used a high similarity threshold (cosine similarity &gt; 0.9).

The statistics for the distances between city pairs in the first graph are as follows:
<ul>
    <li><strong>Mean distance</strong>: 7942.658 km</li>
    <li><strong>Median distance</strong>: 7741.326 km</li>
    <li><strong>Standard deviation</strong>: 5129.801 km</li>
    <li><strong>Minimum distance</strong>: 1.932 km</li>
    <li><strong>Maximum distance</strong>: 19975.287 km</li>
</ul>


<p></p>               
The shortest distance pair is between Jerusalem, Israel, and Al Quds, West Bank, with nearly identical latitude and longitude coordinates (31.7784, 35.2066 for Jerusalem and 31.7764, 35.2269 for Al Quds), highlighting their close proximity. In contrast, the longest distance pair is between Quito, Ecuador, and Pekanbaru, Indonesia. These cities, located on opposite sides of the world, have dramatically different geographical coordinates (-0.2150, -78.5001 for Quito and 0.5650, 101.4250 for Pekanbaru), spanning a vast distance across the globe.

<p></p>


<b>For the second graph</b>, defined by a cosine similarity threshold ranging from -0.4 to -0.2, we observed a moderate level of climatic similarity among city pairs. The key statistics for this graph are as follows:

<p></p>

<p></p>
<ul>
    <li><strong>Mean distance</strong>: 8648.245 km</li>
    <li><strong>Median distance</strong>: 8409.507 km</li>
    <li><strong>Standard deviation</strong>: 4221.592 km</li>
    <li><strong>Minimum distance</strong>: 115.137 km</li>
    <li><strong>Maximum distance</strong>: 19963.729 km</li>
</ul>

<p></p>

For this graph, the shortest distance pair is between Kabul, Afghanistan (latitude 34.5167, longitude 69.1833) and Jalalabad, Afghanistan (latitude 34.4415, longitude 70.4361). The longest distance pair is between Mendoza, Argentina (latitude -32.8833, longitude -68.8166) and Shiyan, China (latitude 32.5700, longitude 110.7800).

<p></p>

Both the first and second graphs had just one connected component. To generate a graph with several connected components, we examined graphs with very high thresholds.
<p></p>
<b>For the third graph</b>, we used a high similarity threshold (cosine similarity &gt; 0.99), resulting in connected components of sizes [514, 468, 7, 5]. The largest connected component, with 514 nodes, predominantly includes cities with stable climates (475 nodes labeled as stable) and a smaller portion with unstable climates (39 nodes labeled as unstable). The second-largest component, containing 468 nodes, primarily consists of cities with unstable climates (451 nodes labeled as unstable) and a few with stable climates (17 nodes labeled as stable). These findings indicate that cities within the same climate category (stable or unstable) exhibit higher similarity, leading to larger connected components, whereas similarities across different climate categories are less pronounced.
<p></p>
Table 4. Cities in the Third Connected Component (7 Nodes)
      <a href="#">
          <img src="/img/preFinTab4.jpg" alt="Post Sample Image" width="383" />
      </a>
<p></p>
In the smaller connected components, city graphs represent areas on the border between stable and unstable climates. The cities in these smaller components illustrate the variability and complexity of climatic relationships, showing a blend of stable and unstable climatic conditions. This underscores the nuanced and intricate climatic patterns that exist at the boundaries between different climate categories.
<p></p>




Table 5. Cities in the Fourth Connected Component (5 Nodes)
          <a href="#">
              <img src="/img/preFinTab5.jpg" alt="Post Sample Image" width="383" />
          </a>
              <p></p>

<p></p>
<p></p>



    <p></p>


<p></p>

<p></p>

<p></p>

<p></p>




<p></p>

<h3>In Conclusion</h3>
<p></p>


In this study, we explored how pre-final vectors from GNN models can be applied in GNN Graph Classification. We showed that linear algebra is vital in transforming various data types into uniform vector formats that deep learning models can effectively use.
<p></p>
Our research demonstrated how GNN Graph Classification models capture complex graph structures through advanced linear algebra techniques. By embedding entire 'small graphs' from these models, we opened up new possibilities for analyzing and clustering small graphs, finding nearest neighbors, and creating meta-graphs.
<p></p>
The results suggest that combining linear algebra with GNNs enhances the models' efficiency and scalability, making them useful in many fields. By capturing and analyzing embedded graphs from GNN Graph Classification models, we can significantly improve data analysis and predictive abilities, advancing artificial intelligence and its many applications.
<p></p>



<p></p>

<p></p>    





<p></p>

<p></p>

<p></p>
<p></p>
</p></p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[Graph-Level Embeddings Graph-level embeddings are the pre-final vectors produced by a GNN graph classification model, giving one compact fingerprint for each graph—whether it represents a city’s climate, an EEG trial, a machine, or a document. Once we have these embeddings, we can use simple vector-space tools (similarity, clustering, thresholds) to compare graphs, group similar cases, spot outliers, and even build a “graph of graphs” on top of them. In other words, graph-level embeddings turn single GNN predictions into a reusable layer for deeper analysis across many small graphs.]]></summary></entry><entry><title type="html">Multi-Layer Graph Analysis for Text-Driven Relationships Using GNN Link Prediction</title><link href="http://localhost:4000/2024/06/21/knowledgeGraphEmail/" rel="alternate" type="text/html" title="Multi-Layer Graph Analysis for Text-Driven Relationships Using GNN Link Prediction" /><published>2024-06-21T08:00:00-04:00</published><updated>2024-06-21T08:00:00-04:00</updated><id>http://localhost:4000/2024/06/21/knowledgeGraphEmail</id><content type="html" xml:base="http://localhost:4000/2024/06/21/knowledgeGraphEmail/"><![CDATA[<h2>Semantic Graphs for Communication Networks</h2>
<p>
  In this project, we move beyond simple “who emailed whom” graphs and build a
  <strong>semantic graph</strong> of communication. Instead of treating edges as raw message
  counts, we create nodes for individual interactions (who wrote to whom, with what text), enrich
  them with transformer-based text embeddings, and use a GNN link prediction model to learn which
  interactions are genuinely related. This text-enriched graph lets us recompute centrality and see
  a different set of key players: not just the loudest senders, but the quiet connectors who bridge
  topics and conversation clusters—hidden connectors that a plain traffic graph would never reveal.
</p>

<h2>Conference &amp; Workshop</h2>
<p>
  The work <em>“Multi-Layer Graph Analysis for Text-Driven Relationships Using GNN Link Prediction”</em>
  was presented at the <strong>MLH 2024 – Mining and Learning with Hypergraphs</strong> workshop,
  co-located with <strong>ECML-PKDD 2024</strong>, in Vilnius, Lithuania, on
  <strong>13 September 2024</strong>. The contribution appears in the non-archival online
  workshop program and is available via the MLH 2024 website.
</p>

<p><h2>Multi-Layer Graph Analysis for Communication Networks </h2>
<p></p>

Analyzing complex graphs can be quite challenging, especially when the whole is greater than the sum of its parts. To address these challenges, we dive into the Enron email dataset, using its rich information to create a strong multi-layer graph analysis framework.
<p></p>
We start by building a foundational graph layer where email addresses are the nodes and email exchanges form the edges. This layer gives us a clear picture of the communication network, showing the direct interactions between individuals within the dataset.
<p></p>

Building upon this, we introduce a second graph layer that goes deeper into the content of these communications. Here, each interaction is represented as a node in the form of triplets—comprising the sender, receiver, email subject, and body. Edges in this layer signify communication chains, illustrating how discussions and information flow within the network.
<p></p>
To extract meaningful patterns from the textual content, we transform these triplet nodes into vectors using a transformer model. This transformation captures the semantic nuances of the email content. Following this, a Graph Neural Network (GNN) Link Prediction model is applied to these vectors. The model identifies potential links within the graph based on semantic similarity and structural patterns.
<p></p>

The output vectors from the GNN Link Prediction model, which capture both the semantic content and the graph structure, help us create a third graph layer. In this layer, nodes represent pairs of emails with high cosine similarities, forming a network that highlights strong semantic connections.
<p></p>
This third graph layer is key to identifying influencers within the network, revealing individuals who play important roles in spreading information. It also gives us a better understanding of engagement dynamics, showing how interactions evolve and spread across the network.
<p></p>
By using this multi-layer approach, we provide a comprehensive framework for analyzing complex textual interactions within graph structures. This method not only offers deeper insights into network dynamics but also improves our ability to identify key influencers, ultimately enhancing our understanding of intricate communication networks.

<p></p>

<h3>Introduction</h3>
<p></p>

Graphs are powerful tools for representing complex relationships, with each level building on the previous one’s capabilities and efficiency. Think of atoms forming molecules with unique properties, molecules creating cells with essential functions, and cells building organs with specialized roles. However, as graphs become more intricate, analyzing them becomes increasingly challenging.
<p></p>
Complex system analysis can be approached both top-down and bottom-up. In this study, we introduce a bottom-up method for analyzing graph layers built on text-driven relationships. This approach captures intricate details and emergent properties from foundational elements upwards.
<p></p>

For example, imagine a bipartite graph with individuals on one side and movie narratives on the other. Relationships in this graph are defined by shared interests in particular movies. By exploring the narrative elements in recommender systems, we can uncover complex relationships that go beyond merely identifying pairs or groups of people with common movie interests.

<p></p>
Another example is influence networks in social media, where nodes represent users and directed edges signify interactions such as likes, comments, or shares. By examining the content of posts and interactions, we can uncover text-driven relationships that reveal influence patterns and topics of interest. This approach helps us understand the dynamics of influence and engagement within the social media ecosystem.

<p></p>



    In a prior study <a href="https://doi.org/10.5220/0011664400003393">
  'Rewiring Knowledge Graphs by Graph Neural Network Link Predictions'
    </a> (2023), we focused on rewiring text-based knowledge graphs through the use of GNN link prediction models, specifically targeting semantic knowledge graphs built from text documents. We utilized GNN link prediction techniques to modify these graphs, revealing hidden connections between nodes.
<p></p>
    In another study <a href="https://doi.org/10.1007/978-981-99-8324-7_2"> 'Uncovering Hidden Connections: Granular Relationship Analysis in Knowledge Graphs' </a> (2024), we also applied GNN link prediction models to semantic knowledge graphs to uncover hidden relationships within a detailed vector space. We focused on identifying 'graph connectors' that expose deeper network structures and used graph triangle analysis to delve into complex interactions.

<p></p>

The Enron email corpus provides a valuable opportunity to explore the potential of text-enhanced knowledge graphs in uncovering hidden patterns within organizational communication. By focusing on direct interactions and using transformer models for text embedding, we lay the groundwork for a knowledge graph that better captures the complexity of real-world relationships.

<p></p>
Our findings highlight the significant impact of incorporating textual data and GNN Link Prediction in knowledge graph analysis. This approach provides a more complete view of how entities interact, helping us understand complex networks better. As we continue to refine these methods, the potential for uncovering new insights in data-rich environments seems limitless, opening up exciting possibilities for future research.
<p></p>




    <h3>Key Methodologies of Our Study</h3>
<p></p>    
<h4>Architecture Pipeline</h4>
<p></p>
    Our architecture pipeline for the multi-layer graph approach begins with raw data processing and follows to link prediction model:
<p></p>
<a href="#">
        <img src="/img/archPipeline2.jpg" alt="Post Sample Image" width="1024" />
</a>
<p></p>
        <ul>
            <li>
                <strong>Raw Data:</strong> The initial dataset includes attributes such as ‘from’, ‘to’, ‘body’, and ‘time’.
            </li>
            <li>
                <strong>Initial Graph Layer:</strong> Email addresses are depicted as nodes connected by edges representing email exchanges.
            </li>
            <li>
                <strong>Transformation to Triplet Nodes:</strong> Email exchanges are converted into triplets (from, to, email body).
            </li>
            <li>
                <strong>Second-Layer Graph Construction:</strong> Triplet nodes form edges based on communication chains (to-to connections).
            </li>
            <li>
                <strong>Node Embedding:</strong> Embedding node features to vectors.
            </li>
            <li>
                <strong>GNN Link Prediction:</strong> The GNN model is applied, transforming triplet nodes into vectors.
            </li>
        </ul>
        <p>
            After GNN Link Prediction model training, we will examine structural changes in the network to uncover key influencers.
        </p>

<p></p>

<h4>Transformation Process from Initial Graph to Second-Layer Graph</h4>
<p></p>
The process begins with constructing the initial graph layer, where email addresses are depicted as nodes connected by edges representing email exchanges, as shown in the picture. Each email exchange is then converted into triplets consisting of 'from', 'to', and the email's subject and body. Subsequently, a second-layer graph is constructed where these triplet nodes form edges based on communication chains ('to-to' connections), as illustrated in the picture.
<p></p>
<a href="#">
    <img src="/img/kgArch.jpg" alt="Post Sample Image" width="978" />
</a>

<p></p>
<h4>Node Embedding</h4>
<p></p>
To translate text into vectors, we will use the 'all-MiniLM-L6-v2' transformer model from Hugging Face. This sentence-transformer model efficiently maps text into 384-dimensional vectors. This process transforms sentences into dense vectors, preserving their semantic content for machine learning applications. This embedding step is crucial, ensuring the text is suitably prepared for deep learning analyses, including GNN link prediction, by capturing the nuanced meanings in a format compatible with our algorithms.
<p></p>
<h4>Training the GNN Link Prediction Model</h4>

<p></p>

After setting up the nodes, we refine the graph with GNN Link Prediction to uncover detailed interactions. By examining the graph’s structure and node details, we reveal previously hidden connections, enhancing the graph’s depth and utility for analysis.
<p></p>
We use the GraphSAGE link prediction model, which generates node embeddings based on attributes and neighbors without retraining. Our study employs a GNN Link Prediction model from the Deep Graph Library (DGL), with two GraphSAGE layers. This approach improves node representation by combining details from nearby nodes and discovering hidden connections in the Enron email dataset.
<p></p>
The output vectors from this model can be used for further analysis, and we will showcase this in our 'Experiments' section.

<p></p>


<h3>Experiments Overview</h3>

<p></p>
<h4>Data Source</h4>

<p></p>

Our main data source is the Enron email corpus, a comprehensive collection of emails exchanged among executives of the Enron Corporation. This dataset, freely available to the public, captures a wealth of corporate communications, offering a deep dive into the intricacies of a complex organizational network. Its rich detail makes it an excellent resource for our knowledge graph analysis, shedding light on the dynamics of corporate interactions.
<p></p>
The Enron email corpus is hosted on Kaggle, providing easy access for those looking to conduct detailed analyses of the dataset. For further information or to explore the dataset yourself, visit <a href="https://www.kaggle.com/datasets/wcukierski/enron-email-dataset/data">Kaggle's Enron Email Dataset</a>.


<p></p>


<h4>Input Data Preparation</h4>
<p></p>

Our study starts with building a graph using the Enron email dataset from the year 2000, focusing on internal communications by selecting emails sent from @enron.com addresses. We aimed to analyze direct email exchanges between individuals, excluding group emails to ensure a clear and focused analysis.
<p></p>
For the graph’s nodes, we merged the 'From', 'To', 'Subject', and 'Body' fields of each email into a single text unit, as illustrated in the picture. This method ensures that each node fully represents an individual email conversation, including all its context and specifics.
<p></p>
To link these nodes in the graph, we connected emails that had either the same sender or recipient, indicating a direct line of communication between parties. This setup accurately mirrors how communication unfolded within Enron, revealing the network’s detailed structure and the rich interplay of relationships among employees.
<p></p>

<h4>Constructing Layer Graphs from Enron's 2000 Email Corpus</h4>
<p></p>
Our investigation begins by creating a knowledge graph derived from the Enron email dataset, specifically focusing on the year 2000. Our selection criteria were emails exchanged internally, identifiable through @enron.com addresses, allowing us to concentrate on direct communications between individual employees while excluding group emails for a more targeted analysis.
<p></p>
<h5>Node Creation in the Knowledge Graph</h5>
<p></p>
To form the nodes of our knowledge graph, we combined the 'From', 'To', 'Subject', and 'Body' of each email into a unified text representation. This approach ensured that each node captured the entirety of an email exchange, preserving both the context and the details of the conversation.
<p></p>

Concatenate 'From', 'To', 'Subject', and 'body' columns with '^' between

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">emailText</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>
   <span class="n">df</span><span class="p">[[</span><span class="sh">'</span><span class="s">From</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">To</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Subject</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">body</span><span class="sh">'</span><span class="p">]]</span>
   <span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="sh">'</span><span class="s"> ^ </span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">row</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code></pre></figure>

        <p></p>
Combine and index 'From' and 'To' columns:
        <p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">unique_emails</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">From</span><span class="sh">'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">To</span><span class="sh">'</span><span class="p">]]).</span><span class="nf">unique</span><span class="p">()</span>
<span class="n">email_index</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">unique_emails</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">unique_emails</span><span class="p">)),</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">emailIdx</span><span class="sh">'</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">FromIdx</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">From</span><span class="sh">'</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="n">email_index</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">ToIdx</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">To</span><span class="sh">'</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="n">email_index</span><span class="p">)</span>
<span class="n">emailFromTo</span><span class="o">=</span><span class="n">df</span><span class="p">[[</span><span class="sh">'</span><span class="s">FromIdx</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">emailTextIdx</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">emailText</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ToIdx</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">emailFromTo</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span></code></pre></figure>

        <p></p>

<a href="#">
            <img src="/img/enron1.jpg" alt="Post Sample Image" width="543" />
</a>

<p></p>

<h5>Linking Nodes in the Knowledge Graph</h5>
<p></p>        
        In establishing connections within the knowledge graph, we linked emails sharing common senders or recipients, thereby reflecting a direct communication pathway between entities. This method provided an accurate reflection of how interactions occurred within Enron, uncovering the intricate structure of the network and the dynamic web of relationships between employees.

<p></p>
        Self-join emailFromTo table to create edges:
<p></p>        

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">=</span><span class="n">emailFromTo</span>
<span class="n">joined_df</span> <span class="o">=</span>
   <span class="n">df</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">left_on</span><span class="o">=</span><span class="sh">'</span><span class="s">ToIdx</span><span class="sh">'</span><span class="p">,</span> <span class="n">right_on</span><span class="o">=</span><span class="sh">'</span><span class="s">FromIdx</span><span class="sh">'</span><span class="p">,</span> <span class="n">suffixes</span><span class="o">=</span><span class="p">(</span><span class="sh">'</span><span class="s">_left</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">_right</span><span class="sh">'</span><span class="p">))</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">joined_df</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="sh">'</span><span class="s">FromIdx_left != ToIdx_right</span><span class="sh">'</span><span class="p">)</span>
<span class="n">dfLeft</span> <span class="o">=</span> <span class="n">em2text2em</span><span class="p">[[</span><span class="sh">'</span><span class="s">emailText_left</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">emailTextIdx_left</span><span class="sh">'</span><span class="p">]]</span>
   <span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">emailText_left</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">emailTextIdx_left</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">})</span>
<span class="n">dfRight</span> <span class="o">=</span> <span class="n">em2text2em</span><span class="p">[[</span><span class="sh">'</span><span class="s">emailText_right</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">emailTextIdx_right</span><span class="sh">'</span><span class="p">]]</span>
   <span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">emailText_right</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">emailTextIdx_right</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">})</span></code></pre></figure>

<p></p>
Excluded disconnected nodes and reindex:

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">dff</span><span class="o">=</span><span class="n">em2text2em</span>  
<span class="n">combined_df</span> <span class="o">=</span>
   <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">dfLeft</span><span class="p">,</span> <span class="n">dfRight</span><span class="p">]).</span><span class="nf">drop_duplicates</span><span class="p">().</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">combined_df</span> <span class="o">=</span> <span class="n">combined_df</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">)</span>
<span class="n">combined_df</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">combined_df</span><span class="p">[</span><span class="sh">'</span><span class="s">new_index</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">combined_df</span><span class="p">.</span><span class="n">index</span>   
<span class="n">nodes</span><span class="o">=</span><span class="n">combined_df</span><span class="p">[[</span><span class="sh">'</span><span class="s">new_index</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">nodes</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span>               </code></pre></figure>

<p></p>
<a href="#">
    <img src="/img/enron2.jpg" alt="Post Sample Image" width="543" />
</a>

<p></p>
      Reindex edges:

<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">idx_mapping</span> <span class="o">=</span>
   <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">combined_df</span><span class="p">[</span><span class="sh">'</span><span class="s">new_index</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">combined_df</span><span class="p">[</span><span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">]).</span><span class="nf">to_dict</span><span class="p">()</span>
<span class="n">dff</span><span class="p">[</span><span class="sh">'</span><span class="s">new_idxLeft</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dfLeft</span><span class="p">[</span><span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="n">idx_mapping</span><span class="p">)</span>
<span class="n">dff</span><span class="p">[</span><span class="sh">'</span><span class="s">new_idxRight</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dfRight</span><span class="p">[</span><span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="n">idx_mapping</span><span class="p">)</span>
<span class="n">edges</span><span class="o">=</span><span class="n">dff</span><span class="p">[[</span><span class="sh">'</span><span class="s">new_idxLeft</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">new_idxRight</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">edges</span><span class="o">=</span><span class="n">edges</span><span class="p">.</span><span class="nf">drop_duplicates</span><span class="p">()</span>
<span class="n">edges</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span>           </code></pre></figure>

<p></p>

<a href="#">
    <img src="/img/enron3.jpg" alt="Post Sample Image" width="314" />
</a>

<p></p>

<h4>Model Training</h4>
<p></p>


For model training, we first used the 'all-MiniLM-L6-v2' transformer from Hugging Face to transform email texts into vectors. Next, we applied the GNN Link Prediction model from the DGL library, aiming to discover unseen graph connections by analyzing these vectors and the graph structure.
<p></p>
    <ul>
        <li>Total number of nodes: 9,654</li>
        <li>Total number of edges: 667,354</li>
        <li>Embedded nodes represented as a PyTorch tensor of size [9,654, 384]</li>
        <li>The output vector size for the GraphSAGE model was set to 64</li>
    </ul>
<p></p>
To evaluate the efficacy of the model, we employed the Area Under Curve (AUC) metric as a measure of accuracy. The achieved model accuracy was approximately 96.7%, demonstrating the model’s high predictive performance.
<p></p>

<h5>Code Details</h5>
<p></p>
Convert edges to DGL model:
    <p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">unpickEdges</span><span class="o">=</span><span class="n">edges</span>
<span class="n">edge_index</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">unpickEdges</span><span class="p">[[</span><span class="sh">'</span><span class="s">new_idxLeft</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">new_idxRight</span><span class="sh">'</span><span class="p">]].</span><span class="n">T</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="o">=</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">g</span><span class="o">=</span><span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="p">))</span>
<span class="n">g</span><span class="o">=</span><span class="n">dgl</span><span class="p">.</span><span class="nf">add_self_loop</span><span class="p">(</span><span class="n">gNew</span><span class="p">)</span>
<span class="n">g</span>
<span class="nc">Graph</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">9654</span><span class="p">,</span> <span class="n">num_edges</span><span class="o">=</span><span class="mi">667354</span><span class="p">,</span>
  <span class="n">ndata_schemes</span><span class="o">=</span><span class="p">{}</span>
  <span class="n">edata_schemes</span><span class="o">=</span><span class="p">{})</span>      </code></pre></figure>

    <p></p>
Embed node feature text:

    <p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="n">modelST</span> <span class="o">=</span> <span class="nc">SentenceTransformer</span><span class="p">(</span><span class="sh">'</span><span class="s">all-MiniLM-L6-v2</span><span class="sh">'</span><span class="p">)</span>
<span class="n">node_embeddings</span> <span class="o">=</span> <span class="n">modelST</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">nodes</span><span class="p">[</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">],</span><span class="n">convert_to_tensor</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">node_embeddings</span> <span class="o">=</span> <span class="n">node_embeddings</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">))</span>
<span class="n">g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">node_embeddings</span>
<span class="n">g</span>
<span class="nc">Graph</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">9654</span><span class="p">,</span> <span class="n">num_edges</span><span class="o">=</span><span class="mi">667354</span><span class="p">,</span>
  <span class="n">ndata_schemes</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">:</span> <span class="nc">Scheme</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">384</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)}</span>
  <span class="n">edata_schemes</span><span class="o">=</span><span class="p">{})</span>        </code></pre></figure>

    <p></p>
    In our training process, we leveraged the GraphSAGE model, following closely with examples provided in the Deep Graph Library (DGL) tutorial. This choice allowed us to utilize a well-established framework for our Graph Neural Network (GNN) Link Prediction model, ensuring a solid foundation for our analysis. Below are GNN Link Prediction model statistics:

    <p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">all_logits</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="c1"># forward
</span>    <span class="n">h</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">train_g</span><span class="p">,</span> <span class="n">train_g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">].</span><span class="nf">float</span><span class="p">())</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">)</span>
    <span class="c1"># backward
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">e</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">In epoch {}, loss: {}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>       </code></pre></figure>

<p></p>
<a href="#">
    <img src="/img/enron4.jpg" alt="Post Sample Image" width="314" />
</a>

<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">AUC</span><span class="sh">'</span><span class="p">,</span> <span class="nf">compute_auc</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">))</span>         
<span class="n">AUC</span> <span class="mf">0.9673248461572111</span></code></pre></figure>

<p></p>


<h4>Results and Further Analysis</h4>

<p></p>

The GNN Link Prediction model outputs a set of re-embedded vectors that capture nuanced relationships within the graph. These vectors are valuable for deeper analysis, including statistical evaluation, clustering, and gaining further insights into the network’s structure. In this study, we built a new graph layer based on pairs of vectors with a cosine similarity threshold of 0.95, allowing for a detailed examination of the network’s dynamics and connections.
<p></p>
This method enables us to observe which influencers within the network have become more or less central after introducing these new connections. For this analysis, we focused on betweenness centrality, which measures a node’s importance in a graph by indicating how often it acts as a bridge along the shortest path between two other nodes. In complex relationships, these metrics help identify key nodes that facilitate communication or interaction across the network, revealing shifts in centrality and influence based on the newly established connections.
<p></p>
<p></p>    
    <a href="#">
        <img src="/img/enronResult1.jpg" alt="Post Sample Image" width="567" />
    </a>
<p></p>
When we compare the betweenness centrality scores before and after applying our method, we observe shifts in network influence. Initially, graph connections were based solely on direct email interactions. After incorporating text-driven relationships, new dynamics and hidden connections were revealed. This significantly altered the network’s structure, uncovering previously unrecognized key connectors and providing a more comprehensive view of the network’s influence and interactions.


  <p></p>

<p></p>

<a href="#">
    <img src="/img/enronResult2.jpg" alt="Post Sample Image" width="567" />
</a>
<p></p>

<p></p>

<p></p>



<h5>Code Details</h5>
<p></p>
Cosine Similarities function:    
<p></p>
    
<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="kn">import</span> <span class="n">torch</span>
    <span class="k">def</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">a_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">b_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">a_norm</span><span class="p">,</span> <span class="n">b_norm</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    </code></pre></figure>

    <p></p>
Select pairs of vectors with cosine similarities higher than 0.95.
    <p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cosine_scores_gnn</span> <span class="o">=</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
<span class="n">pairs_gnn</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">cosine_scores_gnn</span><span class="p">)):</span>
  <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">cosine_scores_gnn</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">&gt;</span><span class="n">j</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">cosine_scores_gnn</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.95</span><span class="p">:</span>
        <span class="n">pairs_gnn</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span><span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">:</span> <span class="n">j</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">cosine_scores_gnn</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()})</span>        </code></pre></figure>

    <p></p>
To pinpoint the main influencers in the knowledge graph, we employed betweenness centrality metrics. This approach enabled us to identify nodes that serve as crucial connectors facilitating information flow throughout the network. The initial step involves creating a graph using the NetworkX library:
<p></p>  

<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.95</span><span class="p">][[</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">edges</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">source</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">G</span><span class="p">.</span><span class="nf">add_edges_from</span><span class="p">(</span><span class="n">edges</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="nf">tolist</span><span class="p">())</span>        </code></pre></figure>


<p></p>
Next, we determined the top 10 nodes with the highest betweenness centrality scores, highlighting the most influential connectors in the graph:
    <p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">betweenness_rewired</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nf">betweenness_centrality</span><span class="p">(</span><span class="n">G1</span><span class="p">)</span>
<span class="n">top_rewired</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">betweenness_rewired</span><span class="p">.</span><span class="nf">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]</span></code></pre></figure>

<p></p>



<h3>In Conclusion</h3>
<p></p>

In this post, we introduced a novel approach to better understand and analyze complex connections within networks by incorporating descriptive texts into graph structures. Traditional models often miss the subtle nuances in textual content that are crucial for revealing hidden linkages and intricate interactions.
<p></p>
Our method treats interactions as high-dimensional entities, transforming email exchange triplets into nodes for the next graph layer and applying a GNN Link Prediction model. This approach captures the complexity of relationships beyond simple pairwise interactions, providing a nuanced understanding of multifaceted connections. By including text-driven relationships, our model allows for deeper semantic analysis, uncovering the underlying meanings and contexts within communications.
<p></p>
Combining semantic and topological features, our approach bridges the gap between textual content and network structure, offering a comprehensive view of the network. Applying this method to the Enron network demonstrated its effectiveness in revealing hidden linkages and identifying key influencers, highlighting its broad applicability.
<p></p>
By focusing on both semantics and graph topology, and leveraging higher graph layers, our method shows potential for use in various fields, including social networks, bioinformatics, healthcare, and beyond. This work paves the way for future research to explore and exploit the intricate interplay between textual content and network structures, advancing the field of network analysis.


<p></p>    





<p></p>

<p></p>

<p></p>
<p></p>
</p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[Semantic Graphs for Communication Networks In this project, we move beyond simple “who emailed whom” graphs and build a semantic graph of communication. Instead of treating edges as raw message counts, we create nodes for individual interactions (who wrote to whom, with what text), enrich them with transformer-based text embeddings, and use a GNN link prediction model to learn which interactions are genuinely related. This text-enriched graph lets us recompute centrality and see a different set of key players: not just the loudest senders, but the quiet connectors who bridge topics and conversation clusters—hidden connectors that a plain traffic graph would never reveal.]]></summary></entry><entry><title type="html">Sliding Window Graph in GNN Graph Classification</title><link href="http://localhost:4000/2024/05/25/slidingWindowGraph/" rel="alternate" type="text/html" title="Sliding Window Graph in GNN Graph Classification" /><published>2024-05-25T08:00:00-04:00</published><updated>2024-05-25T08:00:00-04:00</updated><id>http://localhost:4000/2024/05/25/slidingWindowGraph</id><content type="html" xml:base="http://localhost:4000/2024/05/25/slidingWindowGraph/"><![CDATA[<h2>Graph AI for Time-Series Change Detection</h2>
<p>
  Sliding time series graphs transform long, noisy signals into a sequence of short, structured snapshots,
  each captured as its own graph. By analyzing these snapshots with graph-based AI, we can pinpoint when a
  system shifts from normal to unusual behavior, highlight emerging regimes, and separate stable periods
  from early warning signals. Instead of a single summary label for an entire asset, customer base, or
  region, this approach shows <em>when</em> and <em>where</em> change is happening, enabling faster, more
  targeted decisions.
</p>

<h2>Conference &amp; Publication</h2>
<p>
  This work was presented at <strong>ICMLT 2024</strong> in Oslo, Norway, on
  <strong>24–25 May 2024</strong>, as the paper
  <em>“GNN Graph Classification for Time Series: A New Perspective on Climate Change Analysis”</em>,
  doi:
  <a href="https://doi.org/10.1145/3674029.3674059" target="_blank" rel="noopener">
    10.1145/3674029.3674059
  </a>.
</p>
<p>
  In that presentation, we combined and compared two GNN-based methods for time series climate
  analysis. Our earlier work,
  <a href="http://sparklingdataocean.com/2023/02/11/cityTempGNNgraphs/" target="_blank" rel="noopener">
    “GNN Graph Classification for Climate Change Patterns”
  </a>,
  introduced the <strong>city-graph method</strong>, which captures static temporal snapshots to sort
  cities into “stable” and “unstable” climate categories. The ICMLT paper extended this with a
  new <strong>sliding window graph method</strong>, which breaks time series into overlapping
  segments, turns each segment into a graph, and uses GNN graph classification to reveal how
  short-term climate behavior shifts over time.
</p>

<h2> Time Series Meets GNN Graph Classification</h2>
<p>The use of Graph Neural Networks (GNNs) in time series analysis represents a rising field of study, particularly in the context of GNN Graph Classification, a technique traditionally applied in disciplines such as biology and chemistry. Our research repurposes GNN Graph Classification for the analysis of time series climate data, focusing on two distinct methodologies: the city-graph method, which effectively captures static temporal snapshots, and the sliding window graph method, adept at tracking dynamic temporal changes. This innovative application of GNN Graph Classification within time series data enables the uncovering of nuanced data trends.</p>
<p></p>
<p>We demonstrate how GNNs can construct meaningful graphs from time series data, showcasing their versatility across different analytical contexts. A key finding is GNNs’ adeptness at adapting to changes in graph structure, which significantly improves outlier detection. This enhances our understanding of climate patterns and suggests broader applications of GNN Graph Classification in analyzing complex data systems beyond traditional time series analysis. Our research seeks to fill a gap in current studies by providing an examination of GNNs in climate change analysis, highlighting the potential of these methods in capturing and interpreting intricate data trends.</p>

<h3> Introduction</h3>
<p></p>

<p>In 2012, deep learning and knowledge graphs took a big leap forward in data analysis and machine learning. AlexNet, a new type of Convolutional Neural Network (CNN) for image classification, showed much better results than older methods. Around the same time, Google introduced knowledge graphs, which improved how data is integrated and managed.</p>
<p></p>
<p>However, CNNs struggled with graph-structured data, and graph techniques lacked deep learning’s ability to recognize patterns. This changed with the arrival of Graph Neural Networks (GNNs). GNNs combined deep learning with graph data processing, making it easier to analyze graph-structured data.</p>
<p></p>
<p>GNN models are designed specifically for graph data. They use geometric relationships and combine node features with graph structure. This makes them very useful for tasks like node classification, link prediction, and graph classification. GNN Graph Classification models, which have been used in areas like chemistry and medicine, classify entire graphs based on their structure and features.</p>
<p></p>
<p></p>
<p><a href="#">
    <img src="/img/slidingWindow1.jpg" alt="Post Sample Image" width="777" />
</a></p>
<p></p>
<p></p>
<p>In 2021, the “Geometric Deep Learning” paper was written when Convolutional Neural Networks (CNNs) were the dominant models in the deep learning landscape. If the paper were written in 2023-2024, Large Language Models (LLMs) would undoubtedly be considered the leading technology. The field of deep learning is rapidly evolving, and it remains to be seen what new advancements and models will emerge as the “biggest animals” in the next 2-3 years.</p>
<p></p>

<p>In this study, we expand on our previous research using Graph Neural Network (GNN) models to analyze climate data. Our earlier method categorized climate time series data into ‘stable’ and ‘unstable’ to identify unusual patterns in climate change.</p>
<p></p>
<p>Now, we introduce the sliding window graph method, which breaks down time series data into overlapping sections to capture specific time-related features. This approach creates graphs from these sections, offering a new perspective on short-term climate changes.</p>
<p></p>
<p>Our previous study used a city-graph method, where nodes represent city-year combinations with daily temperature vectors as features. The new sliding window method compares identical dates across different cities and years, helping us understand global climate trends.</p>
<p></p>
<p>Our research aims to explore the potential of GNN graph classification in identifying and interpreting global climate dynamics, providing valuable insights into seasonal changes and long-term shifts in climate.</p>

<p></p>

<h3>Methods</h3>
<p></p>
<h4>Graph Construction Methods</h4>
<p></p>
<p>In our study, we explore two different methods for constructing graphs from climate data: the City-Graph Method and the Sliding Window Method.</p>
<p></p>
<p><a href="#">
    <img src="/img/slidingWindow2.jpg" alt="Post Sample Image" width="678" />
</a></p>
<p></p>
<p></p>
<p>City-Graph Method:</p>
<p></p>
<ul>
        <li>Creating graphs where nodes represent city-year pairs.</li>
        <li>Features are daily temperature vectors for each city-year.</li>
        <li>Edges are established based on cosine similarities between the temperature vectors of different city-years.</li>
        <li>Categorizes city graphs into 'stable' or 'unstable' climates based on their temperature patterns over time.</li>
</ul>
<p></p>
<p>Sliding Window Method:</p>
<p></p>
<ul>
        <li>Constructing graphs by breaking down time series data into overlapping sections.</li>
        <li>Nodes represent data points within a sliding window, with features reflecting their values.</li>
        <li>Edges connect sequential points to maintain the temporal sequence.</li>
        <li>Labels are assigned to capture patterns within the time series.</li>
</ul>

<p></p>

<p></p>
<h4>Common Pipeline</h4>
<p></p>
<p>While the graph construction methods differ, both follow a common pipeline for GNN Graph Classification:</p>
<p></p>
<p><a href="#">
    <img src="/img/slidingWindow3.jpg" alt="Post Sample Image" width="678" />
</a></p>
<p></p>

<ul>
        <li><strong>Data Input:</strong> daily temperature data for 1000 populous cities over 40 years.</li>
        <li><strong>Climate Trends</strong> as 'stable' or 'unstable'.</li>
        <li><strong>Graph Construction:</strong>
            <ul>
                <li>City-Graph Method.</li>
                <li>Sliding Window Method.</li>
            </ul>
        </li>
        <li><strong>Virtual Nodes:</strong> to act as central hubs in small graphs, tuning the models for better accuracy..</li>

        <li><strong>GNN Model Application:</strong> use GNN model to classify graphs based on patterns.</li>
</ul>

<p></p>

<p></p>

<h4>Methodology for Sliding Window Graph Construction</h4>

<p>Our approach uses Graph Neural Networks (GNNs) combined with a sliding window technique to analyze time series data. Here’s an overview of the process:</p>

<h5>Data to Graph Transformation</h5>
<p>We segment time series data into smaller graphs using a sliding window, which captures local temporal patterns. Each time segment forms a unique graph.</p>

<h5>Graph Creation</h5>
<p>In these graphs, nodes represent data points within the window, with features reflecting their values. Edges connect these sequential points to maintain the temporal order.</p>

<h5>Crucial Parameters</h5>
<p>The window size (W) and overlap (shift size S) are important as they determine how the data is segmented and analyzed. Edge definitions within the graphs are tailored to the specifics of the time series data, helping to detect patterns.</p>

<h5>Node Calculation</h5>
<p>For a dataset with N data points, we apply a sliding window of size W with a shift of S to create nodes. The number of nodes, N<sub>nodes</sub>, is calculated as:
    <math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
            <msub>
                <mi>N</mi>
                <mi>nodes</mi>
            </msub>
            <mo>=</mo>
            <mrow>
                <mo>&lfloor;</mo>
                <mfrac>
                    <mrow>
                        <mi>N</mi>
                        <mo>-</mo>
                        <mi>W</mi>
                    </mrow>
                    <mi>S</mi>
                </mfrac>
                <mo>&rfloor;</mo>
            </mrow>
            <mo>+</mo>
            <mn>1</mn>
        </mrow>
    </math></p>

<h5>Graph Calculation</h5>
<p>With the nodes determined, we construct graphs, each comprising G nodes, with a shift of S<sub>g</sub> between successive graphs. The number of graphs, N<sub>graphs</sub>, is calculated by:
    <math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
            <msub>
                <mi>N</mi>
                <mi>graphs</mi>
            </msub>
            <mo>=</mo>
            <mrow>
                <mo>&lfloor;</mo>
                <mfrac>
                    <mrow>
                        <msub>
                            <mi>N</mi>
                            <mi>nodes</mi>
                        </msub>
                        <mo>-</mo>
                        <mi>G</mi>
                    </mrow>
                    <msub>
                        <mi>S</mi>
                        <mi>g</mi>
                    </msub>
                </mfrac>
                <mo>&rfloor;</mo>
            </mrow>
            <mo>+</mo>
            <mn>1</mn>
        </mrow>
    </math></p>

<p>This method allows us to analyze time series data effectively by capturing both local and global patterns, providing valuable insights into temporal dynamics.</p>
<p></p>
<h4>Model Training</h4>
<p></p>

<p>Our methodology involves processing both city-centric and sliding window graphs. We start by generating cosine similarity matrices from time series data, which are then converted into graph adjacency matrices. This process includes creating edges for vector pairs with cosine values above a set threshold and adding a virtual node to ensure network connectivity, a critical step for preparing the graph structure.</p>
<p></p>
<p>For graph classification tasks, we use the GCNConv model from the PyTorch Geometric Library. This model excels in feature extraction through its convolutional operations, taking into account edges, node attributes, and graph labels for comprehensive graph analysis. The approach concludes with the training phase of the GNN model, applying these techniques to both types of graphs for robust classification.</p>
<p></p>

<p></p>
<h3>Experiments Overview</h3>
<p></p>
<h4>Data Source: Climate Data</h4>

<p></p>
<p>For this study, we utilized climate data from Kaggle, specifically the dataset titled
<i><a href="https://www.kaggle.com/hansukyang/temperature-history-of-1000-cities-1980-to-2020">“Temperature History of 1000 Cities 1980 to 2020”</a></i>.
This dataset provides average daily temperature data from 1980 to 2020 for the 1000 most populous cities in the world.
This comprehensive dataset served as the foundation for both the city-centric and sliding window graph methods employed in our analysis.</p>
<p></p>
<p><a href="#">
    <img src="/img/slidingWindow4.jpg" alt="Post Sample Image" width="678" />
</a></p>
<p></p>
<p>The bar chart shows city frequency by latitude. Most cities are between 20 and 60 degrees in the Northern Hemisphere. There are fewer cities around the equator and even fewer in the Southern Hemisphere.</p>

<p></p>
<h4>Sliding Window Graph GNN Graph Classification</h4>
<p></p>
<p>Using a 40-year dataset of daily temperatures from 1000 cities, our study evaluates GNN’s effectiveness in identifying global climate patterns. We focus on data from January 1st to the start of each month, providing insights into climate consistency, seasonal changes, and long-term shifts.</p>
<p></p>
<h5>Sliding Window Analysis for Global Climate Data.</h5>
<p></p>
<p>In our global climate data analysis, we use the sliding window graph method on a dataset with 40 years of daily temperatures from 1000 cities. This approach segments the data into graphs, each defined by a 30-day window (𝑊 = 30) with a 7-day shift (𝑆 = 7), effectively capturing local climate dynamics. This results in 1624 small graphs, allowing us to analyze short-term climate variations and trends.</p>
<p></p>
<p>Our accuracy metrics provide insights into the stability and variability of global climate patterns. High accuracy suggests predictable seasonal trends, while lower accuracy indicates irregular climate patterns or shifts. The sliding window graph method allows us to thoroughly evaluate the model’s ability to identify complex patterns in large climate datasets.</p>
<p></p>
<p></p>
<p><a href="#">
    <img src="/img/slidingWindow5.jpg" alt="Post Sample Image" width="678" />
</a></p>
<p></p>
<p>When examining closely spaced months, such as January 1st to February 1st and January 1st to December 1st, the GNN model’s accuracy around 0.5 suggests difficulty in identifying distinct climate patterns. This low accuracy points to potential variability and unpredictability in global weather patterns during these periods, highlighting the complex dynamics of weather.</p>
<p></p>
<p>For periods between January and months like March, April, or October, the model achieves accuracy metrics averaging around 0.7 to 0.8, indicating moderate success in capturing climatic patterns. This is likely due to the model’s proficiency in identifying consistent seasonal transitions over these extended timeframes.</p>
<p></p>
<p>The highest accuracy metrics, ranging from 0.94 to 0.99, are observed for months other than January, such as May, June, July, August, and September. These results reflect the model’s exceptional performance in predicting climate patterns during these months, particularly in the stable summer months. This suggests that the GNN model excels in recognizing and adapting to distinctive climatic patterns, resulting in highly accurate predictions.</p>
<p></p>
<h5>Sliding Window Analysis for Stable and Unstable Climate Data.</h5>
<p></p>
<p>For classification, we split our graph dataset into ‘stable’ and ‘unstable’ groups based on average cosine similarities between consecutive years. This method segmented the global dataset into stable and unstable categories for our sliding window analysis. Using 20,000 city-year combinations, we set a window size of 30 (𝑊 = 30) and a shift size of 6 (𝑆 = 6), facilitating precise computations for both stable and unstable datasets. Each graph contains 30 nodes (𝐺 = 30), with a shift of 4 (𝑆𝑔 = 4) between successive graphs, resulting in a total of 1648 small graphs.</p>
<p></p>
<p>In our study, GNN graph classification for stable climate cities starts with moderate accuracy in February, significantly improves by May reaching a peak of 100%, and maintains high accuracy through the summer months, only to dip in October with a slight recovery in November. In contrast, unstable climate cities start with near-random accuracy in February, improve steadily, peak in August, and then decline sharply, returning to early-year levels by December. This indicates the model’s varying adaptability to stable and unstable climate patterns throughout the year.</p>
<p></p>
<p><a href="#">
    <img src="/img/slidingWindow6.jpg" alt="Post Sample Image" width="678" />
</a></p>
<p></p>
<p></p>
<p>Analysis starting from January 1 shows that the model’s performance is influenced by the time of year. Unstable climates see low accuracies in the early and late parts of the year, suggesting limited learning during these periods. Conversely, stable climates exhibit significant improvements in accuracy during spring and summer, indicating effective data integration. However, the model’s performance overall is subject to fluctuations, peaking in the summer months before declining towards the end of the year, highlighting the challenges in generalizing across seasonal variations in climate data.</p>
<p></p>

<p></p>
<h4>Code Details</h4>
<p></p>
<p>The <code class="language-plaintext highlighter-rouge">create_segments_df</code> function segments a specified column from a DataFrame into fixed-size windows. For each segment, it adds context such as the start date, row index, and column label. The function then combines these segments into a new DataFrame. This is useful for time series analysis or preparing data for machine learning models.</p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">create_segments_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">column_name</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span><span class="n">columnLabel</span><span class="p">):</span>
    <span class="n">segments</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">-</span> <span class="n">window_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">shift</span><span class="p">):</span>
        <span class="n">segment</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">window_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="n">column_name</span><span class="p">]].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">segment</span> <span class="o">=</span> <span class="n">segment</span><span class="p">.</span><span class="n">T</span>  <span class="c1"># Transpose to get the segment as a row
</span>        <span class="n">segment</span><span class="p">[</span><span class="sh">'</span><span class="s">start_date</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
        <span class="n">segment</span><span class="p">[</span><span class="sh">'</span><span class="s">rowIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">rowIndex</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
        <span class="n">segment</span><span class="p">[</span><span class="sh">'</span><span class="s">theColumn</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">column_name</span>
        <span class="n">segment</span><span class="p">[</span><span class="sh">'</span><span class="s">columnLabel</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">columnLabel</span>
        <span class="n">segments</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">segment</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">segments</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>
<p>The <code class="language-plaintext highlighter-rouge">group_segments</code> function takes a DataFrame of segments and groups them into larger segments based on specified sizes and shifts. It adds a group index to each group and combines them into a new DataFrame. This is useful for aggregating data over larger windows, essential for graph-based models or detailed data analysis.</p>
<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">group_segments</span><span class="p">(</span><span class="n">segments_df</span><span class="p">,</span> <span class="n">group_size</span><span class="p">,</span> <span class="n">group_shift</span><span class="p">):</span>
    <span class="n">grouped_segments</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">group_index</span> <span class="o">=</span> <span class="mi">0</span>  
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">segments_df</span><span class="p">)</span> <span class="o">-</span> <span class="n">group_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">group_shift</span><span class="p">):</span>
        <span class="n">group</span> <span class="o">=</span> <span class="n">segments_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">group_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">group</span><span class="p">[</span><span class="sh">'</span><span class="s">graphIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">group_index</span>  <span class="c1"># Assign group index
</span>        <span class="n">grouped_segments</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">group</span><span class="p">)</span>
        <span class="n">group_index</span> <span class="o">+=</span> <span class="mi">1</span>  
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">grouped_segments</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>
<p>Take columns <code class="language-plaintext highlighter-rouge">col1</code> and <code class="language-plaintext highlighter-rouge">col2</code> from a dataset, fill NaN values in with their mean values and scale these columns using MinMaxScaler.</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="nc">MinMaxScaler</span><span class="p">()</span>
<span class="n">fx_data</span><span class="o">=</span><span class="n">df</span>
<span class="k">if</span> <span class="n">col1</span> <span class="ow">in</span> <span class="n">fx_data</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">fx_data</span><span class="p">[</span><span class="n">col1</span><span class="p">]</span> <span class="o">=</span> <span class="n">fx_data</span><span class="p">[</span><span class="n">col1</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">fx_data</span><span class="p">[</span><span class="n">col1</span><span class="p">].</span><span class="nf">mean</span><span class="p">())</span>
    <span class="n">fx_data</span><span class="p">[</span><span class="n">col1</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">fx_data</span><span class="p">[[</span><span class="n">col1</span><span class="p">]])</span>
<span class="k">if</span> <span class="n">col2</span> <span class="ow">in</span> <span class="n">fx_data</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">fx_data</span><span class="p">[</span><span class="n">col2</span><span class="p">]</span> <span class="o">=</span> <span class="n">fx_data</span><span class="p">[</span><span class="n">col2</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">fx_data</span><span class="p">[</span><span class="n">col2</span><span class="p">].</span><span class="nf">mean</span><span class="p">())</span>
    <span class="n">fx_data</span><span class="p">[</span><span class="n">col2</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">fx_data</span><span class="p">[[</span><span class="n">col2</span><span class="p">]])</span></code></pre></figure>

<p></p>
<p></p>

<p>The code creates segments from two columns (<code>col1</code> and <code>col2</code>) of a dataset using the <code>create_segments_df</code> function, assigns node indices to each segment, and then groups these segments with the <code>group_segments</code> function. It combines the grouped segments into a final dataset, assigning a unique <span style="color: blue;">datasetIdx</span> to each. Finally, it generates metadata for each dataset index and merges it with the segment data to form <span style="color: blue;">graphList</span>.</p>

<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">columnLabel</span><span class="o">=</span><span class="mi">0</span>
<span class="n">segments1</span> <span class="o">=</span> <span class="nf">create_segments_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">col1</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span> <span class="n">columnLabel</span><span class="p">)</span>
<span class="n">columnLabel</span><span class="o">=</span><span class="mi">1</span>
<span class="n">segments2</span> <span class="o">=</span> <span class="nf">create_segments_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">col2</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span> <span class="n">columnLabel</span><span class="p">)</span>
<span class="n">segments1</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIndex</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">segments1</span><span class="p">.</span><span class="n">index</span>
<span class="n">segments2</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIndex</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">segments2</span><span class="p">.</span><span class="n">index</span>
<span class="n">grouped_segments1</span> <span class="o">=</span> <span class="nf">group_segments</span><span class="p">(</span><span class="n">segments1</span><span class="p">,</span> <span class="n">group_size</span><span class="p">,</span> <span class="n">group_shift</span><span class="p">)</span>
<span class="n">grouped_segments2</span> <span class="o">=</span> <span class="nf">group_segments</span><span class="p">(</span><span class="n">segments2</span><span class="p">,</span> <span class="n">group_size</span><span class="p">,</span> <span class="n">group_shift</span><span class="p">)</span>
<span class="n">dataSet</span><span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">grouped_segments1</span><span class="p">,</span> <span class="n">grouped_segments2</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">dataSet</span><span class="p">[</span><span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">dataSet</span><span class="p">[</span><span class="sh">'</span><span class="s">columnLabel</span><span class="sh">'</span><span class="p">]</span><span class="o">*</span><span class="n">graphMax</span><span class="o">+</span><span class="n">dataSet</span><span class="p">[</span><span class="sh">'</span><span class="s">graphIndex</span><span class="sh">'</span><span class="p">]</span>
<span class="n">dataSubset</span> <span class="o">=</span> <span class="n">dataSet</span><span class="p">[[</span><span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">graphIndex</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">columnLabel</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">theColumn</span><span class="sh">'</span><span class="p">]].</span><span class="nf">drop_duplicates</span><span class="p">()</span>
<span class="n">graphMeta</span> <span class="o">=</span> <span class="n">dataSet</span><span class="p">.</span><span class="nf">groupby</span><span class="p">([</span> <span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">])[</span><span class="sh">'</span><span class="s">start_date</span><span class="sh">'</span><span class="p">].</span><span class="nf">agg</span><span class="p">([</span><span class="sh">'</span><span class="s">min</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">max</span><span class="sh">'</span><span class="p">])</span>
<span class="n">graphList</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">dataSubset</span><span class="p">,</span> <span class="n">graphMeta</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>

<p></p>

<p>Continuation of coding is described in our previous study, <a href="http://sparklingdataocean.com/2023/02/11/cityTempGNNgraphs/">“GNN Graph Classification for Climate Change Patterns: Graph Neural Network (GNN) Graph Classification - A Novel Method for Analyzing Time Series Data”</a>. This current work continues the same coding methodology for both city graphs and sliding window graphs.</p>

<p></p>
<h4>Comparison of GNN Graph Classification Methods.</h4>
<p></p>
<p>In this research, we evaluated two distinct GNN Graph Classification techniques for analyzing climate data: the city-graph and the sliding window graph methods. The city-graph method assigns a node to each city-year pair, connecting them based on the cosine similarity of their temperature profiles, making it particularly suited for analyzing long-term climate trends. In contrast, the sliding window technique divides time series data into overlapping segments to form graphs, adeptly identifying short-term climate variations.</p>
<p></p>
<p>Both techniques were applied to the same dataset to compare their effectiveness in categorizing cities by climate stability. We found that the city-graph method more accurately discerned long-term climate stability, whereas the sliding window approach excelled in detecting short-term climate changes. Therefore, the choice of method depends on the specific objectives of the analysis: the city-graph is preferable for examining extended trends, while the sliding window method is ideal for investigating immediate climatic shifts.</p>
<p></p>

<p></p>

<p></p>

<p></p>
<h3>In Conclusion</h3>
<p></p>

<p>GNN graph classification has shown its strength in mapping complex relationships within graph-based datasets, making it a versatile tool in fields ranging from molecular dynamics to social network analysis. This versatility extends to climate data analysis, where it aids in identifying stable versus unstable climate patterns across cities by evaluating average cosine similarities of yearly temperature fluctuations. The addition of the sliding window graph approach further refines our study, enabling the model to continuously integrate new data and offer a detailed view of changing climate patterns. This technique is adept at capturing the dynamic nature of climate data, allowing for a more nuanced analysis of temporal trends and making it particularly suitable for managing the variable nature of climate data. This method’s ability to prioritize recent data over older information is crucial for adapting to the fast-paced changes characteristic of climate patterns.</p>
<p></p>
<p>In this study, we have leveraged GNN graph classification to address the complex challenge of analyzing climate patterns across different geographic locales, underscoring the method’s adaptability and broad applicability. Our research aimed explicitly at harnessing the potential of GNNs to distinguish between stable and unstable climate conditions in cities worldwide, using average cosine similarities of annual temperature variations as a novel classification metric. By integrating the sliding window graph approach, we have enhanced our model’s ability to dynamically assimilate and refresh data, offering a granular perspective on the fluctuating climate patterns and their implications over time.</p>
<p></p>
<p></p>
<p><a href="#">
    <img src="/img/slidingWindow7.jpg" alt="Post Sample Image" width="678" />
</a></p>
<p></p>
<p>This investigation has demonstrated that while equatorial cities exhibit consistency in climate stability, higher latitude cities experience more pronounced fluctuations. Remarkably, our analysis also brought to light certain anomalies, such as Mediterranean cities with unexpectedly consistent climates and cities in China and Mexico with notable climate variability. These findings highlight the critical importance of considering local geographical and climatic factors in climate studies and underscore the nuanced capabilities of GNN models in detecting subtle climate dynamics.</p>
<p></p>
<p>Ultimately, our study reinforces the utility of GNN graph classification, especially with the incorporation of the sliding window approach, as a potent tool for dissecting and understanding climate data. This method does not merely augment the predictive accuracy of our models but significantly bolsters their adaptability to ongoing climate changes, offering a richer comprehension of the complex interplay of factors influencing global climate trends. As such, GNN graph classification emerges as an indispensable instrument in the ongoing efforts to tackle the multifaceted challenges posed by global climate change, paving the way for more informed and effective climate resilience strategies.</p>

<p></p>

<p></p>

<p></p>
<p></p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[Graph AI for Time-Series Change Detection Sliding time series graphs transform long, noisy signals into a sequence of short, structured snapshots, each captured as its own graph. By analyzing these snapshots with graph-based AI, we can pinpoint when a system shifts from normal to unusual behavior, highlight emerging regimes, and separate stable periods from early warning signals. Instead of a single summary label for an entire asset, customer base, or region, this approach shows when and where change is happening, enabling faster, more targeted decisions.]]></summary></entry><entry><title type="html">Uncovering Hidden Triangles</title><link href="http://localhost:4000/2023/11/23/hiddenTriangles/" rel="alternate" type="text/html" title="Uncovering Hidden Triangles" /><published>2023-11-23T07:00:00-05:00</published><updated>2023-11-23T07:00:00-05:00</updated><id>http://localhost:4000/2023/11/23/hiddenTriangles</id><content type="html" xml:base="http://localhost:4000/2023/11/23/hiddenTriangles/"><![CDATA[<h2>Hidden Connectors in Knowledge Graphs</h2>
<p>
  In this project, we dive into a semantic knowledge graph built from art biographies and go
  beyond the simple question “who is linked to whom?”. We use Graph AI to embed nodes in a
  vector space and measure how strongly they connect, then examine tiny three-node patterns
  (triangles) to find cases where one link is much stronger than the others. Those nodes often
  act as quiet bridges between otherwise distant concepts or artists.
</p>
<p>
  The same idea scales far beyond art. In medicine, hidden connectors can illuminate critical genetic pathways that influence disease and point toward targeted therapies. In social networks, they reveal quiet influencers and emerging trends. In finance, connector analysis can surface firms that quietly support market stability; in criminal intelligence, it can highlight organizers who sit behind fragmented activity.
</p>

<h2>Conference Highlights</h2>
<p>
  This research was presented at the 17th International Conference on Information Technology and
  Applications (ICITA 2023), held in Turin, Italy from <strong>October 20–22, 2023</strong>.
  The paper, <em>“Uncovering Hidden Connections: Granular Relationship Analysis in Knowledge Graphs”</em>,
  was published as
  <em>Romanova, A. Uncovering Hidden Connections: Granular Relationship Analysis in Knowledge
  Graphs</em>, in the ICITA 2023 proceedings, doi:
  <a href="https://doi.org/10.1007/978-981-99-8324-7_2" target="_blank" rel="noopener">
    10.1007/978-981-99-8324-7_2
  </a>.
  To complement the text understanding, in this post we will feature some slides from the conference presentation.
</p>

<p></p>
<p><h2>Uncovering Hidden Triangles in Knowledge Graphs </h2>

<p>In recent years, knowledge graphs have become a powerful tool for integrating and analyzing data and shedding lights on the connections between entities. This study narrows its focus on unraveling detailed relationships within knowledge graphs, placing special emphasis on the role of graph connectors through link predictions and triangle analysis.</p>

<p>Using Graph Neural Network (GNN) Link Prediction models and graph triangle analysis in knowledge graphs, we have managed to uncover relationships that had been previously undetected or overlooked. Our findings mark a significant milestone, paving the way for more comprehensive exploration into the complex relationships that exist within knowledge graphs.</p>

<p>This study initiates further research in the area of unveiling the hidden dynamics and connections in knowledge graphs. The insights from this work promise to redefine our understanding of knowledge graphs and their potential for unlocking the complexities of data interrelationships.</p>

<p><h3>Introduction</h3>

<h4>Deep Learning, Knowledge Graphs and the Emergence of GNN</h4>

<p>The year 2012 was pivotal for deep learning and knowledge graphs. In that year, after AlexNet was introduced, a Convolutional Neural Network (CNN) highlighted the power of image classification techniques. Simultaneously, Google's introduction of knowledge graphs transformed data integration and management.</p>

<p>For many years, deep learning and knowledge graphs developed independently. CNN proved effective with grid-structured data but struggled with graph-structured data. On the other hand, graph techniques excelled in representing and reasoning about graph data but lacked deep learning's power. The late 2010s Graph Neural Networks (GNN) bridged this gap and emerged as a potent tool for processing graph-structured data through deep learning techniques.</p>

<p>For years, we've relied on binary graph structures, simplifying complex relationships into 'yes' or 'no', '1' or '0'. But in our ever-evolving world, is that enough? We believed there was more depth to be explored. Thus, we turned to Graph Neural Networks, a frontier technology, to help us transition from these fixed binaries to a more fluid, continuous space. </p>

<h4>Our Past Experiments in Rewiring of Knowledge Graphs</h4>

<p>In our previous study <u><a href="https://www.scitepress.org/Link.aspx?doi=10.5220/0011664400003393">'Rewiring Knowledge Graphs by Link Predictions'</a></u>

we delved into the exploration of knowledge graph rewiring to reveal unknown relationships between modern art artists, employing GNN link prediction models. By training these models on Wikipedia articles about modern art artists' biographies and leveraging GNN link prediction models, we identified previously unknown relationships between artists.</p>

<p>To rewire knowledge graphs, we adopted two distinct methods. First, we utilized a traditional method that involved a full-text analysis of articles and calculation of cosine similarities between embedded nodes. The second method involved the construction of semantic graphs based on the distribution of pairs of co-located words, and edges between nodes that share common words.</p>


<h4>New Study: Focusing on Graph Triangles</h4>
<p></p>

In this study, we continue to leverage the same data source and employ similar techniques for graph representation. However, we introduce a novel approach of comparing two documents and examining entity relationships at granular level. Specifically, we concentrate on analyzing graph triangles, where one side displays a stronger connection than the other two sides.</p>

<p>Let's take a moment to appreciate the evolution and elevation that GNN Link Prediction brings to the table. Remember the days of black and white television? Now imagine transitioning from that to a high-definition colored TV. That's the kind of transformative leap we're talking about when moving from traditional graph representations to GNN Link Prediction. Instead of just binary relationships, we're now operating on a continuous spectrum. Why is this so revolutionary? Because it allows us to see the subtle intricacies, the patterns that were once invisible. We're no longer just categorizing relationships as 'connected' or 'not connected'; we're exploring the depth, the weight, the very essence of these connections. It's like being given a magnifying glass to see the intricate patterns that were always there but previously overlooked. This shift not only boosts our prediction accuracy but also broadens our understanding of the complex web of relationships within our data.</p>



<p>In the vast network of relationships, it's essential to understand not just who is connected to whom, but also the depth and nature of these connections. Let's take a simplified example featuring Alice, Beth, and their college. Alice and Beth shared a close bond during their college days, so their connection is strong. But when we look at their individual relationships with the college, it's more of an association by attendance, making it a weaker connection. Picture a triangle with its vertices representing Alice, Beth, and their college. The strength of the links in this triangle varies. The college acts as a 'Graph Connector'—a node that forms a bridge between different entities. Now, why is this distinction crucial? Because understanding these nuanced connections ensures we don't treat all relationships equally. It enables us to discern, prioritize, and gain richer insights into our network, ensuring our analysis is both detailed and accurate.</p>

<p></p>
<a href="#">
    <img src="/img/slideTurino1.jpg" alt="Post Sample Image" width="628" />
</a>
<p></p>

<p>Analyzing graph triangles offers insights into the strength of connections between nodes within a network. Looking at the relationships among nodes A, B, and C, we are focusing on the strength of the connection between nodes A and B compared to the connections involving node C. Node C, identified as a 'graph connector' node, is critical in facilitating communication and interaction between nodes A and B. Serving as a link, node C allows the smooth flow of information and relationships between the strongly connected nodes A and B.
<p></p>
<p></p>

<p></p>
As analogy, imagine early 20th-century Vienna's intellectual scene as a dynamic network. Berta Zuckerkandl's salon stood out as one of central nodes, orchestrating and facilitating connections.
Her salon served as the platform, connecting diverse talents like artists, scientists, and doctors. Each gathering at her salon can be seen as the creation of 'links' between nodes.
Berta stands as a quintessential 'graph connector' and her role ensures not just random interactions, but impactful connections, emphasizing her integral position in this vibrant intellectual web.
<p></p>
<a href="#">
    <img src="/img/salon1c.jpg" alt="Post Sample Image" width="1000" />
</a>
<p></p>


<p></p>
This characterizes the importance of graph connector nodes in enhancing the network's overall connectivity and functionality, fostering collective behaviors and dynamics among interconnected nodes.

<p></p>
<h4>Depicting Graph Connectors</h4>
<p></p>
To find graph connectors, we will look for graph triangles where one cosine similarity between the nodes is higher than other two cosine similarity values.  This implies a stronger connection between two nodes relative to the connections of two other node pairs.

<p></p>
When delving into the world of graphs, it's essential to recognize the key players, the 'Graph Connectors'. These connectors serve as bridges within the intricate web of nodes. So, how do we uncover them? Let's take a journey through our method.
First, we train our GNN Link Prediction model, which gives us the embeddings for each node. Think of these embeddings as unique signatures, encapsulating the essence of each node.
<p></p>
<a href="#">
    <img src="/img/slideTurino2.jpg" alt="Post Sample Image" width="628" />
</a>
<p></p>
With these embeddings in hand, we compute the cosines between every pair of nodes in each graph triangle. These cosine values measure the similarity between nodes, indicating the strength of their connection.
Finally, the crux of our methodology: identifying the Graph Connectors. Based on our cosine computations, we determine which node acts as a bridge between the other two. For instance, in a triangle comprising nodes A, B, and C - if the connection strength between A and B surpasses the other two connections, it's clear that C plays the pivotal role of the connector.
This method thus allows us to highlight nodes that play an essential role in maintaining the structure and connectivity of the graph.
<p></p>


<p></p>

Graph representation traditionally operates in binary terms: either pairs of nodes are connected by edges or they are not. When using binary edges in graph triangle analysis, we are limited to recognizing the presence or absence of connections between nodes. Such a black-and-white perspective can overlook the nuanced graph connectors.
<p></p>
By employing GNN link prediction models, we move beyond this limitation. GNN link prediction model transcends this binary structure by embedding nodes into continuous vector space, providing a spectrum of ways to compare and evaluate these vectors. This deeper representation makes it possible to identify and understand graph connectors that a simple binary analysis might overlook.

In essence, understanding the nuances of node relationships allows for more robust, dynamic, and insightful analyses, enabling richer interpretations and predictions based on graph data.
<p></p>

<h4>Employing Graph Triangle Analysis and the GraphSAGE Model</h4>

<p>In this study, we aim to compare our previous study's results with the findings obtained through granular graph triangle analysis. Specifically, we'll examine the Wikipedia articles related to Paul Klee and Joan Miró, who were deemed as highly disconnected artists in the previous study. By employing graph triangle analysis techniques, we'll unveil previously overlooked graph connectors and patterns between these artists.</p>

<p>For our GNN link prediction model, we'll use the GraphSAGE model. Unlike traditional approaches relying on the entire adjacency matrix information, GraphSAGE focuses on learning aggregator functions. This allows us to generate embeddings for new nodes based on their features and neighborhood information without the need to retrain the entire model.</p>

<p>It's crucial to note that the outputs of the GraphSAGE model in our study are not actual predicted links, but embedded graphs. These embedded graphs capture the relationships and structural information within the original graphs. While these embeddings can be used for predicting graph edges, we will specifically utilize them for graph triangle analysis to identify and explore graph connectors within the network. These graph connectors play a pivotal role in facilitating connections and interactions between nodes, offering valuable insights into network dynamics and relationships.</p>


<p></p>

<p><h3>Methods</h3>

<h4>Building a Knowledge Graph</h4>
<p></p>
In this section, we'll outline our strategy to formulate an introductory knowledge graph for each article. Our approach uses co-located word pairs as nodes, establishing links between pairs sharing common words. The method can be detailed in the following steps:
<p></p>
<ul>
<li><strong>Text Tokenization:</strong> Begin by breaking down the text from Wikipedia into individual words or 'tokens', while also excluding common stop words that don't contribute much to the overall meaning.</li>

<li><strong>Node Generation:</strong> Nodes in our knowledge graph are created from these co-located word pairs. These pairs of adjacent words from the text will form the basis of our graph.</li>

<li><strong>Edge Calculation:</strong> Edges are established between nodes that share common words. This generates a network of word chains within each article and enables the connection of different articles through these word chains. Conceptually, consider two pairs, pair1 and pair2, represented as:</li>
<p></p>
<pre>
    pair1=[leftWord1, rightWord1],
    pair2=[leftWord2, rightWord2]
</pre>
<p></p>
<li>If rightWord1 and leftWord2 are the same, then we have an edge, edge12, linking pair1 and pair2:</li>
<p></p>
<pre>
    edge12={pair1, pair2}
</pre>
<p></p>
<li><strong>Knowledge Graph Construction:</strong> With the nodes and edges defined, we can build the initial knowledge graph, visually representing the relationships between different co-located word pairs within and across the articles.</li>
</ul>
<p></p>

<p></p>
<a href="#">
    <img src="/img/slideTurino7.jpg" alt="Post Sample Image" width="628" />
</a>
<p></p>
<h4>Node Embedding</h4>
<p></p>

To encapsulate the complexities of the knowledge graph into our nodes and translate the text information into vectors, we're utilizing the 'all-MiniLM-L6-v2' transformer model from Hugging Face. This model is a part of the sentence-transformers family, purposely built to convert text into a dense vector space. The resultant vector space has 384 dimensions, providing a rich and multidimensional representation of our textual information.
<p></p>
<h4>Training a GNN Link Prediction Model</h4>
<p></p>
In our research, we've chosen to implement the GraphSAGE link prediction model proposed by Hamilton and others. This model is operationalized using the code provided in the DGL (Deep Graph Library) tutorial. It necessitates the transformation of the input graph data into an appropriate DGL data format. This transformation is a crucial step in preparing the data for the model training process.
<p></p>


<p></p>
<h4>Triangle Analysis on Graphs</h4>
<p></p>


    <p>To delve deeper into the intricacies of graph structures, we used <strong>graph triangle analysis</strong>. Here's a step-by-step breakdown of our methodology:</p>

    <ol>
        <li>First, potential triangles are generated by considering all possible combinations of three distinct nodes from within the graph.</li>
        <li>Second, for each identified triangle, we compute the cosine similarities between the nodes. This involves calculating three cosine similarity values for each triangle - one for each pairing of nodes.</li>
        <li>Triangles of interest are those where one cosine similarity stands out as being notably higher compared to the other two values. This implies a stronger connection between two nodes relative to the connections of the other node pairs.</li>
    </ol>

    <p>By focusing on such triangles, we can derive more insight into the underlying relationships between nodes. This allows us to uncover intricate patterns and gain a deeper understanding of the structural nuances present within the graph.</p>

<p></p>
<a href="#">
    <img src="/img/slideTurino4.jpg" alt="Post Sample Image" width="628" />
</a>
<p></p>

<h3>Experiments</h3>
<p></p>
In our exploration, we embarked on a transformative journey. We began by constructing semantic graphs, a process much like piecing together a puzzle, where each word forms a crucial piece, connecting with others to build a comprehensive picture. However, merely building the graph wasn't our end goal. To delve deeper into its intricate maze, we utilized Graph Triangle Analysis. This methodology allowed us to zoom in on specific relationships, akin to highlighting crucial intersections in a vast city map. It's through this refined lens that we transitioned from a broad understanding of the semantic landscape to pinpointing the connectors - the linchpins that hold the entire framework together, revealing a richer, more connected narrative.
<p></p>

<h4>Data Source</h4>
<p></p>

As the data source for this study we used a subset of text data from Wikipedia articles about 20 modern art artists:
<p></p>
<a href="#">
    <img src="/img/slideTurino6.jpg" alt="Post Sample Image" width="628" />
</a>
<p></p>
Building on our previous 'Knowledge Graph Rewiring' research, we initially identified artist connections. Now, we're digging deeper to uncover more intricate relationships between artists, using our past findings as a starting point.

<p></p>
In our pursuit of understanding artist interconnections, we took a focused look at two iconic figures of the art world: Paul Klee and Joan Miró. In our previous research, a curious observation emerged. Despite both artists being immersed in significant art movements, our data showed a pronounced disconnect between them. Klee, a Swiss maestro, was deeply rooted in Expressionism, while Miró, the Spanish virtuoso, was an embodiment of Surrealism. On the surface, these movements and their geographic roots seem to keep them apart. Yet, why did we zero in on these two? The intrigue lies in an understated influence: Miró's artistry was, in fact, inspired by Klee. This revelation hints at more profound, nuanced connections between them, suggesting that artistic interplay goes beyond just the obvious associations.

<p></p>
<a href="#">
    <img src="/img/slideTurino3.jpg" alt="Post Sample Image" width="628" />
</a>
<p></p>
<p></p>
<h4>Preparation of Input Data</h4>
<p></p>

We constructed a knowledge graph based on co-located word pairs as described in the Methods. section. For model input data for this study we selected Wikipedia articles about Paul Klee and Joan Miró:
</p><p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">subsetWordpair</span> <span class="o">=</span> <span class="n">cleanPairWords</span><span class="p">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">word1</span><span class="sh">'</span><span class="p">,</span>	<span class="sh">'</span><span class="s">word2</span><span class="sh">'</span>	<span class="p">]]</span>
<span class="n">subsetWordpair</span> <span class="o">=</span> <span class="n">subsetWordpair</span><span class="p">[</span><span class="n">subsetWordpair</span><span class="p">[</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">([</span><span class="mi">13</span><span class="p">,</span><span class="mi">19</span><span class="p">])]</span>
<span class="n">subsetWordpair</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">nodeList</span><span class="o">=</span><span class="n">subsetWordpair</span>
<span class="n">nodeList</span><span class="p">[</span><span class="sh">'</span><span class="s">idxPair</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">nodeList</span><span class="p">.</span><span class="n">index</span></code></pre></figure>


</p><p>
Node list:


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">nodeList1</span><span class="o">=</span><span class="n">nodeList</span><span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">word2</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">theWord</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">wordpair1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wordPairIdx</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">wordPairIdx1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxArtist1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxPair</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxPair1</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">nodeList2</span><span class="o">=</span><span class="n">nodeList</span><span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">word1</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">theWord</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">wordpair2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wordPairIdx</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">wordPairIdx2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxArtist2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxPair</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxPair2</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">allNodes</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">nodeList1</span><span class="p">,</span><span class="n">nodeList2</span><span class="p">,</span><span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">theWord</span><span class="sh">'</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">inner</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>


</p><p>
Get unique word pairs for embedding:


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">bagOfPairWords</span><span class="o">=</span><span class="n">nodeList</span>
<span class="n">bagOfPairWords</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">bagOfPairWords</span><span class="p">[</span><span class="sh">'</span><span class="s">bagPairWordsIdx</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">bagOfPairWords</span><span class="p">.</span><span class="n">index</span></code></pre></figure>



</p><p>
Node embedding:


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">wordpair_embeddings</span> <span class="o">=</span> <span class="n">modelST</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">bagOfPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">wordpair</span><span class="sh">"</span><span class="p">],</span><span class="n">convert_to_tensor</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>
Save embedded word pairs:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">imgPath</span><span class="o">=</span><span class="sh">'</span><span class="s">/content/drive/My Drive/NLP/</span><span class="sh">'</span>
<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">imgPath</span><span class="o">+</span><span class="sh">'</span><span class="s">wordpairs13b.pkl</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">wb</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">fOut</span><span class="p">:</span>
    <span class="n">pickle</span><span class="p">.</span><span class="nf">dump</span><span class="p">({</span><span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">:</span> <span class="n">bagOfPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">bagPairWordsIdx</span><span class="sh">"</span><span class="p">],</span>
                 <span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">:</span> <span class="n">bagOfPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">wordpair</span><span class="sh">"</span><span class="p">],</span>
                 <span class="sh">'</span><span class="s">artist</span><span class="sh">'</span><span class="p">:</span> <span class="n">bagOfPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">idxArtist</span><span class="sh">"</span><span class="p">],</span>
                 <span class="sh">'</span><span class="s">embeddings</span><span class="sh">'</span><span class="p">:</span> <span class="n">wordpair_embeddings</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()},</span> <span class="n">fOut</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="p">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span></code></pre></figure>

<p></p>
<h4>Transform Data to DGL Format</h4>


<p></p>

We trained our GNN link prediction model using the GraphSAGE model from the DGL library. More in-depth information and coding techniques for data preparation and encoding data into the DGL data format are available in our post <u><a href="http://sparklingdataocean.com/2022/11/09/knowledgeGraph4NlpGnn/"> 'Find Semantic Similarities by GNN Link Predictions'</a></u>.
<p></p>

<p></p>
Import DGL andd read saved data:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">dgl</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="n">itertools</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">scipy.sparse</span> <span class="k">as</span> <span class="n">sp</span>
<span class="kn">import</span> <span class="n">dgl.data</span>
<span class="kn">from</span> <span class="n">dgl.data</span> <span class="kn">import</span> <span class="n">DGLDataset</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">imgPath</span><span class="o">+</span><span class="sh">'</span><span class="s">wordpairs13b.pkl</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">rb</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">fIn</span><span class="p">:</span>
    <span class="n">stored_data</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">fIn</span><span class="p">)</span>
    <span class="n">gnn_index</span> <span class="o">=</span> <span class="n">stored_data</span><span class="p">[</span><span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">gnn_artist</span> <span class="o">=</span> <span class="n">stored_data</span><span class="p">[</span><span class="sh">'</span><span class="s">artist</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">gnn_words</span> <span class="o">=</span> <span class="n">stored_data</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">gnn_embeddings</span> <span class="o">=</span> <span class="n">stored_data</span><span class="p">[</span><span class="sh">'</span><span class="s">embeddings</span><span class="sh">'</span><span class="p">]</span>
<span class="n">df_gnn_words</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">gnn_words</span><span class="p">)</span>
<span class="n">df_gnn_words</span><span class="p">[</span><span class="sh">'</span><span class="s">idxNode</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">df_gnn_words</span><span class="p">.</span><span class="n">index</span></code></pre></figure>


</p><p>
Transform data to DGL format:


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">art_edges</span><span class="o">=</span><span class="n">allNodes</span><span class="p">[[</span><span class="sh">'</span><span class="s">idxPair1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxPair2</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">unpickEdges</span><span class="o">=</span><span class="n">art_edges</span>
<span class="n">edge_index</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">unpickEdges</span><span class="p">[[</span><span class="sh">'</span><span class="s">idxPair1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxPair2</span><span class="sh">'</span><span class="p">]].</span><span class="n">T</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="o">=</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">gNew</span><span class="o">=</span><span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="p">))</span>
<span class="n">gNew</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">gnn_embeddings</span>
<span class="n">gNew</span><span class="o">=</span><span class="n">dgl</span><span class="p">.</span><span class="nf">add_self_loop</span><span class="p">(</span><span class="n">gNew</span><span class="p">)</span>
<span class="n">g</span><span class="o">=</span><span class="n">gNew</span></code></pre></figure>


<p></p>
<h4>Model Training</h4>
<p></p>
Split edge set for training and testing
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">g</span><span class="p">.</span><span class="nf">edges</span><span class="p">()</span>
<span class="n">eids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_edges</span><span class="p">())</span>
<span class="n">eids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">permutation</span><span class="p">(</span><span class="n">eids</span><span class="p">)</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">eids</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="n">g</span><span class="p">.</span><span class="nf">number_of_edges</span><span class="p">()</span> <span class="o">-</span> <span class="n">test_size</span>
<span class="n">test_pos_u</span><span class="p">,</span> <span class="n">test_pos_v</span> <span class="o">=</span> <span class="n">u</span><span class="p">[</span><span class="n">eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]],</span> <span class="n">v</span><span class="p">[</span><span class="n">eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]]</span>
<span class="n">train_pos_u</span><span class="p">,</span> <span class="n">train_pos_v</span> <span class="o">=</span> <span class="n">u</span><span class="p">[</span><span class="n">eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]],</span> <span class="n">v</span><span class="p">[</span><span class="n">eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]]</span></code></pre></figure>


<p></p>
Find all negative edges and split them for training and testing
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">adj</span> <span class="o">=</span> <span class="n">sp</span><span class="p">.</span><span class="nf">coo_matrix</span><span class="p">((</span><span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">u</span><span class="p">)),</span> <span class="p">(</span><span class="n">u</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">v</span><span class="p">.</span><span class="nf">numpy</span><span class="p">())))</span>
<span class="n">adj_neg</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">adj</span><span class="p">.</span><span class="nf">todense</span><span class="p">()</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>
<span class="n">neg_u</span><span class="p">,</span> <span class="n">neg_v</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">adj_neg</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">neg_eids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">neg_u</span><span class="p">),</span> <span class="n">g</span><span class="p">.</span><span class="nf">number_of_edges</span><span class="p">())</span>
<span class="n">test_neg_u</span><span class="p">,</span> <span class="n">test_neg_v</span> <span class="o">=</span> <span class="n">neg_u</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]],</span> <span class="n">neg_v</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]]</span>
<span class="n">train_neg_u</span><span class="p">,</span> <span class="n">train_neg_v</span> <span class="o">=</span> <span class="n">neg_u</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]],</span> <span class="n">neg_v</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]]</span>
<span class="n">train_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">remove_edges</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">])</span>
<span class="kn">from</span> <span class="n">dgl.nn</span> <span class="kn">import</span> <span class="n">SAGEConv</span></code></pre></figure>


<p></p>
Create model: build a two-layer GraphSAGE model
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">GraphSAGE</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_feats</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">GraphSAGE</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">SAGEConv</span><span class="p">(</span><span class="n">in_feats</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">,</span> <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">SAGEConv</span><span class="p">(</span><span class="n">h_feats</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">,</span> <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">in_feat</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">in_feat</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span>

<span class="n">train_pos_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">train_pos_u</span><span class="p">,</span> <span class="n">train_pos_v</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>
<span class="n">train_neg_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">train_neg_u</span><span class="p">,</span> <span class="n">train_neg_v</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>

<span class="n">test_pos_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">test_pos_u</span><span class="p">,</span> <span class="n">test_pos_v</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>
<span class="n">test_neg_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">test_neg_u</span><span class="p">,</span> <span class="n">test_neg_v</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>

<span class="kn">import</span> <span class="n">dgl.function</span> <span class="k">as</span> <span class="n">fn</span>

<span class="k">class</span> <span class="nc">DotPredictor</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">g</span><span class="p">.</span><span class="nf">local_scope</span><span class="p">():</span>
            <span class="n">g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span>
            <span class="c1"># Compute a new edge feature named 'score' by a dot-product between the
</span>            <span class="c1"># source node feature 'h' and destination node feature 'h'.
</span>            <span class="n">g</span><span class="p">.</span><span class="nf">apply_edges</span><span class="p">(</span><span class="n">fn</span><span class="p">.</span><span class="nf">u_dot_v</span><span class="p">(</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">))</span>
            <span class="c1"># u_dot_v returns a 1-element vector for each edge so you need to squeeze it.
</span>            <span class="k">return</span> <span class="n">g</span><span class="p">.</span><span class="n">edata</span><span class="p">[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">MLPPredictor</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">W1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">h_feats</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">W2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">h_feats</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">apply_edges</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">edges</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">edges</span><span class="p">.</span><span class="n">src</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">],</span> <span class="n">edges</span><span class="p">.</span><span class="n">dst</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">]],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="nc">W2</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nc">W1</span><span class="p">(</span><span class="n">h</span><span class="p">))).</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)}</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">g</span><span class="p">.</span><span class="nf">local_scope</span><span class="p">():</span>
            <span class="n">g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span>
            <span class="n">g</span><span class="p">.</span><span class="nf">apply_edges</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">apply_edges</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">g</span><span class="p">.</span><span class="n">edata</span><span class="p">[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">]</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">GraphSAGE</span><span class="p">(</span><span class="n">train_g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="nc">DotPredictor</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">):</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">])</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">pos_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">neg_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])])</span>
    <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="nf">binary_cross_entropy_with_logits</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compute_auc</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">):</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">]).</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span>
        <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">pos_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">neg_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]).</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="nf">roc_auc_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span></code></pre></figure>



<p></p>
Set up loss and optimizer:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">itertools</span><span class="p">.</span><span class="nf">chain</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">pred</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span></code></pre></figure>


<p></p>
Model training:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">all_logits</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>
    <span class="c1"># forward
</span>    <span class="n">h</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">train_g</span><span class="p">,</span> <span class="n">train_g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">)</span>

    <span class="c1"># backward
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">e</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">In epoch {}, loss: {}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span></code></pre></figure>



<p></p>
Check results:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">AUC</span><span class="sh">'</span><span class="p">,</span> <span class="nf">compute_auc</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">))</span></code></pre></figure>


<p></p>
The model was trained using the following parameters:
<p></p>
<ul>
  <li>Number of nodes: 3,274</li>
  <li>Number of edges: 13,709</li>
</ul>
Embedded node features were represented as PyTorch tensors of size [3274, 384]. The re-embedded nodes resulted in a tensor of size [3274, 64].

<p></p>
To evaluate our model's performance, we calculated the Area Under the Curve (AUC) accuracy metric, which offers an indication of the model's predictive power. In our case, the accuracy metric was 0.848, demonstrating a high level of accuracy in the model's predictions.

<p></p>
<h4>Interpret Model Results</h4>
<p></p>
<p></p>
Model results:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">gnnResults</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">h</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">())</span></code></pre></figure>

<p></p>
Cosine similarity function and model scores:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">math</span> <span class="kn">import</span> <span class="n">sin</span><span class="p">,</span> <span class="n">cos</span><span class="p">,</span> <span class="n">sqrt</span><span class="p">,</span> <span class="n">atan2</span><span class="p">,</span> <span class="n">radians</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="k">def</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">a_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">a_norm</span><span class="p">,</span> <span class="n">b_norm</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span></code></pre></figure>


<p></p>
Model scores:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cosine_scores_gnn</span> <span class="o">=</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>
<h4>Graph Triangle Analysis</h4>
<p></p>

<p></p>
Define graph and graph triangles:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="n">G</span><span class="o">=</span><span class="n">nx</span><span class="p">.</span><span class="nf">from_pandas_edgelist</span><span class="p">(</span><span class="n">allNodes</span><span class="p">,</span>  <span class="sh">"</span><span class="s">wordpair1</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">wordpair2</span><span class="sh">"</span><span class="p">)</span>
<span class="n">triangles</span> <span class="o">=</span> <span class="p">[</span><span class="n">clique</span> <span class="k">for</span> <span class="n">clique</span> <span class="ow">in</span> <span class="n">nx</span><span class="p">.</span><span class="nf">enumerate_all_cliques</span><span class="p">(</span><span class="n">G</span><span class="p">)</span> <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">clique</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">]</span></code></pre></figure>


<p></p>
Calculate cosine similarities within graph triangles:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">triangleStats</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">triangle</span> <span class="ow">in</span> <span class="n">triangles</span><span class="p">:</span>
  <span class="n">idx3</span><span class="o">=</span><span class="nf">list</span><span class="p">(</span><span class="n">nodeList</span><span class="p">[</span><span class="n">nodeList</span><span class="p">[</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">triangle</span><span class="p">)][</span><span class="sh">'</span><span class="s">bagPairWordsIdx</span><span class="sh">'</span><span class="p">])</span>
  <span class="k">for</span> <span class="n">pair1</span> <span class="ow">in</span> <span class="n">idx3</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">pair2</span> <span class="ow">in</span> <span class="n">idx3</span><span class="p">:</span>
      <span class="nf">if </span><span class="p">(</span><span class="n">pair1</span><span class="o">&lt;</span><span class="n">pair2</span><span class="p">):</span>
        <span class="n">score</span><span class="o">=</span><span class="n">dfWordPairs</span><span class="p">[(</span><span class="n">dfWordPairs</span><span class="p">[</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">pair1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">dfWordPairs</span><span class="p">[</span><span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">pair2</span><span class="p">)][</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span>
        <span class="n">triangleStats</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">triangle</span><span class="sh">'</span><span class="p">:</span><span class="n">triangle</span><span class="p">,</span><span class="sh">'</span><span class="s">pair1</span><span class="sh">'</span><span class="p">:</span><span class="n">pair1</span><span class="p">,</span><span class="sh">'</span><span class="s">pair2</span><span class="sh">'</span><span class="p">:</span><span class="n">pair2</span><span class="p">,</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span><span class="n">score</span><span class="p">})</span></code></pre></figure>


<p></p>
Convert to triangle statistics to pandas data frame and save the results:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">triangleStatsDF</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">triangleStats</span><span class="p">)</span>
<span class="n">triangleStatsDF</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="n">imgPath</span><span class="o">+</span><span class="sh">'</span><span class="s">triangleStats.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></figure>


<p></p>
<h3>Insights from Graph Triangles</h3>
<p></p>
In our exploration of the embedded graph triangles, we utilized ordered edge weights as a basis for analysis. From this process, we identified a total of 46 graph triangles. Among these, several met the criteria for containing a graph connector node, acting as a bridge or link between the other nodes within the graph triangle.


<p></p>
<p></p>
<a href="#">
    <img src="/img/slideTurino5.jpg" alt="Post Sample Image" width="628" />
</a>
<p></p>
<!-- <p></p>
<a href="#">
    <img src="/img/connectors5.jpg" alt="Post Sample Image" width="567">
</a> -->


<p></p>
Our graph triangle analysis is illustrated in the fugure above. In this figure, the numbers you see next to each edge represent the cosine similarities between the vectors of the corresponding nodes. These numbers essentially reflect the strength of the connection between two nodes.
<p></p>
Imagine a vast network, a spider web of connections. Within this web, our goal was to uncover specific points, the linchpins holding everything together. These are our Graph Connectors. How do we identify them? We delve into Triangle Analysis. In this analysis, the sides of the triangles, the 'edges', represent how similar two nodes are to each other, quantified using cosine similarities. The Graph Connectors stand out as the acute-angled vertices, the points where threads converge sharply, indicating their pivotal role in the network's architecture. It's akin to finding the central anchors in our intricate web.

<p></p>
The patterns observed in these graph triangles provide valuable insights into the intricate relationships within our knowledge graph. More importantly, they shed light on the crucial role of graph connectors - the nodes that act as bridges, facilitating communication and interaction between other nodes within the graph triangle.</p>
<p></p>
<h4>Observations and Insights</h4>
<p></p>
As we compare the results of our previous study <u><a href="https://www.scitepress.org/Link.aspx?doi=10.5220/0011664400003393">'Rewiring Knowledge Graphs by Link Predictions'</a></u>
with the findings of this current study, we can notice both similarities and differences in the outcomes.

<h5>Similarities:</h5>

<ul>
  <li>Both studies utilized Wikipedia articles focusing on the biographies of modern art artists.</li>
  <li>The same semantic knowledge graph building method was employed in both studies.</li>
  <li>The GraphSAGE GNN link prediction model was utilized for graph embedding in both studies.</li>
</ul>

<h5>Differences:</h5>

<ul>
  <li>In the previous study, the GNN link prediction model results were aggregated by artists. The analysis suggested that Paul Klee and Joan Miró were highly disconnected artists.</li>
  <li>In contrast, the current study adopts a more granular approach to analyze the relationships between the artists. By using graph triangle analysis techniques, we were able to uncover potentially interesting relationships that were not previously identified.</li>
</ul>

<p>The example graph triangles, like those seen in picture above, demonstrate the crucial role of graph connectors. The numbers placed next to the edges represent the cosine similarities between the vectors of the corresponding nodes, providing valuable insights into the relationships and patterns within the knowledge graph.</p>


<p></p>
<p><h3>Conclusion</h3>



<p>In this study, we utilized GNN link prediction techniques and graph triangle analysis to delve deeper into the intricacies of relationships within knowledge graphs. Leveraging these techniques, we demonstrated their potency in revealing patterns that might have previously gone unnoticed.</p>

<p>Our comparison between granular relationship analysis and aggregated relationships unveiled some compelling insights. In our previous study, based on an aggregated view, the artists Paul Klee and Joan Miró were deemed highly disconnected. However, that analysis failed to capture the finer nuances of their relationships. By applying graph triangle analysis techniques in this study, we found potentially significant connections and patterns between these artists, overlooked in the aggregated results.</p>

<p>This demonstrates the significance of granular analysis in comprehending the complex relationships within knowledge graphs. A deeper probe into the relationships between entities uncovers hidden associations and provides fresh insights into the interconnected data.</p>

<p>We have taken a step in exploring the concept of knowledge graph connectors. Through the use of GNN link prediction models and graph triangle analysis techniques, we have exposed the presence of graph connectors. These connectors play a critical role in facilitating connections and interactions between entities within the knowledge graphs.</p>

<p></p>

<p>

Our study reveals new ways to understand complex connections in knowledge graphs, shedding light on hidden relationships and dynamics. This study is the beginning of a journey towards gaining a deeper understanding of the hidden relationships and dynamics within knowledge graphs.
</p>
<p></p>

<p><h3>Exploring Future Horizons with Graph Connectors</h3>

<p>Envision the transformative impact of applying our advanced graph connector techniques across various fields:</p>

<ul>
    <li><strong>Medicine:</strong> Illuminate critical genetic pathways influencing diseases, paving the way for bespoke therapies and preventive measures.</li>
    <li><strong>Social Networks:</strong> Uncover hidden influencers and emergent trends, reshaping our understanding of digital interactions.</li>
    <li><strong>Finance:</strong> Identify key firms integral to market stability, potentially revolutionizing investment and economic strategies.</li>
    <li><strong>Criminal Networks:</strong> Reveal the masterminds behind criminal activities, enhancing law enforcement capabilities.</li>
    <li><strong>Education:</strong> Discover central interdisciplinary subjects that serve as educational connectors, promoting comprehensive learning experiences.</li>
    <li><strong>Supply Chains:</strong> Spot critical intermediaries to streamline production, boosting efficiency and reducing operational costs.</li>
</ul>

<p>The possibilities are boundless, and the diverse applications of our graph connector methods promise a future rich with insight and innovation!</p>


<p></p>


<p></p>
<p><h3>Next Post - Graph Connectors</h3>

In the next spost we will continue exploring graph connector techniques.
<p></p>
</p></p></p></p></p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[Hidden Connectors in Knowledge Graphs In this project, we dive into a semantic knowledge graph built from art biographies and go beyond the simple question “who is linked to whom?”. We use Graph AI to embed nodes in a vector space and measure how strongly they connect, then examine tiny three-node patterns (triangles) to find cases where one link is much stronger than the others. Those nodes often act as quiet bridges between otherwise distant concepts or artists. The same idea scales far beyond art. In medicine, hidden connectors can illuminate critical genetic pathways that influence disease and point toward targeted therapies. In social networks, they reveal quiet influencers and emerging trends. In finance, connector analysis can surface firms that quietly support market stability; in criminal intelligence, it can highlight organizers who sit behind fragmented activity.]]></summary></entry><entry><title type="html">Exploring Document Comparison with GNN Graph Classification</title><link href="http://localhost:4000/2023/07/07/knowledgeGraph4NlpGnn2/" rel="alternate" type="text/html" title="Exploring Document Comparison with GNN Graph Classification" /><published>2023-07-07T08:00:00-04:00</published><updated>2023-07-07T08:00:00-04:00</updated><id>http://localhost:4000/2023/07/07/knowledgeGraph4NlpGnn2</id><content type="html" xml:base="http://localhost:4000/2023/07/07/knowledgeGraph4NlpGnn2/"><![CDATA[<h2>Semantic Graph for Text Understanding</h2>
<p>
  In this project, we treat text as a semantic graph rather than a flat sequence of words.
  From Wikipedia biographies of modern artists, we build a graph where nodes are meaningful
  word pairs and edges connect them when they appear together or in related contexts.
  Each node carries a transformer embedding, and a Graph Neural Network learns to “rewire”
  this graph—strengthening important links, downplaying weak ones, and revealing which
  artists and concepts truly sit close together or far apart in meaning.
</p>
<p>
  This semantic graph becomes a foundation for NLP tasks: it supports richer recommendations
  (finding both similar and contrastive artists or documents), cleans and enriches the
  underlying knowledge graph, and provides structure-aware representations that go beyond
  simple embedding cosine similarity. Instead of just asking “how similar are these texts?”,
  we can ask “how is their semantic neighborhood wired?” and let Graph AI answer from the
  topology of the semantic graph itself.
</p>

<h2>Conference &amp; Publication</h2>
<p>
  This work was presented at <strong>FRUCT35</strong>, the 35th Conference of the Open Innovations
  Association, held in Tampere, Finland, from <strong>24–26 April 2024</strong>, as the paper
  <em>“Enhancing NLP through GNN-Driven Knowledge Graph Rewiring and Document Classification”</em>.
  It was published in the conference proceedings with the doi:
  <a href="https://doi.org/10.23919/FRUCT61870.2024.10516410" target="_blank" rel="noopener">
    10.23919/FRUCT61870.2024.10516410
  </a>.
</p>

<p><h2>GNN Graph Classification for Semantic Graphs</h2>
<p></p>
In our previous studies, we focused on the exploration of knowledge graph rewiring to uncover unknown relationships between modern art artists. In one study
<u><a href="https://www.springerprofessional.de/en/building-knowledge-graph-in-spark-without-sparql/18375090">'Building Knowledge Graph in Spark Without SPARQL'</a></u>, we utilized artist biographies, known artist relationships, and data on modern art movements to employ graph-specific techniques, revealing hidden patterns within the knowledge graph.
</p>
<p>
In more recent study <u><a href="https://www.scitepress.org/Link.aspx?doi=10.5220/0011664400003393">'Rewiring Knowledge Graphs by Link Predictions'</a></u> our approach involved the application of GNN link prediction models. We trained these models on Wikipedia articles, specifically focusing on biographies of modern art artists. By leveraging GNN, we successfully identified previously unknown relationships between artists.


</p>
<p>

This study aims to extend earlier research by applying GNN graph classification models for document comparison, specifically using Wikipedia articles on modern art artists. Our methodology will involve transforming the text into semantic graphs based on co-located word pairs, then generating subsets of these semantic subgraphs as input data for GNN graph classification models. Finally, we will employ GNN graph classification models for a comparative analysis of the articles.

</p>
<p>
<p><h3>Introduction</h3>

The year 2012 marked a significant breakthrough in the fields of deep learning and knowledge graphs. It was during this year that Convolutional Neural Networks (CNN) gained prominence in image classification with the introduction of AlexNet. At the same time, Google introduced knowledge graphs, which revolutionized data integration and management. This breakthrough highlighted the superiority of CNN techniques over traditional machine learning approaches across various domains. Knowledge graphs enriched data products with intelligent and magical capabilities, transforming the way information is organized, connected, and understood.
</p><p>
For several years, deep learning and knowledge graphs progressed in parallel paths. CNN deep learning excelled at processing grid-structured data but faced challenges when dealing with graph-structured data. Graph techniques effectively represented and reasoned about graph structured data but lacked the powerful capabilities of deep learning. In the late 2010s, the emergence of Graph Neural Networks (GNN) bridged this gap and combined the strengths of deep learning and graphs. GNN became a powerful tool for processing graph- structured data through deep learning techniques.


<p></p>

</p><p>
GNN models allow to use deep learning algorithms for graph structured data by modeling entity relationships and capturing structures and dynamics of graphs. GNN models are being used for the following tasks to analyze graph-structured data: node classification, link prediction, and graph classification. Node classification models predict label or category of a node in a graph based on its local and global neighborhood structures. Link prediction models predict whether a link should exist between two nodes based on node attributes and graph topology. Graph classification models classify entire graphs into different categories based on their graph structure and attributes: edges, nodes with features, and labels on graph level.

</p><p>

</p><p>

GNN graph classification models are developed to classify small graphs and in practice they are commonly used in the fields of chemistry and medicine. For example, chemical molecular structures can be represented as graphs, with atoms as nodes, chemical bonds as edges, and graphs labeled by categories.

</p><p>
One of the challenges in GNN graph classification models lies in their sensitivity, where detecting differences between classes is often easier than identifying outliers or incorrectly predicted results. Currently, we are actively engaged in two studies that focus on the application of GNN graph classification models to time series classification tasks:

<u><a href="http://sparklingdataocean.com/2023/02/11/cityTempGNNgraphs/"> 'GNN Graph Classification for Climate Change Patterns'</a></u> and <u><a href="http://sparklingdataocean.com/2023/05/08/classGraphEeg/"> 'GNN Graph Classification for EEG Pattern Analysis'</a></u>.

</p><p>
In this post, we address the challenges of GNN graph classification on semantic graphs for document comparison. We demonstrate effective techniques to harness graph topology and node features in order to enhance document analysis and comparison. Our approach leverages the power of GNN models in handling semantic graph data, contributing to improved document understanding and similarity assessment.
</p><p>


</p><p>
To create semantic graph from documents we will use method that we introduced in our post
<u><a href="http://sparklingdataocean.com/2022/11/09/knowledgeGraph4NlpGnn/"> 'Find Semantic Similarities by GNN Link Predictions'</a></u>. In that post we demonstrated how to use GNN link prediction models to revire knowledge graphs.
For experiments of that study we looked at semantic similarities and dissimilarities between biographies of 20 modern art artists based on corresponding Wikipedia articles. One experiment was based on traditional method implemented on full test of articles and cosine similarities between reembedded nodes. In another scenario, GNN link prediction model ran on top of articles represented as semantic graphs with nodes as pairs of co-located words and edges as pairs of nodes with common words.
</p><p>
In this study, we expand on our previous research by leveraging the same data source and employing similar graph representation techniques. However, we introduce a new approach by constructing separate semantic graphs dedicated to each individual artist. This departure from considering the entire set of articles as a single knowledge graph enables us to focus on the specific relationships and patterns related to each artist. By adopting this approach, we aim to capture more targeted insights into the connections and dynamics within the knowledge graph, allowing for a deeper exploration of the relationships encoded within the biographies of these artists.
</p><p>



<p><h3>Methods</h3>
<p></p>

The input data for GNN graph classification models consists of a collection of labeled small graphs composed of edges and nodes with associated features. In this section we will describe data processing and model training in the following order:

<ul>
<li>Text preprocessing to transform raw data to semantic graphs. </li>
<li>Node embedding process.</li>
<li>The process of semantic subgraph extraction.</li>
<li>Training GNN graph classification model.</li>
</ul>



<p><h4>From Raw Data to Semantic Graph</h4>
<p></p>
To transform text data to semantic graph with nodes as co-located word pairs we will do the following:



</p>
<ul>
<li>Tokenize Wikipedia text and exclude stop words.</li>
<li>Get nodes as co-located word pairs.</li>
<li>Get edges between nodes.</li>
<li>Build semantic graph.</li>
</ul>
<p></p>
To generate edges we will find pair to pair neighbors following text sequences within articles and joint pairs that have common words.
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">if</span> <span class="n">pair1</span><span class="o">=</span><span class="p">[</span><span class="n">leftWord1</span><span class="p">,</span> <span class="n">rightWord1</span><span class="p">],</span>
   <span class="n">pair2</span><span class="o">=</span><span class="p">[</span><span class="n">leftWord2</span><span class="p">,</span> <span class="n">rightWord2</span><span class="p">]</span>
   <span class="ow">and</span> <span class="n">rightWord1</span><span class="o">=</span><span class="n">leftWord2</span><span class="p">,</span>
<span class="n">then</span> <span class="n">there</span> <span class="ow">is</span> <span class="n">edge12</span><span class="o">=</span><span class="p">{</span><span class="n">pair1</span><span class="p">,</span> <span class="n">pair2</span><span class="p">}</span></code></pre></figure>

<p></p>

Graph edges built based of these rules will cover word to word sequences and word to word chains within articles. On nodes and edges described above we will built an semantic graphs.
</p><p>
</p><p>
<h4>Node Embedding</h4>
</p><p>
To translate text of pairs of co-located to vectors we will use transformer model from Hugging Face: <u><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2"> 'all-MiniLM-L6-v2'</a></u>. This is a sentence-transformers model that maps text to a 384 dimensional vector space.


</p><p>
<p><h4>Extract Semantic Subgraphs</h4>
</p><p>


As input data for GNN graph classification model we need a set of labeled small graphs. In this study from each document of interest we will extract a set of subgraphs. By extracting relevant subgraphs from both documents, GNN graph classification models can compare the structural relationships and contextual information within the subgraphs to assess their similarity or dissimilarity. One of the ways to extract is getting subgraphs as neighbors and neighbors of neighbors of nodes with high centralities. In this study we will use betweenness centrality metrics.

</p><p>

</p><p>
<h4>Train the Model</h4>
</p><p>
The GNN graph classification model is designed to process input graph data, including both the edges and node features, and is trained on graph-level labels. In this case, the input data structure consists of the following components:
</p><p>
<ul>
<li>
Edges in a graph capture the relationships between nodes.
</li><li>
Nodes with embedded features would be embedded into the nodes to provide additional information to the GNN graph classification model.
</li><li>
Graph-level labels are assigned to the entire graph, and the GNN graph classification model leverages these labels to identify and predict patterns specific to each label category.
</li></ul>
<p></p>

As GNN graph classification model we will use a GCNConv (Graph Convolutional Network Convolution) activation model. The model code is taken from tutorial of the <u><a href="https://pytorch-geometric.readthedocs.io/en/latest/"> 'PyTorch Geometric Library (PyG)'</a></u>. The GCNConv graph classification model is a type of graph convolutional network that uses convolution operations to aggregate information from neighboring nodes in a graph. It takes as input graph data (edges, node features, and the graph-level labels) and applies graph convolutional operations to extract meaningful features from the graph structure.
<p></p>
The Python code for the GCNConv model is provided by the PyG library. The code for converting data to the PyG data format, model training and interpretation techniques are described below.
<p></p>


<h3>Experiments</h3>
<p></p>
<h4>Data Source</h4>
<p></p>

As the data source for this study we used text data from Wikipedia articles about 20 modern art artists. Here is the list of artists and Wikipedia text size distribution:
<p></p>
<a href="#">
    <img src="/img/artStats.jpg" alt="Post Sample Image" width="1000" />
</a>
<p></p>

<p>Based on Wikipedia text size distribution, the most well known artist in our artist list is Vincent van Gogh and the most unknown artist is Franz Marc:</p>

<p></p>
<a href="#">
    <img src="/img/artImg1.jpg" alt="Post Sample Image" width="345" />
</a>
<p></p>

<p></p>
More detail information is available in our post <u><a href="http://sparklingdataocean.com/2022/07/23/knowledgeGraph4GNN/">'Rewiring Knowledge Graphs by Link Predictions'</a></u>.

<p></p>

To estimate document similarities based on GNN graph classification model, we experimented with pairs of highly connected artists and highly disconnected artists.

Pairs of artists were selected based on our study <u><a href="https://www.springerprofessional.de/en/building-knowledge-graph-in-spark-without-sparql/18375090">"Building Knowledge Graph in Spark without SPARQL"</a></u>.
This picture illustrates relationships between modern art artists based on their biographies and art movements:

<p></p>
<a href="#">
    <img src="/img/artStats2b.jpg" alt="Post Sample Image" width="1000" />
</a>
<p></p>

<p>As highly connected artists, we selected Pablo Picasso and Georges Braque, artists with well known strong relationships between them: both Pablo Picasso and Georges Braque were pioneers of cubism art movement.
<p></p>
As highly disconnected artists, we selected Claude Monet and Kazimir Male- vich who were notably distant from each other: they lived in different time peri- ods, resided in separate countries, and belonged to contrasting art movements: Claude Monet was a key artist of impressionism and Kazimir Malevich a key artist of Suprematism.</p>

<p></p>

For a more detailed exploration of the relationships between modern art artists discovered through knowledge graph techniques, you can refer to our post:

<u><a href="http://sparklingdataocean.com/2020/02/02/knowledgeGraphIntegration/">"Knowledge Graph for Data Integration"</a></u>.


<p></p>


<p></p>

<p></p>

<p></p>
<h4>Transform Text Document to Semantic Graph</h4>
<p></p>
For each selected Wikipedia article we transformed text to semantic graphs by the following steps:

<ul>
<li>Tokenize Wikipedia text and excluded stop words.</li>
<li>Generate nodes as co-located word pairs.</li>
<li>Calculate edges as joint pairs that have common words. These edges represente word sequences and word chains within articles.</li>
</ul>


<p></p>
<h5>Tokenize Wikipedia text</h5>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">nltk.tokenize</span> <span class="kn">import</span> <span class="n">RegexpTokenizer</span>
<span class="n">tokenizer</span> <span class="o">=</span><span class="nc">RegexpTokenizer</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">[A-Za-z]+</span><span class="sh">'</span><span class="p">)</span>

<span class="n">wikiArtWords</span><span class="o">=</span><span class="n">wikiArtists</span><span class="p">[</span><span class="sh">'</span><span class="s">Wiki</span><span class="sh">'</span><span class="p">]</span>
  <span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nc">RegexpTokenizer</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">[A-Za-z]+</span><span class="sh">'</span><span class="p">).</span><span class="nf">tokenize</span><span class="p">(</span><span class="n">x</span><span class="p">)).</span><span class="nf">reset_index</span><span class="p">()</span>

<span class="n">wikiArtWords</span><span class="o">=</span><span class="n">wikiArtWords</span><span class="p">.</span><span class="nf">explode</span><span class="p">([</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">])</span>
<span class="n">wordStats</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">wikiArtWords</span><span class="p">,</span><span class="n">listArtists</span><span class="p">)</span>

<span class="n">artistWordStats</span><span class="o">=</span><span class="n">wordStats</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">Artist</span><span class="sh">'</span><span class="p">).</span><span class="nf">count</span><span class="p">()</span>
  <span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></figure>




<p></p>
<h5>Exclude stop words</h5>
<p></p>

Exclude stop words and short words woth length&lt;4:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">nltk</span>
<span class="n">nltk</span><span class="p">.</span><span class="nf">download</span><span class="p">(</span><span class="sh">'</span><span class="s">stopwords</span><span class="sh">'</span><span class="p">)</span>
<span class="kn">from</span> <span class="n">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="n">STOPWORDS</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">stopwords</span><span class="p">.</span><span class="nf">words</span><span class="p">(</span><span class="sh">'</span><span class="s">english</span><span class="sh">'</span><span class="p">))</span>
<span class="n">dfStopWords</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame </span><span class="p">(</span><span class="n">STOPWORDS</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">])</span>
<span class="n">dfStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">stop</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="sh">"</span><span class="s">stopWord</span><span class="sh">"</span>
<span class="n">stopWords</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">wikiArtWords</span><span class="p">,</span><span class="n">dfStopWords</span><span class="p">,</span><span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">)</span>

<span class="n">nonStopWords</span><span class="o">=</span><span class="n">stopWords</span><span class="p">[</span><span class="n">stopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">stop</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()]</span>
<span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">stop</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">len</span><span class="p">()</span>
<span class="n">nonStopWords</span><span class="o">=</span><span class="n">nonStopWords</span><span class="p">[</span><span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">stop</span><span class="sh">'</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">3</span><span class="p">]</span>
<span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span> <span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span>
<span class="n">nonStopWords</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">idxWord</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">nonStopWords</span><span class="p">.</span><span class="n">index</span></code></pre></figure>


<p></p>

<p></p>


<p></p>

<p></p>

<p></p>
<h5>Generated nodes as co-located word pairs</h5>
<p></p>
Get pairs of co-located words:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">bagOfWords</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">nonStopWordsSubset</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">])</span>
<span class="n">bagOfWords</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">bagOfWords</span><span class="p">[</span><span class="sh">'</span><span class="s">idxWord</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">bagOfWords</span><span class="p">.</span><span class="n">index</span>

<span class="n">indexWords</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">nonStopWordsSubset</span><span class="p">,</span><span class="n">bagOfWords</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxWord</span><span class="sh">'</span><span class="p">])</span>
<span class="n">idxWord1</span><span class="o">=</span><span class="n">indexWords</span>
  <span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">word1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxArtist1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxWord</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxWord1</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">idxWord2</span><span class="o">=</span><span class="n">indexWords</span>
  <span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">word2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxArtist2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxWord</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxWord2</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">leftWord</span><span class="o">=</span><span class="n">idxWord1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span>
<span class="n">leftWord</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">rightWord</span> <span class="o">=</span> <span class="n">idxWord2</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span> <span class="p">,</span> <span class="p">:].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  

<span class="n">pairWords</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">leftWord</span><span class="p">,</span><span class="n">rightWord</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pairWords</span> <span class="o">=</span> <span class="n">pairWords</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">pairWords</span><span class="p">[</span><span class="n">pairWords</span><span class="p">[</span><span class="sh">'</span><span class="s">idxArtist1</span><span class="sh">'</span><span class="p">]</span><span class="o">!=</span><span class="n">pairWords</span><span class="p">[</span><span class="sh">'</span><span class="s">idxArtist2</span><span class="sh">'</span><span class="p">]].</span><span class="n">index</span><span class="p">)</span>
<span class="n">pairWords</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>

Drop duplicates {artist, word1, word2}

<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cleanPairWords</span> <span class="o">=</span> <span class="n">pairWords</span>
<span class="n">cleanPairWords</span> <span class="o">=</span> <span class="n">cleanPairWords</span><span class="p">.</span><span class="nf">drop_duplicates</span><span class="p">(</span>
  <span class="n">subset</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">idxArtist1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">word1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">word2</span><span class="sh">'</span><span class="p">],</span> <span class="n">keep</span> <span class="o">=</span> <span class="sh">'</span><span class="s">last</span><span class="sh">'</span><span class="p">).</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">cleanPairWords</span><span class="p">[</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>
  <span class="n">cleanPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">word1</span><span class="sh">"</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> </span><span class="sh">"</span> <span class="o">+</span> <span class="n">cleanPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">word2</span><span class="sh">"</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">cleanPairWords</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">cleanPairWords</span><span class="p">.</span><span class="n">index</span></code></pre></figure>

<p></p>



<p></p>


<p></p>
<h5>Calculated edges as joint pairs that have common words.</h5>
<p></p>
Index data:
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">nodeList1</span><span class="o">=</span><span class="n">nodeList</span>
  <span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">word2</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">theWord</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">wordpair1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">nodeIdx1</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">nodeList2</span><span class="o">=</span><span class="n">nodeList</span>
  <span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">word1</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">theWord</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxArtist1</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxArtist2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">wordpair2</span><span class="sh">'</span><span class="p">,</span>
  <span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">nodeIdx2</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">allNodes</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">nodeList1</span><span class="p">,</span><span class="n">nodeList2</span><span class="p">,</span><span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">theWord</span><span class="sh">'</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">inner</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>


<p></p>

<p></p>
<h4>Input Data Preparation</h4>
<p></p>
<h5>Transform Text to Vectors</h5>
As mentioned above, for text to vector translation we used ’all- MiniLM-L6- v2’ transformer model from Hugging Face.
<p></p>
Get unique word pairs for embedding
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">bagOfPairWords</span><span class="o">=</span><span class="n">nodeList</span>
<span class="n">bagOfPairWords</span> <span class="o">=</span> <span class="n">bagOfPairWords</span><span class="p">.</span><span class="nf">drop_duplicates</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">)</span>
<span class="n">bagOfPairWords</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">bagOfPairWords</span><span class="p">[</span><span class="sh">'</span><span class="s">bagPairWordsIdx</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">bagOfPairWords</span><span class="p">.</span><span class="n">index</span></code></pre></figure>

<p></p>
<p></p>
Transform node features to vectors:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="nc">SentenceTransformer</span><span class="p">(</span><span class="sh">'</span><span class="s">all-MiniLM-L6-v2</span><span class="sh">'</span><span class="p">)</span>
<span class="n">wordpair_embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">cleanPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">wordpair</span><span class="sh">"</span><span class="p">],</span><span class="n">convert_to_tensor</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>


<p></p>


<p></p>
<h5>Prepare Input Data for GNN Graph Classification Model</h5>
<p></p>

In GNN graph classification, the input to the model is typically a set of small graphs that represent entities in the dataset. These graphs are composed of nodes and edges, where nodes represent entities, and edges represent the relationships between them. Both nodes and edges may have associated features that describe the attributes of the entity or relationship, respectively. These features can be used by the GNN model to learn the patterns and relationships in the data, and classify or predict labels for the graphs. By considering the structure of the data as a graph, GNNs can be particularly effective in capturing the complex relationships and dependencies between entities, making them a useful tool for a wide range of applications.

<p></p>
To prepare the input data for the GNN graph classification model, we generated labeled semantic subgraphs from each document of interest. These subgraphs were constructed by selecting neighbors and neighbors of neighbors around specific ”central” nodes. The central nodes were determined by identifying the top 500 nodes with the highest betweenness centrality within each document.
<p></p>
By focusing on these central nodes and their neighboring nodes, we aimed to capture the relevant information and relationships within the document. This approach allowed us to create labeled subgraphs that served as the input data for the GNN graph classification model, enabling us to classify and analyze the documents effectively.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="n">list1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span>  
<span class="n">list2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">]</span>  
<span class="n">radius</span><span class="o">=</span><span class="mi">2</span>
<span class="n">datasetTest</span><span class="o">=</span><span class="nf">list</span><span class="p">()</span>
<span class="n">datasetModel</span><span class="o">=</span><span class="nf">list</span><span class="p">()</span>
<span class="n">dfUnion</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">()</span>
<span class="n">seeds</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">artist</span> <span class="ow">in</span> <span class="n">list1</span> <span class="o">+</span> <span class="n">list2</span><span class="p">:</span>
  <span class="k">if</span> <span class="n">artist</span> <span class="ow">in</span> <span class="n">list1</span><span class="p">:</span>
    <span class="n">label</span><span class="o">=</span><span class="mi">0</span>
  <span class="k">if</span> <span class="n">artist</span> <span class="ow">in</span> <span class="n">list2</span><span class="p">:</span>
    <span class="n">label</span><span class="o">=</span><span class="mi">1</span>
    <span class="n">edgeInfo0</span><span class="o">=</span><span class="n">edgeInfo</span><span class="p">[</span><span class="n">edgeInfo</span><span class="p">[</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">artist</span><span class="p">]</span>
    <span class="n">G</span><span class="o">=</span><span class="n">nx</span><span class="p">.</span><span class="nf">from_pandas_edgelist</span><span class="p">(</span><span class="n">edgeInfo0</span><span class="p">,</span>  <span class="sh">"</span><span class="s">wordpair1</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">wordpair2</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">betweenness</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nf">betweenness_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
    <span class="n">sorted_nodes</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">betweenness</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">betweenness</span><span class="p">.</span><span class="n">get</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">top_nodes</span> <span class="o">=</span> <span class="n">sorted_nodes</span><span class="p">[:</span><span class="mi">500</span><span class="p">]</span>
    <span class="n">dfTopNodes</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">top_nodes</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">seedPair</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">dfTopNodes</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">dfTopNodes</span><span class="p">.</span><span class="n">index</span><span class="p">:</span>
      <span class="n">seed_node</span><span class="o">=</span><span class="n">dfTopNodes</span><span class="p">[</span><span class="sh">'</span><span class="s">seedPair</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">seed</span><span class="p">]</span>
      <span class="n">seeds</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span><span class="sh">'</span><span class="s">artist</span><span class="sh">'</span><span class="p">:</span><span class="n">artist</span><span class="p">,</span> <span class="sh">'</span><span class="s">seed_node</span><span class="sh">'</span><span class="p">:</span><span class="n">seed_node</span><span class="p">,</span> <span class="sh">'</span><span class="s">seed</span><span class="sh">'</span><span class="p">:</span><span class="n">seed</span><span class="p">})</span>
      <span class="n">foaf_nodes</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nf">ego_graph</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">seed_node</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="n">radius</span><span class="p">).</span><span class="n">nodes</span>
      <span class="n">dfFoaf</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">foaf_nodes</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">])</span>
      <span class="n">dfFoaf</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="n">dfFoaf</span><span class="p">[</span><span class="sh">'</span><span class="s">foafIdx</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">dfFoaf</span><span class="p">.</span><span class="n">index</span>
      <span class="n">words_embed</span> <span class="o">=</span> <span class="n">words_embeddings</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">dfFoaf</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">)</span>
      <span class="n">values1</span><span class="o">=</span><span class="n">words_embed</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">384</span><span class="p">]</span>
      <span class="n">fXValues1</span><span class="o">=</span> <span class="n">values1</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">values</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
      <span class="n">fXValuesPT1</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">fXValues1</span><span class="p">)</span>
      <span class="n">graphSize</span><span class="o">=</span><span class="n">dfFoaf</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="c1"># dfFoaf.tail()
</span>      <span class="n">oneGraph</span><span class="o">=</span><span class="p">[]</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">graphSize</span><span class="p">):</span>
        <span class="n">pairi</span><span class="o">=</span><span class="n">dfFoaf</span><span class="p">[</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">pairi1</span> <span class="o">=</span> <span class="n">pairi</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">pairi2</span> <span class="o">=</span> <span class="n">pairi</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># for j in range(i+1,graphSize):
</span>        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">graphSize</span><span class="p">):</span>
          <span class="n">pairj</span><span class="o">=</span><span class="n">dfFoaf</span><span class="p">[</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">j</span><span class="p">].</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
          <span class="n">pairj1</span> <span class="o">=</span> <span class="n">pairj</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
          <span class="n">pairj2</span> <span class="o">=</span> <span class="n">pairj</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
          <span class="nf">if </span><span class="p">(</span> <span class="n">pairi2</span><span class="o">==</span><span class="n">pairj1</span><span class="p">):</span>
            <span class="n">oneGraph</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span> <span class="sh">'</span><span class="s">artist</span><span class="sh">'</span><span class="p">:</span><span class="n">artist</span><span class="p">,</span><span class="sh">'</span><span class="s">seed</span><span class="sh">'</span><span class="p">:</span><span class="n">seed</span><span class="p">,</span>
                             <span class="sh">'</span><span class="s">centralNode</span><span class="sh">'</span><span class="p">:</span><span class="n">seed_node</span><span class="p">,</span> <span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">:</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">:</span><span class="n">j</span><span class="p">,</span> <span class="sh">'</span><span class="s">pairi</span><span class="sh">'</span><span class="p">:</span><span class="n">pairi</span><span class="p">,</span> <span class="sh">'</span><span class="s">pairj</span><span class="sh">'</span><span class="p">:</span><span class="n">pairj</span><span class="p">})</span>
      <span class="n">dfGraph</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">oneGraph</span><span class="p">)</span>
      <span class="n">dfUnion</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">dfUnion</span><span class="p">,</span> <span class="n">dfGraph</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="n">edge1</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">dfGraph</span><span class="p">[[</span><span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">]].</span><span class="n">T</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
      <span class="n">dataset1</span> <span class="o">=</span> <span class="nc">Data</span><span class="p">(</span><span class="n">edge_index</span><span class="o">=</span><span class="n">edge1</span><span class="p">)</span>
      <span class="n">dataset1</span><span class="p">.</span><span class="n">y</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">label</span><span class="p">])</span>
      <span class="n">dataset1</span><span class="p">.</span><span class="n">x</span><span class="o">=</span><span class="n">fXValuesPT1</span>
      <span class="n">datasetModel</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">dataset1</span><span class="p">)</span>
      <span class="n">loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">datasetModel</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span></code></pre></figure>

<p></p>

Model size
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">modelSize</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">modelSize</span>
<span class="mi">1000</span></code></pre></figure>

<p></p>
<p></p>

<p><h4>Training the Model</h4>
<p></p>
For this study we used the code provided by PyTorch Geometric as tutorial on GCNConv graph classification models - we just slightly tuned it for our data:

<p></p>
<p><h5>Randomly split data to training and tesing</h5>
<p></p>

<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">random</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
<span class="n">percent</span> <span class="o">=</span> <span class="mf">0.13</span>
<span class="n">sample_size</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">modelSize</span> <span class="o">*</span> <span class="n">percent</span><span class="p">)</span>
<span class="n">train_size</span><span class="o">=</span><span class="nf">int</span><span class="p">(</span><span class="n">modelSize</span><span class="o">-</span><span class="n">sample_size</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">train_size</span><span class="p">)</span></code></pre></figure>


<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Number of training graphs: </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Number of test graphs: </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
<span class="n">Number</span> <span class="n">of</span> <span class="n">training</span> <span class="n">graphs</span><span class="p">:</span> <span class="mi">870</span>
<span class="n">Number</span> <span class="n">of</span> <span class="n">test</span> <span class="n">graphs</span><span class="p">:</span> <span class="mi">130</span></code></pre></figure>


<p></p>

<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Step </span><span class="si">{</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s">:</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">=======</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Number of graphs in the current batch: </span><span class="si">{</span><span class="n">data</span><span class="p">.</span><span class="n">num_graphs</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">()</span></code></pre></figure>

<p></p>
<h5>Prepare the model:</h5>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch.nn</span> <span class="kn">import</span> <span class="n">Linear</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GCNConv</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">global_mean_pool</span>

<span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">GCN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lin</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="c1"># 1. Obtain node embeddings
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="c1"># 2. Readout layer
</span>        <span class="n">x</span> <span class="o">=</span> <span class="nf">global_mean_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>  <span class="c1"># [batch_size, hidden_channels]
</span>        <span class="c1"># 3. Apply a final classifier
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>        
        <span class="k">return</span> <span class="n">x</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span></code></pre></figure>

<p></p>

<p><h5>Train the Model:</h5>
<p></p>

<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">IPython.display</span> <span class="kn">import</span> <span class="n">Javascript</span>
<span class="nf">display</span><span class="p">(</span><span class="nc">Javascript</span><span class="p">(</span><span class="sh">'''</span><span class="s">google.colab.output.setIframeHeight(0, true, {maxHeight: 300})</span><span class="sh">'''</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
   <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
   <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>  <span class="c1"># Iterate in batches over the training dataset.
</span>        <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># Perform a single forward pass.
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># Compute the loss.
</span>        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>  <span class="c1"># Derive gradients.
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>  <span class="c1"># Update parameters based on gradients.
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>  <span class="c1"># Clear gradients.
</span>
<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">loader</span><span class="p">):</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>  <span class="c1"># Iterate in batches over the training/test dataset.
</span>        <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>  
        <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Use the class with highest probability.
</span>        <span class="n">correct</span> <span class="o">+=</span> <span class="nf">int</span><span class="p">((</span><span class="n">pred</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">).</span><span class="nf">sum</span><span class="p">())</span>  <span class="c1"># Check against ground-truth labels.
</span>    <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">)</span>  <span class="c1"># Derive ratio of correct predictions.
</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
   <span class="nf">train</span><span class="p">()</span>
   <span class="n">train_acc</span> <span class="o">=</span> <span class="nf">test</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
   <span class="n">test_acc</span> <span class="o">=</span> <span class="nf">test</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
   <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="mi">03</span><span class="n">d</span><span class="si">}</span><span class="s">, Train Acc: </span><span class="si">{</span><span class="n">train_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, Test Acc: </span><span class="si">{</span><span class="n">test_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>


<p></p>
<p></p>
To estimate the model results we used the same model accuracy metrics as in the PyG tutorial.
<p></p>
<p></p>
<p></p>

<p><h5>Accuracy Metrics of the Model:</h5>
<p></p>

As we mentioned above, the GNN graph classification model exhibits higher sensitivity for classification compared to the GNN link prediction model. In both scenarios, we trained the models for 9 epochs.
<p></p>
Given the distinct differences between Monet and Malevich as artists, we anticipated achieving high accuracy metrics. However, the surprising outcome was obtaining perfect metrics as 1.0000 for training data and 1.0000 for testing right from the initial training step.

<p></p>
<p></p>
<a href="#">
    <img src="/img/modelStats1.jpg" alt="Post Sample Image" width="345" />
</a>
<p></p>

In the classification of Wikipedia articles about Pablo Picasso and Georges Braque, we were not anticipating the significant differentiation between these two documents: these artists had very strong relationships in biography and art movements. Also GNN link prediction models classified these artists as highly similar.
<p></p>
<p></p>
<a href="#">
    <img src="/img/modelStats2.jpg" alt="Post Sample Image" width="345" />
</a>
<p></p>
This observation highlights the high sensitivity of the GNN graph classifica- tion model and emphasizes the ability of the GNN graph classification model to capture nuanced differences and provide a more refined classification approach compared to the GNN Link Prediction models.

<p><h4>Model Results</h4>
<p></p>

<p></p>
To interpret model results we calculated the softmax probabilities for each class output by the model. The softmax probabilities represent the model's confidence in its prediction for each class.
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">modelSize</span>
<span class="mi">1000</span></code></pre></figure>


<p></p>
<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Softmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">graph1</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">modelSize</span><span class="p">):</span>
  <span class="n">label</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">batch</span><span class="p">)</span>
  <span class="n">output</span> <span class="o">=</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">out</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">graph1</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">:</span><span class="n">g</span><span class="p">,</span>
                 <span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span><span class="sh">'</span><span class="s">pred</span><span class="sh">'</span><span class="p">:</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                 <span class="sh">'</span><span class="s">prob0</span><span class="sh">'</span><span class="p">:</span><span class="nf">round</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">4</span><span class="p">),</span><span class="sh">'</span><span class="s">prob1</span><span class="sh">'</span><span class="p">:</span><span class="nf">round</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">4</span><span class="p">)})</span></code></pre></figure>

<p></p>



<p></p>
One of the challenges encountered when utilizing the GNN graph classification model for text classification is the identification of outliers. In the scenario of classifying Wikipedia articles about the biographies of Claude Monet and Kazimir Malevich, the trained model did not detect any outliers.
<p></p>
In the case of Pablo Picasso and Georges Braque, we found that despite their shared biographies and involvement in the same art movements, there were no- table differences between their respective Wikipedia articles. The GNN graph classification model identified these articles as highly dissimilar, suggesting dis- tinct characteristics and content within their biographies. During our analysis of 1000 subgraphs, we encountered only 8 outliers.
<p></p>
<p></p>
<a href="#">
    <img src="/img/modelStats3.jpg" alt="Post Sample Image" width="444" />
</a>
<p></p>



<p></p>
<p></p>
<p><h3>Conclusion</h3>


<p></p>
GNN graph classification is a powerful machine learning technique designed for object classification when the objects can be represented as graphs. By mapping object elements to nodes and their relationships to edges, GNN graph classification models capture complex interdependencies among the elements. This approach is particularly valuable when traditional machine learning methods struggle to capture complex relationships.
<p></p>
GNN graph classification has been successfully applied in various domains, including molecule classification, image recognition, protein classification, social networks, brain connectivity networks, road networks, and climate data analysis.
<p></p>
In this paper, we investigate the application of GNN graph classification models in NLP for document comparison, aiming to uncover document similarities and dissimilarities using graph topology and node features. We focus on comparing Wikipedia articles about modern art artists and demonstrate the potential of these models in extracting relevant information and identifying patterns. Additionally, we address challenges related to model sensitivity and outlier detection in GNN graph classification.
<p></p>
We investigated the effectiveness of GNN graph classification in capturing different types of relationships among artists. We specifically selected two pairs of artists, one representing highly connected relationships (Pablo Picasso and Georges Braque) and the other representing highly disconnected relationships (Claude Monet and Kazimir Malevich). As expected, in the case of classifying Wikipedia articles on the biographies of Claude Monet and Kazimir Malevich, no outliers were detected.
<p></p>
In the case of Pablo Picasso and Georges Braque, despite their shared biographies and association with the cubism art movement, we identified substantial differences in their respective articles. The GNN graph classification model categorized these articles as highly dissimilar and out of 1000 subgraphs, we encountered only 8 outliers, further emphasizing the model’s sensitivity in capturing the nuanced differences between the documents.
<p></p>
Future research can further explore the applications of GNN graph classification models in NLP, with a focus on addressing sensitivity and outlier detection challenges. Additionally, efforts can be made to deeper understanding of semantic graph relationships.
<p></p>
In conclusion, our study advances document comparison using GNN graph classification, offering valuable insights for text analysis and knowledge discovery. It contributes to the growing field of GNN-based methods in NLP, opening avenues for future research and practical applications.
<p></p>
<p><h3>Next Post - Graph Connectors</h3>

In the next spost we will start a new topic related to knowledge graphs and GNN.
<p></p>
</p></p></p></p></p></p></p></p></p></p></p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[Semantic Graph for Text Understanding In this project, we treat text as a semantic graph rather than a flat sequence of words. From Wikipedia biographies of modern artists, we build a graph where nodes are meaningful word pairs and edges connect them when they appear together or in related contexts. Each node carries a transformer embedding, and a Graph Neural Network learns to “rewire” this graph—strengthening important links, downplaying weak ones, and revealing which artists and concepts truly sit close together or far apart in meaning. This semantic graph becomes a foundation for NLP tasks: it supports richer recommendations (finding both similar and contrastive artists or documents), cleans and enriches the underlying knowledge graph, and provides structure-aware representations that go beyond simple embedding cosine similarity. Instead of just asking “how similar are these texts?”, we can ask “how is their semantic neighborhood wired?” and let Graph AI answer from the topology of the semantic graph itself.]]></summary></entry></feed>