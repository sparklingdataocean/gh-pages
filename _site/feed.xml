<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-12-03T16:14:07-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Sparkling Data Ocean</title><subtitle>Spark for Big Data Analytics.</subtitle><entry><title type="html">GNN Link Prediction for Country Population, Life Expectancy, Happiness</title><link href="http://localhost:4000/2024/11/26/vectors2gafGNN/" rel="alternate" type="text/html" title="GNN Link Prediction for Country Population, Life Expectancy, Happiness" /><published>2024-11-26T13:00:00+01:00</published><updated>2024-11-26T13:00:00+01:00</updated><id>http://localhost:4000/2024/11/26/vectors2gafGNN</id><content type="html" xml:base="http://localhost:4000/2024/11/26/vectors2gafGNN/"><![CDATA[<p><h3> Introduction</h3>
<p></p>
Graphs are everywhere in our lives. They represent molecules in chemistry, roads in navigation, and even our social networks like Facebook, a molecule graph, a city map, a social network graph.
<p></p>
<p></p>
<a href="#">
    <img src="/img/gkgSlide1.jpg" alt="Post Sample Image" width="765" />
</a>
<p></p>
<p></p>

So why graphs?

<p></p>

People don’t think sequentially, especially when solving complex problems, often engaging in mind wandering.
This may explain why the smartest people don’t have more neurons but instead have more connections, enabling dynamic and non-linear thinking.
GNNs replicate this by modeling data as graphs, helping us uncover complex relationships and patterns in neuroscience.
<p></p>
What is graph thinking for data analysis: if humans think this way, why wouldn't we force machine to think this way?

What is machine graph thinking? Data domains that can be represented as graphs can use graph thinking to get insights in data. GNN models were created for this reason.
<p></p>
To represent data as graph, start with thinking about relationships. Why relationships are important?
<p></p>
Using GNN for knowledge graphs that are built on variety of date domains is a challenge.
<p></p>
For spatial data, graph structure can be built based on coordinates. In EEG data we introduced it as
<p></p>
For countries neighbors can be defined by countries that they share borders with.

<p></p>
The next step will be to link these subgraphs through common connections. For example, when we have different domains for the same entities (countries), we connect the same countries across subgraphs.
<p></p>
Many data types can be converted to vectors -- everything -to- vector.
<p></p>
In this study we will put together information about:
long time data for country populations
a few years information about population by age;
median, age 0-5, age 15-64,  65-older
several years of information about country life expectancy
income
country territory
density
agriculture

<p></p>

<p></p>

To define neighbors for countries we can use information about country borders -
Getting information about pairs of countries that share borders will be interesting, especially if we have information about types and quality of borders -- how can people cross the borders.
<p></p>
Two types of country borders: land borders and sea borders.
<p></p>

Land Borders:
<p></p>
<a href="#">
    <img src="/img/gkgMap1.jpg" alt="Post Sample Image" width="700" />
</a>
</p>
<p>
Sea Borders:
<p></p>
<a href="#">
    <img src="/img/gkgMap2.jpg" alt="Post Sample Image" width="700" />
</a>
</p>
<p>
How locations can affect lives? For bigger countries it's more difficult to figure out, for example territory of Russia is very big with a variety of climates.

<p></p>

Borders between the countries are like synapses between neurons. The quality (edge weight) is changing with time: the open the borders are, the better are connections between the countries. The more closed borders are the stronger the conflict between countries.


<p></p>

We will analyze how the border qualities affect how similar are life quality and longertivity.
<p></p>


<p></p>

<p></p>
<a href="#">
    <img src="/img/gkgSlide2.jpg" alt="Post Sample Image" width="479" />
</a>
<p></p>


<p></p>

<h3>Methodologies</h3>
<h4>Prepare Input Data for the Model</h4>
As input data for GNN Link Prediction model we need to create small labeled graphs:
<p></p>
<ul>
<li>
Edges
</li><li>
Nodes with features.
</li><li>

</li></ul>


  <p></p>

<h4>Train the GNN Graph Classification Model</h4>

  In this study we uses a GCNConv model from PyTorch Geometric Library as a GNN graph classification model. The GCNConv model is a type of graph convolutional network that applies convolutional operations to extract meaningful features from the input graph data (edges, node features, and the graph-level labels). The code for the model is taken from a PyG tutorial.
  </p>
<p>
  <p></p>

<p></p>
<h4>XXXd</h4>
To calculate cosine similarities between pairs of vectors, we will use Cosine Similarities function:  
    <p></p>
    
<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="o">**</span>
    </code></pre></figure>

    <p></p>

    <p></p>


<p></p>      


<p></p>


<h4>Node Embedding: Catching Pre-Final Vectors in GNN Link Prediction</h4>
<p>GNN Graph Classification with pre-final stop, .</p>

<p></p>
<h4>Interpreting Model Results: Cosine Similarity </h4>
    <p>With node embeddings in place, .</p>

    Select pairs of vectors with cosine similarities higher than 0.95.
        <p></p>  
    <p>This integrated approach allows us to delve deeper into .</p>
<p></p>
<h4>Interpreting Model Results: Symmetry Metrics </h4>


<p></p>
<p></p>
<p></p>
<p></p>
<h3>Experiments Overview </h3>
<p></p>
<p></p>
<p></p>
<p>This section outlines the experimental framework used to </p>
<p></p>
<p></p>
<p></p>     
<h4>Data Sources</h4>
<p></p>
<p></p>
<p></p>
<h5>Data Sources for Country Land Borders</h5>
<p></p>
<p></p>
<p></p>
<p></p>
Country land boundaries and associated metadata are sourced from Natural Earth’s Admin 0 - Countries dataset, version 5.0.1 (2023). This dataset is publicly available under the CC0 1.0 Public Domain Dedication and includes information on GDP, population, and administrative classifications.
<p></p>

Path to your zip file in Google Drive
Path to extract the files
Unzip the file
<p></p>
<p></p>
<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">zipfile</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="n">zip_file_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/Geo/ne_10m_admin_0_countries.zip</span><span class="sh">"</span>
<span class="n">extract_to_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/Geo/</span><span class="sh">"</span>
<span class="k">with</span> <span class="n">zipfile</span><span class="p">.</span><span class="nc">ZipFile</span><span class="p">(</span><span class="n">zip_file_path</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
    <span class="n">zip_ref</span><span class="p">.</span><span class="nf">extractall</span><span class="p">(</span><span class="n">extract_to_path</span><span class="p">)</span></code></pre></figure>

<p></p>
<p></p>
<h5>Data Sources for Country Sea Borders</h5>
<p></p>
<p></p>
<p></p>
<p></p>     
Sea boundaries and Exclusive Economic Zones (EEZs) were obtained from Marineregions.org's World EEZ v12 dataset, version 12 (2023). The dataset is licensed under the Creative Commons Attribution 4.0 International License (CC BY 4.0).
<p></p>
<p></p>
Path to the ZIP file
Directory to extract files
Unzip the file
List the extracted files
<p></p>
Next,
<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">zipfile</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="n">zip_file_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/Geo/World_EEZ_v12_20231025_gpkg.zip</span><span class="sh">"</span>
<span class="n">extract_to_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/Geo/World_EEZ_v12_20231025_gpkg/</span><span class="sh">"</span>
<span class="k">with</span> <span class="n">zipfile</span><span class="p">.</span><span class="nc">ZipFile</span><span class="p">(</span><span class="n">zip_file_path</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
    <span class="n">zip_ref</span><span class="p">.</span><span class="nf">extractall</span><span class="p">(</span><span class="n">extract_to_path</span><span class="p">)</span>
<span class="n">extracted_files</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">extract_to_path</span><span class="p">)</span></code></pre></figure>

<p></p>
<p></p>
<h5>Data Sources for Country Life Expectancy</h5>
<p></p>
<p></p>
<p></p>
Next, Load the dataset with additional options
Skip the first 4 rows (based on World Bank CSV format)
Ensure the delimiter is a comma
Use the Python engine for parsing flexibility
<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">file_path</span> <span class="o">=</span><span class="sh">'</span><span class="s">/content/drive/My Drive/Geo/API_SP.DYN.LE00.IN_DS2_en_csv_v2_99.csv</span><span class="sh">'</span>
<span class="n">life_expectancy</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span>
    <span class="n">file_path</span><span class="p">,</span>
    <span class="n">skiprows</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>          
    <span class="n">delimiter</span><span class="o">=</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">,</span>       
    <span class="n">engine</span><span class="o">=</span><span class="sh">"</span><span class="s">python</span><span class="sh">"</span>      
<span class="p">)</span></code></pre></figure>

<p></p>
<p></p>
Next, Extract unique country names
Print the total number of countries and their names
<p></p>               

<p></p>
<p></p>
Next,
<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">xxxx</span></code></pre></figure>

<p></p>
<p></p>
Next,
<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">xxxx</span></code></pre></figure>

<p></p>

<p></p>
<p></p>
<h4>Input Data Preparation</h4>
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">xxxx</span></code></pre></figure>

<p></p>
<p></p>
When integrating multiple datasets with potentially different country naming conventions, it's essential to standardize country names systematically. Below are best practices and tools for handling this efficiently. As country indicators, instead of country names we used ISO_A3 code.
<p></p>
<p></p>
<h5>Step by Step</h5>
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">xxxx</span></code></pre></figure>

<p></p>
<p></p>
<h5>Land Neighbors Graph</h5>
<p></p>
To read borders between countries from the shapefile and extract them as connections (edges) in a graph, follow these steps:
Load the Shapefile
Ensure you've loaded the dataset correctly:
<p></p>

Load the shapefile
Inspect the dataset
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">geopandas</span> <span class="k">as</span> <span class="n">gpd</span>
<span class="n">shapefile_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/natural_earth/ne_110m_admin_0_countries.shp</span><span class="sh">"</span>
<span class="n">world</span> <span class="o">=</span> <span class="n">gpd</span><span class="p">.</span><span class="nf">read_file</span><span class="p">(</span><span class="n">shapefile_path</span><span class="p">)</span></code></pre></figure>

<p></p>
<p></p>
<p></p>
<p></p>
Simplify the Dataset
Focus on the necessary columns:

Country Name: Typically NAME, SOVEREIGNT, or similar.
Geometry: Contains polygon data for borders.
Simplify the dataset:
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">world</span> <span class="o">=</span> <span class="n">world</span><span class="p">[[</span><span class="sh">'</span><span class="s">NAME</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">geometry</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">world</span> <span class="o">=</span> <span class="n">world</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">NAME</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">})</span></code></pre></figure>
<p></p>
<p></p>
<p></p>
<p></p>
Identify Neighboring Countries
Use geopandas spatial operations to find countries that share borders:
 Create a dictionary to store country neighbors
Find all countries that touch the current country's borders
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">world</span><span class="p">[</span><span class="sh">'</span><span class="s">geometry</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">world</span><span class="p">[</span><span class="sh">'</span><span class="s">geometry</span><span class="sh">'</span><span class="p">].</span><span class="nf">buffer</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">neighbors</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">country</span> <span class="ow">in</span> <span class="n">world</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
    <span class="n">touching</span> <span class="o">=</span> <span class="n">world</span><span class="p">[</span><span class="n">world</span><span class="p">.</span><span class="n">geometry</span><span class="p">.</span><span class="nf">touches</span><span class="p">(</span><span class="n">country</span><span class="p">.</span><span class="n">geometry</span><span class="p">)][</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
    <span class="n">neighbors</span><span class="p">[</span><span class="n">country</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]]</span> <span class="o">=</span> <span class="n">touching</span></code></pre></figure>

<p></p>
<p></p>
<p></p>
Create the Graph
Convert the neighbors dictionary into a graph using networkx:
<p></p>

Initialize a graph

Add edges (connections between countries)

Inspect the graph
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="k">for</span> <span class="n">country</span><span class="p">,</span> <span class="n">neighbor_list</span> <span class="ow">in</span> <span class="n">neighbors</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="n">neighbor_list</span><span class="p">:</span>
        <span class="n">G</span><span class="p">.</span><span class="nf">add_edge</span><span class="p">(</span><span class="n">country</span><span class="p">,</span> <span class="n">neighbor</span><span class="p">)</span></code></pre></figure>
<p></p>
<p></p>
<p></p>
<h5>Sea Neighbors Graph</h5>
<p></p>
<p></p>

Path to the ZIP file
Directory to extract files
Unzip the file
List the extracted files
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">zipfile</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="n">zip_file_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/Geo/World_EEZ_v12_20231025_gpkg.zip</span><span class="sh">"</span>
<span class="n">extract_to_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/content/drive/My Drive/Geo/World_EEZ_v12_20231025_gpkg/</span><span class="sh">"</span>
<span class="k">with</span> <span class="n">zipfile</span><span class="p">.</span><span class="nc">ZipFile</span><span class="p">(</span><span class="n">zip_file_path</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
    <span class="n">zip_ref</span><span class="p">.</span><span class="nf">extractall</span><span class="p">(</span><span class="n">extract_to_path</span><span class="p">)</span>
<span class="n">extracted_files</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">extract_to_path</span><span class="p">)</span></code></pre></figure>


<p></p>
<p></p>
Ensure Valid Geometry
Some polygons might have invalid geometries, which can cause issues during spatial operations. Fix any invalid geometries using buffer(0):
Confirm the geometries are valid -- # Should return True
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">eez</span><span class="p">[</span><span class="sh">'</span><span class="s">geometry</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">eez</span><span class="p">[</span><span class="sh">'</span><span class="s">geometry</span><span class="sh">'</span><span class="p">].</span><span class="nf">buffer</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span></code></pre></figure>
<p></p>
<p></p>
<p></p>
<p></p>
To find overlapping EEZs (Sea Neighbors), find which countries share overlapping EEZ boundaries using spatial operations:
Loop through each EEZ polygon to find overlaps
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">country_pairs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">country</span> <span class="ow">in</span> <span class="n">eez_sea</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
    <span class="n">overlapping_countries</span> <span class="o">=</span> <span class="n">eez_sea</span><span class="p">[</span><span class="n">eez_sea</span><span class="p">.</span><span class="n">geometry</span><span class="p">.</span><span class="nf">intersects</span><span class="p">(</span><span class="n">country</span><span class="p">.</span><span class="n">geometry</span><span class="p">)][</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
    <span class="n">overlapping_countries</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">overlapping_countries</span> <span class="k">if</span> <span class="n">c</span> <span class="o">!=</span> <span class="n">country</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]]</span>
    <span class="k">for</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="n">overlapping_countries</span><span class="p">:</span>
        <span class="n">pair</span> <span class="o">=</span> <span class="nf">tuple</span><span class="p">(</span><span class="nf">sorted</span><span class="p">([</span><span class="n">country</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">],</span> <span class="n">neighbor</span><span class="p">]))</span>
        <span class="k">if</span> <span class="n">pair</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">country_pairs</span><span class="p">:</span>
            <span class="n">country_pairs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">pair</span><span class="p">)</span></code></pre></figure>

<p></p>
To create the Sea Neighbor Graph, convert the sea_neighbors dictionary into a graph using networkx:
<p></p>

Create the graph
Initialize the graph

 Add edges to the graph
 Print basic graph info
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">sea_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">country_pairs</span><span class="p">:</span>
    <span class="n">sea_graph</span><span class="p">.</span><span class="nf">add_edge</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>  
<span class="n">isolated_nodes</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">nx</span><span class="p">.</span><span class="nf">isolates</span><span class="p">(</span><span class="n">sea_graph</span><span class="p">))</span>
<span class="n">sea_graph</span><span class="p">.</span><span class="nf">remove_nodes_from</span><span class="p">(</span><span class="n">isolated_nodes</span><span class="p">)</span></code></pre></figure>

<p></p>
<p></p>
<p></p>
<h5>Combine Land and Sea Graphs </h5>
<p></p>
<p></p>
<p></p>
Add 'land' attribute to all land borders
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">land_graph</span><span class="p">.</span><span class="n">edges</span><span class="p">:</span>
    <span class="n">land_graph</span><span class="p">[</span><span class="n">u</span><span class="p">][</span><span class="n">v</span><span class="p">][</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">land</span><span class="sh">'</span></code></pre></figure>

<p></p>

<p></p>
Add 'sea' attribute to all sea borders
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">sea_graph</span><span class="p">.</span><span class="n">edges</span><span class="p">:</span>
    <span class="n">sea_graph</span><span class="p">[</span><span class="n">u</span><span class="p">][</span><span class="n">v</span><span class="p">][</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">sea</span><span class="sh">'</span></code></pre></figure>

<p></p>

<p></p>
Combine land and sea graphs
If an edge exists in both graphs, mark it as both land and sea
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">combined_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nf">compose</span><span class="p">(</span><span class="n">land_graph</span><span class="p">,</span> <span class="n">sea_graph</span><span class="p">)</span>
<span class="k">for</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">combined_graph</span><span class="p">.</span><span class="n">edges</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">land_graph</span><span class="p">.</span><span class="nf">has_edge</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">and</span> <span class="n">sea_graph</span><span class="p">.</span><span class="nf">has_edge</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="n">combined_graph</span><span class="p">[</span><span class="n">u</span><span class="p">][</span><span class="n">v</span><span class="p">][</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">both</span><span class="sh">'</span>  <span class="c1"># Mark as both land and sea</span></code></pre></figure>

<p></p>
<p></p>
<p></p>

<h5>World Bank life expectancy dataset </h5>

join it with the both_graph (representing countries as nodes), you can follow these steps

Step 1: Load and Inspect the Data
Load the CSV file to inspect its structure and contents.

<p></p>
<p></p>
Filter and Reshape the Data
Extract the relevant columns and reshape the data into a more usable format.
<p></p>
Keep relevant columns

Melt the dataframe to long format (year as a variable)

Convert year to integer
Drop rows with NaN values
 Preview the reshaped data
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">life_expectancy_filtered</span> <span class="o">=</span> <span class="n">life_expectancy</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">Indicator Name</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Indicator Code</span><span class="sh">"</span><span class="p">])</span>
<span class="n">life_expectancy_long</span> <span class="o">=</span> <span class="n">life_expectancy_filtered</span><span class="p">.</span><span class="nf">melt</span><span class="p">(</span>
    <span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">Country Name</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Country Code</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">var_name</span><span class="o">=</span><span class="sh">"</span><span class="s">Year</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">value_name</span><span class="o">=</span><span class="sh">"</span><span class="s">Life Expectancy</span><span class="sh">"</span>
<span class="p">)</span>
<span class="n">life_expectancy_long</span><span class="p">[</span><span class="sh">"</span><span class="s">Year</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_numeric</span><span class="p">(</span><span class="n">life_expectancy_long</span><span class="p">[</span><span class="sh">"</span><span class="s">Year</span><span class="sh">"</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="sh">"</span><span class="s">coerce</span><span class="sh">"</span><span class="p">)</span>
<span class="n">life_expectancy_long</span> <span class="o">=</span> <span class="n">life_expectancy_long</span><span class="p">.</span><span class="nf">dropna</span><span class="p">()</span></code></pre></figure>


<p></p>
To join the life expectancy data with the graph, map the Country Code or Country Name from the dataset to the nodes in your graph.
Get a list of nodes in the graph
Check if the graph uses country names or codes
Example: If the graph uses country names
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="n">mapped_data</span> <span class="o">=</span> <span class="n">life_expectancy_long</span><span class="p">[</span><span class="n">life_expectancy_long</span><span class="p">[</span><span class="sh">"</span><span class="s">Country Name</span><span class="sh">"</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">nodes</span><span class="p">)]</span></code></pre></figure>

<p></p>
<p></p>
<p></p>
<p></p>
Group life expectancy data by country for easy access

Add life expectancy as node features

Check a sample node's data
For missing data, assign an empty dictionary
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">life_expectancy_dict</span> <span class="o">=</span> <span class="n">life_expectancy_long</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">"</span><span class="s">Country Name</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">df</span><span class="p">:</span> <span class="n">df</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="sh">"</span><span class="s">Year</span><span class="sh">"</span><span class="p">)[</span><span class="sh">"</span><span class="s">Life Expectancy</span><span class="sh">"</span><span class="p">].</span><span class="nf">to_dict</span><span class="p">())</span> \
    <span class="p">.</span><span class="nf">to_dict</span><span class="p">()</span>
<span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">both_graph</span><span class="p">.</span><span class="n">nodes</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">life_expectancy_dict</span><span class="p">:</span>
        <span class="n">nx</span><span class="p">.</span><span class="nf">set_node_attributes</span><span class="p">(</span><span class="n">both_graph</span><span class="p">,</span> <span class="p">{</span><span class="n">node</span><span class="p">:</span> <span class="n">life_expectancy_dict</span><span class="p">[</span><span class="n">node</span><span class="p">]},</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">life_expectancy</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">nx</span><span class="p">.</span><span class="nf">set_node_attributes</span><span class="p">(</span><span class="n">both_graph</span><span class="p">,</span> <span class="p">{</span><span class="n">node</span><span class="p">:</span> <span class="p">{}},</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">life_expectancy</span><span class="sh">"</span><span class="p">)</span></code></pre></figure>


<p></p>
<p></p>

<h4>Model Training</h4>
    <p>The model training phase
<p></p>


    <p></p>               



<p></p>

    <p></p>
<h4>Rewiring Knowledge Graph</h4>



    <p></p>

<p></p>  

<p></p>               


    <p></p>
Next,
    <p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">xxxx</span></code></pre></figure>

    <p></p>


<p></p>

<p></p>






<p></p>








    <h3>In Conclusion</h3>
<p></p>
    In this study,
<p></p>
    Our work
<p></p>
    This research marks
<p></p>    

<p></p>
One of the challenges with using GNN for knowledge graph is that knowledge graphs consist of variety of different data domains and different formats of data values. In this study we introduce a method to deal with these challenges.  
<p></p>
We start with domain specific subgraphs and run GNN link prediction models on each subgraphs. The output of these models will be vectors of the same size.



<p></p>
We also can combine across domains different entities if connections exist in initial knowledge graph. For example, in one domain has artists as nodes, another domain paintings,  and another domain art museums than we can connect artists with paintings and pinting with museums that have that paintings.
<p></p>
<p></p>

<p></p>
<p></p>
</p></p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[Introduction Graphs are everywhere in our lives. They represent molecules in chemistry, roads in navigation, and even our social networks like Facebook, a molecule graph, a city map, a social network graph.]]></summary></entry><entry><title type="html">Graph Neural Networks for EEG Connectivity Analysis</title><link href="http://localhost:4000/2024/11/09/GNN_timeSeries_EEG/" rel="alternate" type="text/html" title="Graph Neural Networks for EEG Connectivity Analysis" /><published>2024-11-09T07:00:00-05:00</published><updated>2024-11-09T07:00:00-05:00</updated><id>http://localhost:4000/2024/11/09/GNN_timeSeries_EEG</id><content type="html" xml:base="http://localhost:4000/2024/11/09/GNN_timeSeries_EEG/"><![CDATA[<h3>Introduction</h3>

<p>
    Electroencephalography (EEG) is a widely used non-invasive neuroimaging technique that captures electrical activity in the brain. By recording voltage fluctuations across the scalp, EEG enables researchers to monitor real-time brain activity, providing insights into cognitive processes, mental states, and neurological disorders. It is a valuable tool for understanding how different brain regions coordinate to support functions such as attention, memory, and motor control, making EEG essential for studying neural connectivity.
</p>

<p>
    Traditional methods for analyzing EEG data, such as feature extraction, spectral analysis, and machine learning models like Support Vector Machines (SVM) or Convolutional Neural Networks (CNN), often process channels independently or in predefined groups. While these approaches have achieved moderate success, they struggle to fully model the complex, non-linear spatial and temporal dependencies present in EEG signals. This limitation often results in the loss of crucial information about brain network dynamics.
</p>

<p>
    The graph-like nature of EEG data, where electrode positions can be represented as nodes and interactions as edges, has led to the adoption of Graph Neural Networks (GNNs) for more advanced analysis. GNNs capture the intricate spatial relationships and temporal dependencies in EEG signals, offering a powerful framework for understanding neural dynamics. This capability makes GNNs highly effective for applications such as cognitive state monitoring, emotion recognition, and neurological disorder diagnosis. Recent studies have demonstrated that GNN-based models can provide deeper insights into brain activity compared to traditional methods by revealing subtle connectivity patterns.
</p>

<h4>Current Study Overview</h4>

<p>
    This study utilizes the publicly available <em>EEG-Alcohol</em> dataset from Kaggle, which includes EEG recordings from subjects exposed to visual stimuli. Trials involved either a single picture stimulus or two picture stimuli, with the latter being either matched (identical) or non-matched (different). This dataset serves as a basis for exploring the impact of alcohol on brain connectivity and cognitive processing.
</p>

<h4>Building on Prior Work</h4>
<p>
    Our previous studies analyzed this dataset using different methodologies:
</p>
<ul>
    <li>
        <i>Study 1:</i> Used CNNs and time series analysis to classify EEG signals, showing higher accuracy with Gramian Angular Field (GAF) transformations but limited success in distinguishing Alcoholic and Control groups for single-stimulus trials.
    </li>
    <p></p>
    <a href="#">
        <img src="/img/dataSource5.jpg" alt="Figure 1: Connectivity Patterns from Previous Study" width="404" />
    </a>
    <p></p>
    <p>
        This figure from our previous study shows how connectivity patterns were analyzed using traditional graph mining, revealing stronger and weaker similarities between EEG positions. We found that single-image trials were not effective for distinguishing Alcoholic and Control groups. In this study, we extend these findings by using GNN Link Prediction models.
    </p>

    <li>
        <i>Study 2:</i> Employed GNN Graph Classification models, representing each trial as a graph with EEG channels as nodes. While this approach improved classification accuracy, it struggled with single-stimulus trials and highlighted the need for more detailed connectivity analysis.
    </li>
</ul>

<p>
    Building on these findings, this study introduces a unified graph structure where edges represent spatial relationships between EEG channels. This new framework provides a consistent basis for analyzing brain-trial combinations at a granular level, capturing both spatial and temporal dependencies in EEG data.
</p>

<h4>Significance of the Unified Graph Approach</h4>
<p>
    In contrast to earlier studies that created separate graphs for each trial, this approach integrates all EEG signals into a unified graph structure. Nodes represent EEG channels, while edges reflect spatial proximity, ensuring consistency across analyses. Each trial contributes to a subgraph within the unified structure, capturing both local and global dependencies. The unified graph serves as input for the GNN Link Prediction model, enabling us to detect subtle variations in connectivity across experimental conditions.
</p>

<p>
    By transforming EEG signals into high-dimensional embeddings, this method provides a deeper exploration of spatial and temporal relationships, revealing interactions that conventional techniques could not capture. The study contributes to the growing field of AI-driven neuroscience by offering a versatile framework for analyzing EEG connectivity patterns and improving our understanding of neural dynamics.
</p>

<h3>Methods</h3>

<h4>EEG Channel Position Mapping and Graph Construction</h4>

<p>
    This section outlines the process of mapping EEG channel positions in 3D space and constructing an initial graph to capture spatial relationships between the electrodes. The goal was to create a graph where nodes represent EEG channels, and edges reflect their spatial proximity, forming the foundation for subsequent analysis.
</p>

<h5>EEG Channel Position Extraction</h5>
<ul>
    <li>We loaded the standard EEG montage (<code>'standard_1005'</code>) using the <strong>mne</strong> library.</li>
    <li>Channel positions were retrieved as (x, y, z) coordinates, representing each EEG channel in 3D space.</li>
    <li>Pairwise Euclidean distances between channels were calculated using <b>scipy.spatial.distance</b>, capturing the spatial proximity between electrodes.</li>
</ul>

<h5>Distance Matrix Construction</h5>
<ul>
    <li>The computed distances were used to create a distance matrix that encapsulates the spatial relationships between EEG channels.</li>
    <li>This matrix was formatted into a structured dataset, making it suitable for graph-based modeling.</li>
</ul>

<h5>Minimum Distance Filtering and Graph Creation</h5>
<ul>
    <li>To ensure no channel was isolated, we identified the shortest distance for each channel.</li>
    <li>A distance threshold was applied, defined as the maximum of these minimum distances, to retain only the closest pairs of channels.</li>
    <li>The final graph was constructed with nodes representing EEG channels and edges indicating spatial proximity, ensuring the graph was fully connected for analysis.</li>
</ul>

<h5>Initial EEG Graph Construction</h5>
<ul>
    <li>We built an initial graph representing the spatial configuration of the EEG channels.</li>
    <li>In this graph:
        <ul>
            <li><i>Nodes:</i> Represent EEG channels.</li>
            <li><i>Edges:</i> Represent spatial proximity between channels.</li>
        </ul>
    </li>
    <li>Time-series EEG signals for each channel were incorporated as node features, capturing both spatial and temporal dependencies within the EEG data.</li>
</ul>

<p>
    Figure 2: An overview of the EEG graph analysis pipeline. The initial graph (left) is built using spatial and temporal EEG data. The GNN Link Prediction model (center) processes the graph to learn node connections, generating embedded vectors (right) that capture complex relationships within the EEG signals for further analysis.
</p>
<p></p>
<p><a href="#">
    <img src="/img/pipeline2.jpg" alt="EEG Graph Analysis Pipeline" width="888" />
</a></p>
<p></p>

<p></p>
<h3>Experiments </h3>

<p></p>
<p>Using the EEG-Alcohol dataset from Kaggle, we preprocessed data from 61 EEG channels across multiple trials. The GNN model trained on this graph data demonstrated high accuracy, achieving an 81.45% AUC in distinguishing connectivity patterns between control and alcohol groups. Key differences emerged between experimental conditions, with the control group displaying stronger connectivity in visual processing areas compared to the alcohol group​</p>
<p></p>

<h4>Data Source</h4>

<p>In our study on brain connectivity, we used the publicly available <a href="https://www.kaggle.com/datasets/nnair25/Alcoholics">EEG-Alcohol dataset</a> from Kaggle (Kaggle.com, EEG-Alcohol Data Set, 2017). This dataset contains EEG recordings collected to explore how genetic predisposition to alcoholism might affect neural responses. Each participant was exposed to visual stimuli, either as a single image or two consecutive images. In trials with two images, the stimuli could either be identical (matched) or different (non-matched). The images used were selected from the well-known Snodgrass and Vanderwart picture set, created in 1980, which is commonly used in psychological studies.</p>

<p>The dataset includes EEG data from 8 participants in each group—those with and without alcohol exposure. EEG activity was recorded using 64 electrodes placed across the scalp, capturing brain signals at a high sampling rate of 256 Hz over short, 1-second trials. Due to quality issues in some channels, we focused on data from 61 out of the 64 electrodes, resulting in a total of 61 person-trial pairs included in our analysis.</p>

<p>Our data preparation approach was partly inspired by <a href="https://www.kaggle.com/code/ruslankl/eeg-data-analysis">Ruslan Klymentiev's Kaggle notebook</a> on EEG Data Analysis, which provided a foundation for processing the raw EEG data into a structured format. Building on Klymentiev’s work, we implemented additional transformations to convert these EEG recordings into a structured time series format for each electrode, making the data suitable for graph-based modeling.</p>

<p>To organize the raw sensor data, we categorized it by sensor position and trial number, then created a structured dataset where each row represents a single time point, and each column shows the sensor value from a specific EEG channel at that moment. This transformation was essential for enabling our subsequent graph-based analysis, laying the groundwork for understanding connectivity patterns in the brain. For a more detailed look at our data transformation process, check out our related blog post.</p>

<p>This preprocessing step was crucial as it prepared the dataset for our deeper analysis, allowing us to model brain connectivity patterns effectively. Through this structured data, we could dive into the fascinating world of neural dynamics and uncover insights into how alcohol exposure might influence brain connectivity.</p>

<h4>Prepare Input Data for GNN Link Prediction Model</h4>
<p>
The initial graph structure was created by calculating pairwise Euclidean distances between EEG channels, as outlined in the EEG Channel Position Mapping and Graph Construction subsection of the Methods section. These distances capture the spatial relationships between electrodes based on their physical positions on the scalp. The maximum of the minimum distances between EEG channels was calculated to be 0.038, and to prevent isolated nodes, a slightly higher threshold of 0.04 was used to filter and retain the closest channel pairs. This process resulted in a consistent graph structure with 61 nodes and 108 edges, representing the spatial layout of EEG channels across all subjects and trials. This shared graph provides a uniform topology for all subsequent subject-trial graphs, facilitating comparative analysis.
</p>
<p>
After establishing the graph structure, we defined graph nodes and their features for each subject-trial combination. Each node corresponds to one of the 61 EEG channels, while node features are derived from the time series signals recorded at these positions during the trials. The data was grouped by type (Alcohol and Control), subject, trial, and channel position, forming structured datasets that capture both spatial and temporal characteristics of the EEG signals. While the spatial configuration of the graph remains constant, node features vary based on each subject and trial, enabling the GNN Link Prediction model to detect connectivity patterns specific to different experimental conditions. For further details on the data preparation process, refer to our related blog post [18].

</p>

<h4>Data Preparation: Building the Initial Graph Structure</h4>

<p>To analyze EEG connectivity patterns effectively, we constructed an initial graph structure that represents the spatial relationships between EEG channels. This process involved calculating pairwise Euclidean distances based on the physical positions of electrodes on the scalp. Using these distances, we created a graph where nodes correspond to EEG channels and edges represent spatial proximity. To ensure no isolated nodes, a distance threshold was set slightly above the maximum of the minimum distances between channels, calculated to be <code>0.038</code>. A threshold of <code>0.04</code> was applied to retain the closest channel pairs, resulting in a connected graph with 61 nodes.</p>

<p>The following Python code demonstrates the steps to build the graph structure, including calculating distances and filtering edges based on the threshold:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">mne</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">pdist</span><span class="p">,</span> <span class="n">squareform</span>

<span class="c1"># Load EEG channel positions using MNE's standard montage
</span>
<span class="n">montage</span> <span class="o">=</span> <span class="n">mne</span><span class="p">.</span><span class="n">channels</span><span class="p">.</span><span class="nf">make_standard_montage</span><span class="p">(</span><span class="sh">'</span><span class="s">standard_1005</span><span class="sh">'</span><span class="p">)</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">montage</span><span class="p">.</span><span class="nf">get_positions</span><span class="p">()[</span><span class="sh">'</span><span class="s">ch_pos</span><span class="sh">'</span><span class="p">]</span>
<span class="n">uppercase_pos</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">.</span><span class="nf">upper</span><span class="p">():</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">pos</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>

<span class="c1"># Filter positions to retain only the relevant EEG channels
</span>
<span class="n">filtered_positions</span> <span class="o">=</span> <span class="p">[</span><span class="n">ch</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">positions</span> <span class="k">if</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">uppercase_pos</span><span class="p">]</span>

<span class="nf">len</span><span class="p">(</span><span class="n">filtered_positions</span><span class="p">)</span>
<span class="mi">61</span></code></pre></figure>

<p></p>

<p>The coordinates of the EEG channels were extracted, and a pairwise distance matrix was calculated:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Extract coordinates for the filtered EEG channels
</span>
<span class="n">coordinates</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">uppercase_pos</span><span class="p">[</span><span class="n">ch</span><span class="p">]</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">filtered_positions</span><span class="p">])</span>
<span class="n">distance_matrix</span> <span class="o">=</span> <span class="nf">squareform</span><span class="p">(</span><span class="nf">pdist</span><span class="p">(</span><span class="n">coordinates</span><span class="p">))</span>

<span class="c1"># Calculate pairwise distances and store them in a list
</span>
<span class="n">distance_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">pos1</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">filtered_positions</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">pos2</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">filtered_positions</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">:</span>  
            <span class="n">distance</span> <span class="o">=</span> <span class="n">distance_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">distance_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">pos1</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">pos2</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">distance</span><span class="si">:</span><span class="p">.</span><span class="mi">6</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="nf">len</span><span class="p">(</span><span class="n">distance_list</span><span class="p">)</span>
<span class="mi">3660</span></code></pre></figure>

<p></p>

<p>To organize the distances, a DataFrame was created, and the minimum distance for each EEG channel was identified:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># Split distance data into a structured DataFrame
</span>
<span class="n">split_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">distance_list</span><span class="p">]</span>
<span class="n">distance_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">split_data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">left</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">right</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">distance</span><span class="sh">"</span><span class="p">])</span>
<span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

<span class="n">distance_df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
<span class="c1"># Example output
# left    right    distance
# AF1     AF2      0.038294
# AF1     AF7      0.057702
# AF1     AF8      0.086636
# AF1     AFZ      0.018912
# AF1     C1       0.107897
</span>
<span class="c1"># Calculate the maximum of the minimum distances
</span>
<span class="n">min_distances</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">position</span> <span class="ow">in</span> <span class="nf">set</span><span class="p">(</span><span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">]).</span><span class="nf">union</span><span class="p">(</span><span class="nf">set</span><span class="p">(</span><span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">])):</span>
    <span class="n">filtered_df</span> <span class="o">=</span> <span class="n">distance_df</span><span class="p">[(</span><span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">position</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">position</span><span class="p">)]</span>
    <span class="n">min_distance</span> <span class="o">=</span> <span class="n">filtered_df</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span>
    <span class="n">min_distances</span><span class="p">[</span><span class="n">position</span><span class="p">]</span> <span class="o">=</span> <span class="n">min_distance</span>

<span class="n">max_of_min_distances</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">min_distances</span><span class="p">.</span><span class="nf">values</span><span class="p">())</span>

<span class="n">max_of_min_distances</span>
<span class="mf">0.038043</span></code></pre></figure>

<p></p>

<p>Using the calculated maximum of the minimum distances (<code>0.038043</code>), we applied a slightly higher threshold (<code>0.04</code>) to retain only the closest channel pairs. This ensured that the graph remained fully connected, providing a robust structure for subsequent analysis.</p>

<p><a href="#">
    <img src="/img/distanceEEG.jpg" alt="Post Sample Image" width="567" />
</a></p>
<p></p>

<p>This data preparation step was critical for constructing a meaningful graph structure that captures the spatial relationships between EEG channels. By incorporating both node positions and proximity-based edge definitions, this graph provides a solid foundation for analyzing connectivity patterns using Graph Neural Networks.</p>

<p>The distribution of distances between electrode positions was analyzed to verify the spatial relationships used for graph construction. Below is a histogram illustrating the distance distribution:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Distribution of Distances Between Electrode Positions</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Distance</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Frequency</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Print basic statistics
</span>
<span class="nf">print</span><span class="p">(</span><span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">].</span><span class="nf">describe</span><span class="p">())</span></code></pre></figure>

<p></p>

<p>Basic statistics of the distances:</p>
<ul>
    <li><i>Count:</i> 3660</li>
    <li><i>Mean:</i> 0.119815</li>
    <li><i>Standard Deviation:</i> 0.045156</li>
    <li><i>Min:</i> 0.018912</li>
    <li><i>Max:</i> 0.206672</li>
</ul>

<p>Filtered edges below the threshold distance (<code>0.04</code>) were selected to ensure a fully connected graph. The following code demonstrates the construction of the graph:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>

<span class="c1"># Filter pairs below the threshold
</span>
<span class="n">filtered_pairs</span> <span class="o">=</span> <span class="n">distance_df</span><span class="p">[</span><span class="n">distance_df</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.04</span><span class="p">]</span>

<span class="c1"># Create the graph and add edges with weights
</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">filtered_pairs</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
    <span class="n">G</span><span class="p">.</span><span class="nf">add_edge</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">],</span> <span class="n">weight</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">])</span>

<span class="c1"># Visualize the graph
</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nf">kamada_kawai_layout</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">nx</span><span class="p">.</span><span class="nf">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="sh">'</span><span class="s">white</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure>

<p></p>

<p><a href="#">
    <img src="/img/eegLandscape.jpg" alt="Post Sample Image" width="404" />
</a></p>
<p></p>

<p>The resulting graph represents the spatial relationships between EEG electrodes, as shown in the visualization above. This consistent graph topology is used for all subsequent analyses, with the node features varying based on subject-trial combinations. This approach enables the model to explore dynamic connectivity patterns, providing insights into brain network interactions under different conditions.</p>

<p>For further details on the data preparation and modeling process, refer to our related <a href="#">blog post</a>.</p>

<h4>Pre-Training Data Preparation for EEG Graph Neural Network</h4>

<p>Following the construction of the initial graph with 61 nodes and 108 edges based on spatial distances between EEG channels, we defined node features for each subject-trial combination. This graph structure provided a uniform topology, enabling the detection of connectivity patterns that varied across different experimental conditions, such as Alcohol and Control groups.</p>

<p>Each node in the graph represents one of the 61 EEG channels, with node features derived from the time series signals recorded during trials. By grouping the data by type (Alcohol and Control), subject, trial, and channel position, we captured both spatial and temporal aspects of the EEG signals. While the graph's spatial configuration remains constant, node features vary across subject-trial combinations, allowing the Graph Neural Network (GNN) Link Prediction model to identify connectivity patterns specific to different conditions.</p>

<p>We started by creating a DataFrame of edges that represents the connections between nodes (EEG channels). This involved combining metadata and filtering edges based on group matching. Here’s the code for constructing the edges:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>

<span class="c1"># Create an edges DataFrame from the graph's edges
</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">G</span><span class="p">.</span><span class="n">edges</span><span class="p">)</span>
<span class="n">edges</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Separate feature and metadata columns
</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">rawData</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">6</span><span class="p">:</span><span class="mi">262</span><span class="p">]</span>
<span class="n">metavalues1</span> <span class="o">=</span> <span class="n">rawData</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">6</span><span class="p">]</span>
<span class="n">metavalues2</span> <span class="o">=</span> <span class="n">rawData</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">262</span><span class="p">:]</span>
<span class="n">metavalues</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">metavalues1</span><span class="p">,</span> <span class="n">metavalues2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Drop unnecessary metadata columns and merge with edges
</span>
<span class="n">metaData</span> <span class="o">=</span> <span class="n">metavalues</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">'</span><span class="s">trial</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">match</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">channel</span><span class="sh">'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">edges_left</span> <span class="o">=</span> <span class="n">metaData</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">left_on</span><span class="o">=</span><span class="sh">'</span><span class="s">positionIdx</span><span class="sh">'</span><span class="p">,</span> <span class="n">right_on</span><span class="o">=</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">).</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">edges_left</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">left_index</span><span class="sh">'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">edges_right</span> <span class="o">=</span> <span class="n">edges_left</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">metaData</span><span class="p">,</span> <span class="n">left_on</span><span class="o">=</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">,</span>
   <span class="n">right_on</span><span class="o">=</span><span class="sh">'</span><span class="s">positionIdx</span><span class="sh">'</span><span class="p">).</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">edges_right</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">right_index</span><span class="sh">'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Filter edges by group matching and reset index
</span>
<span class="n">filtered_edges</span> <span class="o">=</span> <span class="n">edges_right</span><span class="p">[</span><span class="n">edges_right</span><span class="p">[</span><span class="sh">'</span><span class="s">group_x</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">edges_right</span><span class="p">[</span><span class="sh">'</span><span class="s">group_y</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">edges_final</span> <span class="o">=</span> <span class="n">filtered_edges</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">'</span><span class="s">group_y</span><span class="sh">'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">edges_final</span><span class="p">[</span><span class="sh">'</span><span class="s">index_final</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">edges_final</span><span class="p">.</span><span class="n">index</span>  <span class="c1"># Add final index as a column
</span>
<span class="c1"># Create the final NetworkX graph from the processed edges DataFrame
</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nf">from_pandas_edgelist</span><span class="p">(</span><span class="n">edges_final</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="sh">'</span><span class="s">left_index</span><span class="sh">'</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="sh">'</span><span class="s">right_index</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>

<p></p>

<p>After defining the edges and nodes, we used the Deep Graph Library (DGL) to convert the NetworkX graph into a DGL graph. We then added the node features (time series signals) as tensors, which the model will use to analyze connectivity patterns. Here’s the code for preparing the DGL graph and adding features:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">dgl</span>
<span class="kn">import</span> <span class="n">torch</span>

<span class="c1"># Convert NetworkX graph to DGL graph
</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">from_networkx</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>

<span class="c1"># Convert EEG time series data to a tensor and add it as node features
</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">rawData</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">6</span><span class="p">:</span><span class="mi">262</span><span class="p">]</span>
<span class="n">features_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">values</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">features_tensor</span>

<span class="c1"># Display the graph summary
</span>
<span class="n">g</span>
<span class="nc">Graph</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">3721</span><span class="p">,</span> <span class="n">num_edges</span><span class="o">=</span><span class="mi">13176</span><span class="p">,</span>
      <span class="n">ndata_schemes</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">:</span> <span class="nc">Scheme</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)}</span>
      <span class="n">edata_schemes</span><span class="o">=</span><span class="p">{})</span></code></pre></figure>

<p></p>

<p>This data preparation stage established a robust graph-based representation of EEG data, where each node (EEG channel) has unique features based on time series signals across trials. The resulting graph, with 3721 nodes and 13176 edges, serves as input to the GNN model, allowing it to explore complex connectivity patterns across experimental conditions. This setup lays the groundwork for effective pre-training and connectivity analysis.</p>

<p>For more information on the data preparation process and detailed GNN modeling steps, refer to our related <a href="#">blog post</a>.</p>

<h4>Train the Model</h4>

<p>We utilized the GraphSAGE link prediction model, implemented with the Deep Graph Library (DGL), to train our model on the EEG graph data. GraphSAGE employs two layers to aggregate information from neighboring nodes, enabling the model to capture complex connectivity patterns and interactions between EEG channels.</p>

<ul>
    <li><i>Total Nodes:</i> 3,721</li>
    <li><i>Total Edges:</i> 13,176</li>
    <li><i>Node Feature Size:</i> 256</li>
</ul>

<p>The model’s performance was evaluated using the Area Under the Curve (AUC) metric, achieving an accuracy of <strong>81.45%</strong>. This high AUC score demonstrates the model’s effectiveness in predicting connectivity patterns and capturing the underlying signal dependencies within the EEG data.</p>

<p>We implemented our model using code from the tutorial "<a href="https://www.dgl.ai">Deep Graph Library (DGL): Link Prediction Using Graph Neural Networks</a>," published in 2018. This resource provided a foundational framework for building and optimizing our GraphSAGE-based link prediction model.</p>

<h4>EEG Connectivity Analysis: GNN Link Prediction and Statistical Calculations</h4>

<p>
    The foundation of our connectivity analysis stems from the results of a Graph Neural Network (GNN) link prediction model. This model generates a matrix, <code>h</code>, where each row represents an embedded vector corresponding to a graph node. In our context, these nodes represent EEG channels, and the embedded vectors capture the spatial and temporal relationships between signals from different brain regions.
</p>
<p>
    These embeddings provide a powerful, compressed representation of connectivity patterns, allowing us to measure the relationships between nodes through cosine similarity.
</p>

<p>
    To evaluate the strength of connections between EEG nodes, we calculated pairwise cosine similarity scores between their embedded vectors. Cosine similarity measures the cosine of the angle between two vectors, producing a value between -1 (completely opposite) and 1 (completely identical).
</p>
<p>Below is the PyTorch-based implementation for calculating cosine similarity:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>

<span class="c1"># Define a function to calculate cosine similarity using PyTorch
</span>
<span class="k">def</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>

<span class="c1"># Ensure inputs are PyTorch tensors
</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

<span class="c1"># Adjust dimensions for single-row tensors
</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Normalize the vectors
</span>
    <span class="n">a_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Compute cosine similarity
</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">a_norm</span><span class="p">,</span> <span class="n">b_norm</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>

<span class="c1"># Example usage: compute cosine similarity for matrix `h`
</span>
<span class="n">cosine_scores</span> <span class="o">=</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span></code></pre></figure>

<p></p>

<h5>Statistical Analysis Using Self-Join Cosine Similarity</h5>
<p>
    Once the cosine similarity matrix (<code>cosine_scores</code>) is computed, we perform statistical calculations by grouping the data and applying self-join operations. This allows us to analyze the pairwise connectivity patterns within specific experimental groups (e.g., Alcohol and Control) and conditions (e.g., Single Stimulus, Two Stimuli).
</p>
<p>The self-join operation systematically computes pairwise statistics within each group, focusing on unique connections between EEG channels. Below is the implementation:</p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">group_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Iterate over each unique group in the 'group' column
</span>
<span class="k">for</span> <span class="n">group_idx</span> <span class="ow">in</span> <span class="n">metaRawData</span><span class="p">[</span><span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">].</span><span class="nf">unique</span><span class="p">():</span>

<span class="c1"># Filter rows that belong to the current group
</span>
    <span class="n">group_data</span> <span class="o">=</span> <span class="n">metaRawData</span><span class="p">[</span><span class="n">metaRawData</span><span class="p">[</span><span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">group_idx</span><span class="p">]</span>

<span class="c1"># Extract `type`, `match`, and `name` for the group (assuming they are the same for the group)
</span>
    <span class="n">group_type</span> <span class="o">=</span> <span class="n">group_data</span><span class="p">[</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">group_match</span> <span class="o">=</span> <span class="n">group_data</span><span class="p">[</span><span class="sh">'</span><span class="s">match</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">group_name</span> <span class="o">=</span> <span class="n">group_data</span><span class="p">[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Get the indices of the rows for the current group
</span>
    <span class="n">group_indices</span> <span class="o">=</span> <span class="n">group_data</span><span class="p">.</span><span class="n">index</span>

<span class="c1"># Calculate self-join cosine similarity within the group
</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row_i</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">group_indices</span><span class="p">):</span>
        <span class="n">position_i</span> <span class="o">=</span> <span class="n">metaRawData</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">row_i</span><span class="p">,</span> <span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">]</span>

<span class="c1"># Start from the next index to avoid duplicate pairs (i, j) and (j, i)
</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">row_j</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">group_indices</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:],</span> <span class="n">start</span><span class="o">=</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">position_j</span> <span class="o">=</span> <span class="n">metaRawData</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">row_j</span><span class="p">,</span> <span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">]</span>

<span class="c1"># Retrieve cosine similarity score from cosine_scores array
</span>
            <span class="n">cos</span> <span class="o">=</span> <span class="n">cosine_scores</span><span class="p">[</span><span class="n">row_i</span><span class="p">][</span><span class="n">row_j</span><span class="p">].</span><span class="nf">item</span><span class="p">()</span>

<span class="c1"># Append the results to the list
</span>
            <span class="n">group_scores</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span>
                <span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">:</span> <span class="n">group_idx</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">:</span> <span class="n">group_type</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">match</span><span class="sh">'</span><span class="p">:</span> <span class="n">group_match</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">:</span> <span class="n">group_name</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">position_i</span><span class="sh">'</span><span class="p">:</span> <span class="n">position_i</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">position_j</span><span class="sh">'</span><span class="p">:</span> <span class="n">position_j</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">left_idx</span><span class="sh">'</span><span class="p">:</span> <span class="n">row_i</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">right_index</span><span class="sh">'</span><span class="p">:</span> <span class="n">row_j</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">cosine_similarity</span><span class="sh">'</span><span class="p">:</span> <span class="n">cos</span>
            <span class="p">})</span></code></pre></figure>

<p></p>

<p>
    The result of this process is a structured dataset where each row represents a unique connection between two EEG channels, along with the computed cosine similarity and group-level metadata. An example entry might look like this:
</p>
<pre>
<code>
{
    "group": "Alcohol",
    "type": "Experimental",
    "match": "Two Stimuli - Matched",
    "name": "Subject 1",
    "position_i": "Cz",
    "position_j": "Pz",
    "left_idx": 5,
    "right_index": 10,
    "cosine_similarity": 0.76
}
</code>
</pre>

<p>Key Insights and Applications</p>
<ul>
    <li>Condition-Wise Connectivity Analysis: Aggregating cosine similarity scores allows us to compare connectivity strength between experimental groups (e.g., Alcohol vs. Control) under various conditions (e.g., Single Stimulus, Two Stimuli).</li>

    <li>Node-Level Connectivity Patterns: The <code>position_i</code> and <code>position_j</code> fields enable spatial mapping of connectivity patterns across the brain.</li>

    <li>Group Comparisons: By grouping the results, we can identify statistically significant differences in connectivity patterns between conditions.</li>
</ul>

<p>
    The combination of GNN embeddings, cosine similarity, and statistical grouping enables a robust and scalable approach to analyzing EEG connectivity. By leveraging self-join matrices, we quantify pairwise relationships between EEG channels, uncovering patterns that provide valuable insights into the neural effects of experimental conditions such as alcohol exposure.
</p>

<h3>Interpreting Model Results</h3>

<h4>Condition-wise Analysis of Cosine Similarities</h4>

<p>To compare connectivity patterns between the Alcohol and Control groups, we computed the average cosine similarities from the embedded vectors generated by the model. These cosine similarities represent the strength of connectivity between brain regions, with higher values indicating stronger connections. The computed values were aggregated by condition type and match status to assess differences across the experimental groups.</p>

<p>As shown in Table 1, the <strong>‘Single stimulus’</strong> condition revealed minimal differences between the Alcohol and Control groups. This finding aligns with results from our previous studies [2, 3]. Since the <strong>‘Single stimulus’</strong> condition did not show significant variation in connectivity patterns, it was excluded from further analysis.</p>

<p>We instead focused on the <strong>‘Two stimuli - matched’</strong> and <strong>‘Two stimuli - non-matched’</strong> conditions, where clearer distinctions between the groups were observed:</p>

<ul>
    <li><i>Alcohol group:</i> Average cosine similarity of 0.546.</li>
    <li><i>Control group:</i> Average cosine similarity of 0.645.</li>
</ul>

<p>The higher average cosine similarity in the Control group suggests stronger overall connectivity compared to the Alcohol group. This finding may reflect differences in the efficiency or robustness of neural communication between the two groups. These variations could be indicative of the impact of alcohol on brain connectivity.</p>

<p>In the following sections, we will delve deeper into these patterns at the node level, highlighting specific regions of the brain with both high and low signal correlations between the groups.</p>

<p>This table shows average cosine similarities by condition and group:</p>
<p></p>
<p><a href="#">
    <img src="/img/eegTable1.jpg" alt="Post Sample Image" width="471" />
</a></p>
<p></p>

<h4>Strongly Connected Positions</h4>

<p>
    Our analysis utilized a GNN Link Prediction model to explore the EEG connectivity patterns in both the Alcohol and Control groups. This model was specifically designed to capture the intricate spatial relationships and temporal dependencies present in EEG data. By analyzing connectivity patterns at a granular level, the GNN Link Prediction model provided critical insights into how different brain regions interact under various experimental conditions.
</p>

<p>
    The GNN Link Prediction model generated embedded vectors, which were used to calculate edge weights based on the initial graph structure. Node-level cosine similarities were then computed by combining left and right node positions, grouping them by type and position, and averaging the values to evaluate overall connectivity strength.
</p>

<p>
    Tables 2 and 3 highlight the top highly connected node pairs and nodes, respectively. In the Control group, the strongest connections are concentrated in the occipital and parietal regions. These regions play a vital role in visual processing and sensory integration, showcasing a stable and efficient brain network organization. The occipital region's dominance in the Control group suggests healthy neural patterns without significant disruptions. This enables consistent and efficient communication within the brain, particularly in areas essential for interpreting visual input.
</p>

<p>
    On the other hand, the Alcohol group displays more disruptions, characterized by lower overall connectivity values. Although connections are observed in the parietal and occipital regions, they are weaker compared to the Control group. This indicates a less organized and consistent brain network in the Alcohol group, likely reflecting the effects of alcohol on neural connectivity. Interestingly, the parietal region's dominance in the Alcohol group might suggest a compensatory mechanism, where the brain attempts to enhance connectivity in regions responsible for sensory processing and spatial awareness to counterbalance alcohol-induced disruptions.
</p>

<p>
    Table 2 highlights the top connected node pairs based on cosine similarity for the Alcohol and Control groups. The analysis reveals that the Alcohol group exhibits strong connectivity in the parietal and occipital regions, which are associated with sensory processing and spatial awareness. However, the Control group demonstrates even stronger connections within the occipital area, a region crucial for visual processing and sensory integration.
</p>
<p></p>
<p><a href="#">
    <img src="/img/eegTable2.jpg" alt="Top Connected Node Pairs" width="471" />
</a></p>
<p></p>
<p>
    These findings suggest that the Control group has a more stable and efficient brain network organization, enabling robust communication between regions involved in visual and sensory information processing. In contrast, the Alcohol group's connectivity, while present, appears less stable, potentially reflecting the impact of alcohol on neural communication pathways.
</p>

<p>
    Table 3 showcases the nodes with the highest cosine similarity values for both the Alcohol and Control groups. In the Alcohol group, the strongest connectivity is observed in the parietal region, suggesting a focus on regions responsible for sensory processing and spatial awareness. This pattern could indicate a compensatory mechanism in response to disruptions caused by alcohol.
</p>
<p></p>
<p><a href="#">
    <img src="/img/eegTable3.jpg" alt="Top Nodes with Highest Cosine Similarity" width="333" />
</a></p>
<p></p>
<p>
    Conversely, the Control group shows dominance in the occipital region, which reflects consistent and efficient neural communication critical for interpreting visual information. This occipital region dominance highlights the Control group's more organized and robust brain network, supporting efficient sensory and visual information processing. The contrast between the two groups underscores differences in how the brain processes sensory and visual stimuli under varying conditions.
</p>

<h4>Weakly Connected Positions</h4>

<p>
    As shown in Tables 4 and 5, the nodes and node pairs with the lowest cosine similarity values for both the Alcohol and Control groups are concentrated in the central brain regions, such as <strong>CZ</strong>, <strong>C1</strong>, and <strong>C2</strong>. These regions are primarily associated with motor functions and are not expected to exhibit high connectivity in trials focused on visual stimuli. This finding aligns with the task's emphasis on visual processing rather than motor activity.
</p>

<p>
    In the Control group, these motor-related regions display low connectivity, which is consistent with the visual nature of the task. However, in the Alcohol group, the connectivity in these regions is even weaker, indicating that alcohol exposure may lead to broader disruptions across brain networks, even in areas not directly involved in the experimental task. This suggests that alcohol may impair not only task-relevant connectivity but also overall neural network stability.
</p>

<p>
    Table 4 highlights node pairs with the lowest cosine similarity values in both the Alcohol and Control groups. These weakly connected regions are particularly concentrated in central areas associated with motor function. While both groups show reduced connectivity in these regions, the Alcohol group exhibits more pronounced disruptions, indicating a broader impact of alcohol on neural networks.
</p>
<p></p>
<p><a href="#">
    <img src="/img/eegTable4.jpg" alt="Table 4: Lowest Connected Node Pairs" width="471" />
</a></p>
<p></p>

<p>
    Table 5 identifies individual nodes with the lowest cosine similarity values in both groups, primarily located in central regions such as CZ, C1, and C2. The Control group maintains slightly higher connectivity in these areas, aligning with the task's visual focus. In contrast, the Alcohol group demonstrates more pronounced disruptions, further reflecting the potential impact of alcohol on overall brain network stability.
</p>
<p></p>
<p><a href="#">
    <img src="/img/eegTable5.jpg" alt="Table 5: Lowest Connected Nodes" width="333" />
</a></p>
<p></p>

<h4>Graphical Representation of High and Low Connectivity Nodes</h4>

<p>
    The figure displays a topographical map of EEG channels, highlighting nodes based on their overall cosine similarity values for the Alcohol and Control groups. Nodes with the highest connectivity are shown in <strong>turquoise</strong> for the Alcohol group and in <strong>blue</strong> for the Control group, while those with the lowest connectivity are represented in <strong>yellow</strong> for the Alcohol group and <strong>orange</strong> for the Control group. This visualization offers a clear comparison of connectivity patterns, identifying regions of stronger and weaker signal correlations.
</p>
<p></p>
<div style="text-align: center; border: 2px solid #ccc; padding: 10px; width: fit-content; margin: auto;">

    <a href="#">
        <img src="/img/brain4.jpg" alt="Graphical Representation of Connectivity Nodes" width="598" />
    </a>
</div>
<p></p>
<p></p>

<p></p>
<p>
    In the Control group, the high-connectivity nodes are primarily located in the occipital region, which is responsible for visual processing. This stable neural interaction is expected during visual trials, indicating efficient brain network organization in response to visual stimuli. In contrast, the Alcohol group exhibits stronger connections in the parietal region, with fewer occipital nodes involved. This shift in connectivity may indicate how alcohol alters brain activity, possibly disrupting normal visual processing and causing compensatory activity in other regions.
</p>

<p>
    Both groups demonstrate low connectivity in the central region, which is typically linked to motor and sensorimotor processing. The lower activity in these areas during visual trials suggests they are not heavily engaged, aligning with their expected limited role in visual perception and processing tasks.
</p>

<h3>In Conclusion</h3>

<p>
    This study highlights the potential of GNN Link Prediction models to uncover subtle variations in EEG connectivity, providing a deeper understanding of neural dynamics. By developing a unified graph structure based on spatial distances between EEG electrodes, we successfully applied these models to analyze and interpret brain connectivity patterns in both Alcohol and Control groups.
</p>

<p>
    Our findings reveal that GNN Link Prediction models offer unique insights into connectivity patterns that traditional methods might miss. In the Control group, high-connectivity nodes were predominantly found in the occipital region, which is crucial for visual processing, reflecting stable and efficient neural responses. In contrast, the Alcohol group exhibited stronger connectivity in the parietal region, suggesting compensatory mechanisms to address disruptions caused by alcohol exposure. This shift highlights how alcohol may alter typical brain activity, particularly in regions linked to sensory and cognitive functions.
</p>

<p>
    Beyond EEG analysis, this framework is adaptable to other types of time series data, making it a versatile tool for studying connectivity patterns and uncovering underlying physiological dynamics. By integrating AI with neuroscience, this work demonstrates how GNN Link Prediction models can enhance our understanding of brain connectivity and open new avenues for research and clinical applications.
</p>

<p></p>
<h3>Workshop</h3>

<p></p>

<p>This study was presented in <i><a href="https://iwain.lucentia.es/programme/">“2024 International Workshop on Artificial Intelligence for Neuroscience”</a></i> - workshop in Alicante, Spain on November 26, 2024. Here are some slides from the presentation that are not in this poster.</p>
<p></p>
<p>We started with explaining people that graphs are everywhere in our lives. They represent molecules in chemistry, roads in navigation, and even our social networks like Facebook as molecule graphs, traffic graph, and social network graph.</p>

<p></p>
<p><a href="#">
    <img src="/img/alicante1.jpg" alt="Top Connected Node Pairs" width="711" />
</a></p>
<p></p>
<p>Then we showed that perhaps the most important graph of all is the one inside us: the network of neurons and synapses that forms our brain and for neuroscience, understanding graphs is key to unraveling how our brains process information, learn, and adapt.</p>
<p></p>
<p><a href="#">
    <img src="/img/alicante2.jpg" alt="Top Connected Node Pairs" width="711" />
</a></p>
<p></p>
<p>Then we introduced deep learning history, how GNN was created and what is the most important to know about GGN models.</p>
<p></p>
<p><a href="#">
    <img src="/img/alicante3.jpg" alt="Top Connected Node Pairs" width="711" />
</a></p>
<p></p>
<p>Finally, we discussed why for neuroscience graph thinking is really important and how neuroscientists can start thinking in that direction.</p>
<p></p>
<p><a href="#">
    <img src="/img/alicante4.jpg" alt="Top Connected Node Pairs" width="711" />
</a></p>
<p></p>

<p></p>
<p></p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Unlocking the Power of Pre-Final Vectors in GNN Graph Classification</title><link href="http://localhost:4000/2024/07/04/vectorsGNN/" rel="alternate" type="text/html" title="Unlocking the Power of Pre-Final Vectors in GNN Graph Classification" /><published>2024-07-04T08:00:00-04:00</published><updated>2024-07-04T08:00:00-04:00</updated><id>http://localhost:4000/2024/07/04/vectorsGNN</id><content type="html" xml:base="http://localhost:4000/2024/07/04/vectorsGNN/"><![CDATA[<p>This study highlights how linear algebra can enhance deep learning by making data representation and manipulation more efficient. We extract pre-final vectors from Graph Neural Networks (GNN) Graph Classification models and analyze the small graphs embedded within them. By applying these techniques to climate time series data, we show that combining linear algebra with GNN Graph Classification models improves the analysis of climate data. Additionally, we use these embedded small graphs for statistical analysis and build meta-graphs on top of them. This layered approach enhances our analytical capabilities and leads to better overall results.</p>
<p></p>
<p><h3> Introduction</h3>

<p></p>
Linear algebra plays a crucial role in machine learning and artificial intelligence by providing efficient ways to represent and manipulate data. Whether dealing with matrices or vectors, these mathematical structures help model complex problems in a manageable form. The rise of deep learning models has shown just how versatile linear algebra can be across various fields.
<p></p>
Converting different types of data—like images, audio, text, and social network information—into a uniform vector format is essential for deep learning. This standardization makes it easier for deep learning algorithms to process and analyze data, paving the way for innovative AI applications that work across multiple domains. Linear algebra supports many machine learning methods, including clustering, classification, and regression, by enabling data manipulation and analysis within neural network pipelines. Each step in these pipelines often involves vector operations, highlighting the critical role of linear algebra in advancing deep learning technology.
<p></p>

<p></p>



In this post, we explore how to capture pre-final vectors from GNN processes and apply these intermediate vectors to various techniques beyond their primary tasks. GNNs are used for key tasks like node classification, link prediction, and graph classification. Node classification and link prediction rely on node embeddings, while graph classification uses whole graph embeddings. These pre-final vectors, which represent embedded node features, can be utilized for tasks like node classification, regression, clustering, finding closest members, and triangle analysis.
<p></p>
For example, the GraphSAGE link prediction model in the Deep Graph Library (DGL) produces pre-final vectors, or embeddings, for each node instead of direct link predictions. These embeddings capture the nodes’ features and relationships within the graph. Previous studies have used these pre-final vectors for tasks like node classification, clustering, regression, and graph triangle analysis.
<p></p>
While the potential of pre-final vectors from link prediction models has been studied, our research shows that no studies currently look into capturing embedded whole graphs from GNN Graph Classification models. These models capture graph structures through both individual nodes and overall topology, using both attribute and relational information in small graphs. This makes GNN Graph Classification models powerful for specific challenges in fields like social networks, biological networks, and knowledge graphs. In this study, we will show how to capture embedded vectors of entire 'small graphs' from such models and use them for further graph data analysis.
<p></p>


<p></p>


GNN Graph Classification models use many labeled small graphs as input data. Traditionally used in chemistry and biology, these models can also be applied to small graphs from other domains. For instance, in social networks, these techniques analyze the surroundings of points of interest identified by high centrality metrics, including their friends and friends of friends. Time series data can be segmented into small graphs using sliding window techniques, effectively capturing short-term variability and rapid changes for dynamic data analysis.
<p></p>
In our study, we will use climate time series data from a Kaggle dataset containing daily temperature data for 40 years in the 1000 most populous cities worldwide. For each city, we will create a graph where nodes represent combinations of cities and years, and node features are daily temperature vectors for each city-year node. To define graph edges, we will select pairs of vectors with cosine similarities higher than a threshold.
<p></p>
We will validate the methods for capturing pre-final vectors and demonstrate their effectiveness in managing and analyzing dynamic datasets. By capturing these embedded vectors and applying similarity measures to them, we will extend beyond graph classification to apply methods like clustering, finding the closest neighbors for any graph, or even using small graphs as nodes to create meta-graphs on top of small graphs.
<p></p>


<p></p>

<p></p>



<p><h3> Related Work</h3>
<p></p>

<p></p>
<p></p>


In 2012, deep learning and knowledge graphs experienced a significant breakthrough. The introduction of Convolutional Neural Network (CNN) image classification through AlexNet demonstrated its superiority over previous machine learning techniques in various domains. Around the same time, Google introduced knowledge graphs, which enabled machines to understand relationships between entities and revolutionized data integration and management, enhancing products with intelligent capabilities.
<p></p>
For years, deep learning and knowledge graphs grew simultaneously, with CNNs excelling at tasks involving grid-structured data but struggling with graph-structured data. Conversely, graph techniques thrived on graph-structured data but lacked the sophisticated capabilities of deep learning. In the late 2010s, Graph Neural Networks (GNNs) emerged, combining deep learning with graph processing. This innovation revolutionized the handling of graph-structured data by enabling complex data analysis and predictions through the effective capture of relationships between graph nodes.
<p></p>
Starting in 2022, Large Language Models (LLMs) became prominent in the deep learning landscape, capturing much of the research attention. However, the potential of GNNs continues to be recognized, and we remain optimistic that GNN research and applications will continue to grow and expand.
<p></p>



<p></p>
<a href="#">
    <img src="/img/climateGnnGc1.jpg" alt="Post Sample Image" width="479" />
</a>
<p></p>
(Picture from a book: Bronstein, M., Bruna, J., Cohen, T., and Velickovic ́, P.
“Geometric deep learning: Grids, groups, graphs, geodesics, and gauges”, 2021)
</p><p>

<p></p>
The "Geometric Deep Learning" paper was written in 2021 when Convolutional Neural Networks (CNNs) were the leading models in the deep learning world. If that paper were written in 2023-2024, Large Language Models (LLMs) would undoubtedly be at the forefront. It's exciting to think about what might be the biggest breakthrough in deep learning in the next 2-3 years.
<p></p>

<p></p>

<h3>Methods</h3>
<p></p>

<h4>Graph Construction and Climate Labeling</h4>
<p></p>

In this study, we utilized GNN Graph Classification models to analyze small labeled graphs created from nodes and edges. We constructed graphs for each city, with nodes representing specific city-year pairs and edges defined by pairs of nodes with cosine similarities higher than threshold values. Each graph was labeled as either 'stable' or 'unstable' based on the city's geographical latitude.
<p></p>
<h4>Implementation of GCNConv for Graph Classification</h4>

<p></p>
For classifying these graphs, we used the Graph Convolutional Network (GCNConv) model from the PyTorch Geometric Library (PyG). The GCNConv model allowed us to extract feature vectors from the graph data, enabling us to perform a binary classification to determine whether the climate for each city was 'stable' or 'unstable'.
<p></p>

<h4>Python Code for Extracting Pre-Final Vectors: Graph Embedding</h4>
<p></p>
This function defines a custom Graph Convolutional Network (GCN) model using the PyTorch Geometric (PyG) library. The model is designed for classifying graphs, such as determining the climate stability of cities based on their temperature data. Here's a detailed breakdown of the function:
<p></p>
<p></p>  

<p></p>

<p></p>


<ul>
  <li>Node Embedding:
    <ul>
      <li>Input features are processed through multiple graph convolutional layers.</li>
      <li>ReLU activation is applied to enhance node embeddings.</li>
    </ul>
  </li>
  <li>Aggregation:
    <ul>
      <li>Node embeddings are pooled into a single graph embedding using global mean pooling.</li>
      <li>This aggregation creates a vector representing the entire graph.</li>
    </ul>
  </li>
  <li>Returning Graph Embedding:
    <ul>
      <li>If a specific parameter is set, the function returns these graph embeddings as pre-final vectors.</li>
      <li>These intermediate vectors can then be used for further analysis, such as climate data analysis, clustering, or other tasks.</li>
    </ul>
  </li>
</ul>

<p></p>  





<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch.nn</span> <span class="kn">import</span> <span class="n">Linear</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GCNConv</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">global_mean_pool</span>
<span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">GCN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="mi">365</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lin</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">return_graph_embedding</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="c1"># Node Embedding Steps
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="c1"># Graph Embedding Step
</span>        <span class="n">graph_embedding</span> <span class="o">=</span> <span class="nf">global_mean_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>  <span class="c1"># [num_graphs, hidden_channels]
</span>        <span class="k">if</span> <span class="n">return_graph_embedding</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">graph_embedding</span>  <span class="c1"># Return graph-level embedding here
</span>        <span class="c1"># Classification Step
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">graph_embedding</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span></code></pre></figure>



<p></p>

After training the Graph Convolutional Network (GCN) model, this code snippet extracts the graph embedding for a specific graph in the dataset:
The graph embedding is stored in <code><span style="color: blue;">out</span></code>, capturing the structural and feature information of the entire graph.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">g</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_graph_embedding</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">out</span><span class="p">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">])</span></code></pre></figure>

<p></p>
<ul>
    <li><em>dataset[g].x.float()</em>: Node features as floating-point tensor.</li>
    <li><em>dataset[g].edge_index</em>: Edge list of the graph.</li>
    <li><em>dataset[g].batch</em>: Batch assignment for nodes.</li>
    <li><em>return_graph_embedding=True</em>: Requests the graph-level embedding instead of classification.</li>
</ul>

<p></p>
The following code processes a series of graphs using a GCN model, applies a softmax function to the outputs, extracts predictions and graph embeddings, and stores the embeddings along with graph indices in a list for further analysis.
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Softmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">graphUnion</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">graphCount</span><span class="p">):</span>
  <span class="n">label</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">batch</span><span class="p">,</span> <span class="n">return_graph_embedding</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="n">output</span> <span class="o">=</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">out</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">graphUnion</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">:</span><span class="n">g</span><span class="p">,</span><span class="sh">'</span><span class="s">vector</span><span class="sh">'</span><span class="p">:</span> <span class="n">out</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()})</span></code></pre></figure>

<p></p>
<p></p>
Cosine similarity function:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch.nn.functional</span> <span class="kn">import</span> <span class="n">normalize</span>
<span class="k">def</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">a_norm</span> <span class="o">=</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b_norm</span> <span class="o">=</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">a_norm</span><span class="p">,</span> <span class="n">b_norm</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span></code></pre></figure>

<p></p>
This code calculates the cosine similarity between pairs of graph embeddings stored in <code><span style="color: blue;">graphUnion</span></code> and appends the results, along with their corresponding graph indices, to the <code><span style="color: blue;">cosine_similarities</span></code> list.
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cosine_similarities</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">graphUnion</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">graphUnion</span><span class="p">)):</span>  
        <span class="n">vector_i</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">graphUnion</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">'</span><span class="s">vector</span><span class="sh">'</span><span class="p">])</span>
        <span class="n">vector_j</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">graphUnion</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="sh">'</span><span class="s">vector</span><span class="sh">'</span><span class="p">])</span>
        <span class="n">cos_sim_value</span> <span class="o">=</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">vector_i</span><span class="p">,</span> <span class="n">vector_j</span><span class="p">).</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">flatten</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>  
        <span class="n">cosine_similarities</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span>
            <span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">:</span> <span class="n">graphUnion</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">],</span>
            <span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">:</span> <span class="n">graphUnion</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">],</span>
            <span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span> <span class="n">cos_sim_value</span>
        <span class="p">})</span></code></pre></figure>

<p></p>
<p></p>

<p></p>
<p></p>

<p></p>

<p></p>

<p></p>

<h3>Experiments Overview</h3>
<p></p>
<h4>Data Source: Climate Data</h4>
<p></p>
Our primary dataset, sourced from Kaggle, is titled:
<i><a href="
https://www.kaggle.com/hansukyang/temperature-history-of-1000-cities-1980-to-2020">"Temperature History of 1000 cities 1980 to 2020"</a></i> - daily temperature from 1980 to 2020 years for 1000 most populous cities in the world. This dataset provides a comprehensive record of average daily temperatures in Celsius for the 1000 most populous cities worldwide, spanning from 1980 to 2019. Using this extensive dataset, we developed a Graph Neural Network (GNN) Graph Classification model to analyze and interpret the climatic behaviors of these urban centers.
<p></p>
For our analysis, each city was represented as an individual graph, with nodes corresponding to specific city-year pairs. These nodes encapsulate the temperature data for their respective years, facilitating a detailed examination of temporal climatic patterns within each city.
<p></p>
The graphs were labeled as 'stable' or 'unstable' based on the latitude of the cities. We assumed that cities closer to the equator exhibit less temperature variability and hence more stability. This assumption aligns with observed climatic trends, where equatorial regions generally experience less seasonal variation compared to higher latitudes. To categorize the cities, we divided the 1000 cities into two groups based on their latitude, with one group consisting of cities nearer to the equator and the other group comprising cities at higher latitudes.


<p></p>
<p></p>

   <p></p>
  <p></p>

   <a href="#">
       <img src="/img/preFinFig1.jpg" alt="Post Sample Image" width="678" />
   </a>
Fig. 1. Latitude Distribution of the 1000 Most Populous Cities.
   <p></p>
   The bar chart on this picture shows the latitude distribution of the 1000 most populous cities, highlighting a higher concentration of cities in the Northern Hemisphere, particularly between 20 and 60 degrees latitude, with fewer cities in the Southern Hemisphere. The equator is marked by a dashed line.
   <p></p>


    <p></p>

        <h4>Data Preparation and Model Training</h4>
  <p></p>
In our project, we developed a Graph Neural Network (GNN) Graph Classification model to analyze climate data. We created individual graphs for each city, labeling them as 'stable' or 'unstable' based on their latitude. Edges in these graphs were defined by high cosine similarities between node pairs, indicating similar temperature trends. To ensure consistency across all graphs, we introduced virtual nodes, which improved connectivity and helped the model generalize across different urban climates.
  <p></p>
For our analysis, we used the GCNConv model from the PyTorch Geometric (PyG) library. This model is excellent for extracting important feature vectors from graphs before making final classification decisions, which are essential for a detailed analysis of climate patterns.


<p></p>

 <a href="#">
     <img src="/img/preFinalVector1.jpg" alt="Post Sample Image" width="678" />
 </a>
 <p></p>
  <p></p>
The GCNConv model performed very well, with accuracy rates of around 94% on training data and 92% on test data. These results highlight the model’s ability to effectively detect and classify unusual climate trends using daily temperature data represented in graph form.
  <p></p>   

<h4>Application of Graph Embedded Vectors: Cosine Similarity Analysis</h4>
<p></p>

  After training the GNN Graph Classification model, we transformed each city graph into an embedded vector. These vectors became the foundation for our subsequent data analyses.
<p></p>
<h5>Cosine Similarity Matrix Analysis of Graph-Embedded Vectors</h5>
<p></p>
  We constructed a cosine similarity matrix for 1000 cities to identify closely related climate profiles. This matrix allows for detailed comparisons and clustering based on the embedded vector data.
<p></p>
  To illustrate, we examined the closest neighbors of the graph vectors for Tokyo, Japan (the largest city in our dataset), and Gothenburg, Sweden (the smallest city in our dataset). Tokyo’s closest neighbors are primarily major Asian cities, indicating strong climatic and geographical similarities. Similarly, Gothenburg’s nearest neighbors are predominantly European cities, reflecting similar weather patterns across Northern and Central Europe.
<p></p>
  We also identified vector pairs with the lowest cosine similarity, specifically -0.543011, between Ulaanbaatar, Mongolia, and Shaoguan, China. This negative similarity suggests stark climatic differences. Additionally, the pair with a cosine similarity closest to 0.0 (-0.000047), indicating orthogonality, is between Nanchang, China, and N’Djamena, Chad. This near-zero similarity underscores the lack of a significant relationship between these cities’ climatic attributes.
<p></p>




    <p></p>    

<p></p>    
Table 1. Closest Neighbors of Tokyo, Japan (Lat 35.69, Long 139.69). Based on Cosine
Similarity
     <a href="#">
         <img src="/img/preFinTab1.jpg" alt="Post Sample Image" width="404" />
     </a>

<p></p>
<p></p>

Table 2. Closest Neighbors of Gothenburg, Sweden (Lat 57.71, Long 12.00). Based on Cosine Similarity
      <a href="#">
          <img src="/img/preFinTab2.jpg" alt="Post Sample Image" width="383" />
      </a>
<p></p>
Code to identify the top 5 closest neighbors to a specific node (node 0) based on cosine similarity values:
<p></p>
<ul>
    <li>Select neighbors where node 0 is either the 'left' or 'right' node from the DataFrame <em>dfCosSim</em>.</li>
    <li>Concatenate these rows into a single DataFrame <em>neighbors</em>.</li>
    <li>Sort the combined DataFrame by cosine similarity in descending order to prioritize the closest neighbors.</li>
    <li>Add a 'neighbor' column to identify the neighboring node, adjusting between 'left' and 'right' as needed.</li>
    <li>Select the top 5 rows with the highest cosine similarity and keep only the 'neighbor' and 'cos' columns.</li>
</ul>

    <p></p>

    
<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="n">neighbors_left</span> <span class="o">=</span> <span class="n">dfCosSim</span><span class="p">[</span><span class="n">dfCosSim</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">neighbors_right</span> <span class="o">=</span> <span class="n">dfCosSim</span><span class="p">[</span><span class="n">dfCosSim</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">neighbors</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">neighbors_left</span><span class="p">,</span> <span class="n">neighbors_right</span><span class="p">])</span>
    <span class="n">neighbors</span> <span class="o">=</span> <span class="n">neighbors</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">neighbors</span><span class="p">[</span><span class="sh">'</span><span class="s">neighbor</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">neighbors</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">]</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">top_5_neighbors</span> <span class="o">=</span> <span class="n">neighbors</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">top_5_neighbors</span> <span class="o">=</span> <span class="n">top_5_neighbors</span><span class="p">[[</span><span class="sh">'</span><span class="s">neighbor</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">]]</span>
    </code></pre></figure>



    </p><p>  

<h5>Analyzing Climate Profiles with Cosine Similarity Matrix</h5>
<p></p>


The cosine similarity matrix distribution from the embedded city graphs reveals distinct clustering patterns, with notable peaks for values over 0.9 and between -0.4 to -0.2. These peaks indicate clusters of cities with nearly identical climates and those with shared but less pronounced features. This skewed distribution highlights areas with the highest concentration of values, providing essential insights into the relational dynamics and clustering patterns of the cities based on their climate data. The bar chart clearly illustrates how cities with similar climate profiles group together.

<p></p>
Table 3. Distribution of Cosine Similarities.
      <a href="#">
          <img src="/img/preFinTab3.jpg" alt="Post Sample Image" width="256" />
      </a>

<p></p>
<p></p>

 <a href="#">
     <img src="/img/preFinFig2.jpg" alt="Post Sample Image" width="678" />
 </a>
<p></p>
Code for distribution of cosine similarities
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>  <span class="c1"># Adjust the size of the figure, swapped dimensions for vertical orientation
</span><span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">dfCosSim</span><span class="p">[</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span>
         <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">CornflowerBlue</span><span class="sh">'</span><span class="p">,</span>
         <span class="n">orientation</span><span class="o">=</span><span class="sh">'</span><span class="s">horizontal</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># Set orientation to horizontal
</span><span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Distribution of Cosine Similarities</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Cosine Similarity</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># Now y-axis is cosine similarity
</span><span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Frequency</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># And x-axis is frequency
</span><span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure>


<p></p>
<h4>Application of Graph Embedded Vectors: Graphs Derived from Cosine Similarity Thresholds</h4>
<p></p>
Based on the observed distribution of cosine similarities, we generated three distinct graphs for further analysis, each using different cosine similarity thresholds to explore their impact on city pair distances.


<p></p>
To calculate distances between cities we used the following code:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">math</span> <span class="kn">import</span> <span class="n">sin</span><span class="p">,</span> <span class="n">cos</span><span class="p">,</span> <span class="n">sqrt</span><span class="p">,</span> <span class="n">atan2</span><span class="p">,</span> <span class="n">radians</span>
<span class="k">def</span> <span class="nf">dist</span><span class="p">(</span><span class="n">lat1</span><span class="p">,</span><span class="n">lon1</span><span class="p">,</span><span class="n">lat2</span><span class="p">,</span><span class="n">lon2</span><span class="p">):</span>
  <span class="n">rlat1</span> <span class="o">=</span> <span class="nf">radians</span><span class="p">(</span><span class="nf">float</span><span class="p">(</span><span class="n">lat1</span><span class="p">))</span>
  <span class="n">rlon1</span> <span class="o">=</span> <span class="nf">radians</span><span class="p">(</span><span class="nf">float</span><span class="p">(</span><span class="n">lon1</span><span class="p">))</span>
  <span class="n">rlat2</span> <span class="o">=</span> <span class="nf">radians</span><span class="p">(</span><span class="nf">float</span><span class="p">(</span><span class="n">lat2</span><span class="p">))</span>
  <span class="n">rlon2</span> <span class="o">=</span> <span class="nf">radians</span><span class="p">(</span><span class="nf">float</span><span class="p">(</span><span class="n">lon2</span><span class="p">))</span>
  <span class="n">dlon</span> <span class="o">=</span> <span class="n">rlon2</span> <span class="o">-</span> <span class="n">rlon1</span>
  <span class="n">dlat</span> <span class="o">=</span> <span class="n">rlat2</span> <span class="o">-</span> <span class="n">rlat1</span>
  <span class="n">a</span> <span class="o">=</span> <span class="nf">sin</span><span class="p">(</span><span class="n">dlat</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="nf">cos</span><span class="p">(</span><span class="n">rlat1</span><span class="p">)</span> <span class="o">*</span> <span class="nf">cos</span><span class="p">(</span><span class="n">rlat2</span><span class="p">)</span> <span class="o">*</span> <span class="nf">sin</span><span class="p">(</span><span class="n">dlon</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
  <span class="n">c</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="nf">atan2</span><span class="p">(</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="nf">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a</span><span class="p">))</span>
  <span class="n">R</span><span class="o">=</span><span class="mf">6371.0</span>
  <span class="k">return</span> <span class="n">R</span> <span class="o">*</span> <span class="n">c</span>

  <span class="k">def</span> <span class="nf">cityDist</span><span class="p">(</span><span class="n">city1</span><span class="p">,</span><span class="n">country1</span><span class="p">,</span><span class="n">city2</span><span class="p">,</span><span class="n">country2</span><span class="p">):</span>
    <span class="n">lat1</span><span class="o">=</span><span class="n">cityMetadata</span><span class="p">[(</span><span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">city_ascii</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">city1</span><span class="p">)</span>
      <span class="o">&amp;</span> <span class="p">(</span><span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">country1</span><span class="p">)][</span><span class="sh">'</span><span class="s">lat</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">lat2</span><span class="o">=</span><span class="n">cityMetadata</span><span class="p">[(</span><span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">city_ascii</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">city2</span><span class="p">)</span>
      <span class="o">&amp;</span> <span class="p">(</span><span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">country2</span><span class="p">)][</span><span class="sh">'</span><span class="s">lat</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">lon1</span><span class="o">=</span><span class="n">cityMetadata</span><span class="p">[(</span><span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">city_ascii</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">city1</span><span class="p">)</span>
      <span class="o">&amp;</span> <span class="p">(</span><span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">country1</span><span class="p">)][</span><span class="sh">'</span><span class="s">lng</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">lon2</span><span class="o">=</span><span class="n">cityMetadata</span><span class="p">[(</span><span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">city_ascii</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">city2</span><span class="p">)</span>
      <span class="o">&amp;</span> <span class="p">(</span><span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">country2</span><span class="p">)][</span><span class="sh">'</span><span class="s">lng</span><span class="sh">'</span><span class="p">]</span>
    <span class="k">return</span> <span class="nf">dist</span><span class="p">(</span><span class="n">lat1</span><span class="p">,</span><span class="n">lon1</span><span class="p">,</span><span class="n">lat2</span><span class="p">,</span><span class="n">lon2</span><span class="p">)</span>  </code></pre></figure>

<p></p>


The following function filters a DataFrame for high cosine similarity values, creates a graph, and adds edges between nodes with high similarities, ready for further analysis or visualization.
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">df</span><span class="o">=</span><span class="n">dfCosSim</span>
<span class="n">high_cos_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.9</span><span class="p">]</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">high_cos_df</span><span class="p">.</span><span class="n">empty</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">high_cos_df</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
        <span class="n">G</span><span class="p">.</span><span class="nf">add_edge</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">],</span> <span class="n">weight</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">])</span></code></pre></figure>


<p></p>

<p></p>


The following code enriches the edges of the graph <em>G</em> with distance information and then collects all the distance values into a list for further analysis:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">distData</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
  <span class="k">if</span> <span class="n">G</span><span class="p">.</span><span class="nf">has_edge</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">]):</span>
    <span class="n">G</span><span class="p">[</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">]][</span><span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">]][</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">]</span>

<span class="n">distances</span> <span class="o">=</span> <span class="p">[</span><span class="n">attr</span><span class="p">[</span><span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">G</span><span class="p">.</span><span class="nf">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="bp">True</span><span class="p">)]</span>
<span class="n">mean_distance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
<span class="n">median_distance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">median</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
<span class="n">std_deviation</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">std</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
<span class="n">min_distance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">min</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
<span class="n">max_distance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span></code></pre></figure>

<p></p>
This code iterates through the <em>distData</em> DataFrame, checks for existing edges in the graph <em>G</em>, and adds distance attributes to these edges. It then calculates the mean, median, standard deviation, minimum, and maximum of the distance values.
<p></p>
<b>For the first graph</b>, we used a high similarity threshold (cosine similarity &gt; 0.9).

The statistics for the distances between city pairs in the first graph are as follows:
<ul>
    <li><strong>Mean distance</strong>: 7942.658 km</li>
    <li><strong>Median distance</strong>: 7741.326 km</li>
    <li><strong>Standard deviation</strong>: 5129.801 km</li>
    <li><strong>Minimum distance</strong>: 1.932 km</li>
    <li><strong>Maximum distance</strong>: 19975.287 km</li>
</ul>


<p></p>               
The shortest distance pair is between Jerusalem, Israel, and Al Quds, West Bank, with nearly identical latitude and longitude coordinates (31.7784, 35.2066 for Jerusalem and 31.7764, 35.2269 for Al Quds), highlighting their close proximity. In contrast, the longest distance pair is between Quito, Ecuador, and Pekanbaru, Indonesia. These cities, located on opposite sides of the world, have dramatically different geographical coordinates (-0.2150, -78.5001 for Quito and 0.5650, 101.4250 for Pekanbaru), spanning a vast distance across the globe.

<p></p>


<b>For the second graph</b>, defined by a cosine similarity threshold ranging from -0.4 to -0.2, we observed a moderate level of climatic similarity among city pairs. The key statistics for this graph are as follows:

<p></p>

<p></p>
<ul>
    <li><strong>Mean distance</strong>: 8648.245 km</li>
    <li><strong>Median distance</strong>: 8409.507 km</li>
    <li><strong>Standard deviation</strong>: 4221.592 km</li>
    <li><strong>Minimum distance</strong>: 115.137 km</li>
    <li><strong>Maximum distance</strong>: 19963.729 km</li>
</ul>

<p></p>

For this graph, the shortest distance pair is between Kabul, Afghanistan (latitude 34.5167, longitude 69.1833) and Jalalabad, Afghanistan (latitude 34.4415, longitude 70.4361). The longest distance pair is between Mendoza, Argentina (latitude -32.8833, longitude -68.8166) and Shiyan, China (latitude 32.5700, longitude 110.7800).

<p></p>

Both the first and second graphs had just one connected component. To generate a graph with several connected components, we examined graphs with very high thresholds.
<p></p>
<b>For the third graph</b>, we used a high similarity threshold (cosine similarity &gt; 0.99), resulting in connected components of sizes [514, 468, 7, 5]. The largest connected component, with 514 nodes, predominantly includes cities with stable climates (475 nodes labeled as stable) and a smaller portion with unstable climates (39 nodes labeled as unstable). The second-largest component, containing 468 nodes, primarily consists of cities with unstable climates (451 nodes labeled as unstable) and a few with stable climates (17 nodes labeled as stable). These findings indicate that cities within the same climate category (stable or unstable) exhibit higher similarity, leading to larger connected components, whereas similarities across different climate categories are less pronounced.
<p></p>
Table 4. Cities in the Third Connected Component (7 Nodes)
      <a href="#">
          <img src="/img/preFinTab4.jpg" alt="Post Sample Image" width="383" />
      </a>
<p></p>
In the smaller connected components, city graphs represent areas on the border between stable and unstable climates. The cities in these smaller components illustrate the variability and complexity of climatic relationships, showing a blend of stable and unstable climatic conditions. This underscores the nuanced and intricate climatic patterns that exist at the boundaries between different climate categories.
<p></p>




Table 5. Cities in the Fourth Connected Component (5 Nodes)
          <a href="#">
              <img src="/img/preFinTab5.jpg" alt="Post Sample Image" width="383" />
          </a>
              <p></p>

<p></p>
<p></p>



    <p></p>


<p></p>

<p></p>

<p></p>

<p></p>




<p></p>

<h3>In Conclusion</h3>
<p></p>


In this study, we explored how pre-final vectors from GNN models can be applied in GNN Graph Classification. We showed that linear algebra is vital in transforming various data types into uniform vector formats that deep learning models can effectively use.
<p></p>
Our research demonstrated how GNN Graph Classification models capture complex graph structures through advanced linear algebra techniques. By embedding entire 'small graphs' from these models, we opened up new possibilities for analyzing and clustering small graphs, finding nearest neighbors, and creating meta-graphs.
<p></p>
The results suggest that combining linear algebra with GNNs enhances the models' efficiency and scalability, making them useful in many fields. By capturing and analyzing embedded graphs from GNN Graph Classification models, we can significantly improve data analysis and predictive abilities, advancing artificial intelligence and its many applications.
<p></p>



<p></p>

<p></p>    





<p></p>

<p></p>

<p></p>
<p></p>
</p></p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[This study highlights how linear algebra can enhance deep learning by making data representation and manipulation more efficient. We extract pre-final vectors from Graph Neural Networks (GNN) Graph Classification models and analyze the small graphs embedded within them. By applying these techniques to climate time series data, we show that combining linear algebra with GNN Graph Classification models improves the analysis of climate data. Additionally, we use these embedded small graphs for statistical analysis and build meta-graphs on top of them. This layered approach enhances our analytical capabilities and leads to better overall results. Introduction]]></summary></entry><entry><title type="html">Multi-Layer Graph Analysis for Text-Driven Relationships Using GNN Link Prediction</title><link href="http://localhost:4000/2024/06/21/knowledgeGraphEmail/" rel="alternate" type="text/html" title="Multi-Layer Graph Analysis for Text-Driven Relationships Using GNN Link Prediction" /><published>2024-06-21T08:00:00-04:00</published><updated>2024-06-21T08:00:00-04:00</updated><id>http://localhost:4000/2024/06/21/knowledgeGraphEmail</id><content type="html" xml:base="http://localhost:4000/2024/06/21/knowledgeGraphEmail/"><![CDATA[<p><h3> </h3>
<p></p>

Analyzing complex graphs can be quite challenging, especially when the whole is greater than the sum of its parts. To address these challenges, we dive into the Enron email dataset, using its rich information to create a strong multi-layer graph analysis framework.
<p></p>
We start by building a foundational graph layer where email addresses are the nodes and email exchanges form the edges. This layer gives us a clear picture of the communication network, showing the direct interactions between individuals within the dataset.
<p></p>

Building upon this, we introduce a second graph layer that goes deeper into the content of these communications. Here, each interaction is represented as a node in the form of triplets—comprising the sender, receiver, email subject, and body. Edges in this layer signify communication chains, illustrating how discussions and information flow within the network.
<p></p>
To extract meaningful patterns from the textual content, we transform these triplet nodes into vectors using a transformer model. This transformation captures the semantic nuances of the email content. Following this, a Graph Neural Network (GNN) Link Prediction model is applied to these vectors. The model identifies potential links within the graph based on semantic similarity and structural patterns.
<p></p>

The output vectors from the GNN Link Prediction model, which capture both the semantic content and the graph structure, help us create a third graph layer. In this layer, nodes represent pairs of emails with high cosine similarities, forming a network that highlights strong semantic connections.
<p></p>
This third graph layer is key to identifying influencers within the network, revealing individuals who play important roles in spreading information. It also gives us a better understanding of engagement dynamics, showing how interactions evolve and spread across the network.
<p></p>
By using this multi-layer approach, we provide a comprehensive framework for analyzing complex textual interactions within graph structures. This method not only offers deeper insights into network dynamics but also improves our ability to identify key influencers, ultimately enhancing our understanding of intricate communication networks.

<p></p>

<h3>Introduction</h3>
<p></p>

Graphs are powerful tools for representing complex relationships, with each level building on the previous one’s capabilities and efficiency. Think of atoms forming molecules with unique properties, molecules creating cells with essential functions, and cells building organs with specialized roles. However, as graphs become more intricate, analyzing them becomes increasingly challenging.
<p></p>
Complex system analysis can be approached both top-down and bottom-up. In this study, we introduce a bottom-up method for analyzing graph layers built on text-driven relationships. This approach captures intricate details and emergent properties from foundational elements upwards.
<p></p>

For example, imagine a bipartite graph with individuals on one side and movie narratives on the other. Relationships in this graph are defined by shared interests in particular movies. By exploring the narrative elements in recommender systems, we can uncover complex relationships that go beyond merely identifying pairs or groups of people with common movie interests.

<p></p>
Another example is influence networks in social media, where nodes represent users and directed edges signify interactions such as likes, comments, or shares. By examining the content of posts and interactions, we can uncover text-driven relationships that reveal influence patterns and topics of interest. This approach helps us understand the dynamics of influence and engagement within the social media ecosystem.

<p></p>



    In a prior study <a href="https://doi.org/10.5220/0011664400003393">
  'Rewiring Knowledge Graphs by Graph Neural Network Link Predictions'
    </a> (2023), we focused on rewiring text-based knowledge graphs through the use of GNN link prediction models, specifically targeting semantic knowledge graphs built from text documents. We utilized GNN link prediction techniques to modify these graphs, revealing hidden connections between nodes.
<p></p>
    In another study <a href="https://doi.org/10.1007/978-981-99-8324-7_2"> 'Uncovering Hidden Connections: Granular Relationship Analysis in Knowledge Graphs' </a> (2024), we also applied GNN link prediction models to semantic knowledge graphs to uncover hidden relationships within a detailed vector space. We focused on identifying 'graph connectors' that expose deeper network structures and used graph triangle analysis to delve into complex interactions.

<p></p>

The Enron email corpus provides a valuable opportunity to explore the potential of text-enhanced knowledge graphs in uncovering hidden patterns within organizational communication. By focusing on direct interactions and using transformer models for text embedding, we lay the groundwork for a knowledge graph that better captures the complexity of real-world relationships.

<p></p>
Our findings highlight the significant impact of incorporating textual data and GNN Link Prediction in knowledge graph analysis. This approach provides a more complete view of how entities interact, helping us understand complex networks better. As we continue to refine these methods, the potential for uncovering new insights in data-rich environments seems limitless, opening up exciting possibilities for future research.
<p></p>




    <h3>Key Methodologies of Our Study</h3>
<p></p>    
<h4>Architecture Pipeline</h4>
<p></p>
    Our architecture pipeline for the multi-layer graph approach begins with raw data processing and follows to link prediction model:
<p></p>
<a href="#">
        <img src="/img/archPipeline2.jpg" alt="Post Sample Image" width="1024" />
</a>
<p></p>
        <ul>
            <li>
                <strong>Raw Data:</strong> The initial dataset includes attributes such as ‘from’, ‘to’, ‘body’, and ‘time’.
            </li>
            <li>
                <strong>Initial Graph Layer:</strong> Email addresses are depicted as nodes connected by edges representing email exchanges.
            </li>
            <li>
                <strong>Transformation to Triplet Nodes:</strong> Email exchanges are converted into triplets (from, to, email body).
            </li>
            <li>
                <strong>Second-Layer Graph Construction:</strong> Triplet nodes form edges based on communication chains (to-to connections).
            </li>
            <li>
                <strong>Node Embedding:</strong> Embedding node features to vectors.
            </li>
            <li>
                <strong>GNN Link Prediction:</strong> The GNN model is applied, transforming triplet nodes into vectors.
            </li>
        </ul>
        <p>
            After GNN Link Prediction model training, we will examine structural changes in the network to uncover key influencers.
        </p>

<p></p>

<h4>Transformation Process from Initial Graph to Second-Layer Graph</h4>
<p></p>
The process begins with constructing the initial graph layer, where email addresses are depicted as nodes connected by edges representing email exchanges, as shown in the picture. Each email exchange is then converted into triplets consisting of 'from', 'to', and the email's subject and body. Subsequently, a second-layer graph is constructed where these triplet nodes form edges based on communication chains ('to-to' connections), as illustrated in the picture.
<p></p>
<a href="#">
    <img src="/img/kgArch.jpg" alt="Post Sample Image" width="978" />
</a>

<p></p>
<h4>Node Embedding</h4>
<p></p>
To translate text into vectors, we will use the 'all-MiniLM-L6-v2' transformer model from Hugging Face. This sentence-transformer model efficiently maps text into 384-dimensional vectors. This process transforms sentences into dense vectors, preserving their semantic content for machine learning applications. This embedding step is crucial, ensuring the text is suitably prepared for deep learning analyses, including GNN link prediction, by capturing the nuanced meanings in a format compatible with our algorithms.
<p></p>
<h4>Training the GNN Link Prediction Model</h4>

<p></p>

After setting up the nodes, we refine the graph with GNN Link Prediction to uncover detailed interactions. By examining the graph’s structure and node details, we reveal previously hidden connections, enhancing the graph’s depth and utility for analysis.
<p></p>
We use the GraphSAGE link prediction model, which generates node embeddings based on attributes and neighbors without retraining. Our study employs a GNN Link Prediction model from the Deep Graph Library (DGL), with two GraphSAGE layers. This approach improves node representation by combining details from nearby nodes and discovering hidden connections in the Enron email dataset.
<p></p>
The output vectors from this model can be used for further analysis, and we will showcase this in our 'Experiments' section.

<p></p>


<h3>Experiments Overview</h3>

<p></p>
<h4>Data Source</h4>

<p></p>

Our main data source is the Enron email corpus, a comprehensive collection of emails exchanged among executives of the Enron Corporation. This dataset, freely available to the public, captures a wealth of corporate communications, offering a deep dive into the intricacies of a complex organizational network. Its rich detail makes it an excellent resource for our knowledge graph analysis, shedding light on the dynamics of corporate interactions.
<p></p>
The Enron email corpus is hosted on Kaggle, providing easy access for those looking to conduct detailed analyses of the dataset. For further information or to explore the dataset yourself, visit <a href="https://www.kaggle.com/datasets/wcukierski/enron-email-dataset/data">Kaggle's Enron Email Dataset</a>.


<p></p>


<h4>Input Data Preparation</h4>
<p></p>

Our study starts with building a graph using the Enron email dataset from the year 2000, focusing on internal communications by selecting emails sent from @enron.com addresses. We aimed to analyze direct email exchanges between individuals, excluding group emails to ensure a clear and focused analysis.
<p></p>
For the graph’s nodes, we merged the 'From', 'To', 'Subject', and 'Body' fields of each email into a single text unit, as illustrated in the picture. This method ensures that each node fully represents an individual email conversation, including all its context and specifics.
<p></p>
To link these nodes in the graph, we connected emails that had either the same sender or recipient, indicating a direct line of communication between parties. This setup accurately mirrors how communication unfolded within Enron, revealing the network’s detailed structure and the rich interplay of relationships among employees.
<p></p>

<h4>Constructing Layer Graphs from Enron's 2000 Email Corpus</h4>
<p></p>
Our investigation begins by creating a knowledge graph derived from the Enron email dataset, specifically focusing on the year 2000. Our selection criteria were emails exchanged internally, identifiable through @enron.com addresses, allowing us to concentrate on direct communications between individual employees while excluding group emails for a more targeted analysis.
<p></p>
<h5>Node Creation in the Knowledge Graph</h5>
<p></p>
To form the nodes of our knowledge graph, we combined the 'From', 'To', 'Subject', and 'Body' of each email into a unified text representation. This approach ensured that each node captured the entirety of an email exchange, preserving both the context and the details of the conversation.
<p></p>

Concatenate 'From', 'To', 'Subject', and 'body' columns with '^' between

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">emailText</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>
   <span class="n">df</span><span class="p">[[</span><span class="sh">'</span><span class="s">From</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">To</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Subject</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">body</span><span class="sh">'</span><span class="p">]]</span>
   <span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="sh">'</span><span class="s"> ^ </span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">row</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code></pre></figure>

        <p></p>
Combine and index 'From' and 'To' columns:
        <p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">unique_emails</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">From</span><span class="sh">'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">To</span><span class="sh">'</span><span class="p">]]).</span><span class="nf">unique</span><span class="p">()</span>
<span class="n">email_index</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">unique_emails</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">unique_emails</span><span class="p">)),</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">emailIdx</span><span class="sh">'</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">FromIdx</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">From</span><span class="sh">'</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="n">email_index</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">ToIdx</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">To</span><span class="sh">'</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="n">email_index</span><span class="p">)</span>
<span class="n">emailFromTo</span><span class="o">=</span><span class="n">df</span><span class="p">[[</span><span class="sh">'</span><span class="s">FromIdx</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">emailTextIdx</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">emailText</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ToIdx</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">emailFromTo</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span></code></pre></figure>

        <p></p>

<a href="#">
            <img src="/img/enron1.jpg" alt="Post Sample Image" width="543" />
</a>

<p></p>

<h5>Linking Nodes in the Knowledge Graph</h5>
<p></p>        
        In establishing connections within the knowledge graph, we linked emails sharing common senders or recipients, thereby reflecting a direct communication pathway between entities. This method provided an accurate reflection of how interactions occurred within Enron, uncovering the intricate structure of the network and the dynamic web of relationships between employees.

<p></p>
        Self-join emailFromTo table to create edges:
<p></p>        

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">=</span><span class="n">emailFromTo</span>
<span class="n">joined_df</span> <span class="o">=</span>
   <span class="n">df</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">left_on</span><span class="o">=</span><span class="sh">'</span><span class="s">ToIdx</span><span class="sh">'</span><span class="p">,</span> <span class="n">right_on</span><span class="o">=</span><span class="sh">'</span><span class="s">FromIdx</span><span class="sh">'</span><span class="p">,</span> <span class="n">suffixes</span><span class="o">=</span><span class="p">(</span><span class="sh">'</span><span class="s">_left</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">_right</span><span class="sh">'</span><span class="p">))</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">joined_df</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="sh">'</span><span class="s">FromIdx_left != ToIdx_right</span><span class="sh">'</span><span class="p">)</span>
<span class="n">dfLeft</span> <span class="o">=</span> <span class="n">em2text2em</span><span class="p">[[</span><span class="sh">'</span><span class="s">emailText_left</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">emailTextIdx_left</span><span class="sh">'</span><span class="p">]]</span>
   <span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">emailText_left</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">emailTextIdx_left</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">})</span>
<span class="n">dfRight</span> <span class="o">=</span> <span class="n">em2text2em</span><span class="p">[[</span><span class="sh">'</span><span class="s">emailText_right</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">emailTextIdx_right</span><span class="sh">'</span><span class="p">]]</span>
   <span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">emailText_right</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">emailTextIdx_right</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">})</span></code></pre></figure>

<p></p>
Excluded disconnected nodes and reindex:

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">dff</span><span class="o">=</span><span class="n">em2text2em</span>  
<span class="n">combined_df</span> <span class="o">=</span>
   <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">dfLeft</span><span class="p">,</span> <span class="n">dfRight</span><span class="p">]).</span><span class="nf">drop_duplicates</span><span class="p">().</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">combined_df</span> <span class="o">=</span> <span class="n">combined_df</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">)</span>
<span class="n">combined_df</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">combined_df</span><span class="p">[</span><span class="sh">'</span><span class="s">new_index</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">combined_df</span><span class="p">.</span><span class="n">index</span>   
<span class="n">nodes</span><span class="o">=</span><span class="n">combined_df</span><span class="p">[[</span><span class="sh">'</span><span class="s">new_index</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">nodes</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span>               </code></pre></figure>

<p></p>
<a href="#">
    <img src="/img/enron2.jpg" alt="Post Sample Image" width="543" />
</a>

<p></p>
      Reindex edges:

<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">idx_mapping</span> <span class="o">=</span>
   <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">combined_df</span><span class="p">[</span><span class="sh">'</span><span class="s">new_index</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">combined_df</span><span class="p">[</span><span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">]).</span><span class="nf">to_dict</span><span class="p">()</span>
<span class="n">dff</span><span class="p">[</span><span class="sh">'</span><span class="s">new_idxLeft</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dfLeft</span><span class="p">[</span><span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="n">idx_mapping</span><span class="p">)</span>
<span class="n">dff</span><span class="p">[</span><span class="sh">'</span><span class="s">new_idxRight</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dfRight</span><span class="p">[</span><span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="n">idx_mapping</span><span class="p">)</span>
<span class="n">edges</span><span class="o">=</span><span class="n">dff</span><span class="p">[[</span><span class="sh">'</span><span class="s">new_idxLeft</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">new_idxRight</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">edges</span><span class="o">=</span><span class="n">edges</span><span class="p">.</span><span class="nf">drop_duplicates</span><span class="p">()</span>
<span class="n">edges</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span>           </code></pre></figure>

<p></p>

<a href="#">
    <img src="/img/enron3.jpg" alt="Post Sample Image" width="314" />
</a>

<p></p>

<h4>Model Training</h4>
<p></p>


For model training, we first used the 'all-MiniLM-L6-v2' transformer from Hugging Face to transform email texts into vectors. Next, we applied the GNN Link Prediction model from the DGL library, aiming to discover unseen graph connections by analyzing these vectors and the graph structure.
<p></p>
    <ul>
        <li>Total number of nodes: 9,654</li>
        <li>Total number of edges: 667,354</li>
        <li>Embedded nodes represented as a PyTorch tensor of size [9,654, 384]</li>
        <li>The output vector size for the GraphSAGE model was set to 64</li>
    </ul>
<p></p>
To evaluate the efficacy of the model, we employed the Area Under Curve (AUC) metric as a measure of accuracy. The achieved model accuracy was approximately 96.7%, demonstrating the model’s high predictive performance.
<p></p>

<h5>Code Details</h5>
<p></p>
Convert edges to DGL model:
    <p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">unpickEdges</span><span class="o">=</span><span class="n">edges</span>
<span class="n">edge_index</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">unpickEdges</span><span class="p">[[</span><span class="sh">'</span><span class="s">new_idxLeft</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">new_idxRight</span><span class="sh">'</span><span class="p">]].</span><span class="n">T</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="o">=</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">g</span><span class="o">=</span><span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="p">))</span>
<span class="n">g</span><span class="o">=</span><span class="n">dgl</span><span class="p">.</span><span class="nf">add_self_loop</span><span class="p">(</span><span class="n">gNew</span><span class="p">)</span>
<span class="n">g</span>
<span class="nc">Graph</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">9654</span><span class="p">,</span> <span class="n">num_edges</span><span class="o">=</span><span class="mi">667354</span><span class="p">,</span>
  <span class="n">ndata_schemes</span><span class="o">=</span><span class="p">{}</span>
  <span class="n">edata_schemes</span><span class="o">=</span><span class="p">{})</span>      </code></pre></figure>

    <p></p>
Embed node feature text:

    <p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="n">modelST</span> <span class="o">=</span> <span class="nc">SentenceTransformer</span><span class="p">(</span><span class="sh">'</span><span class="s">all-MiniLM-L6-v2</span><span class="sh">'</span><span class="p">)</span>
<span class="n">node_embeddings</span> <span class="o">=</span> <span class="n">modelST</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">nodes</span><span class="p">[</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">],</span><span class="n">convert_to_tensor</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">node_embeddings</span> <span class="o">=</span> <span class="n">node_embeddings</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">))</span>
<span class="n">g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">node_embeddings</span>
<span class="n">g</span>
<span class="nc">Graph</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">9654</span><span class="p">,</span> <span class="n">num_edges</span><span class="o">=</span><span class="mi">667354</span><span class="p">,</span>
  <span class="n">ndata_schemes</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">:</span> <span class="nc">Scheme</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">384</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)}</span>
  <span class="n">edata_schemes</span><span class="o">=</span><span class="p">{})</span>        </code></pre></figure>

    <p></p>
    In our training process, we leveraged the GraphSAGE model, following closely with examples provided in the Deep Graph Library (DGL) tutorial. This choice allowed us to utilize a well-established framework for our Graph Neural Network (GNN) Link Prediction model, ensuring a solid foundation for our analysis. Below are GNN Link Prediction model statistics:

    <p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">all_logits</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="c1"># forward
</span>    <span class="n">h</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">train_g</span><span class="p">,</span> <span class="n">train_g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">].</span><span class="nf">float</span><span class="p">())</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">)</span>
    <span class="c1"># backward
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">e</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">In epoch {}, loss: {}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>       </code></pre></figure>

<p></p>
<a href="#">
    <img src="/img/enron4.jpg" alt="Post Sample Image" width="314" />
</a>

<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">AUC</span><span class="sh">'</span><span class="p">,</span> <span class="nf">compute_auc</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">))</span>         
<span class="n">AUC</span> <span class="mf">0.9673248461572111</span></code></pre></figure>

<p></p>


<h4>Results and Further Analysis</h4>

<p></p>

The GNN Link Prediction model outputs a set of re-embedded vectors that capture nuanced relationships within the graph. These vectors are valuable for deeper analysis, including statistical evaluation, clustering, and gaining further insights into the network’s structure. In this study, we built a new graph layer based on pairs of vectors with a cosine similarity threshold of 0.95, allowing for a detailed examination of the network’s dynamics and connections.
<p></p>
This method enables us to observe which influencers within the network have become more or less central after introducing these new connections. For this analysis, we focused on betweenness centrality, which measures a node’s importance in a graph by indicating how often it acts as a bridge along the shortest path between two other nodes. In complex relationships, these metrics help identify key nodes that facilitate communication or interaction across the network, revealing shifts in centrality and influence based on the newly established connections.
<p></p>
<p></p>    
    <a href="#">
        <img src="/img/enronResult1.jpg" alt="Post Sample Image" width="567" />
    </a>
<p></p>
When we compare the betweenness centrality scores before and after applying our method, we observe shifts in network influence. Initially, graph connections were based solely on direct email interactions. After incorporating text-driven relationships, new dynamics and hidden connections were revealed. This significantly altered the network’s structure, uncovering previously unrecognized key connectors and providing a more comprehensive view of the network’s influence and interactions.


  <p></p>

<p></p>

<a href="#">
    <img src="/img/enronResult2.jpg" alt="Post Sample Image" width="567" />
</a>
<p></p>

<p></p>

<p></p>



<h5>Code Details</h5>
<p></p>
Cosine Similarities function:    
<p></p>
    
<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="kn">import</span> <span class="n">torch</span>
    <span class="k">def</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">a_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">b_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">a_norm</span><span class="p">,</span> <span class="n">b_norm</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    </code></pre></figure>

    <p></p>
Select pairs of vectors with cosine similarities higher than 0.95.
    <p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cosine_scores_gnn</span> <span class="o">=</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
<span class="n">pairs_gnn</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">cosine_scores_gnn</span><span class="p">)):</span>
  <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">cosine_scores_gnn</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">&gt;</span><span class="n">j</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">cosine_scores_gnn</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.95</span><span class="p">:</span>
        <span class="n">pairs_gnn</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span><span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">:</span> <span class="n">j</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">cosine_scores_gnn</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()})</span>        </code></pre></figure>

    <p></p>
To pinpoint the main influencers in the knowledge graph, we employed betweenness centrality metrics. This approach enabled us to identify nodes that serve as crucial connectors facilitating information flow throughout the network. The initial step involves creating a graph using the NetworkX library:
<p></p>  

<p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.95</span><span class="p">][[</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">edges</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">source</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">G</span><span class="p">.</span><span class="nf">add_edges_from</span><span class="p">(</span><span class="n">edges</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="nf">tolist</span><span class="p">())</span>        </code></pre></figure>


<p></p>
Next, we determined the top 10 nodes with the highest betweenness centrality scores, highlighting the most influential connectors in the graph:
    <p></p>               

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">betweenness_rewired</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nf">betweenness_centrality</span><span class="p">(</span><span class="n">G1</span><span class="p">)</span>
<span class="n">top_rewired</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">betweenness_rewired</span><span class="p">.</span><span class="nf">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]</span></code></pre></figure>

<p></p>



<h3>In Conclusion</h3>
<p></p>

In this post, we introduced a novel approach to better understand and analyze complex connections within networks by incorporating descriptive texts into graph structures. Traditional models often miss the subtle nuances in textual content that are crucial for revealing hidden linkages and intricate interactions.
<p></p>
Our method treats interactions as high-dimensional entities, transforming email exchange triplets into nodes for the next graph layer and applying a GNN Link Prediction model. This approach captures the complexity of relationships beyond simple pairwise interactions, providing a nuanced understanding of multifaceted connections. By including text-driven relationships, our model allows for deeper semantic analysis, uncovering the underlying meanings and contexts within communications.
<p></p>
Combining semantic and topological features, our approach bridges the gap between textual content and network structure, offering a comprehensive view of the network. Applying this method to the Enron network demonstrated its effectiveness in revealing hidden linkages and identifying key influencers, highlighting its broad applicability.
<p></p>
By focusing on both semantics and graph topology, and leveraging higher graph layers, our method shows potential for use in various fields, including social networks, bioinformatics, healthcare, and beyond. This work paves the way for future research to explore and exploit the intricate interplay between textual content and network structures, advancing the field of network analysis.


<p></p>    





<p></p>

<p></p>

<p></p>
<p></p>
</p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Sliding Window Graph in GNN Graph Classification</title><link href="http://localhost:4000/2024/05/25/slidingWindowGraph/" rel="alternate" type="text/html" title="Sliding Window Graph in GNN Graph Classification" /><published>2024-05-25T08:00:00-04:00</published><updated>2024-05-25T08:00:00-04:00</updated><id>http://localhost:4000/2024/05/25/slidingWindowGraph</id><content type="html" xml:base="http://localhost:4000/2024/05/25/slidingWindowGraph/"><![CDATA[<p></p>
<p>The use of Graph Neural Networks (GNNs) in time series analysis represents a rising field of study, particularly in the context of GNN Graph Classification, a technique traditionally applied in disciplines such as biology and chemistry. Our research repurposes GNN Graph Classification for the analysis of time series climate data, focusing on two distinct methodologies: the city-graph method, which effectively captures static temporal snapshots, and the sliding window graph method, adept at tracking dynamic temporal changes. This innovative application of GNN Graph Classification within time series data enables the uncovering of nuanced data trends.</p>
<p></p>
<p>We demonstrate how GNNs can construct meaningful graphs from time series data, showcasing their versatility across different analytical contexts. A key finding is GNNs’ adeptness at adapting to changes in graph structure, which significantly improves outlier detection. This enhances our understanding of climate patterns and suggests broader applications of GNN Graph Classification in analyzing complex data systems beyond traditional time series analysis. Our research seeks to fill a gap in current studies by providing an examination of GNNs in climate change analysis, highlighting the potential of these methods in capturing and interpreting intricate data trends.</p>

<p></p>
<h3> Conference Presentation: ICMLT 2024</h3>
<p></p>
<p>This study was presented at the <a href="https://www.icmlt.org/index.html">International Conference on Machine Learning Technologies (ICMLT)</a> and is included in the proceedings.</p>
<p></p>
<p>In our research, we combined and compared two methods for analyzing time series climate data using Graph Neural Networks (GNNs). Our previous study, <a href="http://sparklingdataocean.com/2023/02/11/cityTempGNNgraphs/">“GNN Graph Classification for Climate Change Patterns: Graph Neural Network (GNN) Graph Classification - A Novel Method for Analyzing Time Series Data”</a>, introduced the city-graph method, which captures static temporal snapshots to sort climate data into ‘stable’ and ‘unstable’ categories.
In this post, we focus on our new technique: the sliding window graph method. This approach breaks down time series data into overlapping sections to capture specific time-related features. These sections are then used to create graphs, providing a new way to understand short-term changes in climate patterns.</p>
<p></p>

<h3> Introduction</h3>
<p></p>

<p>In 2012, deep learning and knowledge graphs took a big leap forward in data analysis and machine learning. AlexNet, a new type of Convolutional Neural Network (CNN) for image classification, showed much better results than older methods. Around the same time, Google introduced knowledge graphs, which improved how data is integrated and managed.</p>
<p></p>
<p>However, CNNs struggled with graph-structured data, and graph techniques lacked deep learning’s ability to recognize patterns. This changed with the arrival of Graph Neural Networks (GNNs). GNNs combined deep learning with graph data processing, making it easier to analyze graph-structured data.</p>
<p></p>
<p>GNN models are designed specifically for graph data. They use geometric relationships and combine node features with graph structure. This makes them very useful for tasks like node classification, link prediction, and graph classification. GNN Graph Classification models, which have been used in areas like chemistry and medicine, classify entire graphs based on their structure and features.</p>
<p></p>
<p></p>
<p><a href="#">
    <img src="/img/slidingWindow1.jpg" alt="Post Sample Image" width="777" />
</a></p>
<p></p>
<p></p>
<p>In 2021, the “Geometric Deep Learning” paper was written when Convolutional Neural Networks (CNNs) were the dominant models in the deep learning landscape. If the paper were written in 2023-2024, Large Language Models (LLMs) would undoubtedly be considered the leading technology. The field of deep learning is rapidly evolving, and it remains to be seen what new advancements and models will emerge as the “biggest animals” in the next 2-3 years.</p>
<p></p>

<p>In this study, we expand on our previous research using Graph Neural Network (GNN) models to analyze climate data. Our earlier method categorized climate time series data into ‘stable’ and ‘unstable’ to identify unusual patterns in climate change.</p>
<p></p>
<p>Now, we introduce the sliding window graph method, which breaks down time series data into overlapping sections to capture specific time-related features. This approach creates graphs from these sections, offering a new perspective on short-term climate changes.</p>
<p></p>
<p>Our previous study used a city-graph method, where nodes represent city-year combinations with daily temperature vectors as features. The new sliding window method compares identical dates across different cities and years, helping us understand global climate trends.</p>
<p></p>
<p>Our research aims to explore the potential of GNN graph classification in identifying and interpreting global climate dynamics, providing valuable insights into seasonal changes and long-term shifts in climate.</p>

<p></p>

<h3>Methods</h3>
<p></p>
<h4>Graph Construction Methods</h4>
<p></p>
<p>In our study, we explore two different methods for constructing graphs from climate data: the City-Graph Method and the Sliding Window Method.</p>
<p></p>
<p><a href="#">
    <img src="/img/slidingWindow2.jpg" alt="Post Sample Image" width="678" />
</a></p>
<p></p>
<p></p>
<p>City-Graph Method:</p>
<p></p>
<ul>
        <li>Creating graphs where nodes represent city-year pairs.</li>
        <li>Features are daily temperature vectors for each city-year.</li>
        <li>Edges are established based on cosine similarities between the temperature vectors of different city-years.</li>
        <li>Categorizes city graphs into 'stable' or 'unstable' climates based on their temperature patterns over time.</li>
</ul>
<p></p>
<p>Sliding Window Method:</p>
<p></p>
<ul>
        <li>Constructing graphs by breaking down time series data into overlapping sections.</li>
        <li>Nodes represent data points within a sliding window, with features reflecting their values.</li>
        <li>Edges connect sequential points to maintain the temporal sequence.</li>
        <li>Labels are assigned to capture patterns within the time series.</li>
</ul>

<p></p>

<p></p>
<h4>Common Pipeline</h4>
<p></p>
<p>While the graph construction methods differ, both follow a common pipeline for GNN Graph Classification:</p>
<p></p>
<p><a href="#">
    <img src="/img/slidingWindow3.jpg" alt="Post Sample Image" width="678" />
</a></p>
<p></p>

<ul>
        <li><strong>Data Input:</strong> daily temperature data for 1000 populous cities over 40 years.</li>
        <li><strong>Climate Trends</strong> as 'stable' or 'unstable'.</li>
        <li><strong>Graph Construction:</strong>
            <ul>
                <li>City-Graph Method.</li>
                <li>Sliding Window Method.</li>
            </ul>
        </li>
        <li><strong>Virtual Nodes:</strong> to act as central hubs in small graphs, tuning the models for better accuracy..</li>

        <li><strong>GNN Model Application:</strong> use GNN model to classify graphs based on patterns.</li>
</ul>

<p></p>

<p></p>

<h4>Methodology for Sliding Window Graph Construction</h4>

<p>Our approach uses Graph Neural Networks (GNNs) combined with a sliding window technique to analyze time series data. Here’s an overview of the process:</p>

<h5>Data to Graph Transformation</h5>
<p>We segment time series data into smaller graphs using a sliding window, which captures local temporal patterns. Each time segment forms a unique graph.</p>

<h5>Graph Creation</h5>
<p>In these graphs, nodes represent data points within the window, with features reflecting their values. Edges connect these sequential points to maintain the temporal order.</p>

<h5>Crucial Parameters</h5>
<p>The window size (W) and overlap (shift size S) are important as they determine how the data is segmented and analyzed. Edge definitions within the graphs are tailored to the specifics of the time series data, helping to detect patterns.</p>

<h5>Node Calculation</h5>
<p>For a dataset with N data points, we apply a sliding window of size W with a shift of S to create nodes. The number of nodes, N<sub>nodes</sub>, is calculated as:
    <math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
            <msub>
                <mi>N</mi>
                <mi>nodes</mi>
            </msub>
            <mo>=</mo>
            <mrow>
                <mo>&lfloor;</mo>
                <mfrac>
                    <mrow>
                        <mi>N</mi>
                        <mo>-</mo>
                        <mi>W</mi>
                    </mrow>
                    <mi>S</mi>
                </mfrac>
                <mo>&rfloor;</mo>
            </mrow>
            <mo>+</mo>
            <mn>1</mn>
        </mrow>
    </math></p>

<h5>Graph Calculation</h5>
<p>With the nodes determined, we construct graphs, each comprising G nodes, with a shift of S<sub>g</sub> between successive graphs. The number of graphs, N<sub>graphs</sub>, is calculated by:
    <math xmlns="http://www.w3.org/1998/Math/MathML">
        <mrow>
            <msub>
                <mi>N</mi>
                <mi>graphs</mi>
            </msub>
            <mo>=</mo>
            <mrow>
                <mo>&lfloor;</mo>
                <mfrac>
                    <mrow>
                        <msub>
                            <mi>N</mi>
                            <mi>nodes</mi>
                        </msub>
                        <mo>-</mo>
                        <mi>G</mi>
                    </mrow>
                    <msub>
                        <mi>S</mi>
                        <mi>g</mi>
                    </msub>
                </mfrac>
                <mo>&rfloor;</mo>
            </mrow>
            <mo>+</mo>
            <mn>1</mn>
        </mrow>
    </math></p>

<p>This method allows us to analyze time series data effectively by capturing both local and global patterns, providing valuable insights into temporal dynamics.</p>
<p></p>
<h4>Model Training</h4>
<p></p>

<p>Our methodology involves processing both city-centric and sliding window graphs. We start by generating cosine similarity matrices from time series data, which are then converted into graph adjacency matrices. This process includes creating edges for vector pairs with cosine values above a set threshold and adding a virtual node to ensure network connectivity, a critical step for preparing the graph structure.</p>
<p></p>
<p>For graph classification tasks, we use the GCNConv model from the PyTorch Geometric Library. This model excels in feature extraction through its convolutional operations, taking into account edges, node attributes, and graph labels for comprehensive graph analysis. The approach concludes with the training phase of the GNN model, applying these techniques to both types of graphs for robust classification.</p>
<p></p>

<p></p>
<h3>Experiments Overview</h3>
<p></p>
<h4>Data Source: Climate Data</h4>

<p></p>
<p>For this study, we utilized climate data from Kaggle, specifically the dataset titled
<i><a href="https://www.kaggle.com/hansukyang/temperature-history-of-1000-cities-1980-to-2020">“Temperature History of 1000 Cities 1980 to 2020”</a></i>.
This dataset provides average daily temperature data from 1980 to 2020 for the 1000 most populous cities in the world.
This comprehensive dataset served as the foundation for both the city-centric and sliding window graph methods employed in our analysis.</p>
<p></p>
<p><a href="#">
    <img src="/img/slidingWindow4.jpg" alt="Post Sample Image" width="678" />
</a></p>
<p></p>
<p>The bar chart shows city frequency by latitude. Most cities are between 20 and 60 degrees in the Northern Hemisphere. There are fewer cities around the equator and even fewer in the Southern Hemisphere.</p>

<p></p>
<h4>Sliding Window Graph GNN Graph Classification</h4>
<p></p>
<p>Using a 40-year dataset of daily temperatures from 1000 cities, our study evaluates GNN’s effectiveness in identifying global climate patterns. We focus on data from January 1st to the start of each month, providing insights into climate consistency, seasonal changes, and long-term shifts.</p>
<p></p>
<h5>Sliding Window Analysis for Global Climate Data.</h5>
<p></p>
<p>In our global climate data analysis, we use the sliding window graph method on a dataset with 40 years of daily temperatures from 1000 cities. This approach segments the data into graphs, each defined by a 30-day window (𝑊 = 30) with a 7-day shift (𝑆 = 7), effectively capturing local climate dynamics. This results in 1624 small graphs, allowing us to analyze short-term climate variations and trends.</p>
<p></p>
<p>Our accuracy metrics provide insights into the stability and variability of global climate patterns. High accuracy suggests predictable seasonal trends, while lower accuracy indicates irregular climate patterns or shifts. The sliding window graph method allows us to thoroughly evaluate the model’s ability to identify complex patterns in large climate datasets.</p>
<p></p>
<p></p>
<p><a href="#">
    <img src="/img/slidingWindow5.jpg" alt="Post Sample Image" width="678" />
</a></p>
<p></p>
<p>When examining closely spaced months, such as January 1st to February 1st and January 1st to December 1st, the GNN model’s accuracy around 0.5 suggests difficulty in identifying distinct climate patterns. This low accuracy points to potential variability and unpredictability in global weather patterns during these periods, highlighting the complex dynamics of weather.</p>
<p></p>
<p>For periods between January and months like March, April, or October, the model achieves accuracy metrics averaging around 0.7 to 0.8, indicating moderate success in capturing climatic patterns. This is likely due to the model’s proficiency in identifying consistent seasonal transitions over these extended timeframes.</p>
<p></p>
<p>The highest accuracy metrics, ranging from 0.94 to 0.99, are observed for months other than January, such as May, June, July, August, and September. These results reflect the model’s exceptional performance in predicting climate patterns during these months, particularly in the stable summer months. This suggests that the GNN model excels in recognizing and adapting to distinctive climatic patterns, resulting in highly accurate predictions.</p>
<p></p>
<h5>Sliding Window Analysis for Stable and Unstable Climate Data.</h5>
<p></p>
<p>For classification, we split our graph dataset into ‘stable’ and ‘unstable’ groups based on average cosine similarities between consecutive years. This method segmented the global dataset into stable and unstable categories for our sliding window analysis. Using 20,000 city-year combinations, we set a window size of 30 (𝑊 = 30) and a shift size of 6 (𝑆 = 6), facilitating precise computations for both stable and unstable datasets. Each graph contains 30 nodes (𝐺 = 30), with a shift of 4 (𝑆𝑔 = 4) between successive graphs, resulting in a total of 1648 small graphs.</p>
<p></p>
<p>In our study, GNN graph classification for stable climate cities starts with moderate accuracy in February, significantly improves by May reaching a peak of 100%, and maintains high accuracy through the summer months, only to dip in October with a slight recovery in November. In contrast, unstable climate cities start with near-random accuracy in February, improve steadily, peak in August, and then decline sharply, returning to early-year levels by December. This indicates the model’s varying adaptability to stable and unstable climate patterns throughout the year.</p>
<p></p>
<p><a href="#">
    <img src="/img/slidingWindow6.jpg" alt="Post Sample Image" width="678" />
</a></p>
<p></p>
<p></p>
<p>Analysis starting from January 1 shows that the model’s performance is influenced by the time of year. Unstable climates see low accuracies in the early and late parts of the year, suggesting limited learning during these periods. Conversely, stable climates exhibit significant improvements in accuracy during spring and summer, indicating effective data integration. However, the model’s performance overall is subject to fluctuations, peaking in the summer months before declining towards the end of the year, highlighting the challenges in generalizing across seasonal variations in climate data.</p>
<p></p>

<p></p>
<h4>Code Details</h4>
<p></p>
<p>The <code class="language-plaintext highlighter-rouge">create_segments_df</code> function segments a specified column from a DataFrame into fixed-size windows. For each segment, it adds context such as the start date, row index, and column label. The function then combines these segments into a new DataFrame. This is useful for time series analysis or preparing data for machine learning models.</p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">create_segments_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">column_name</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span><span class="n">columnLabel</span><span class="p">):</span>
    <span class="n">segments</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">-</span> <span class="n">window_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">shift</span><span class="p">):</span>
        <span class="n">segment</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">window_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="n">column_name</span><span class="p">]].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">segment</span> <span class="o">=</span> <span class="n">segment</span><span class="p">.</span><span class="n">T</span>  <span class="c1"># Transpose to get the segment as a row
</span>        <span class="n">segment</span><span class="p">[</span><span class="sh">'</span><span class="s">start_date</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
        <span class="n">segment</span><span class="p">[</span><span class="sh">'</span><span class="s">rowIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">rowIndex</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
        <span class="n">segment</span><span class="p">[</span><span class="sh">'</span><span class="s">theColumn</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">column_name</span>
        <span class="n">segment</span><span class="p">[</span><span class="sh">'</span><span class="s">columnLabel</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">columnLabel</span>
        <span class="n">segments</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">segment</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">segments</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>
<p>The <code class="language-plaintext highlighter-rouge">group_segments</code> function takes a DataFrame of segments and groups them into larger segments based on specified sizes and shifts. It adds a group index to each group and combines them into a new DataFrame. This is useful for aggregating data over larger windows, essential for graph-based models or detailed data analysis.</p>
<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">group_segments</span><span class="p">(</span><span class="n">segments_df</span><span class="p">,</span> <span class="n">group_size</span><span class="p">,</span> <span class="n">group_shift</span><span class="p">):</span>
    <span class="n">grouped_segments</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">group_index</span> <span class="o">=</span> <span class="mi">0</span>  
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">segments_df</span><span class="p">)</span> <span class="o">-</span> <span class="n">group_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">group_shift</span><span class="p">):</span>
        <span class="n">group</span> <span class="o">=</span> <span class="n">segments_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">group_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">group</span><span class="p">[</span><span class="sh">'</span><span class="s">graphIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">group_index</span>  <span class="c1"># Assign group index
</span>        <span class="n">grouped_segments</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">group</span><span class="p">)</span>
        <span class="n">group_index</span> <span class="o">+=</span> <span class="mi">1</span>  
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">grouped_segments</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>
<p>Take columns <code class="language-plaintext highlighter-rouge">col1</code> and <code class="language-plaintext highlighter-rouge">col2</code> from a dataset, fill NaN values in with their mean values and scale these columns using MinMaxScaler.</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="nc">MinMaxScaler</span><span class="p">()</span>
<span class="n">fx_data</span><span class="o">=</span><span class="n">df</span>
<span class="k">if</span> <span class="n">col1</span> <span class="ow">in</span> <span class="n">fx_data</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">fx_data</span><span class="p">[</span><span class="n">col1</span><span class="p">]</span> <span class="o">=</span> <span class="n">fx_data</span><span class="p">[</span><span class="n">col1</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">fx_data</span><span class="p">[</span><span class="n">col1</span><span class="p">].</span><span class="nf">mean</span><span class="p">())</span>
    <span class="n">fx_data</span><span class="p">[</span><span class="n">col1</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">fx_data</span><span class="p">[[</span><span class="n">col1</span><span class="p">]])</span>
<span class="k">if</span> <span class="n">col2</span> <span class="ow">in</span> <span class="n">fx_data</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">fx_data</span><span class="p">[</span><span class="n">col2</span><span class="p">]</span> <span class="o">=</span> <span class="n">fx_data</span><span class="p">[</span><span class="n">col2</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">fx_data</span><span class="p">[</span><span class="n">col2</span><span class="p">].</span><span class="nf">mean</span><span class="p">())</span>
    <span class="n">fx_data</span><span class="p">[</span><span class="n">col2</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">fx_data</span><span class="p">[[</span><span class="n">col2</span><span class="p">]])</span></code></pre></figure>

<p></p>
<p></p>

<p>The code creates segments from two columns (<code>col1</code> and <code>col2</code>) of a dataset using the <code>create_segments_df</code> function, assigns node indices to each segment, and then groups these segments with the <code>group_segments</code> function. It combines the grouped segments into a final dataset, assigning a unique <span style="color: blue;">datasetIdx</span> to each. Finally, it generates metadata for each dataset index and merges it with the segment data to form <span style="color: blue;">graphList</span>.</p>

<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">columnLabel</span><span class="o">=</span><span class="mi">0</span>
<span class="n">segments1</span> <span class="o">=</span> <span class="nf">create_segments_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">col1</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span> <span class="n">columnLabel</span><span class="p">)</span>
<span class="n">columnLabel</span><span class="o">=</span><span class="mi">1</span>
<span class="n">segments2</span> <span class="o">=</span> <span class="nf">create_segments_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">col2</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span> <span class="n">columnLabel</span><span class="p">)</span>
<span class="n">segments1</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIndex</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">segments1</span><span class="p">.</span><span class="n">index</span>
<span class="n">segments2</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIndex</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">segments2</span><span class="p">.</span><span class="n">index</span>
<span class="n">grouped_segments1</span> <span class="o">=</span> <span class="nf">group_segments</span><span class="p">(</span><span class="n">segments1</span><span class="p">,</span> <span class="n">group_size</span><span class="p">,</span> <span class="n">group_shift</span><span class="p">)</span>
<span class="n">grouped_segments2</span> <span class="o">=</span> <span class="nf">group_segments</span><span class="p">(</span><span class="n">segments2</span><span class="p">,</span> <span class="n">group_size</span><span class="p">,</span> <span class="n">group_shift</span><span class="p">)</span>
<span class="n">dataSet</span><span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">grouped_segments1</span><span class="p">,</span> <span class="n">grouped_segments2</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">dataSet</span><span class="p">[</span><span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">dataSet</span><span class="p">[</span><span class="sh">'</span><span class="s">columnLabel</span><span class="sh">'</span><span class="p">]</span><span class="o">*</span><span class="n">graphMax</span><span class="o">+</span><span class="n">dataSet</span><span class="p">[</span><span class="sh">'</span><span class="s">graphIndex</span><span class="sh">'</span><span class="p">]</span>
<span class="n">dataSubset</span> <span class="o">=</span> <span class="n">dataSet</span><span class="p">[[</span><span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">graphIndex</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">columnLabel</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">theColumn</span><span class="sh">'</span><span class="p">]].</span><span class="nf">drop_duplicates</span><span class="p">()</span>
<span class="n">graphMeta</span> <span class="o">=</span> <span class="n">dataSet</span><span class="p">.</span><span class="nf">groupby</span><span class="p">([</span> <span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">])[</span><span class="sh">'</span><span class="s">start_date</span><span class="sh">'</span><span class="p">].</span><span class="nf">agg</span><span class="p">([</span><span class="sh">'</span><span class="s">min</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">max</span><span class="sh">'</span><span class="p">])</span>
<span class="n">graphList</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">dataSubset</span><span class="p">,</span> <span class="n">graphMeta</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">datasetIdx</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>

<p></p>

<p>Continuation of coding is described in our previous study, <a href="http://sparklingdataocean.com/2023/02/11/cityTempGNNgraphs/">“GNN Graph Classification for Climate Change Patterns: Graph Neural Network (GNN) Graph Classification - A Novel Method for Analyzing Time Series Data”</a>. This current work continues the same coding methodology for both city graphs and sliding window graphs.</p>

<p></p>
<h4>Comparison of GNN Graph Classification Methods.</h4>
<p></p>
<p>In this research, we evaluated two distinct GNN Graph Classification techniques for analyzing climate data: the city-graph and the sliding window graph methods. The city-graph method assigns a node to each city-year pair, connecting them based on the cosine similarity of their temperature profiles, making it particularly suited for analyzing long-term climate trends. In contrast, the sliding window technique divides time series data into overlapping segments to form graphs, adeptly identifying short-term climate variations.</p>
<p></p>
<p>Both techniques were applied to the same dataset to compare their effectiveness in categorizing cities by climate stability. We found that the city-graph method more accurately discerned long-term climate stability, whereas the sliding window approach excelled in detecting short-term climate changes. Therefore, the choice of method depends on the specific objectives of the analysis: the city-graph is preferable for examining extended trends, while the sliding window method is ideal for investigating immediate climatic shifts.</p>
<p></p>

<p></p>

<p></p>

<p></p>
<h3>In Conclusion</h3>
<p></p>

<p>GNN graph classification has shown its strength in mapping complex relationships within graph-based datasets, making it a versatile tool in fields ranging from molecular dynamics to social network analysis. This versatility extends to climate data analysis, where it aids in identifying stable versus unstable climate patterns across cities by evaluating average cosine similarities of yearly temperature fluctuations. The addition of the sliding window graph approach further refines our study, enabling the model to continuously integrate new data and offer a detailed view of changing climate patterns. This technique is adept at capturing the dynamic nature of climate data, allowing for a more nuanced analysis of temporal trends and making it particularly suitable for managing the variable nature of climate data. This method’s ability to prioritize recent data over older information is crucial for adapting to the fast-paced changes characteristic of climate patterns.</p>
<p></p>
<p>In this study, we have leveraged GNN graph classification to address the complex challenge of analyzing climate patterns across different geographic locales, underscoring the method’s adaptability and broad applicability. Our research aimed explicitly at harnessing the potential of GNNs to distinguish between stable and unstable climate conditions in cities worldwide, using average cosine similarities of annual temperature variations as a novel classification metric. By integrating the sliding window graph approach, we have enhanced our model’s ability to dynamically assimilate and refresh data, offering a granular perspective on the fluctuating climate patterns and their implications over time.</p>
<p></p>
<p></p>
<p><a href="#">
    <img src="/img/slidingWindow7.jpg" alt="Post Sample Image" width="678" />
</a></p>
<p></p>
<p>This investigation has demonstrated that while equatorial cities exhibit consistency in climate stability, higher latitude cities experience more pronounced fluctuations. Remarkably, our analysis also brought to light certain anomalies, such as Mediterranean cities with unexpectedly consistent climates and cities in China and Mexico with notable climate variability. These findings highlight the critical importance of considering local geographical and climatic factors in climate studies and underscore the nuanced capabilities of GNN models in detecting subtle climate dynamics.</p>
<p></p>
<p>Ultimately, our study reinforces the utility of GNN graph classification, especially with the incorporation of the sliding window approach, as a potent tool for dissecting and understanding climate data. This method does not merely augment the predictive accuracy of our models but significantly bolsters their adaptability to ongoing climate changes, offering a richer comprehension of the complex interplay of factors influencing global climate trends. As such, GNN graph classification emerges as an indispensable instrument in the ongoing efforts to tackle the multifaceted challenges posed by global climate change, paving the way for more informed and effective climate resilience strategies.</p>

<p></p>

<p></p>

<p></p>
<p></p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[The use of Graph Neural Networks (GNNs) in time series analysis represents a rising field of study, particularly in the context of GNN Graph Classification, a technique traditionally applied in disciplines such as biology and chemistry. Our research repurposes GNN Graph Classification for the analysis of time series climate data, focusing on two distinct methodologies: the city-graph method, which effectively captures static temporal snapshots, and the sliding window graph method, adept at tracking dynamic temporal changes. This innovative application of GNN Graph Classification within time series data enables the uncovering of nuanced data trends. We demonstrate how GNNs can construct meaningful graphs from time series data, showcasing their versatility across different analytical contexts. A key finding is GNNs’ adeptness at adapting to changes in graph structure, which significantly improves outlier detection. This enhances our understanding of climate patterns and suggests broader applications of GNN Graph Classification in analyzing complex data systems beyond traditional time series analysis. Our research seeks to fill a gap in current studies by providing an examination of GNNs in climate change analysis, highlighting the potential of these methods in capturing and interpreting intricate data trends.]]></summary></entry><entry><title type="html">Uncovering Hidden Triangles</title><link href="http://localhost:4000/2023/11/23/hiddenTriangles/" rel="alternate" type="text/html" title="Uncovering Hidden Triangles" /><published>2023-11-23T07:00:00-05:00</published><updated>2023-11-23T07:00:00-05:00</updated><id>http://localhost:4000/2023/11/23/hiddenTriangles</id><content type="html" xml:base="http://localhost:4000/2023/11/23/hiddenTriangles/"><![CDATA[<p><h3>Conference Highlights</h3>
This research was presented at the 17th International Conference on Information Technology and Applications (ICITA 2023) that was held in Turin, Italy from October 20–22, 2023.
<p></p>
Paper 'Uncovering Hidden Connections: Granular Relationship Analysis in Knowledge Graphs' is estimated to be published in February, 2024.
<p></p>
To complement the text understanding, in this post we will feature some slides from the conference presentation.

<p></p>
<p><h3>Uncovering Hidden Triangles in Knowledge Graphs </h3>

<p>In recent years, knowledge graphs have become a powerful tool for integrating and analyzing data and shedding lights on the connections between entities. This study narrows its focus on unraveling detailed relationships within knowledge graphs, placing special emphasis on the role of graph connectors through link predictions and triangle analysis.</p>

<p>Using Graph Neural Network (GNN) Link Prediction models and graph triangle analysis in knowledge graphs, we have managed to uncover relationships that had been previously undetected or overlooked. Our findings mark a significant milestone, paving the way for more comprehensive exploration into the complex relationships that exist within knowledge graphs.</p>

<p>This study initiates further research in the area of unveiling the hidden dynamics and connections in knowledge graphs. The insights from this work promise to redefine our understanding of knowledge graphs and their potential for unlocking the complexities of data interrelationships.</p>

<p><h3>Introduction</h3>

<h4>Deep Learning, Knowledge Graphs and the Emergence of GNN</h4>

<p>The year 2012 was pivotal for deep learning and knowledge graphs. In that year, after AlexNet was introduced, a Convolutional Neural Network (CNN) highlighted the power of image classification techniques. Simultaneously, Google's introduction of knowledge graphs transformed data integration and management.</p>

<p>For many years, deep learning and knowledge graphs developed independently. CNN proved effective with grid-structured data but struggled with graph-structured data. On the other hand, graph techniques excelled in representing and reasoning about graph data but lacked deep learning's power. The late 2010s Graph Neural Networks (GNN) bridged this gap and emerged as a potent tool for processing graph-structured data through deep learning techniques.</p>

<p>For years, we've relied on binary graph structures, simplifying complex relationships into 'yes' or 'no', '1' or '0'. But in our ever-evolving world, is that enough? We believed there was more depth to be explored. Thus, we turned to Graph Neural Networks, a frontier technology, to help us transition from these fixed binaries to a more fluid, continuous space. </p>

<h4>Our Past Experiments in Rewiring of Knowledge Graphs</h4>

<p>In our previous study <u><a href="https://www.scitepress.org/Link.aspx?doi=10.5220/0011664400003393">'Rewiring Knowledge Graphs by Link Predictions'</a></u>

we delved into the exploration of knowledge graph rewiring to reveal unknown relationships between modern art artists, employing GNN link prediction models. By training these models on Wikipedia articles about modern art artists' biographies and leveraging GNN link prediction models, we identified previously unknown relationships between artists.</p>

<p>To rewire knowledge graphs, we adopted two distinct methods. First, we utilized a traditional method that involved a full-text analysis of articles and calculation of cosine similarities between embedded nodes. The second method involved the construction of semantic graphs based on the distribution of pairs of co-located words, and edges between nodes that share common words.</p>


<h4>New Study: Focusing on Graph Triangles</h4>
<p></p>

In this study, we continue to leverage the same data source and employ similar techniques for graph representation. However, we introduce a novel approach of comparing two documents and examining entity relationships at granular level. Specifically, we concentrate on analyzing graph triangles, where one side displays a stronger connection than the other two sides.</p>

<p>Let's take a moment to appreciate the evolution and elevation that GNN Link Prediction brings to the table. Remember the days of black and white television? Now imagine transitioning from that to a high-definition colored TV. That's the kind of transformative leap we're talking about when moving from traditional graph representations to GNN Link Prediction. Instead of just binary relationships, we're now operating on a continuous spectrum. Why is this so revolutionary? Because it allows us to see the subtle intricacies, the patterns that were once invisible. We're no longer just categorizing relationships as 'connected' or 'not connected'; we're exploring the depth, the weight, the very essence of these connections. It's like being given a magnifying glass to see the intricate patterns that were always there but previously overlooked. This shift not only boosts our prediction accuracy but also broadens our understanding of the complex web of relationships within our data.</p>



<p>In the vast network of relationships, it's essential to understand not just who is connected to whom, but also the depth and nature of these connections. Let's take a simplified example featuring Alice, Beth, and their college. Alice and Beth shared a close bond during their college days, so their connection is strong. But when we look at their individual relationships with the college, it's more of an association by attendance, making it a weaker connection. Picture a triangle with its vertices representing Alice, Beth, and their college. The strength of the links in this triangle varies. The college acts as a 'Graph Connector'—a node that forms a bridge between different entities. Now, why is this distinction crucial? Because understanding these nuanced connections ensures we don't treat all relationships equally. It enables us to discern, prioritize, and gain richer insights into our network, ensuring our analysis is both detailed and accurate.</p>

<p></p>
<a href="#">
    <img src="/img/slideTurino1.jpg" alt="Post Sample Image" width="628" />
</a>
<p></p>

<p>Analyzing graph triangles offers insights into the strength of connections between nodes within a network. Looking at the relationships among nodes A, B, and C, we are focusing on the strength of the connection between nodes A and B compared to the connections involving node C. Node C, identified as a 'graph connector' node, is critical in facilitating communication and interaction between nodes A and B. Serving as a link, node C allows the smooth flow of information and relationships between the strongly connected nodes A and B.
<p></p>
<p></p>

<p></p>
As analogy, imagine early 20th-century Vienna's intellectual scene as a dynamic network. Berta Zuckerkandl's salon stood out as one of central nodes, orchestrating and facilitating connections.
Her salon served as the platform, connecting diverse talents like artists, scientists, and doctors. Each gathering at her salon can be seen as the creation of 'links' between nodes.
Berta stands as a quintessential 'graph connector' and her role ensures not just random interactions, but impactful connections, emphasizing her integral position in this vibrant intellectual web.
<p></p>
<a href="#">
    <img src="/img/salon1c.jpg" alt="Post Sample Image" width="1000" />
</a>
<p></p>


<p></p>
This characterizes the importance of graph connector nodes in enhancing the network's overall connectivity and functionality, fostering collective behaviors and dynamics among interconnected nodes.

<p></p>
<h4>Depicting Graph Connectors</h4>
<p></p>
To find graph connectors, we will look for graph triangles where one cosine similarity between the nodes is higher than other two cosine similarity values.  This implies a stronger connection between two nodes relative to the connections of two other node pairs.

<p></p>
When delving into the world of graphs, it's essential to recognize the key players, the 'Graph Connectors'. These connectors serve as bridges within the intricate web of nodes. So, how do we uncover them? Let's take a journey through our method.
First, we train our GNN Link Prediction model, which gives us the embeddings for each node. Think of these embeddings as unique signatures, encapsulating the essence of each node.
<p></p>
<a href="#">
    <img src="/img/slideTurino2.jpg" alt="Post Sample Image" width="628" />
</a>
<p></p>
With these embeddings in hand, we compute the cosines between every pair of nodes in each graph triangle. These cosine values measure the similarity between nodes, indicating the strength of their connection.
Finally, the crux of our methodology: identifying the Graph Connectors. Based on our cosine computations, we determine which node acts as a bridge between the other two. For instance, in a triangle comprising nodes A, B, and C - if the connection strength between A and B surpasses the other two connections, it's clear that C plays the pivotal role of the connector.
This method thus allows us to highlight nodes that play an essential role in maintaining the structure and connectivity of the graph.
<p></p>


<p></p>

Graph representation traditionally operates in binary terms: either pairs of nodes are connected by edges or they are not. When using binary edges in graph triangle analysis, we are limited to recognizing the presence or absence of connections between nodes. Such a black-and-white perspective can overlook the nuanced graph connectors.
<p></p>
By employing GNN link prediction models, we move beyond this limitation. GNN link prediction model transcends this binary structure by embedding nodes into continuous vector space, providing a spectrum of ways to compare and evaluate these vectors. This deeper representation makes it possible to identify and understand graph connectors that a simple binary analysis might overlook.

In essence, understanding the nuances of node relationships allows for more robust, dynamic, and insightful analyses, enabling richer interpretations and predictions based on graph data.
<p></p>

<h4>Employing Graph Triangle Analysis and the GraphSAGE Model</h4>

<p>In this study, we aim to compare our previous study's results with the findings obtained through granular graph triangle analysis. Specifically, we'll examine the Wikipedia articles related to Paul Klee and Joan Miró, who were deemed as highly disconnected artists in the previous study. By employing graph triangle analysis techniques, we'll unveil previously overlooked graph connectors and patterns between these artists.</p>

<p>For our GNN link prediction model, we'll use the GraphSAGE model. Unlike traditional approaches relying on the entire adjacency matrix information, GraphSAGE focuses on learning aggregator functions. This allows us to generate embeddings for new nodes based on their features and neighborhood information without the need to retrain the entire model.</p>

<p>It's crucial to note that the outputs of the GraphSAGE model in our study are not actual predicted links, but embedded graphs. These embedded graphs capture the relationships and structural information within the original graphs. While these embeddings can be used for predicting graph edges, we will specifically utilize them for graph triangle analysis to identify and explore graph connectors within the network. These graph connectors play a pivotal role in facilitating connections and interactions between nodes, offering valuable insights into network dynamics and relationships.</p>


<p></p>

<p><h3>Methods</h3>

<h4>Building a Knowledge Graph</h4>
<p></p>
In this section, we'll outline our strategy to formulate an introductory knowledge graph for each article. Our approach uses co-located word pairs as nodes, establishing links between pairs sharing common words. The method can be detailed in the following steps:
<p></p>
<ul>
<li><strong>Text Tokenization:</strong> Begin by breaking down the text from Wikipedia into individual words or 'tokens', while also excluding common stop words that don't contribute much to the overall meaning.</li>

<li><strong>Node Generation:</strong> Nodes in our knowledge graph are created from these co-located word pairs. These pairs of adjacent words from the text will form the basis of our graph.</li>

<li><strong>Edge Calculation:</strong> Edges are established between nodes that share common words. This generates a network of word chains within each article and enables the connection of different articles through these word chains. Conceptually, consider two pairs, pair1 and pair2, represented as:</li>
<p></p>
<pre>
    pair1=[leftWord1, rightWord1],
    pair2=[leftWord2, rightWord2]
</pre>
<p></p>
<li>If rightWord1 and leftWord2 are the same, then we have an edge, edge12, linking pair1 and pair2:</li>
<p></p>
<pre>
    edge12={pair1, pair2}
</pre>
<p></p>
<li><strong>Knowledge Graph Construction:</strong> With the nodes and edges defined, we can build the initial knowledge graph, visually representing the relationships between different co-located word pairs within and across the articles.</li>
</ul>
<p></p>

<p></p>
<a href="#">
    <img src="/img/slideTurino7.jpg" alt="Post Sample Image" width="628" />
</a>
<p></p>
<h4>Node Embedding</h4>
<p></p>

To encapsulate the complexities of the knowledge graph into our nodes and translate the text information into vectors, we're utilizing the 'all-MiniLM-L6-v2' transformer model from Hugging Face. This model is a part of the sentence-transformers family, purposely built to convert text into a dense vector space. The resultant vector space has 384 dimensions, providing a rich and multidimensional representation of our textual information.
<p></p>
<h4>Training a GNN Link Prediction Model</h4>
<p></p>
In our research, we've chosen to implement the GraphSAGE link prediction model proposed by Hamilton and others. This model is operationalized using the code provided in the DGL (Deep Graph Library) tutorial. It necessitates the transformation of the input graph data into an appropriate DGL data format. This transformation is a crucial step in preparing the data for the model training process.
<p></p>


<p></p>
<h4>Triangle Analysis on Graphs</h4>
<p></p>


    <p>To delve deeper into the intricacies of graph structures, we used <strong>graph triangle analysis</strong>. Here's a step-by-step breakdown of our methodology:</p>

    <ol>
        <li>First, potential triangles are generated by considering all possible combinations of three distinct nodes from within the graph.</li>
        <li>Second, for each identified triangle, we compute the cosine similarities between the nodes. This involves calculating three cosine similarity values for each triangle - one for each pairing of nodes.</li>
        <li>Triangles of interest are those where one cosine similarity stands out as being notably higher compared to the other two values. This implies a stronger connection between two nodes relative to the connections of the other node pairs.</li>
    </ol>

    <p>By focusing on such triangles, we can derive more insight into the underlying relationships between nodes. This allows us to uncover intricate patterns and gain a deeper understanding of the structural nuances present within the graph.</p>

<p></p>
<a href="#">
    <img src="/img/slideTurino4.jpg" alt="Post Sample Image" width="628" />
</a>
<p></p>

<h3>Experiments</h3>
<p></p>
In our exploration, we embarked on a transformative journey. We began by constructing semantic graphs, a process much like piecing together a puzzle, where each word forms a crucial piece, connecting with others to build a comprehensive picture. However, merely building the graph wasn't our end goal. To delve deeper into its intricate maze, we utilized Graph Triangle Analysis. This methodology allowed us to zoom in on specific relationships, akin to highlighting crucial intersections in a vast city map. It's through this refined lens that we transitioned from a broad understanding of the semantic landscape to pinpointing the connectors - the linchpins that hold the entire framework together, revealing a richer, more connected narrative.
<p></p>

<h4>Data Source</h4>
<p></p>

As the data source for this study we used a subset of text data from Wikipedia articles about 20 modern art artists:
<p></p>
<a href="#">
    <img src="/img/slideTurino6.jpg" alt="Post Sample Image" width="628" />
</a>
<p></p>
Building on our previous 'Knowledge Graph Rewiring' research, we initially identified artist connections. Now, we're digging deeper to uncover more intricate relationships between artists, using our past findings as a starting point.

<p></p>
In our pursuit of understanding artist interconnections, we took a focused look at two iconic figures of the art world: Paul Klee and Joan Miró. In our previous research, a curious observation emerged. Despite both artists being immersed in significant art movements, our data showed a pronounced disconnect between them. Klee, a Swiss maestro, was deeply rooted in Expressionism, while Miró, the Spanish virtuoso, was an embodiment of Surrealism. On the surface, these movements and their geographic roots seem to keep them apart. Yet, why did we zero in on these two? The intrigue lies in an understated influence: Miró's artistry was, in fact, inspired by Klee. This revelation hints at more profound, nuanced connections between them, suggesting that artistic interplay goes beyond just the obvious associations.

<p></p>
<a href="#">
    <img src="/img/slideTurino3.jpg" alt="Post Sample Image" width="628" />
</a>
<p></p>
<p></p>
<h4>Preparation of Input Data</h4>
<p></p>

We constructed a knowledge graph based on co-located word pairs as described in the Methods. section. For model input data for this study we selected Wikipedia articles about Paul Klee and Joan Miró:
</p><p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">subsetWordpair</span> <span class="o">=</span> <span class="n">cleanPairWords</span><span class="p">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">word1</span><span class="sh">'</span><span class="p">,</span>	<span class="sh">'</span><span class="s">word2</span><span class="sh">'</span>	<span class="p">]]</span>
<span class="n">subsetWordpair</span> <span class="o">=</span> <span class="n">subsetWordpair</span><span class="p">[</span><span class="n">subsetWordpair</span><span class="p">[</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">([</span><span class="mi">13</span><span class="p">,</span><span class="mi">19</span><span class="p">])]</span>
<span class="n">subsetWordpair</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">nodeList</span><span class="o">=</span><span class="n">subsetWordpair</span>
<span class="n">nodeList</span><span class="p">[</span><span class="sh">'</span><span class="s">idxPair</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">nodeList</span><span class="p">.</span><span class="n">index</span></code></pre></figure>


</p><p>
Node list:


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">nodeList1</span><span class="o">=</span><span class="n">nodeList</span><span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">word2</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">theWord</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">wordpair1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wordPairIdx</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">wordPairIdx1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxArtist1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxPair</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxPair1</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">nodeList2</span><span class="o">=</span><span class="n">nodeList</span><span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">word1</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">theWord</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">wordpair2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wordPairIdx</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">wordPairIdx2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxArtist2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxPair</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxPair2</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">allNodes</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">nodeList1</span><span class="p">,</span><span class="n">nodeList2</span><span class="p">,</span><span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">theWord</span><span class="sh">'</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">inner</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>


</p><p>
Get unique word pairs for embedding:


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">bagOfPairWords</span><span class="o">=</span><span class="n">nodeList</span>
<span class="n">bagOfPairWords</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">bagOfPairWords</span><span class="p">[</span><span class="sh">'</span><span class="s">bagPairWordsIdx</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">bagOfPairWords</span><span class="p">.</span><span class="n">index</span></code></pre></figure>



</p><p>
Node embedding:


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">wordpair_embeddings</span> <span class="o">=</span> <span class="n">modelST</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">bagOfPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">wordpair</span><span class="sh">"</span><span class="p">],</span><span class="n">convert_to_tensor</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>
Save embedded word pairs:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">imgPath</span><span class="o">=</span><span class="sh">'</span><span class="s">/content/drive/My Drive/NLP/</span><span class="sh">'</span>
<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">imgPath</span><span class="o">+</span><span class="sh">'</span><span class="s">wordpairs13b.pkl</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">wb</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">fOut</span><span class="p">:</span>
    <span class="n">pickle</span><span class="p">.</span><span class="nf">dump</span><span class="p">({</span><span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">:</span> <span class="n">bagOfPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">bagPairWordsIdx</span><span class="sh">"</span><span class="p">],</span>
                 <span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">:</span> <span class="n">bagOfPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">wordpair</span><span class="sh">"</span><span class="p">],</span>
                 <span class="sh">'</span><span class="s">artist</span><span class="sh">'</span><span class="p">:</span> <span class="n">bagOfPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">idxArtist</span><span class="sh">"</span><span class="p">],</span>
                 <span class="sh">'</span><span class="s">embeddings</span><span class="sh">'</span><span class="p">:</span> <span class="n">wordpair_embeddings</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()},</span> <span class="n">fOut</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="p">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span></code></pre></figure>

<p></p>
<h4>Transform Data to DGL Format</h4>


<p></p>

We trained our GNN link prediction model using the GraphSAGE model from the DGL library. More in-depth information and coding techniques for data preparation and encoding data into the DGL data format are available in our post <u><a href="http://sparklingdataocean.com/2022/11/09/knowledgeGraph4NlpGnn/"> 'Find Semantic Similarities by GNN Link Predictions'</a></u>.
<p></p>

<p></p>
Import DGL andd read saved data:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">dgl</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="n">itertools</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">scipy.sparse</span> <span class="k">as</span> <span class="n">sp</span>
<span class="kn">import</span> <span class="n">dgl.data</span>
<span class="kn">from</span> <span class="n">dgl.data</span> <span class="kn">import</span> <span class="n">DGLDataset</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">imgPath</span><span class="o">+</span><span class="sh">'</span><span class="s">wordpairs13b.pkl</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">rb</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">fIn</span><span class="p">:</span>
    <span class="n">stored_data</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">fIn</span><span class="p">)</span>
    <span class="n">gnn_index</span> <span class="o">=</span> <span class="n">stored_data</span><span class="p">[</span><span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">gnn_artist</span> <span class="o">=</span> <span class="n">stored_data</span><span class="p">[</span><span class="sh">'</span><span class="s">artist</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">gnn_words</span> <span class="o">=</span> <span class="n">stored_data</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">gnn_embeddings</span> <span class="o">=</span> <span class="n">stored_data</span><span class="p">[</span><span class="sh">'</span><span class="s">embeddings</span><span class="sh">'</span><span class="p">]</span>
<span class="n">df_gnn_words</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">gnn_words</span><span class="p">)</span>
<span class="n">df_gnn_words</span><span class="p">[</span><span class="sh">'</span><span class="s">idxNode</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">df_gnn_words</span><span class="p">.</span><span class="n">index</span></code></pre></figure>


</p><p>
Transform data to DGL format:


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">art_edges</span><span class="o">=</span><span class="n">allNodes</span><span class="p">[[</span><span class="sh">'</span><span class="s">idxPair1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxPair2</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">unpickEdges</span><span class="o">=</span><span class="n">art_edges</span>
<span class="n">edge_index</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">unpickEdges</span><span class="p">[[</span><span class="sh">'</span><span class="s">idxPair1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxPair2</span><span class="sh">'</span><span class="p">]].</span><span class="n">T</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="o">=</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">gNew</span><span class="o">=</span><span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="p">))</span>
<span class="n">gNew</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">gnn_embeddings</span>
<span class="n">gNew</span><span class="o">=</span><span class="n">dgl</span><span class="p">.</span><span class="nf">add_self_loop</span><span class="p">(</span><span class="n">gNew</span><span class="p">)</span>
<span class="n">g</span><span class="o">=</span><span class="n">gNew</span></code></pre></figure>


<p></p>
<h4>Model Training</h4>
<p></p>
Split edge set for training and testing
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">g</span><span class="p">.</span><span class="nf">edges</span><span class="p">()</span>
<span class="n">eids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_edges</span><span class="p">())</span>
<span class="n">eids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">permutation</span><span class="p">(</span><span class="n">eids</span><span class="p">)</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">eids</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="n">g</span><span class="p">.</span><span class="nf">number_of_edges</span><span class="p">()</span> <span class="o">-</span> <span class="n">test_size</span>
<span class="n">test_pos_u</span><span class="p">,</span> <span class="n">test_pos_v</span> <span class="o">=</span> <span class="n">u</span><span class="p">[</span><span class="n">eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]],</span> <span class="n">v</span><span class="p">[</span><span class="n">eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]]</span>
<span class="n">train_pos_u</span><span class="p">,</span> <span class="n">train_pos_v</span> <span class="o">=</span> <span class="n">u</span><span class="p">[</span><span class="n">eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]],</span> <span class="n">v</span><span class="p">[</span><span class="n">eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]]</span></code></pre></figure>


<p></p>
Find all negative edges and split them for training and testing
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">adj</span> <span class="o">=</span> <span class="n">sp</span><span class="p">.</span><span class="nf">coo_matrix</span><span class="p">((</span><span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">u</span><span class="p">)),</span> <span class="p">(</span><span class="n">u</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">v</span><span class="p">.</span><span class="nf">numpy</span><span class="p">())))</span>
<span class="n">adj_neg</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">adj</span><span class="p">.</span><span class="nf">todense</span><span class="p">()</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>
<span class="n">neg_u</span><span class="p">,</span> <span class="n">neg_v</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">adj_neg</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">neg_eids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">neg_u</span><span class="p">),</span> <span class="n">g</span><span class="p">.</span><span class="nf">number_of_edges</span><span class="p">())</span>
<span class="n">test_neg_u</span><span class="p">,</span> <span class="n">test_neg_v</span> <span class="o">=</span> <span class="n">neg_u</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]],</span> <span class="n">neg_v</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]]</span>
<span class="n">train_neg_u</span><span class="p">,</span> <span class="n">train_neg_v</span> <span class="o">=</span> <span class="n">neg_u</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]],</span> <span class="n">neg_v</span><span class="p">[</span><span class="n">neg_eids</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]]</span>
<span class="n">train_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">remove_edges</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">eids</span><span class="p">[:</span><span class="n">test_size</span><span class="p">])</span>
<span class="kn">from</span> <span class="n">dgl.nn</span> <span class="kn">import</span> <span class="n">SAGEConv</span></code></pre></figure>


<p></p>
Create model: build a two-layer GraphSAGE model
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">GraphSAGE</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_feats</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">GraphSAGE</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">SAGEConv</span><span class="p">(</span><span class="n">in_feats</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">,</span> <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">SAGEConv</span><span class="p">(</span><span class="n">h_feats</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">,</span> <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">in_feat</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">in_feat</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span>

<span class="n">train_pos_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">train_pos_u</span><span class="p">,</span> <span class="n">train_pos_v</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>
<span class="n">train_neg_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">train_neg_u</span><span class="p">,</span> <span class="n">train_neg_v</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>

<span class="n">test_pos_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">test_pos_u</span><span class="p">,</span> <span class="n">test_pos_v</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>
<span class="n">test_neg_g</span> <span class="o">=</span> <span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">test_neg_u</span><span class="p">,</span> <span class="n">test_neg_v</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">g</span><span class="p">.</span><span class="nf">number_of_nodes</span><span class="p">())</span>

<span class="kn">import</span> <span class="n">dgl.function</span> <span class="k">as</span> <span class="n">fn</span>

<span class="k">class</span> <span class="nc">DotPredictor</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">g</span><span class="p">.</span><span class="nf">local_scope</span><span class="p">():</span>
            <span class="n">g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span>
            <span class="c1"># Compute a new edge feature named 'score' by a dot-product between the
</span>            <span class="c1"># source node feature 'h' and destination node feature 'h'.
</span>            <span class="n">g</span><span class="p">.</span><span class="nf">apply_edges</span><span class="p">(</span><span class="n">fn</span><span class="p">.</span><span class="nf">u_dot_v</span><span class="p">(</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">))</span>
            <span class="c1"># u_dot_v returns a 1-element vector for each edge so you need to squeeze it.
</span>            <span class="k">return</span> <span class="n">g</span><span class="p">.</span><span class="n">edata</span><span class="p">[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">MLPPredictor</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">W1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">h_feats</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">h_feats</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">W2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">h_feats</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">apply_edges</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">edges</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">edges</span><span class="p">.</span><span class="n">src</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">],</span> <span class="n">edges</span><span class="p">.</span><span class="n">dst</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">]],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="nc">W2</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nc">W1</span><span class="p">(</span><span class="n">h</span><span class="p">))).</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)}</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">g</span><span class="p">.</span><span class="nf">local_scope</span><span class="p">():</span>
            <span class="n">g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span>
            <span class="n">g</span><span class="p">.</span><span class="nf">apply_edges</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">apply_edges</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">g</span><span class="p">.</span><span class="n">edata</span><span class="p">[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">]</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">GraphSAGE</span><span class="p">(</span><span class="n">train_g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="nc">DotPredictor</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">):</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">])</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">pos_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">neg_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])])</span>
    <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="nf">binary_cross_entropy_with_logits</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compute_auc</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">):</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">]).</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span>
        <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">pos_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">neg_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]).</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="nf">roc_auc_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span></code></pre></figure>



<p></p>
Set up loss and optimizer:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">itertools</span><span class="p">.</span><span class="nf">chain</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">pred</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span></code></pre></figure>


<p></p>
Model training:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">all_logits</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>
    <span class="c1"># forward
</span>    <span class="n">h</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">train_g</span><span class="p">,</span> <span class="n">train_g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">train_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">)</span>

    <span class="c1"># backward
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">e</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">In epoch {}, loss: {}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span></code></pre></figure>



<p></p>
Check results:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="n">pos_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_pos_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">neg_score</span> <span class="o">=</span> <span class="nf">pred</span><span class="p">(</span><span class="n">test_neg_g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">AUC</span><span class="sh">'</span><span class="p">,</span> <span class="nf">compute_auc</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">))</span></code></pre></figure>


<p></p>
The model was trained using the following parameters:
<p></p>
<ul>
  <li>Number of nodes: 3,274</li>
  <li>Number of edges: 13,709</li>
</ul>
Embedded node features were represented as PyTorch tensors of size [3274, 384]. The re-embedded nodes resulted in a tensor of size [3274, 64].

<p></p>
To evaluate our model's performance, we calculated the Area Under the Curve (AUC) accuracy metric, which offers an indication of the model's predictive power. In our case, the accuracy metric was 0.848, demonstrating a high level of accuracy in the model's predictions.

<p></p>
<h4>Interpret Model Results</h4>
<p></p>
<p></p>
Model results:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">gnnResults</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">h</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">())</span></code></pre></figure>

<p></p>
Cosine similarity function and model scores:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">math</span> <span class="kn">import</span> <span class="n">sin</span><span class="p">,</span> <span class="n">cos</span><span class="p">,</span> <span class="n">sqrt</span><span class="p">,</span> <span class="n">atan2</span><span class="p">,</span> <span class="n">radians</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="k">def</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">a_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">a_norm</span><span class="p">,</span> <span class="n">b_norm</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span></code></pre></figure>


<p></p>
Model scores:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cosine_scores_gnn</span> <span class="o">=</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>
<h4>Graph Triangle Analysis</h4>
<p></p>

<p></p>
Define graph and graph triangles:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="n">G</span><span class="o">=</span><span class="n">nx</span><span class="p">.</span><span class="nf">from_pandas_edgelist</span><span class="p">(</span><span class="n">allNodes</span><span class="p">,</span>  <span class="sh">"</span><span class="s">wordpair1</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">wordpair2</span><span class="sh">"</span><span class="p">)</span>
<span class="n">triangles</span> <span class="o">=</span> <span class="p">[</span><span class="n">clique</span> <span class="k">for</span> <span class="n">clique</span> <span class="ow">in</span> <span class="n">nx</span><span class="p">.</span><span class="nf">enumerate_all_cliques</span><span class="p">(</span><span class="n">G</span><span class="p">)</span> <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">clique</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">]</span></code></pre></figure>


<p></p>
Calculate cosine similarities within graph triangles:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">triangleStats</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">triangle</span> <span class="ow">in</span> <span class="n">triangles</span><span class="p">:</span>
  <span class="n">idx3</span><span class="o">=</span><span class="nf">list</span><span class="p">(</span><span class="n">nodeList</span><span class="p">[</span><span class="n">nodeList</span><span class="p">[</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">triangle</span><span class="p">)][</span><span class="sh">'</span><span class="s">bagPairWordsIdx</span><span class="sh">'</span><span class="p">])</span>
  <span class="k">for</span> <span class="n">pair1</span> <span class="ow">in</span> <span class="n">idx3</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">pair2</span> <span class="ow">in</span> <span class="n">idx3</span><span class="p">:</span>
      <span class="nf">if </span><span class="p">(</span><span class="n">pair1</span><span class="o">&lt;</span><span class="n">pair2</span><span class="p">):</span>
        <span class="n">score</span><span class="o">=</span><span class="n">dfWordPairs</span><span class="p">[(</span><span class="n">dfWordPairs</span><span class="p">[</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">pair1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">dfWordPairs</span><span class="p">[</span><span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">pair2</span><span class="p">)][</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span>
        <span class="n">triangleStats</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">triangle</span><span class="sh">'</span><span class="p">:</span><span class="n">triangle</span><span class="p">,</span><span class="sh">'</span><span class="s">pair1</span><span class="sh">'</span><span class="p">:</span><span class="n">pair1</span><span class="p">,</span><span class="sh">'</span><span class="s">pair2</span><span class="sh">'</span><span class="p">:</span><span class="n">pair2</span><span class="p">,</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span><span class="n">score</span><span class="p">})</span></code></pre></figure>


<p></p>
Convert to triangle statistics to pandas data frame and save the results:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">triangleStatsDF</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">triangleStats</span><span class="p">)</span>
<span class="n">triangleStatsDF</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="n">imgPath</span><span class="o">+</span><span class="sh">'</span><span class="s">triangleStats.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></figure>


<p></p>
<h3>Insights from Graph Triangles</h3>
<p></p>
In our exploration of the embedded graph triangles, we utilized ordered edge weights as a basis for analysis. From this process, we identified a total of 46 graph triangles. Among these, several met the criteria for containing a graph connector node, acting as a bridge or link between the other nodes within the graph triangle.


<p></p>
<p></p>
<a href="#">
    <img src="/img/slideTurino5.jpg" alt="Post Sample Image" width="628" />
</a>
<p></p>
<!-- <p></p>
<a href="#">
    <img src="/img/connectors5.jpg" alt="Post Sample Image" width="567">
</a> -->


<p></p>
Our graph triangle analysis is illustrated in the fugure above. In this figure, the numbers you see next to each edge represent the cosine similarities between the vectors of the corresponding nodes. These numbers essentially reflect the strength of the connection between two nodes.
<p></p>
Imagine a vast network, a spider web of connections. Within this web, our goal was to uncover specific points, the linchpins holding everything together. These are our Graph Connectors. How do we identify them? We delve into Triangle Analysis. In this analysis, the sides of the triangles, the 'edges', represent how similar two nodes are to each other, quantified using cosine similarities. The Graph Connectors stand out as the acute-angled vertices, the points where threads converge sharply, indicating their pivotal role in the network's architecture. It's akin to finding the central anchors in our intricate web.

<p></p>
The patterns observed in these graph triangles provide valuable insights into the intricate relationships within our knowledge graph. More importantly, they shed light on the crucial role of graph connectors - the nodes that act as bridges, facilitating communication and interaction between other nodes within the graph triangle.</p>
<p></p>
<h4>Observations and Insights</h4>
<p></p>
As we compare the results of our previous study <u><a href="https://www.scitepress.org/Link.aspx?doi=10.5220/0011664400003393">'Rewiring Knowledge Graphs by Link Predictions'</a></u>
with the findings of this current study, we can notice both similarities and differences in the outcomes.

<h5>Similarities:</h5>

<ul>
  <li>Both studies utilized Wikipedia articles focusing on the biographies of modern art artists.</li>
  <li>The same semantic knowledge graph building method was employed in both studies.</li>
  <li>The GraphSAGE GNN link prediction model was utilized for graph embedding in both studies.</li>
</ul>

<h5>Differences:</h5>

<ul>
  <li>In the previous study, the GNN link prediction model results were aggregated by artists. The analysis suggested that Paul Klee and Joan Miró were highly disconnected artists.</li>
  <li>In contrast, the current study adopts a more granular approach to analyze the relationships between the artists. By using graph triangle analysis techniques, we were able to uncover potentially interesting relationships that were not previously identified.</li>
</ul>

<p>The example graph triangles, like those seen in picture above, demonstrate the crucial role of graph connectors. The numbers placed next to the edges represent the cosine similarities between the vectors of the corresponding nodes, providing valuable insights into the relationships and patterns within the knowledge graph.</p>


<p></p>
<p><h3>Conclusion</h3>



<p>In this study, we utilized GNN link prediction techniques and graph triangle analysis to delve deeper into the intricacies of relationships within knowledge graphs. Leveraging these techniques, we demonstrated their potency in revealing patterns that might have previously gone unnoticed.</p>

<p>Our comparison between granular relationship analysis and aggregated relationships unveiled some compelling insights. In our previous study, based on an aggregated view, the artists Paul Klee and Joan Miró were deemed highly disconnected. However, that analysis failed to capture the finer nuances of their relationships. By applying graph triangle analysis techniques in this study, we found potentially significant connections and patterns between these artists, overlooked in the aggregated results.</p>

<p>This demonstrates the significance of granular analysis in comprehending the complex relationships within knowledge graphs. A deeper probe into the relationships between entities uncovers hidden associations and provides fresh insights into the interconnected data.</p>

<p>We have taken a step in exploring the concept of knowledge graph connectors. Through the use of GNN link prediction models and graph triangle analysis techniques, we have exposed the presence of graph connectors. These connectors play a critical role in facilitating connections and interactions between entities within the knowledge graphs.</p>

<p></p>

<p>

Our study reveals new ways to understand complex connections in knowledge graphs, shedding light on hidden relationships and dynamics. This study is the beginning of a journey towards gaining a deeper understanding of the hidden relationships and dynamics within knowledge graphs.
</p>
<p></p>

<p><h3>Exploring Future Horizons with Graph Connectors</h3>

<p>Envision the transformative impact of applying our advanced graph connector techniques across various fields:</p>

<ul>
    <li><strong>Medicine:</strong> Illuminate critical genetic pathways influencing diseases, paving the way for bespoke therapies and preventive measures.</li>
    <li><strong>Social Networks:</strong> Uncover hidden influencers and emergent trends, reshaping our understanding of digital interactions.</li>
    <li><strong>Finance:</strong> Identify key firms integral to market stability, potentially revolutionizing investment and economic strategies.</li>
    <li><strong>Criminal Networks:</strong> Reveal the masterminds behind criminal activities, enhancing law enforcement capabilities.</li>
    <li><strong>Education:</strong> Discover central interdisciplinary subjects that serve as educational connectors, promoting comprehensive learning experiences.</li>
    <li><strong>Supply Chains:</strong> Spot critical intermediaries to streamline production, boosting efficiency and reducing operational costs.</li>
</ul>

<p>The possibilities are boundless, and the diverse applications of our graph connector methods promise a future rich with insight and innovation!</p>


<p></p>


<p></p>
<p><h3>Next Post - Graph Connectors</h3>

In the next spost we will continue exploring graph connector techniques.
<p></p>
</p></p></p></p></p></p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[Conference Highlights This research was presented at the 17th International Conference on Information Technology and Applications (ICITA 2023) that was held in Turin, Italy from October 20–22, 2023. Paper 'Uncovering Hidden Connections: Granular Relationship Analysis in Knowledge Graphs' is estimated to be published in February, 2024. To complement the text understanding, in this post we will feature some slides from the conference presentation.]]></summary></entry><entry><title type="html">Exploring Document Comparison with GNN Graph Classification</title><link href="http://localhost:4000/2023/07/07/knowledgeGraph4NlpGnn2/" rel="alternate" type="text/html" title="Exploring Document Comparison with GNN Graph Classification" /><published>2023-07-07T08:00:00-04:00</published><updated>2023-07-07T08:00:00-04:00</updated><id>http://localhost:4000/2023/07/07/knowledgeGraph4NlpGnn2</id><content type="html" xml:base="http://localhost:4000/2023/07/07/knowledgeGraph4NlpGnn2/"><![CDATA[<p><h3>GNN Graph Classification for Semantic Graphs</h3>
<p></p>
In our previous studies, we focused on the exploration of knowledge graph rewiring to uncover unknown relationships between modern art artists. In one study
<u><a href="https://www.springerprofessional.de/en/building-knowledge-graph-in-spark-without-sparql/18375090">'Building Knowledge Graph in Spark Without SPARQL'</a></u>, we utilized artist biographies, known artist relationships, and data on modern art movements to employ graph-specific techniques, revealing hidden patterns within the knowledge graph.
</p>
<p>
In more recent study <u><a href="https://www.scitepress.org/Link.aspx?doi=10.5220/0011664400003393">'Rewiring Knowledge Graphs by Link Predictions'</a></u> our approach involved the application of GNN link prediction models. We trained these models on Wikipedia articles, specifically focusing on biographies of modern art artists. By leveraging GNN, we successfully identified previously unknown relationships between artists.


</p>
<p>

This study aims to extend earlier research by applying GNN graph classification models for document comparison, specifically using Wikipedia articles on modern art artists. Our methodology will involve transforming the text into semantic graphs based on co-located word pairs, then generating subsets of these semantic subgraphs as input data for GNN graph classification models. Finally, we will employ GNN graph classification models for a comparative analysis of the articles.

</p>
<p>
<p><h3>Introduction</h3>

The year 2012 marked a significant breakthrough in the fields of deep learning and knowledge graphs. It was during this year that Convolutional Neural Networks (CNN) gained prominence in image classification with the introduction of AlexNet. At the same time, Google introduced knowledge graphs, which revolutionized data integration and management. This breakthrough highlighted the superiority of CNN techniques over traditional machine learning approaches across various domains. Knowledge graphs enriched data products with intelligent and magical capabilities, transforming the way information is organized, connected, and understood.
</p><p>
For several years, deep learning and knowledge graphs progressed in parallel paths. CNN deep learning excelled at processing grid-structured data but faced challenges when dealing with graph-structured data. Graph techniques effectively represented and reasoned about graph structured data but lacked the powerful capabilities of deep learning. In the late 2010s, the emergence of Graph Neural Networks (GNN) bridged this gap and combined the strengths of deep learning and graphs. GNN became a powerful tool for processing graph- structured data through deep learning techniques.


<p></p>

</p><p>
GNN models allow to use deep learning algorithms for graph structured data by modeling entity relationships and capturing structures and dynamics of graphs. GNN models are being used for the following tasks to analyze graph-structured data: node classification, link prediction, and graph classification. Node classification models predict label or category of a node in a graph based on its local and global neighborhood structures. Link prediction models predict whether a link should exist between two nodes based on node attributes and graph topology. Graph classification models classify entire graphs into different categories based on their graph structure and attributes: edges, nodes with features, and labels on graph level.

</p><p>

</p><p>

GNN graph classification models are developed to classify small graphs and in practice they are commonly used in the fields of chemistry and medicine. For example, chemical molecular structures can be represented as graphs, with atoms as nodes, chemical bonds as edges, and graphs labeled by categories.

</p><p>
One of the challenges in GNN graph classification models lies in their sensitivity, where detecting differences between classes is often easier than identifying outliers or incorrectly predicted results. Currently, we are actively engaged in two studies that focus on the application of GNN graph classification models to time series classification tasks:

<u><a href="http://sparklingdataocean.com/2023/02/11/cityTempGNNgraphs/"> 'GNN Graph Classification for Climate Change Patterns'</a></u> and <u><a href="http://sparklingdataocean.com/2023/05/08/classGraphEeg/"> 'GNN Graph Classification for EEG Pattern Analysis'</a></u>.

</p><p>
In this post, we address the challenges of GNN graph classification on semantic graphs for document comparison. We demonstrate effective techniques to harness graph topology and node features in order to enhance document analysis and comparison. Our approach leverages the power of GNN models in handling semantic graph data, contributing to improved document understanding and similarity assessment.
</p><p>


</p><p>
To create semantic graph from documents we will use method that we introduced in our post
<u><a href="http://sparklingdataocean.com/2022/11/09/knowledgeGraph4NlpGnn/"> 'Find Semantic Similarities by GNN Link Predictions'</a></u>. In that post we demonstrated how to use GNN link prediction models to revire knowledge graphs.
For experiments of that study we looked at semantic similarities and dissimilarities between biographies of 20 modern art artists based on corresponding Wikipedia articles. One experiment was based on traditional method implemented on full test of articles and cosine similarities between reembedded nodes. In another scenario, GNN link prediction model ran on top of articles represented as semantic graphs with nodes as pairs of co-located words and edges as pairs of nodes with common words.
</p><p>
In this study, we expand on our previous research by leveraging the same data source and employing similar graph representation techniques. However, we introduce a new approach by constructing separate semantic graphs dedicated to each individual artist. This departure from considering the entire set of articles as a single knowledge graph enables us to focus on the specific relationships and patterns related to each artist. By adopting this approach, we aim to capture more targeted insights into the connections and dynamics within the knowledge graph, allowing for a deeper exploration of the relationships encoded within the biographies of these artists.
</p><p>



<p><h3>Methods</h3>
<p></p>

The input data for GNN graph classification models consists of a collection of labeled small graphs composed of edges and nodes with associated features. In this section we will describe data processing and model training in the following order:

<ul>
<li>Text preprocessing to transform raw data to semantic graphs. </li>
<li>Node embedding process.</li>
<li>The process of semantic subgraph extraction.</li>
<li>Training GNN graph classification model.</li>
</ul>



<p><h4>From Raw Data to Semantic Graph</h4>
<p></p>
To transform text data to semantic graph with nodes as co-located word pairs we will do the following:



</p>
<ul>
<li>Tokenize Wikipedia text and exclude stop words.</li>
<li>Get nodes as co-located word pairs.</li>
<li>Get edges between nodes.</li>
<li>Build semantic graph.</li>
</ul>
<p></p>
To generate edges we will find pair to pair neighbors following text sequences within articles and joint pairs that have common words.
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">if</span> <span class="n">pair1</span><span class="o">=</span><span class="p">[</span><span class="n">leftWord1</span><span class="p">,</span> <span class="n">rightWord1</span><span class="p">],</span>
   <span class="n">pair2</span><span class="o">=</span><span class="p">[</span><span class="n">leftWord2</span><span class="p">,</span> <span class="n">rightWord2</span><span class="p">]</span>
   <span class="ow">and</span> <span class="n">rightWord1</span><span class="o">=</span><span class="n">leftWord2</span><span class="p">,</span>
<span class="n">then</span> <span class="n">there</span> <span class="ow">is</span> <span class="n">edge12</span><span class="o">=</span><span class="p">{</span><span class="n">pair1</span><span class="p">,</span> <span class="n">pair2</span><span class="p">}</span></code></pre></figure>

<p></p>

Graph edges built based of these rules will cover word to word sequences and word to word chains within articles. On nodes and edges described above we will built an semantic graphs.
</p><p>
</p><p>
<h4>Node Embedding</h4>
</p><p>
To translate text of pairs of co-located to vectors we will use transformer model from Hugging Face: <u><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2"> 'all-MiniLM-L6-v2'</a></u>. This is a sentence-transformers model that maps text to a 384 dimensional vector space.


</p><p>
<p><h4>Extract Semantic Subgraphs</h4>
</p><p>


As input data for GNN graph classification model we need a set of labeled small graphs. In this study from each document of interest we will extract a set of subgraphs. By extracting relevant subgraphs from both documents, GNN graph classification models can compare the structural relationships and contextual information within the subgraphs to assess their similarity or dissimilarity. One of the ways to extract is getting subgraphs as neighbors and neighbors of neighbors of nodes with high centralities. In this study we will use betweenness centrality metrics.

</p><p>

</p><p>
<h4>Train the Model</h4>
</p><p>
The GNN graph classification model is designed to process input graph data, including both the edges and node features, and is trained on graph-level labels. In this case, the input data structure consists of the following components:
</p><p>
<ul>
<li>
Edges in a graph capture the relationships between nodes.
</li><li>
Nodes with embedded features would be embedded into the nodes to provide additional information to the GNN graph classification model.
</li><li>
Graph-level labels are assigned to the entire graph, and the GNN graph classification model leverages these labels to identify and predict patterns specific to each label category.
</li></ul>
<p></p>

As GNN graph classification model we will use a GCNConv (Graph Convolutional Network Convolution) activation model. The model code is taken from tutorial of the <u><a href="https://pytorch-geometric.readthedocs.io/en/latest/"> 'PyTorch Geometric Library (PyG)'</a></u>. The GCNConv graph classification model is a type of graph convolutional network that uses convolution operations to aggregate information from neighboring nodes in a graph. It takes as input graph data (edges, node features, and the graph-level labels) and applies graph convolutional operations to extract meaningful features from the graph structure.
<p></p>
The Python code for the GCNConv model is provided by the PyG library. The code for converting data to the PyG data format, model training and interpretation techniques are described below.
<p></p>


<h3>Experiments</h3>
<p></p>
<h4>Data Source</h4>
<p></p>

As the data source for this study we used text data from Wikipedia articles about 20 modern art artists. Here is the list of artists and Wikipedia text size distribution:
<p></p>
<a href="#">
    <img src="/img/artStats.jpg" alt="Post Sample Image" width="1000" />
</a>
<p></p>

<p>Based on Wikipedia text size distribution, the most well known artist in our artist list is Vincent van Gogh and the most unknown artist is Franz Marc:</p>

<p></p>
<a href="#">
    <img src="/img/artImg1.jpg" alt="Post Sample Image" width="345" />
</a>
<p></p>

<p></p>
More detail information is available in our post <u><a href="http://sparklingdataocean.com/2022/07/23/knowledgeGraph4GNN/">'Rewiring Knowledge Graphs by Link Predictions'</a></u>.

<p></p>

To estimate document similarities based on GNN graph classification model, we experimented with pairs of highly connected artists and highly disconnected artists.

Pairs of artists were selected based on our study <u><a href="https://www.springerprofessional.de/en/building-knowledge-graph-in-spark-without-sparql/18375090">"Building Knowledge Graph in Spark without SPARQL"</a></u>.
This picture illustrates relationships between modern art artists based on their biographies and art movements:

<p></p>
<a href="#">
    <img src="/img/artStats2b.jpg" alt="Post Sample Image" width="1000" />
</a>
<p></p>

<p>As highly connected artists, we selected Pablo Picasso and Georges Braque, artists with well known strong relationships between them: both Pablo Picasso and Georges Braque were pioneers of cubism art movement.
<p></p>
As highly disconnected artists, we selected Claude Monet and Kazimir Male- vich who were notably distant from each other: they lived in different time peri- ods, resided in separate countries, and belonged to contrasting art movements: Claude Monet was a key artist of impressionism and Kazimir Malevich a key artist of Suprematism.</p>

<p></p>

For a more detailed exploration of the relationships between modern art artists discovered through knowledge graph techniques, you can refer to our post:

<u><a href="http://sparklingdataocean.com/2020/02/02/knowledgeGraphIntegration/">"Knowledge Graph for Data Integration"</a></u>.


<p></p>


<p></p>

<p></p>

<p></p>
<h4>Transform Text Document to Semantic Graph</h4>
<p></p>
For each selected Wikipedia article we transformed text to semantic graphs by the following steps:

<ul>
<li>Tokenize Wikipedia text and excluded stop words.</li>
<li>Generate nodes as co-located word pairs.</li>
<li>Calculate edges as joint pairs that have common words. These edges represente word sequences and word chains within articles.</li>
</ul>


<p></p>
<h5>Tokenize Wikipedia text</h5>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">nltk.tokenize</span> <span class="kn">import</span> <span class="n">RegexpTokenizer</span>
<span class="n">tokenizer</span> <span class="o">=</span><span class="nc">RegexpTokenizer</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">[A-Za-z]+</span><span class="sh">'</span><span class="p">)</span>

<span class="n">wikiArtWords</span><span class="o">=</span><span class="n">wikiArtists</span><span class="p">[</span><span class="sh">'</span><span class="s">Wiki</span><span class="sh">'</span><span class="p">]</span>
  <span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nc">RegexpTokenizer</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">[A-Za-z]+</span><span class="sh">'</span><span class="p">).</span><span class="nf">tokenize</span><span class="p">(</span><span class="n">x</span><span class="p">)).</span><span class="nf">reset_index</span><span class="p">()</span>

<span class="n">wikiArtWords</span><span class="o">=</span><span class="n">wikiArtWords</span><span class="p">.</span><span class="nf">explode</span><span class="p">([</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">])</span>
<span class="n">wordStats</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">wikiArtWords</span><span class="p">,</span><span class="n">listArtists</span><span class="p">)</span>

<span class="n">artistWordStats</span><span class="o">=</span><span class="n">wordStats</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">Artist</span><span class="sh">'</span><span class="p">).</span><span class="nf">count</span><span class="p">()</span>
  <span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></figure>




<p></p>
<h5>Exclude stop words</h5>
<p></p>

Exclude stop words and short words woth length&lt;4:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">nltk</span>
<span class="n">nltk</span><span class="p">.</span><span class="nf">download</span><span class="p">(</span><span class="sh">'</span><span class="s">stopwords</span><span class="sh">'</span><span class="p">)</span>
<span class="kn">from</span> <span class="n">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="n">STOPWORDS</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">stopwords</span><span class="p">.</span><span class="nf">words</span><span class="p">(</span><span class="sh">'</span><span class="s">english</span><span class="sh">'</span><span class="p">))</span>
<span class="n">dfStopWords</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame </span><span class="p">(</span><span class="n">STOPWORDS</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">])</span>
<span class="n">dfStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">stop</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="sh">"</span><span class="s">stopWord</span><span class="sh">"</span>
<span class="n">stopWords</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">wikiArtWords</span><span class="p">,</span><span class="n">dfStopWords</span><span class="p">,</span><span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">)</span>

<span class="n">nonStopWords</span><span class="o">=</span><span class="n">stopWords</span><span class="p">[</span><span class="n">stopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">stop</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()]</span>
<span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">stop</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">len</span><span class="p">()</span>
<span class="n">nonStopWords</span><span class="o">=</span><span class="n">nonStopWords</span><span class="p">[</span><span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">stop</span><span class="sh">'</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">3</span><span class="p">]</span>
<span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span> <span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span>
<span class="n">nonStopWords</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">idxWord</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">nonStopWords</span><span class="p">.</span><span class="n">index</span></code></pre></figure>


<p></p>

<p></p>


<p></p>

<p></p>

<p></p>
<h5>Generated nodes as co-located word pairs</h5>
<p></p>
Get pairs of co-located words:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">bagOfWords</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">nonStopWordsSubset</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">])</span>
<span class="n">bagOfWords</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">bagOfWords</span><span class="p">[</span><span class="sh">'</span><span class="s">idxWord</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">bagOfWords</span><span class="p">.</span><span class="n">index</span>

<span class="n">indexWords</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">nonStopWordsSubset</span><span class="p">,</span><span class="n">bagOfWords</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxWord</span><span class="sh">'</span><span class="p">])</span>
<span class="n">idxWord1</span><span class="o">=</span><span class="n">indexWords</span>
  <span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">word1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxArtist1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxWord</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxWord1</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">idxWord2</span><span class="o">=</span><span class="n">indexWords</span>
  <span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">word2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxArtist2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxWord</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxWord2</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">leftWord</span><span class="o">=</span><span class="n">idxWord1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span>
<span class="n">leftWord</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">rightWord</span> <span class="o">=</span> <span class="n">idxWord2</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span> <span class="p">,</span> <span class="p">:].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  

<span class="n">pairWords</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">leftWord</span><span class="p">,</span><span class="n">rightWord</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pairWords</span> <span class="o">=</span> <span class="n">pairWords</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">pairWords</span><span class="p">[</span><span class="n">pairWords</span><span class="p">[</span><span class="sh">'</span><span class="s">idxArtist1</span><span class="sh">'</span><span class="p">]</span><span class="o">!=</span><span class="n">pairWords</span><span class="p">[</span><span class="sh">'</span><span class="s">idxArtist2</span><span class="sh">'</span><span class="p">]].</span><span class="n">index</span><span class="p">)</span>
<span class="n">pairWords</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>

Drop duplicates {artist, word1, word2}

<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cleanPairWords</span> <span class="o">=</span> <span class="n">pairWords</span>
<span class="n">cleanPairWords</span> <span class="o">=</span> <span class="n">cleanPairWords</span><span class="p">.</span><span class="nf">drop_duplicates</span><span class="p">(</span>
  <span class="n">subset</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">idxArtist1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">word1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">word2</span><span class="sh">'</span><span class="p">],</span> <span class="n">keep</span> <span class="o">=</span> <span class="sh">'</span><span class="s">last</span><span class="sh">'</span><span class="p">).</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">cleanPairWords</span><span class="p">[</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>
  <span class="n">cleanPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">word1</span><span class="sh">"</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> </span><span class="sh">"</span> <span class="o">+</span> <span class="n">cleanPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">word2</span><span class="sh">"</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">cleanPairWords</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">cleanPairWords</span><span class="p">.</span><span class="n">index</span></code></pre></figure>

<p></p>



<p></p>


<p></p>
<h5>Calculated edges as joint pairs that have common words.</h5>
<p></p>
Index data:
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">nodeList1</span><span class="o">=</span><span class="n">nodeList</span>
  <span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">word2</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">theWord</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">wordpair1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">nodeIdx1</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">nodeList2</span><span class="o">=</span><span class="n">nodeList</span>
  <span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">word1</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">theWord</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxArtist1</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxArtist2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">wordpair2</span><span class="sh">'</span><span class="p">,</span>
  <span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">nodeIdx2</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">allNodes</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">nodeList1</span><span class="p">,</span><span class="n">nodeList2</span><span class="p">,</span><span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">theWord</span><span class="sh">'</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">inner</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>


<p></p>

<p></p>
<h4>Input Data Preparation</h4>
<p></p>
<h5>Transform Text to Vectors</h5>
As mentioned above, for text to vector translation we used ’all- MiniLM-L6- v2’ transformer model from Hugging Face.
<p></p>
Get unique word pairs for embedding
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">bagOfPairWords</span><span class="o">=</span><span class="n">nodeList</span>
<span class="n">bagOfPairWords</span> <span class="o">=</span> <span class="n">bagOfPairWords</span><span class="p">.</span><span class="nf">drop_duplicates</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">)</span>
<span class="n">bagOfPairWords</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">bagOfPairWords</span><span class="p">[</span><span class="sh">'</span><span class="s">bagPairWordsIdx</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">bagOfPairWords</span><span class="p">.</span><span class="n">index</span></code></pre></figure>

<p></p>
<p></p>
Transform node features to vectors:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="nc">SentenceTransformer</span><span class="p">(</span><span class="sh">'</span><span class="s">all-MiniLM-L6-v2</span><span class="sh">'</span><span class="p">)</span>
<span class="n">wordpair_embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">cleanPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">wordpair</span><span class="sh">"</span><span class="p">],</span><span class="n">convert_to_tensor</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>


<p></p>


<p></p>
<h5>Prepare Input Data for GNN Graph Classification Model</h5>
<p></p>

In GNN graph classification, the input to the model is typically a set of small graphs that represent entities in the dataset. These graphs are composed of nodes and edges, where nodes represent entities, and edges represent the relationships between them. Both nodes and edges may have associated features that describe the attributes of the entity or relationship, respectively. These features can be used by the GNN model to learn the patterns and relationships in the data, and classify or predict labels for the graphs. By considering the structure of the data as a graph, GNNs can be particularly effective in capturing the complex relationships and dependencies between entities, making them a useful tool for a wide range of applications.

<p></p>
To prepare the input data for the GNN graph classification model, we generated labeled semantic subgraphs from each document of interest. These subgraphs were constructed by selecting neighbors and neighbors of neighbors around specific ”central” nodes. The central nodes were determined by identifying the top 500 nodes with the highest betweenness centrality within each document.
<p></p>
By focusing on these central nodes and their neighboring nodes, we aimed to capture the relevant information and relationships within the document. This approach allowed us to create labeled subgraphs that served as the input data for the GNN graph classification model, enabling us to classify and analyze the documents effectively.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="n">list1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span>  
<span class="n">list2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">]</span>  
<span class="n">radius</span><span class="o">=</span><span class="mi">2</span>
<span class="n">datasetTest</span><span class="o">=</span><span class="nf">list</span><span class="p">()</span>
<span class="n">datasetModel</span><span class="o">=</span><span class="nf">list</span><span class="p">()</span>
<span class="n">dfUnion</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">()</span>
<span class="n">seeds</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">artist</span> <span class="ow">in</span> <span class="n">list1</span> <span class="o">+</span> <span class="n">list2</span><span class="p">:</span>
  <span class="k">if</span> <span class="n">artist</span> <span class="ow">in</span> <span class="n">list1</span><span class="p">:</span>
    <span class="n">label</span><span class="o">=</span><span class="mi">0</span>
  <span class="k">if</span> <span class="n">artist</span> <span class="ow">in</span> <span class="n">list2</span><span class="p">:</span>
    <span class="n">label</span><span class="o">=</span><span class="mi">1</span>
    <span class="n">edgeInfo0</span><span class="o">=</span><span class="n">edgeInfo</span><span class="p">[</span><span class="n">edgeInfo</span><span class="p">[</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">artist</span><span class="p">]</span>
    <span class="n">G</span><span class="o">=</span><span class="n">nx</span><span class="p">.</span><span class="nf">from_pandas_edgelist</span><span class="p">(</span><span class="n">edgeInfo0</span><span class="p">,</span>  <span class="sh">"</span><span class="s">wordpair1</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">wordpair2</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">betweenness</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nf">betweenness_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
    <span class="n">sorted_nodes</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">betweenness</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">betweenness</span><span class="p">.</span><span class="n">get</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">top_nodes</span> <span class="o">=</span> <span class="n">sorted_nodes</span><span class="p">[:</span><span class="mi">500</span><span class="p">]</span>
    <span class="n">dfTopNodes</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">top_nodes</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">seedPair</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">dfTopNodes</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">dfTopNodes</span><span class="p">.</span><span class="n">index</span><span class="p">:</span>
      <span class="n">seed_node</span><span class="o">=</span><span class="n">dfTopNodes</span><span class="p">[</span><span class="sh">'</span><span class="s">seedPair</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">seed</span><span class="p">]</span>
      <span class="n">seeds</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span><span class="sh">'</span><span class="s">artist</span><span class="sh">'</span><span class="p">:</span><span class="n">artist</span><span class="p">,</span> <span class="sh">'</span><span class="s">seed_node</span><span class="sh">'</span><span class="p">:</span><span class="n">seed_node</span><span class="p">,</span> <span class="sh">'</span><span class="s">seed</span><span class="sh">'</span><span class="p">:</span><span class="n">seed</span><span class="p">})</span>
      <span class="n">foaf_nodes</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nf">ego_graph</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">seed_node</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="n">radius</span><span class="p">).</span><span class="n">nodes</span>
      <span class="n">dfFoaf</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">foaf_nodes</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">])</span>
      <span class="n">dfFoaf</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="n">dfFoaf</span><span class="p">[</span><span class="sh">'</span><span class="s">foafIdx</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">dfFoaf</span><span class="p">.</span><span class="n">index</span>
      <span class="n">words_embed</span> <span class="o">=</span> <span class="n">words_embeddings</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">dfFoaf</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">)</span>
      <span class="n">values1</span><span class="o">=</span><span class="n">words_embed</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">384</span><span class="p">]</span>
      <span class="n">fXValues1</span><span class="o">=</span> <span class="n">values1</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">values</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
      <span class="n">fXValuesPT1</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">fXValues1</span><span class="p">)</span>
      <span class="n">graphSize</span><span class="o">=</span><span class="n">dfFoaf</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="c1"># dfFoaf.tail()
</span>      <span class="n">oneGraph</span><span class="o">=</span><span class="p">[]</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">graphSize</span><span class="p">):</span>
        <span class="n">pairi</span><span class="o">=</span><span class="n">dfFoaf</span><span class="p">[</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">pairi1</span> <span class="o">=</span> <span class="n">pairi</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">pairi2</span> <span class="o">=</span> <span class="n">pairi</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># for j in range(i+1,graphSize):
</span>        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">graphSize</span><span class="p">):</span>
          <span class="n">pairj</span><span class="o">=</span><span class="n">dfFoaf</span><span class="p">[</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">j</span><span class="p">].</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
          <span class="n">pairj1</span> <span class="o">=</span> <span class="n">pairj</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
          <span class="n">pairj2</span> <span class="o">=</span> <span class="n">pairj</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
          <span class="nf">if </span><span class="p">(</span> <span class="n">pairi2</span><span class="o">==</span><span class="n">pairj1</span><span class="p">):</span>
            <span class="n">oneGraph</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span> <span class="sh">'</span><span class="s">artist</span><span class="sh">'</span><span class="p">:</span><span class="n">artist</span><span class="p">,</span><span class="sh">'</span><span class="s">seed</span><span class="sh">'</span><span class="p">:</span><span class="n">seed</span><span class="p">,</span>
                             <span class="sh">'</span><span class="s">centralNode</span><span class="sh">'</span><span class="p">:</span><span class="n">seed_node</span><span class="p">,</span> <span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">:</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">:</span><span class="n">j</span><span class="p">,</span> <span class="sh">'</span><span class="s">pairi</span><span class="sh">'</span><span class="p">:</span><span class="n">pairi</span><span class="p">,</span> <span class="sh">'</span><span class="s">pairj</span><span class="sh">'</span><span class="p">:</span><span class="n">pairj</span><span class="p">})</span>
      <span class="n">dfGraph</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">oneGraph</span><span class="p">)</span>
      <span class="n">dfUnion</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">dfUnion</span><span class="p">,</span> <span class="n">dfGraph</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="n">edge1</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">dfGraph</span><span class="p">[[</span><span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">]].</span><span class="n">T</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
      <span class="n">dataset1</span> <span class="o">=</span> <span class="nc">Data</span><span class="p">(</span><span class="n">edge_index</span><span class="o">=</span><span class="n">edge1</span><span class="p">)</span>
      <span class="n">dataset1</span><span class="p">.</span><span class="n">y</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">label</span><span class="p">])</span>
      <span class="n">dataset1</span><span class="p">.</span><span class="n">x</span><span class="o">=</span><span class="n">fXValuesPT1</span>
      <span class="n">datasetModel</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">dataset1</span><span class="p">)</span>
      <span class="n">loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">datasetModel</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span></code></pre></figure>

<p></p>

Model size
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">modelSize</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">modelSize</span>
<span class="mi">1000</span></code></pre></figure>

<p></p>
<p></p>

<p><h4>Training the Model</h4>
<p></p>
For this study we used the code provided by PyTorch Geometric as tutorial on GCNConv graph classification models - we just slightly tuned it for our data:

<p></p>
<p><h5>Randomly split data to training and tesing</h5>
<p></p>

<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">random</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
<span class="n">percent</span> <span class="o">=</span> <span class="mf">0.13</span>
<span class="n">sample_size</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">modelSize</span> <span class="o">*</span> <span class="n">percent</span><span class="p">)</span>
<span class="n">train_size</span><span class="o">=</span><span class="nf">int</span><span class="p">(</span><span class="n">modelSize</span><span class="o">-</span><span class="n">sample_size</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">train_size</span><span class="p">)</span></code></pre></figure>


<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Number of training graphs: </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Number of test graphs: </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
<span class="n">Number</span> <span class="n">of</span> <span class="n">training</span> <span class="n">graphs</span><span class="p">:</span> <span class="mi">870</span>
<span class="n">Number</span> <span class="n">of</span> <span class="n">test</span> <span class="n">graphs</span><span class="p">:</span> <span class="mi">130</span></code></pre></figure>


<p></p>

<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Step </span><span class="si">{</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s">:</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">=======</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Number of graphs in the current batch: </span><span class="si">{</span><span class="n">data</span><span class="p">.</span><span class="n">num_graphs</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">()</span></code></pre></figure>

<p></p>
<h5>Prepare the model:</h5>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch.nn</span> <span class="kn">import</span> <span class="n">Linear</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GCNConv</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">global_mean_pool</span>

<span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">GCN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lin</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="c1"># 1. Obtain node embeddings
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="c1"># 2. Readout layer
</span>        <span class="n">x</span> <span class="o">=</span> <span class="nf">global_mean_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>  <span class="c1"># [batch_size, hidden_channels]
</span>        <span class="c1"># 3. Apply a final classifier
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>        
        <span class="k">return</span> <span class="n">x</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span></code></pre></figure>

<p></p>

<p><h5>Train the Model:</h5>
<p></p>

<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">IPython.display</span> <span class="kn">import</span> <span class="n">Javascript</span>
<span class="nf">display</span><span class="p">(</span><span class="nc">Javascript</span><span class="p">(</span><span class="sh">'''</span><span class="s">google.colab.output.setIframeHeight(0, true, {maxHeight: 300})</span><span class="sh">'''</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
   <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
   <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>  <span class="c1"># Iterate in batches over the training dataset.
</span>        <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># Perform a single forward pass.
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># Compute the loss.
</span>        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>  <span class="c1"># Derive gradients.
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>  <span class="c1"># Update parameters based on gradients.
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>  <span class="c1"># Clear gradients.
</span>
<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">loader</span><span class="p">):</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>  <span class="c1"># Iterate in batches over the training/test dataset.
</span>        <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>  
        <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Use the class with highest probability.
</span>        <span class="n">correct</span> <span class="o">+=</span> <span class="nf">int</span><span class="p">((</span><span class="n">pred</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">).</span><span class="nf">sum</span><span class="p">())</span>  <span class="c1"># Check against ground-truth labels.
</span>    <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">)</span>  <span class="c1"># Derive ratio of correct predictions.
</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
   <span class="nf">train</span><span class="p">()</span>
   <span class="n">train_acc</span> <span class="o">=</span> <span class="nf">test</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
   <span class="n">test_acc</span> <span class="o">=</span> <span class="nf">test</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
   <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="mi">03</span><span class="n">d</span><span class="si">}</span><span class="s">, Train Acc: </span><span class="si">{</span><span class="n">train_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, Test Acc: </span><span class="si">{</span><span class="n">test_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>


<p></p>
<p></p>
To estimate the model results we used the same model accuracy metrics as in the PyG tutorial.
<p></p>
<p></p>
<p></p>

<p><h5>Accuracy Metrics of the Model:</h5>
<p></p>

As we mentioned above, the GNN graph classification model exhibits higher sensitivity for classification compared to the GNN link prediction model. In both scenarios, we trained the models for 9 epochs.
<p></p>
Given the distinct differences between Monet and Malevich as artists, we anticipated achieving high accuracy metrics. However, the surprising outcome was obtaining perfect metrics as 1.0000 for training data and 1.0000 for testing right from the initial training step.

<p></p>
<p></p>
<a href="#">
    <img src="/img/modelStats1.jpg" alt="Post Sample Image" width="345" />
</a>
<p></p>

In the classification of Wikipedia articles about Pablo Picasso and Georges Braque, we were not anticipating the significant differentiation between these two documents: these artists had very strong relationships in biography and art movements. Also GNN link prediction models classified these artists as highly similar.
<p></p>
<p></p>
<a href="#">
    <img src="/img/modelStats2.jpg" alt="Post Sample Image" width="345" />
</a>
<p></p>
This observation highlights the high sensitivity of the GNN graph classifica- tion model and emphasizes the ability of the GNN graph classification model to capture nuanced differences and provide a more refined classification approach compared to the GNN Link Prediction models.

<p><h4>Model Results</h4>
<p></p>

<p></p>
To interpret model results we calculated the softmax probabilities for each class output by the model. The softmax probabilities represent the model's confidence in its prediction for each class.
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">modelSize</span>
<span class="mi">1000</span></code></pre></figure>


<p></p>
<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Softmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">graph1</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">modelSize</span><span class="p">):</span>
  <span class="n">label</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">batch</span><span class="p">)</span>
  <span class="n">output</span> <span class="o">=</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">out</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">graph1</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">:</span><span class="n">g</span><span class="p">,</span>
                 <span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span><span class="sh">'</span><span class="s">pred</span><span class="sh">'</span><span class="p">:</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                 <span class="sh">'</span><span class="s">prob0</span><span class="sh">'</span><span class="p">:</span><span class="nf">round</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">4</span><span class="p">),</span><span class="sh">'</span><span class="s">prob1</span><span class="sh">'</span><span class="p">:</span><span class="nf">round</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">4</span><span class="p">)})</span></code></pre></figure>

<p></p>



<p></p>
One of the challenges encountered when utilizing the GNN graph classification model for text classification is the identification of outliers. In the scenario of classifying Wikipedia articles about the biographies of Claude Monet and Kazimir Malevich, the trained model did not detect any outliers.
<p></p>
In the case of Pablo Picasso and Georges Braque, we found that despite their shared biographies and involvement in the same art movements, there were no- table differences between their respective Wikipedia articles. The GNN graph classification model identified these articles as highly dissimilar, suggesting dis- tinct characteristics and content within their biographies. During our analysis of 1000 subgraphs, we encountered only 8 outliers.
<p></p>
<p></p>
<a href="#">
    <img src="/img/modelStats3.jpg" alt="Post Sample Image" width="444" />
</a>
<p></p>



<p></p>
<p></p>
<p><h3>Conclusion</h3>


<p></p>
GNN graph classification is a powerful machine learning technique designed for object classification when the objects can be represented as graphs. By mapping object elements to nodes and their relationships to edges, GNN graph classification models capture complex interdependencies among the elements. This approach is particularly valuable when traditional machine learning methods struggle to capture complex relationships.
<p></p>
GNN graph classification has been successfully applied in various domains, including molecule classification, image recognition, protein classification, social networks, brain connectivity networks, road networks, and climate data analysis.
<p></p>
In this paper, we investigate the application of GNN graph classification models in NLP for document comparison, aiming to uncover document similarities and dissimilarities using graph topology and node features. We focus on comparing Wikipedia articles about modern art artists and demonstrate the potential of these models in extracting relevant information and identifying patterns. Additionally, we address challenges related to model sensitivity and outlier detection in GNN graph classification.
<p></p>
We investigated the effectiveness of GNN graph classification in capturing different types of relationships among artists. We specifically selected two pairs of artists, one representing highly connected relationships (Pablo Picasso and Georges Braque) and the other representing highly disconnected relationships (Claude Monet and Kazimir Malevich). As expected, in the case of classifying Wikipedia articles on the biographies of Claude Monet and Kazimir Malevich, no outliers were detected.
<p></p>
In the case of Pablo Picasso and Georges Braque, despite their shared biographies and association with the cubism art movement, we identified substantial differences in their respective articles. The GNN graph classification model categorized these articles as highly dissimilar and out of 1000 subgraphs, we encountered only 8 outliers, further emphasizing the model’s sensitivity in capturing the nuanced differences between the documents.
<p></p>
Future research can further explore the applications of GNN graph classification models in NLP, with a focus on addressing sensitivity and outlier detection challenges. Additionally, efforts can be made to deeper understanding of semantic graph relationships.
<p></p>
In conclusion, our study advances document comparison using GNN graph classification, offering valuable insights for text analysis and knowledge discovery. It contributes to the growing field of GNN-based methods in NLP, opening avenues for future research and practical applications.
<p></p>
<p><h3>Next Post - Graph Connectors</h3>

In the next spost we will start a new topic related to knowledge graphs and GNN.
<p></p>
</p></p></p></p></p></p></p></p></p></p></p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[GNN Graph Classification for Semantic Graphs In our previous studies, we focused on the exploration of knowledge graph rewiring to uncover unknown relationships between modern art artists. In one study 'Building Knowledge Graph in Spark Without SPARQL', we utilized artist biographies, known artist relationships, and data on modern art movements to employ graph-specific techniques, revealing hidden patterns within the knowledge graph. In more recent study 'Rewiring Knowledge Graphs by Link Predictions' our approach involved the application of GNN link prediction models. We trained these models on Wikipedia articles, specifically focusing on biographies of modern art artists. By leveraging GNN, we successfully identified previously unknown relationships between artists.]]></summary></entry><entry><title type="html">GNN Graph Classification for EEG Pattern Analysis</title><link href="http://localhost:4000/2023/05/08/classGraphEeg/" rel="alternate" type="text/html" title="GNN Graph Classification for EEG Pattern Analysis" /><published>2023-05-08T08:00:00-04:00</published><updated>2023-05-08T08:00:00-04:00</updated><id>http://localhost:4000/2023/05/08/classGraphEeg</id><content type="html" xml:base="http://localhost:4000/2023/05/08/classGraphEeg/"><![CDATA[<p><h3>GNN for pattern discovery in time series data</h3>

In one of our previous posts <i><a href="http://sparklingdataocean.com/2020/08/19/brainGraphEeg/">
"EEG Patterns by Deep Learning and Graph Mining"</a></i> we studied how to use CNN image classification to distinguish between Alcoholic person behavior and behavior of person from Control group based on EEG data. This study was presented
in <i><a href="
https://www.dexa.org/previous/dexa2021/protime2021.html">"The 1st International Workshop on Time Ordered Data (ProTime2021)"</a></i>
of DEXA 2021 conference and it was published in <i><a href="https://link.springer.com/chapter/10.1007/978-3-030-87101-7_19">"Time Series Pattern Discovery by Deep Learning and Graph Mining"</a></i> paper.
</p>
<p>
That study found that using the Gramian Angular Field (GAF) image transformation technique for time series data improved the accuracy of CNN image classification models compared to using raw plot pictures. By transforming the time series vectors into GAF images, the data was represented in a different embedded space that captured different aspects of the data compared to raw plots of the EEG data. This suggests that GAF image transformation is a useful technique for improving the accuracy of image classification models for time series data.
</p>
<p>
The study utilized a combination of advanced deep learning CNN image classification models and traditional graph mining techniques for time series pattern discovery. For image classification, the time series vectors were transformed into GAF images, and for graph mining, the study created graphs based on pairwise cosine similarities between the time series data points. To analyze these graphs, traditional graph mining techniques such as community detection and graph visualization were applied. This hybrid approach enabled the study to capture and analyze different aspects of the time series data, leading to a more comprehensive understanding of the patterns present in the data.
</p>
<p>
In this study we will explore how Graph Neural Network (GNN) graph classification models can be applied to classify time series data based on the underlying graph structure.

</p>
<p>

<p><h3>Introduction</h3>

<p><h4>Why GNN Graph Classification?</h4>
</p><p>
Graph mining is the process of extracting useful information from graphs. Traditional graph-based algorithms such as graph clustering, community detection, and centrality analysis have been used for this purpose. However, these methods have limitations in terms of their ability to learn complex representations and features from graph-structured data.
</p><p>
Graph Neural Networks (GNN) were developed to address these limitations. GNNs enable end-to-end learning of representations and features from graph data, allowing deep learning algorithms to process and learn from graph data. By modeling the relationships between the nodes and edges in a graph, GNNs can capture the underlying structure and dynamics of the graph. This makes them a powerful tool for analyzing and processing complex graph-structured data in various domains, including social networks, biological systems, and recommendation systems.
</p><p>

GNN models allow for deep learning on graph-structured data by modeling entity relationships and capturing graph structures and dynamics. They can be used for tasks such as node classification, link prediction, and graph classification. Node classification models predict the label or category of a node based on its local and global neighborhood structure. Link prediction models predict whether a link should exist between two nodes based on node attributes and graph structure. Graph classification models classify entire graphs into different categories based on their structure and attributes.

</p><p>

</p><p>
GNN graph classification models are developed to classify small graphs and in practice they are commonly used in the fields of chemistry and medicine. For example, chemical molecular structures can be represented as graphs, with atoms as nodes, chemical bonds as edges, and graphs labeled by categories.
</p><p>

In this post we will experiment with time series graph classification from healthcare domains and GNN graph classification models will be applied to electroencephalography (EEG) signal data by modeling the brain activity as a graph. Methods presented on this post can also be applied to time series data in various fields such as engineering, healthcare, and finance. The input data for the GNN graph classification models is a set of small labeled graphs, where each graph represents a group of nodes corresponding to time series and edges representing some measures of similarities or correlations between them.
</p><p>

</p><p>


</p><p>

</p><p>

<p><h4>Why EEG Data?</h4>
</p><p>

EEG tools studying human behaviors are well described in Bryn Farnsworth's blog
<i><a href="
https://imotions.com/blog/eeg/">"EEG (Electroencephalography): The Complete Pocket Guide"</a></i>. There are several reasons why EEG is an exceptional tool for studying the neurocognitive processes:
</p><p>
<ul>
<li>EEG has very high time resolution and captures cognitive processes in the time frame in which cognition occurs.
</li>
<li>EEG directly measures neural activity.</li>
<li>EEG is inexpensive, lightweight, and portable.</li>
<li>EEG data is publically available: we found this dataset in Kaggle.com</li>
</ul>
</p><p>
The study will use the same approach as the one described above, where EEG signal data is modeled as a graph to represent brain activity. The nodes in the graph will represent brain regions or electrode locations, and edges will represent functional or structural connections between them. The raw data for the experiments will come from the kaggle.com EEG dataset 'EEG-Alcohol', which was part of a large study on EEG correlates of genetic predisposition to alcoholism.
</p><p>
The study aims to use GNN graph classification models to predict alcoholism, where a single graph corresponds to one brain reaction on a trial. Time series graphs will be created for each trial using electrode positions as nodes, EEG channel signals as node features, and graph edges as pairs of vectors with cosine similarities above certain thresholds. The EEG graph classification models will be used to determine whether a person is from the alcoholic or control group based on their trial reactions, which can potentially help in early detection and treatment of alcoholism.

</p><p>


</p><p>


</p><p>



</p><p>
<p><h3>Related Work</h3>
</p><p>
<p><h4>Machine Learning as EEG Analysis</h4>
</p><p>
Electroencephalography (EEG) signals are complex and require extensive training and advanced signal processing techniques for proper interpretation. Deep learning has shown promise in making sense of EEG signals by learning feature representations from raw data. In the

meta-data analysis paper <i><a href="
https://arxiv.org/pdf/1901.05498.pdf">"Deep learning-based electroencephalography analysis: a systematic review"</a></i>

the authors conduct a meta-analysis of EEG deep learning and compare it to traditional EEG processing methods to determine which deep learning approaches work well for EEG data analysis and which do not.
</p><p>

In a previous study, EEG channel data was transformed into graphs based on pairwise cosine similarities. These graphs were analyzed using connected components and visualization techniques. Traditional graph mining methods were used to find explicit EEG channel patterns by transforming time series into vectors, constructing graphs based on cosine similarity, and identifying patterns using connected components.


</p><p>

</p><p>
<p></p>
<p></p>
<a href="#">
    <img src="/img/dataSource5.jpg" alt="Post Sample Image" width="500" />
</a>
<p></p>


</p>
<p></p><p>

</p><p>
<p><h3>Methods</h3>

In GNN graph classification for EEG data, separate graphs will be created for each brain-trial. Indicators of the alcohol or control group of corresponding person will be used as labels for the graphs. The electrode positions will be used as nodes, and channel signals will be used as node features. Graph edges will be defined as pairs of vectors with cosine similarities higher than thresholds. For the GNN graph classification model, a GCNConv (Graph Convolutional Network Convolution) model from PyTorch Geometric Library (PyG) will be used.
<p></p><p>
In this section we will describe data processing and model training methods is the following order:
<ul>
<li>
Cosine similarity matrix functions.
</li><li>
Process of transforming cosine similarity matrices to graphs.
</li><li>
Process of training GNN graph classification model.

</li>
</ul>

</p><p>

<h4>Cosine Similarity Function</h4>

</p><p>
For cosine similarities we used the following functions:

<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="k">def</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">a_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">a_norm</span><span class="p">,</span> <span class="n">b_norm</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span></code></pre></figure>


<p></p>

<p></p>
<h4>Cosine Similarity Matrices to Graphs</h4>
</p><p>
Next, for each brain-trial we will calculate cosine similarity matrices and transform them into graphs by taking only vector pairs with cosine similarities higher than a threshold.
</p><p>

For each brain-trial graph we will add a virtual node to transform disconnected graphs into single connected components. This process makes it is easier for GNN graph classification models to process and analyze the relationships between nodes.

</p><p>


</p><p>
<h4>Train the Model</h4>
</p><p>
The GNN graph classification model is designed to process input graph data, including both the edges and node features, and is trained on graph-level labels. In this case, the input data structure consists of the following components:
</p><p>
<ul>
<li>
Edges: The graph adjacency matrix represents the relationships between nodes in the graph. For instance, it could represent the correlations between daily temperature vectors over different years.
</li><li>
Nodes with embedded features: The node features, such as the average values of the consecutive yearly sequences, would be embedded into the nodes to provide additional information to the GNN graph classification model.
</li><li>
Labels on graph level: The labels, such as alcohol or control group, are assigned to the graph as a whole, and the GNN graph classification model uses these graph-level labels to make predictions about the alcohol or non-alcohol patterns.
</li></ul>

</p><p>
This study uses a GCNConv model from PyTorch Geometric Library as a GNN graph classification model. The GCNConv model is a type of graph convolutional network that applies convolutional operations to extract meaningful features from the input graph data (edges, node features, and the graph-level labels). The code for the model is taken from a PyG tutorial.
</p><p>
<p></p>

</p><p>
<p><h3>Experiments</h3>
</p><p>
<h4>EEG Data Source</h4>
<p></p>
<p></p>
For this post we used EEG dataset that we found in kaggle.com website: <i><a href="https://www.kaggle.com/nnair25/Alcoholics">'EEG-Alcohol' Kaggle dataset.</a></i> This dataset came from a large study of examining EEG correlates of genetic predisposition to alcoholism. We will classify EEG channel time series data to alcoholic and control person's EEG channels. Note: there are some data quality problems in this dataset.
<p></p>
<a href="#">
    <img src="/img/picEEG1a.jpg" alt="Post Sample Image" width="600" />
</a>
<p></p>
Amount of subjects in each group is 8. The 64 electrodes were placed on subject's scalps to measure the electrical activity of the brain. The response values were sampled at 256 Hz (3.9-msec epoch) for 1 second.
Each subject was exposed to either a single stimulus (S1) or to two stimuli (S1 and S2) which were pictures of objects chosen from the 1980 Snodgrass and Vanderwart picture set. When two stimuli were shown, they were presented in either a matched condition where S1 was identical to S2 or in a non-matched condition where S1 differed from S2. The total number of person-trial combination was 61.

</p>

<h4>Transform Raw Data to EEG Channel Time Series</h4>
<p></p>
Kaggle EEG dataset was well analyzed in
<i><a href="https://www.kaggle.com/ruslankl/eeg-data-analysis"> 'EEG Data Analysis: Alcoholic vs Control Groups' </a></i>
Kaggle notebook by Ruslan Klymentiev. We used his code for some parts of our data preparation. Here is raw data:
<p></p>
<p></p>
<a href="#">
    <img src="/img/dataSource1.jpg" alt="Post Sample Image" width="700" />
</a>
<p></p>
Python code to transform raw data to EEG channel time series data :
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">EEG_data</span><span class="p">[</span><span class="sh">'</span><span class="s">rn</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">EEG_data</span><span class="p">.</span><span class="nf">groupby</span><span class="p">([</span><span class="sh">'</span><span class="s">sensor position</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">trial number</span><span class="sh">'</span><span class="p">,</span>
   <span class="sh">'</span><span class="s">subject identifier</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">matching condition</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">]).</span><span class="nf">cumcount</span><span class="p">()</span>
<span class="n">EEG_TS</span><span class="o">=</span><span class="n">EEG_data</span><span class="p">.</span><span class="nf">pivot_table</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">trial number</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">sensor position</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">subject identifier</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">matching condition</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">channel</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">columns</span><span class="o">=</span><span class="sh">'</span><span class="s">rn</span><span class="sh">'</span><span class="p">,</span><span class="n">values</span><span class="o">=</span><span class="sh">'</span><span class="s">sensor value</span><span class="sh">'</span><span class="p">,</span> <span class="n">aggfunc</span><span class="o">=</span><span class="sh">'</span><span class="s">first</span><span class="sh">'</span><span class="p">).</span><span class="nf">reset_index</span><span class="p">()</span>
<span class="n">EEG_TS</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span></code></pre></figure>

<p></p>
EEG channels - time series data:
<p></p>

<p></p>
<a href="#">
    <img src="/img/dataSource2.jpg" alt="Post Sample Image" width="700" />
</a>
<p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">EEG_TS</span><span class="o">=</span><span class="n">EEG_TS</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">trial number</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">trial</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">sensor position</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">,</span>
                                <span class="sh">'</span><span class="s">subject identifier</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">matching condition</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">match</span><span class="sh">'</span><span class="p">,</span>
                                <span class="sh">'</span><span class="s">Unnamed: 0</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">})</span></code></pre></figure>

<p></p>
Calculate EEG positions
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">positions</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">EEG_TS</span><span class="p">[</span><span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">].</span><span class="nf">unique</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">])</span>
<span class="n">positions</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">positions</span><span class="p">[</span><span class="sh">'</span><span class="s">positionIdx</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">positions</span><span class="p">.</span><span class="n">index</span>
<span class="n">inputData</span><span class="o">=</span><span class="n">EEG_TS</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">positions</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">inner</span><span class="sh">'</span><span class="p">)</span>
<span class="n">inputData</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span></code></pre></figure>

<p></p>
Define 61 groups for small graphs:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">inputData</span> <span class="o">=</span> <span class="n">inputData</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">([</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">trial</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">])</span>
<span class="n">inputData</span><span class="p">[</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">inputData</span><span class="p">[</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="sh">'</span><span class="s">a</span><span class="sh">'</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">inputData</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">inputData</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">inputData</span><span class="p">.</span><span class="n">index</span>
<span class="kn">import</span> <span class="n">math</span>
<span class="n">inputData</span><span class="p">[</span><span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">inputData</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span><span class="o">//</span><span class="mi">61</span></code></pre></figure>

<p></p>

Calculate cosine similarity matrix by brain-trial groups:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">IMG</span><span class="o">=</span><span class="sh">'</span><span class="s">/content/drive/My Drive/EEG/groupCos/</span><span class="sh">'</span>

<span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">61</span><span class="p">):</span>
  <span class="n">data1</span><span class="o">=</span><span class="n">inputData</span><span class="p">[(</span><span class="n">inputData</span><span class="p">[</span><span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">group</span><span class="p">)]</span>
  <span class="n">values1</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">6</span><span class="p">:</span><span class="mi">262</span><span class="p">]</span>
  <span class="n">fXValues1</span><span class="o">=</span> <span class="n">values1</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">values</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
  <span class="n">fXValuesPT1</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">fXValues1</span><span class="p">)</span>
  <span class="n">cosine_scores1</span> <span class="o">=</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">fXValuesPT1</span><span class="p">,</span> <span class="n">fXValuesPT1</span><span class="p">)</span>
  <span class="n">cosPairs1</span><span class="o">=</span><span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">61</span><span class="p">):</span>
    <span class="n">position1</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">61</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">i</span><span class="o">!=</span><span class="n">j</span><span class="p">:</span>
        <span class="n">score</span><span class="o">=</span><span class="n">cosine_scores1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>  
        <span class="n">position2</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">]</span>
        <span class="n">combo</span><span class="o">=</span><span class="nf">str</span><span class="p">(</span><span class="n">group</span><span class="p">)</span><span class="o">+</span><span class="sh">'</span><span class="s">~</span><span class="sh">'</span><span class="o">+</span><span class="n">position1</span><span class="o">+</span><span class="sh">'</span><span class="s">~</span><span class="sh">'</span><span class="o">+</span><span class="n">position2</span>
        <span class="n">cosPairs1</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">combo</span><span class="sh">'</span><span class="p">:</span><span class="n">combo</span><span class="p">,</span> <span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">:</span><span class="n">position1</span><span class="p">,</span> <span class="sh">'</span><span class="s">right</span><span class="sh">'</span><span class="p">:</span><span class="n">position2</span><span class="p">,</span> <span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span> <span class="n">score</span><span class="p">})</span>
  <span class="n">dfCosPairs1</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">cosPairs1</span><span class="p">)</span>
  <span class="n">path</span><span class="o">=</span><span class="n">IMG</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">group</span><span class="p">)</span><span class="o">+</span><span class="sh">"</span><span class="s">scores.csv</span><span class="sh">"</span>
  <span class="n">dfCosPairs1</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>

<p></p>


</p>


<p></p>

<p></p>
<h4>Prepare Input Data for GNN Graph Classification Model</h4>
<p></p>

In GNN graph classification, the input to the model is typically a set of small graphs that represent entities in the dataset. These graphs are composed of nodes and edges, where nodes represent entities, and edges represent the relationships between them. Both nodes and edges may have associated features that describe the attributes of the entity or relationship, respectively. These features can be used by the GNN model to learn the patterns and relationships in the data, and classify or predict labels for the graphs. By considering the structure of the data as a graph, GNNs can be particularly effective in capturing the complex relationships and dependencies between entities, making them a useful tool for a wide range of applications.
<p></p>
As input for GNN graph classification for EEG data we created separate graphs for all 61 person-trial combinations. As graph labels we used indicators of alcohol or control group of corresponding person. For graph nodes as node features we used electrode positions as nodes and EEG channel signals. As graph edges, for each graph we calculated cosine similarity matrices and selected pairs of nodes with cosine similarities higher that thresholds.
<p></p>
In this study, one of the challenges was to define thresholds for creating input graphs for GNN graph classification. As there were only 61 person-trial graphs available, this number was not sufficient for training a GNN graph classification model. To overcome this challenge, additional input graphs were created by varying the threshold values randomly within a predefined range (0.75, 0.95). This approach helped to augment the input dataset and improve the performance of the GNN graph classification model.
<p></p>

The following code prepares input data for GNN graph classification model:
<p></p>

<ul>
<li>Transform cosine similarity matries to graph adjacency matrices based on treasholds
</li><li>For each brain-trial graph add a virtual node to transform disconnected graphs into single connected components.
</li><li>Transform data to PyTorch Geometric data format
</li>
</ul>
</p><p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="n">datasetModel</span><span class="o">=</span><span class="nf">list</span><span class="p">()</span>
<span class="n">datasetTest</span><span class="o">=</span><span class="nf">list</span><span class="p">()</span>
<span class="n">cosPairsUnion</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">17</span><span class="p">):</span>
  <span class="n">cosPairsRange</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">()</span>
  <span class="n">cos</span><span class="o">=</span><span class="nf">round</span><span class="p">(</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">),</span> <span class="mi">20</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">61</span><span class="p">):</span>
    <span class="n">name</span><span class="o">=</span><span class="n">groupAtrbts</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">group</span><span class="p">,</span> <span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">trial</span><span class="o">=</span><span class="n">groupAtrbts</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">group</span><span class="p">,</span> <span class="sh">'</span><span class="s">trial</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">label</span><span class="o">=</span><span class="n">groupAtrbts</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">group</span><span class="p">,</span> <span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">data1</span><span class="o">=</span><span class="n">subData</span><span class="p">[(</span><span class="n">subData</span><span class="p">[</span><span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">group</span><span class="p">)]</span>
    <span class="n">values1</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">6</span><span class="p">:</span><span class="mi">262</span><span class="p">]</span>
    <span class="n">fXValues1</span><span class="o">=</span> <span class="n">values1</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">values</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">fXValuesPT1</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">fXValues1</span><span class="p">)</span>
    <span class="n">fXValuesPT1avg</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">fXValuesPT1</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">fXValuesPT1union</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">fXValuesPT1</span><span class="p">,</span><span class="n">fXValuesPT1avg</span><span class="p">),</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">cosPairs1</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">61</span><span class="p">):</span>
      <span class="n">position1</span><span class="o">=</span><span class="sh">'</span><span class="s">XX</span><span class="sh">'</span>
      <span class="n">position2</span><span class="o">=</span><span class="n">positionList</span><span class="p">[(</span><span class="n">positionList</span><span class="p">[</span><span class="sh">'</span><span class="s">positionIdx</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">i</span><span class="p">)][</span><span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">]</span>
      <span class="n">cosPairs1</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">round</span><span class="sh">'</span><span class="p">:</span><span class="n">j</span><span class="p">,</span> <span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span><span class="n">cos</span><span class="p">,</span>
          <span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">:</span><span class="n">group</span><span class="p">,</span> <span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span> <span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">:</span><span class="mi">61</span><span class="p">,</span><span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">:</span><span class="n">i</span><span class="p">,</span>
          <span class="sh">'</span><span class="s">pos1</span><span class="sh">'</span><span class="p">:</span><span class="n">position1</span><span class="p">,</span> <span class="sh">'</span><span class="s">pos2</span><span class="sh">'</span><span class="p">:</span><span class="n">position2</span><span class="p">,</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">})</span>
    <span class="n">edge1</span><span class="o">=</span><span class="n">edges</span><span class="p">[(</span><span class="n">edges</span><span class="p">[</span><span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">group</span><span class="p">)]</span>
    <span class="n">edge1</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">edge1</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge1</span><span class="p">.</span><span class="n">index</span>
    <span class="n">size</span><span class="o">=</span><span class="n">edge1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
      <span class="n">score2</span><span class="o">=</span><span class="n">edge1</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">score2</span><span class="o">&gt;</span><span class="n">cos</span><span class="p">:</span>
        <span class="n">position1</span><span class="o">=</span><span class="n">edge1</span><span class="p">[</span><span class="sh">'</span><span class="s">col1</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
        <span class="n">position2</span><span class="o">=</span><span class="n">edge1</span><span class="p">[</span><span class="sh">'</span><span class="s">col2</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
        <span class="n">k1</span><span class="o">=</span> <span class="n">positionList</span><span class="p">[</span><span class="sh">'</span><span class="s">positionIdx</span><span class="sh">'</span><span class="p">].</span><span class="n">index</span><span class="p">[</span><span class="n">positionList</span><span class="p">[</span><span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">position1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">k2</span><span class="o">=</span> <span class="n">positionList</span><span class="p">[</span><span class="sh">'</span><span class="s">positionIdx</span><span class="sh">'</span><span class="p">].</span><span class="n">index</span><span class="p">[</span><span class="n">positionList</span><span class="p">[</span><span class="sh">'</span><span class="s">position</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">position2</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">cosPairs1</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">round</span><span class="sh">'</span><span class="p">:</span><span class="n">j</span><span class="p">,</span> <span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span><span class="n">cos</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">:</span><span class="n">group</span><span class="p">,</span> <span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span> <span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">:</span><span class="n">k1</span><span class="p">,</span><span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">:</span><span class="n">k2</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">pos1</span><span class="sh">'</span><span class="p">:</span><span class="n">position1</span><span class="p">,</span> <span class="sh">'</span><span class="s">pos2</span><span class="sh">'</span><span class="p">:</span><span class="n">position2</span><span class="p">,</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">score2</span><span class="p">})</span>
    <span class="n">dfCosPairs1</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">cosPairs1</span><span class="p">)</span>
    <span class="n">edge2</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">dfCosPairs1</span><span class="p">[[</span><span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">]].</span><span class="n">T</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">dataset1</span> <span class="o">=</span> <span class="nc">Data</span><span class="p">(</span><span class="n">edge_index</span><span class="o">=</span><span class="n">edge2</span><span class="p">)</span>
    <span class="n">dataset1</span><span class="p">.</span><span class="n">y</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">label</span><span class="p">])</span>
    <span class="n">dataset1</span><span class="p">.</span><span class="n">x</span><span class="o">=</span><span class="n">fXValuesPT1union</span>
    <span class="n">datasetModel</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">dataset1</span><span class="p">)</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">datasetModel</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">cosPairsRange</span> <span class="o">=</span> <span class="n">cosPairsRange</span><span class="p">.</span><span class="nf">append</span><span class="p">([</span><span class="n">dfCosPairs1</span><span class="p">])</span>
    <span class="n">cosPairsUnion</span> <span class="o">=</span> <span class="n">cosPairsUnion</span><span class="p">.</span><span class="nf">append</span><span class="p">([</span><span class="n">dfCosPairs1</span><span class="p">])</span></code></pre></figure>


<p></p>

<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">modelSize</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">modelSize</span>
<span class="mi">1037</span></code></pre></figure>


<p></p>
<p><h4>Training GNN Graph Classification Model</h4>
<p></p>
Randomly split input data to training and tesing:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">random</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
<span class="n">percent</span> <span class="o">=</span> <span class="mf">0.15</span>
<span class="n">sample_size</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">modelSize</span> <span class="o">*</span> <span class="n">percent</span><span class="p">)</span>
<span class="n">train_size</span><span class="o">=</span><span class="nf">int</span><span class="p">(</span><span class="n">modelSize</span><span class="o">-</span><span class="n">sample_size</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">train_size</span><span class="p">)</span><span class="n">e</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>


<p></p>
For this study we used the code provided by PyTorch Geometric as tutorial on GCNConv graph classification models - we just slightly tuned it for our data:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch.nn</span> <span class="kn">import</span> <span class="n">Linear</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GCNConv</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">global_mean_pool</span>

<span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">GCN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lin</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="c1"># 1. Obtain node embeddings
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>

        <span class="c1"># 2. Readout layer
</span>        <span class="n">x</span> <span class="o">=</span> <span class="nf">global_mean_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>  <span class="c1"># [batch_size, hidden_channels]
</span>
        <span class="c1"># 3. Apply a final classifier
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span></code></pre></figure>

<p></p>
</p>
<h4>Train the Model</h4>
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">IPython.display</span> <span class="kn">import</span> <span class="n">Javascript</span>
<span class="nf">display</span><span class="p">(</span><span class="nc">Javascript</span><span class="p">(</span><span class="sh">'''</span><span class="s">google.colab.output.setIframeHeight(0, true, {maxHeight: 300})</span><span class="sh">'''</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>  <span class="c1"># Iterate in batches over the training dataset.
</span>         <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># Perform a single forward pass.
</span>         <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># Compute the loss.
</span>         <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>  <span class="c1"># Derive gradients.
</span>         <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>  <span class="c1"># Update parameters based on gradients.
</span>         <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>  <span class="c1"># Clear gradients.
</span>
<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">loader</span><span class="p">):</span>
     <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
     <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
     <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>  <span class="c1"># Iterate in batches over the training/test dataset.
</span>         <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>  
         <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Use the class with highest probability.
</span>         <span class="n">correct</span> <span class="o">+=</span> <span class="nf">int</span><span class="p">((</span><span class="n">pred</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">).</span><span class="nf">sum</span><span class="p">())</span>  <span class="c1"># Check against ground-truth labels.
</span>     <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">)</span>  <span class="c1"># Derive ratio of correct predictions.
</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="nf">train</span><span class="p">()</span>
    <span class="n">train_acc</span> <span class="o">=</span> <span class="nf">test</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="nf">test</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="mi">03</span><span class="n">d</span><span class="si">}</span><span class="s">, Train Acc: </span><span class="si">{</span><span class="n">train_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, Test Acc: </span><span class="si">{</span><span class="n">test_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>
<a href="#">
    <img src="/img/epics1.jpg" alt="Post Sample Image" width="777" />
</a>
<p></p>
To estimate the model results we used the same model accuracy metrics as in the PyG tutorial: training data accuracy was about 98.4 percents and testing data accuracy was about 98.1 percents. Reasons for the fluctations in accuracy can be explained by the rather small dataset (only 155 test graphs)
<p></p>
<p></p>
</p>
<h4>Interpret EEG Model Results</h4>

<p></p>
To interpret model results we calculated the softmax probabilities for each class output by the model. The softmax probabilities represent the model's confidence in its prediction for each class.

In the output of the graph classification model we have 17 outliers with the model's predictions not equal to the input labels.
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">modelSize</span>
<span class="mi">1037</span></code></pre></figure>


<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Softmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">graph1</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">modelSize</span><span class="p">):</span>
  <span class="n">label</span><span class="o">=</span><span class="n">datasetTest</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">datasetTest</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">datasetTest</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">datasetTest</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">batch</span><span class="p">)</span>
  <span class="n">output</span> <span class="o">=</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">out</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">graph1</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">:</span><span class="n">g</span><span class="p">,</span>
                 <span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span><span class="sh">'</span><span class="s">pred</span><span class="sh">'</span><span class="p">:</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                 <span class="sh">'</span><span class="s">prob0</span><span class="sh">'</span><span class="p">:</span><span class="nf">round</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">4</span><span class="p">),</span><span class="sh">'</span><span class="s">prob1</span><span class="sh">'</span><span class="p">:</span><span class="nf">round</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">4</span><span class="p">)})</span></code></pre></figure>

<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">graph2df</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">graph1</span><span class="p">)</span>

<span class="nf">len</span><span class="p">(</span><span class="n">graph2_df</span><span class="p">[</span><span class="n">graph2_df</span><span class="p">[</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">graph2_df</span><span class="p">[</span><span class="sh">'</span><span class="s">pred</span><span class="sh">'</span><span class="p">]])</span>
<span class="mi">1020</span>

<span class="nf">len</span><span class="p">(</span><span class="n">graph2_df</span><span class="p">[</span><span class="n">graph2_df</span><span class="p">[</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">]</span><span class="o">!=</span><span class="n">graph2_df</span><span class="p">[</span><span class="sh">'</span><span class="s">pred</span><span class="sh">'</span><span class="p">]])</span>
<span class="mi">17</span></code></pre></figure>

<p></p>

<p></p>
Here is detail information about these outliers:  

<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">graphDF</span><span class="p">[</span><span class="n">graphDF</span><span class="p">[</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">]</span><span class="o">!=</span><span class="n">graphDF</span><span class="p">[</span><span class="sh">'</span><span class="s">pred</span><span class="sh">'</span><span class="p">]].</span><span class="nf">sort_values</span><span class="p">(</span><span class="sh">'</span><span class="s">prob0</span><span class="sh">'</span><span class="p">).</span><span class="nf">head</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span></code></pre></figure>

<p></p>
<p></p>
<a href="#">
    <img src="/img/resultsEEG1.jpg" alt="Post Sample Image" width="543" />
</a>
<p></p>
Our observations:
</p><p>
<ul>
<li>Probabilities of incorrectly predicted graph classification labels is close to 0.5 (between 0.45 and 0.55), which means that the model is very uncertain about these predictions.
</li>
<li>Type of stimulus in all outlier graphs is "single stimulus".
</li>
<li>
All outlier graphs belong to the same person (records have the same name, but different trials). These graphs marked as persons from Control group but they were predicted as persons from Alchogol group.
</li>
</ul>
</p><p>
Most of graph classifiction model results with low confidence also are related to "single stimulus" patters:
<p></p>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">graphDF</span><span class="p">[</span><span class="sh">'</span><span class="s">diff</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="nf">abs</span><span class="p">(</span><span class="n">graphDF</span><span class="p">[</span><span class="sh">'</span><span class="s">prob1</span><span class="sh">'</span><span class="p">]</span><span class="o">-</span><span class="n">graphDF</span><span class="p">[</span><span class="sh">'</span><span class="s">prob0</span><span class="sh">'</span><span class="p">])</span>
<span class="n">graphDF</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="sh">'</span><span class="s">diff</span><span class="sh">'</span><span class="p">).</span><span class="nf">head</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span></code></pre></figure>

<p></p>
<p></p>
<a href="#">
    <img src="/img/resultsEEG2.jpg" alt="Post Sample Image" width="589" />
</a>
<p></p>
<p></p>

This corresponds with the results of our previous study about EEG signal classification:
trials with "single stimulus" patters had lower confidence on CNN time series classification compared to trials with "two stimuli, matched" and "two stimuli, non-matched" patterns.



 <p></p>
 <a href="#">
     <img src="/img/dataSource7.jpg" alt="Post Sample Image" width="444" />
 </a>
 <p></p>

More interesting, graph vizualiation examples show that trials with "single stimulus" patters have much lower differences between persons from Alcoholic and Control groups then trials with "two stimuli, matched" and "two stimuli, non-matched" patterns.

The results of a previous study showed that trials with "single stimulus" patterns had much lower differences between persons from the alcoholic and control groups compared to trials with "two stimuli, matched" and "two stimuli, non-matched" patterns. This suggests that "single stimulus" trials are not sufficient for accurately distinguishing between the two groups. Furthermore, graph visualization examples taken from the previous study demonstrated this difference in patterns between the different types of stimuli.

 <p></p>
 <a href="#">
     <img src="/img/dataSource5.jpg" alt="Post Sample Image" width="374" />
 </a>
 <p></p>

<p><h3>Conclusion</h3>

In conclusion, this study provides evidence that GNN graph classification models can effectively classify time series data represented as graphs in EEG data. The study found that these methods are capable of capturing the complex relationships between the nodes in the input graphs and use this information to accurately classify them.
<p></p>
For each person-trial we created separate graphs that were labeled according to whether the corresponding person belonged to the alcohol or control group. Graph nodes were represented by electrode positions and node features were represented by the EEG channel signals.
<p></p>
Cosine similarity matrices were used to define graph edges by selecting vector pairs with cosines above a threshold, and transforming them into graph adjacency matrices. To ensure disconnected graphs became single connected components, to each graph was also added a virtual node.

<p></p>
The study encountered a limitation in the amount of input graphs available for model training. To overcome this limit, random thresholds were used to create additional input graphs, which increased the amount of input data available for training and improved the accuracy of the predictions.

<p></p>



<p></p>

The study found that GNN graph classification models are highly effective in accurately classifying time series data by capturing the relationships between the data points and using this information to make accurate predictions. In particular, GNN graph classification models accurately classified EEG recordings as alcoholic or non-alcoholic person.

 <p></p>

 The study identified some interesting outliers where the GNN graph classification model had difficulty accurately predicting the results. Specifically, it found that the model struggled to accurately classify graphs with a "single stimulus" type of stimulus and "single stimulus" trials were not sufficient for accurately distinguishing between the control and alcohol groups in EEG recordings. This finding is consistent with the results of a previous study, which found that trials with "single stimulus" patterns had lower confidence in CNN time series classification compared to trials with "two stimuli, matched" and "two stimuli, non-matched" patterns.

 <p></p>


<p></p>
Future research could investigate the use of GNN graph classification methods for other types of time series data and explore ways to address the identified limitations of these models. Overall, we believe that GNN graph classification models have great potential for a variety of applications in fields such as healthcare, environmental monitoring, and finance. For example, stock prices can be modeled as time series data and GNN Graph classification algorithms can be used to classify groups of time series into different patterns, such as bullish or bearish trends, which can be used for predicting future prices.
<p></p>
We hope that our study will contribute to the development of more accurate and effective classification models for time series data domains.


</p><p>



</p><p>

<p><h3>Next Post - EEG analysis</h3>
In the next several posts we will continue building bridges between AI, graphs and neuroscience.</p>
</p></p></p></p></p></p></p></p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[GNN for pattern discovery in time series data]]></summary></entry><entry><title type="html">GNN Graph Classification for Climate Change Patterns</title><link href="http://localhost:4000/2023/02/11/cityTempGNNgraphs/" rel="alternate" type="text/html" title="GNN Graph Classification for Climate Change Patterns" /><published>2023-02-11T07:00:00-05:00</published><updated>2023-02-11T07:00:00-05:00</updated><id>http://localhost:4000/2023/02/11/cityTempGNNgraphs</id><content type="html" xml:base="http://localhost:4000/2023/02/11/cityTempGNNgraphs/"><![CDATA[<p><h3>GNN Graph Classification for Climate Data Analysis</h3>

This post represents Graph Neural Network (GNN) graph classification model as a novel method for analyzing stability of temperature patterns over time. Our method involves building graphs based on cosine similarities between daily temperature vectors, training graph classification model and making predictions about temperature stability by graph location.

</p>
<p>
This study highlights GNN graph classifications as powerful tools for analyzing and modeling the complex relationships and dependencies in data that is represented as graphs. They are enabling to uncover hidden patterns, making more accurate predictions and improving the understanding of the Earth's climate.
</p>
<p>

</p>
<p>
<p><h3>Introduction</h3>
2012 was a breakthrough year for both deep learning and knowledge graph: in 2012 the evolutionary model AlexNet was created and in 2012 Google introduced knowledge graph. Convolutional Neural Network (CNN) image classification techniques demonstrated great success outperforming previous state-of-the-art machine learning techniques in various domains. Knowledge graph became essential as a new era in data integration and data management that drive many products and make them more intelligent and ”magical”.
</p><p>
For several years deep learning and knowledge graph were growing in parallel with a gap between them. This gap made it challenging to apply deep learning to graph-structured data and to leverage the strength of both approaches. In the late 2010s, Graph Neural Network (GNN) emerged as a powerful tool for processing graph-structured data and bridged the gap between them.
<p></p>
<a href="#">
    <img src="/img/climateGnnGc1.jpg" alt="Post Sample Image" width="479" />
</a>
<p></p>
(Picture from a book: Bronstein, M., Bruna, J., Cohen, T., and Velickovic ́, P.
“Geometric deep learning: Grids, groups, graphs, geodesics, and gauges”)
</p><p>
CNN and GNN models have a lot in common: both CNN and GNN models are realizations of Geometric Deep Learning. But GNN models are designed specifically for graph-structured data and can leverage the geometric relationships between nodes and combine node features with graph topology. GNN models represent powerful tools for analyzing and modeling the complex relationships and dependencies in data enabling to uncover and understand hidden patterns and making more accurate predictions.
</p><p>

</p><p>
In this post we will investigate how GNN graph classification models can be used to detect abnormal climate change patters.
For experiments of this study we will use climate data from kaggle.com data sets:
<i><a href="
https://www.kaggle.com/hansukyang/temperature-history-of-1000-cities-1980-to-2020">"Temperature History of 1000 cities 1980 to 2020"</a></i> - average daily temperature data for years 1980 - 2019 for 1000 most populous cities in the world.
</p><p>
</p><p>

</p><p>

</p><p>

To track long-term climate trend and patterns we will start with estimation of average daily temperature for consecutive years. For each city weather station we will calculate sequence of cosines between daily temperature vectors for consecutive years to identify changes in temperature patterns over time. This can be used to understand the effects of climate change and natural variability in weather patterns. Average values of these sequences will show effect of climate change in temperature over time.  By tracking these average values, we can identify trends and changes in the temperature patterns and determine how they are related to climate change. A decrease in the average cosine similarity between consecutive years can indicate an increase in the variance or difference in daily temperature patterns, which could be a sign of climate change. On the other hand, an increase in average cosine similarity could indicate a more stable climate with less variance in daily temperature patterns.

</p><p>
To deeper understand the effects of climate change over a longer period of time we will calculate cosine similarity matrices between daily temperature vectors for non-consecutive years. Then by taking vector pairs with a cosine similarity higher than a threshold, we will transform cosine matrices into graph adjacency matrices. These adjacency matrices will represent city graphs that will be used as input into a graph classification model.  
</p><p>

If a city graph produced from the cosine similarity matrix shows high degree of connectivity, it could indicate that the climate patterns in that location are relatively stable over time (Fig. 1), while a city graph with low degree of connectivity may suggest that the climate patterns in that location are more unstable or unpredictable (Fig. 2).
<p></p>
Graph 1: Stable climate in Malaga, Spain represented in graph with high degree of connectivity:
<p></p>
<a href="#">
    <img src="/img/graphMalaga.jpg" alt="Post Sample Image" width="398" />
</a>
<p></p>
Graph 2: Graph with low degree of connectivity at Orenburg, Russia shows that the climate patterns in that location are unstable and unpredictable:
</p><p>

<p></p>
<a href="#">
    <img src="/img/graphOrenburg.jpg" alt="Post Sample Image" width="398" />
</a>
<p></p>

City graphs will be used as input to GNN graph classification model that will identify graph classes as stable or unstable to understand how temperature patterns change over time.
</p><p>


In this post we will demonstrate the following:

</p><p>
<ul>
<li>Describe related work. </li>
<li>Describe methods of data preparation, model training and interpreting model results. </li>
<li>Describe the process of transforming temperature time series to vectors, calculating average values of corresponding sequences of consecutive years, and calculating cosine similarity matrices.</li>
<li>Describe transformation of cosine similarity matrices to graph adjacency matrices and input data preparation for GNN graph classification model. </li>
<li>Describe how to train GNN graph classification model.</li>

<li>Interpret model results by identifying regions that are more vulnerable to climate change and to detect ubnormal climate change patters.</li>
</ul>

<p><h3>Related Work</h3>
GNN graph classification is an emerging area in recent years in GNN architectures, as well as node and graph representations.

In GNN architectures effective for graph classification tasks are Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs) and GraphSAGE.
</p><p>
In practice GNN graph classification in mostly used for drug discovery and protein function prediction.
It can be applied to other areas where data can be represented as graph with graph labels.
</p><p>


</p><p>

<p><h3>Methods</h3>

In this post we will describe data processing and model training methods is the following order:

<ul>
<li>
Process of calculating sequences of cosines between daily temperature vectors between consecutive years.
</li><li>
Process of transforming cosine similarity matrices to graphs.
</li><li>
Process of training GNN graph classification model.

</li>
</ul>


</p><p>
</p><p>
<h4>Cosines between Consecutive Years</h4>

To detect abnormal climate change patterns, the first step will be to calculate and analyze the average cosine similarity between consecutive years. This can be done by comparing temperature vectors of each {city, year} and computing average cosine similarities by city. This will give us a general idea of how the temperature patterns are changing over time. The results of this analysis can be used to detect any abnormal climate change patterns and provide valuable insights into the impact of global warming.
</p><p>
For cosine similarities we used the following functions:

<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="k">def</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">a_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">a_norm</span><span class="p">,</span> <span class="n">b_norm</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span></code></pre></figure>


<p></p>

Values of average cosines between consecutive years will be used as graph labels for GNN graph classification model.
<p></p>
<h4>Cosine Similarity Matrices to Graphs</h4>
</p><p>
Next, for each city we will calculate cosine similarity matrices and transform them into graphs by taking only vector pairs with cosine similarities higher than a threshold.
</p><p>
For each graph we will add a virtual node to transform disconnected graphs into single connected components. This process makes it is easier for graph classification models to process and analyze the relationships between nodes. On graph visualizations pictures in Graph1 and Graph2 virtual nodes are represented with number 40 and all nodes for other years with numbers from 0 to 39.
</p><p>
<h4>Train the Model</h4>
</p><p>
As Graph Neural Networks (GNN) link prediction model we used a GCNConv (Graph Convolutional Network Convolution) model from tutorial of the PyTorch Geometric Library (PyG).
<p></p>
The GCNConv model is a type of graph convolutional network that uses convolution operations to aggregate information from neighboring nodes in a graph. The model is trained on the input graph data, including the edges and node features, and the graph-level labels and it's based on the following input data structure:

<p></p>
<ul>
<li>
Edges: A graph adjacency matrix representing the relationships between the nodes in the graph. In this case, the graph would be the relationships between daily temperature vectors for different years.
</li><li>
Nodes with embedded features: The node features, such as the average values of the corresponding sequences of consecutive years, would be embedded into the nodes to provide additional information to the GNN graph classification model.
</li><li>
Labels on graph level: The labels, such as stable or unstable, would be assigned to the graph as a whole, indicating the stability of the temperature patterns over time. These graph-level labels would be used by the GNN graph classification model to make predictions about the stability of the temperature patterns.
</li></ul>

<p></p>





<p>
<h3>Experiments</h3>
<p></p>


<p><h4>Data Source</h4>

To demonstrate how this methods work we will use climate data from kaggle.com data sets:
<i><a href="
https://www.kaggle.com/hansukyang/temperature-history-of-1000-cities-1980-to-2020">"Temperature History of 1000 cities 1980 to 2020"</a></i>.
</p><p>
This data has average daily temperature in Celsius degrees for years from January 1, 1980 to September 30, 2020 for 1000 most populous cities in the world.

</p><p>


<h4>Transform Raw Data to Vectors of Daily Temperature by Year </h4>
<p></p>

<p></p>

The raw data of average daily temperature for 1000 cities is represented in 1001 columns - city metadata and average temperature rows for all dates from 1980, January 1 to September 30, 2020.    
<p></p>
<a href="#">
    <img src="/img/scr1a.jpg" alt="Post Sample Image" width="800" />
</a>
<p></p>

<p></p>
As city metadata we will use the following columns:
<p></p>
<ul>
<li>City</li>
<li>Country</li>
<li>Latitude</li>
<li>Longitude</li>
</ul>

<p></p>
Next, we will convert raw data to set of embedded vectors {city, year}:
<p></p>

<ul>
<li>To get the same data format for each time series from raw data we excluded February 29 rows</li>
<li>As we had data only until September 30, 2020, we excluded data for year 2020</li>
<li>From dates formated as 'mm/dd/yyyy' strings we extracted year as 'yyyy' strings</li>

</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">tempCity3</span><span class="o">=</span><span class="n">tempCity2</span><span class="p">[</span><span class="o">~</span><span class="p">(</span><span class="n">tempCity2</span><span class="p">[</span><span class="sh">'</span><span class="s">metadata</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">contains</span><span class="p">(</span><span class="sh">"</span><span class="s">2020-</span><span class="sh">"</span><span class="p">))]</span>
<span class="n">tempCity4</span><span class="o">=</span><span class="n">tempCity3</span><span class="p">[</span><span class="o">~</span><span class="p">(</span><span class="n">tempCity3</span><span class="p">[</span><span class="sh">'</span><span class="s">metadata</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">contains</span><span class="p">(</span><span class="sh">"</span><span class="s">-02-29</span><span class="sh">"</span><span class="p">))]</span>
<span class="n">tempCity4</span><span class="p">[</span><span class="sh">'</span><span class="s">metadata</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">tempCity4</span><span class="p">[</span><span class="sh">'</span><span class="s">metadata</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sa">r</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">expand</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">tempCity4</span><span class="o">=</span><span class="n">tempCity4</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>


<p></p>
Next, we transformed data to the following structure:
<ul>
<li>Metadata columns: city, latitude, longitude, country, zone, year</li>
<li>365 columns with average daily temperatures</li>
</ul>
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">tempCityGroups</span><span class="o">=</span><span class="n">tempCity5</span><span class="p">.</span><span class="nf">groupby</span><span class="p">([</span><span class="sh">'</span><span class="s">metadata</span><span class="sh">'</span><span class="p">])</span>
<span class="n">dataSet</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1980</span><span class="p">,</span> <span class="mi">2020</span><span class="p">):</span>
  <span class="n">tmpX</span><span class="o">=</span><span class="n">tempCityGroups</span><span class="p">.</span><span class="nf">get_group</span><span class="p">(</span><span class="nf">str</span><span class="p">(</span><span class="n">x</span><span class="p">)).</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="n">tmpX</span><span class="o">=</span><span class="n">tmpX</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">tmpX</span><span class="p">.</span><span class="n">columns</span><span class="p">[[</span><span class="mi">0</span><span class="p">]],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">T</span>
  <span class="n">cityMetadata</span><span class="p">[</span><span class="sh">'</span><span class="s">year</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">x</span>  
  <span class="n">cityMetadata</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="n">tmpX</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span> <span class="p">[</span><span class="n">cityMetadata</span><span class="p">,</span> <span class="n">tmpX</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">dataSet</span><span class="o">=</span><span class="n">dataSet</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span></code></pre></figure>

<p></p>
Data example:
<p></p>
<a href="#">
    <img src="/img/scr1b.jpg" alt="Post Sample Image" width="800" />
</a>

</p><p>


<p></p>
<p><h4>Average Cosines between Consecutive Years.</h4>
<p></p>
Calculate cosine sequence {year, year+1} for all cities:
<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cosPairs</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">city</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
  <span class="n">cityName</span><span class="o">=</span><span class="n">metaCity</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">city</span><span class="p">][</span><span class="sh">'</span><span class="s">city_ascii</span><span class="sh">'</span><span class="p">]</span>
  <span class="n">country</span><span class="o">=</span><span class="n">metaCity</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">city</span><span class="p">][</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]</span>
  <span class="n">cityIndex</span><span class="o">=</span><span class="n">metaCity</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">city</span><span class="p">][</span><span class="sh">'</span><span class="s">cityInd</span><span class="sh">'</span><span class="p">]</span>
  <span class="n">data1</span><span class="o">=</span><span class="n">dataSet</span><span class="p">[(</span><span class="n">dataSet</span><span class="p">[</span><span class="sh">'</span><span class="s">cityInd</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">city</span><span class="p">)]</span>
  <span class="n">values1</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">8</span><span class="p">:</span><span class="mi">373</span><span class="p">]</span>
  <span class="n">fXValues1</span><span class="o">=</span> <span class="n">values1</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">values</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
  <span class="n">fXValuesPT1</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">fXValues1</span><span class="p">)</span>
  <span class="n">cosine_scores1</span> <span class="o">=</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">fXValuesPT1</span><span class="p">,</span> <span class="n">fXValuesPT1</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">39</span><span class="p">):</span>
    <span class="n">score</span><span class="o">=</span><span class="n">cosine_scores1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>   
    <span class="n">cosPairs</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">cityIndex</span><span class="sh">'</span><span class="p">:</span><span class="n">city</span><span class="p">,</span><span class="sh">'</span><span class="s">cityName</span><span class="sh">'</span><span class="p">:</span><span class="n">cityName</span><span class="p">,</span> <span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">:</span><span class="n">country</span><span class="p">,</span>
                            <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">score</span><span class="p">})</span></code></pre></figure>


<p></p>
Calculate average for each city and order by scores:
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cosPairs_df</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">cosPairs</span><span class="p">)</span>
<span class="n">cosAverage</span><span class="o">=</span><span class="n">cosPairs_df</span><span class="p">.</span><span class="nf">groupby</span><span class="p">([</span><span class="sh">'</span><span class="s">cityName</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">cityIndex</span><span class="sh">'</span><span class="p">])[</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">().</span><span class="nf">reset_index</span><span class="p">()</span>
<span class="n">lineScore</span><span class="o">=</span><span class="n">cosAverage</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">).</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>

A decrease in the average cosine similarity between consecutive years can indicate an increase in the variance or difference in daily temperature patterns, which could be a sign of climate change:
<p></p>
<p></p>
<a href="#">
    <img src="/img/cosLine1.jpg" alt="Post Sample Image" width="400" />
</a>

</p><p>


<p></p>
<p></p>

Very high average cosine similarities indicate stable climate with less variance in daily temperature patterns.
<p></p>

<p></p>
<a href="#">
    <img src="/img/cosLine2.jpg" alt="Post Sample Image" width="400" />
</a>
<p></p>
<h4>Prepare Input Data for GNN Graph Classification Model</h4>
<p></p>
</p><p>
Average cosines between consecutive years were used as graph labels for GNN graph classification. The set of graphs was divided in half and marked with stable and unstable labels:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">lineScore</span><span class="p">[</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">][</span><span class="n">lineScore</span><span class="p">[</span><span class="sh">'</span><span class="s">labelIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">499</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">lineScore</span><span class="p">[</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">][</span><span class="n">lineScore</span><span class="p">[</span><span class="sh">'</span><span class="s">labelIndex</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">500</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">lineScore</span><span class="o">=</span><span class="n">lineScore</span><span class="p">[[</span><span class="sh">'</span><span class="s">cityIndex</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">]].</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">cityIndex</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">cityInd</span><span class="sh">'</span><span class="p">})</span>
<span class="n">lineScore</span><span class="o">=</span><span class="n">lineScore</span><span class="p">[</span><span class="n">lineScore</span><span class="p">[</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">]</span><span class="o">&gt;=</span><span class="mi">0</span><span class="p">]</span></code></pre></figure>


<p></p>
Join scores and labels to the dataSet:
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">subData</span><span class="o">=</span><span class="n">dataSet</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">lineScore</span><span class="p">,</span><span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">cityInd</span><span class="sh">'</span><span class="p">,</span><span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">inner</span><span class="sh">'</span><span class="p">)</span>
<span class="n">subData</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>


<p></p>
Split data to metadata and values:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">metaGroups</span><span class="o">=</span><span class="n">subData</span><span class="p">[(</span><span class="n">subData</span><span class="p">[</span><span class="sh">'</span><span class="s">nextYear</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="mi">1980</span><span class="p">)].</span><span class="n">iloc</span><span class="p">[:,[</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">374</span><span class="p">]]</span>
<span class="n">metaGroups</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">metaGroups</span><span class="p">[</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">metaGroups</span><span class="p">.</span><span class="n">index</span>
<span class="n">values1</span><span class="o">=</span><span class="n">subData</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">9</span><span class="p">:</span><span class="mi">374</span><span class="p">]</span>
<span class="n">values1</span><span class="p">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">40000</span><span class="p">,</span> <span class="mi">365</span><span class="p">)</span></code></pre></figure>

<p></p>

The following code prepares input data for GNN graph classification model:

<ul>
<li>
Calculating cosine similarity matrix by cities
</li><li>Transforming cosine similarity matries to graph adjacency matrices based on treashold cos=.975
</li><li>Transforming data to PyTorch Geometric data format
</li>
</ul>
<p></p>
<p></p>

<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="n">datasetTest</span><span class="o">=</span><span class="nf">list</span><span class="p">()</span>
<span class="n">datasetModel</span><span class="o">=</span><span class="nf">list</span><span class="p">()</span>
<span class="n">cosList</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.975</span><span class="p">]</span>
<span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="n">datasetTest</span><span class="o">=</span><span class="nf">list</span><span class="p">()</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="k">for</span> <span class="n">cos</span> <span class="ow">in</span> <span class="n">cosList</span><span class="p">:</span>
  <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">cityName</span><span class="o">=</span><span class="n">metaGroups</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">g</span><span class="p">][</span><span class="sh">'</span><span class="s">city_ascii</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">country</span><span class="o">=</span><span class="n">metaGroups</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">g</span><span class="p">][</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">label</span><span class="o">=</span><span class="n">metaGroups</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">g</span><span class="p">][</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">cityInd</span><span class="o">=</span><span class="n">metaGroups</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">g</span><span class="p">][</span><span class="sh">'</span><span class="s">cityInd</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">data1</span><span class="o">=</span><span class="n">subData</span><span class="p">[(</span><span class="n">subData</span><span class="p">[</span><span class="sh">'</span><span class="s">cityInd</span><span class="sh">'</span><span class="p">]</span><span class="o">==</span><span class="n">cityInd</span><span class="p">)]</span>
    <span class="n">values1</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">9</span><span class="p">:</span><span class="mi">374</span><span class="p">]</span>
    <span class="n">fXValues1</span><span class="o">=</span> <span class="n">values1</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">values</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">fXValuesPT1</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">fXValues1</span><span class="p">)</span>
    <span class="n">fXValuesPT1avg</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">fXValuesPT1</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">fXValuesPT1union</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">fXValuesPT1</span><span class="p">,</span><span class="n">fXValuesPT1avg</span><span class="p">),</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">cosine_scores1</span> <span class="o">=</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">fXValuesPT1</span><span class="p">,</span> <span class="n">fXValuesPT1</span><span class="p">)</span>
    <span class="n">cosPairs1</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">score0</span><span class="o">=</span><span class="n">cosine_scores1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">40</span><span class="p">):</span>
      <span class="n">year1</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">'</span><span class="s">nextYear</span><span class="sh">'</span><span class="p">]</span>
      <span class="n">cosPairs1</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span><span class="n">score0</span><span class="p">,</span> <span class="sh">'</span><span class="s">cityName</span><span class="sh">'</span><span class="p">:</span><span class="n">cityName</span><span class="p">,</span> <span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">:</span><span class="n">country</span><span class="p">,</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span>
                      <span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">:</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">:</span><span class="mi">40</span><span class="p">,</span> <span class="sh">'</span><span class="s">year1</span><span class="sh">'</span><span class="p">:</span><span class="n">year1</span><span class="p">,</span> <span class="sh">'</span><span class="s">year2</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">XXX</span><span class="sh">'</span><span class="p">,</span>
                      <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">score0</span><span class="p">})</span>
      <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">40</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">j</span><span class="p">:</span>
          <span class="n">score</span><span class="o">=</span><span class="n">cosine_scores1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>   
          <span class="k">if</span> <span class="n">score</span><span class="o">&gt;</span><span class="n">cos</span><span class="p">:</span>
            <span class="n">year2</span><span class="o">=</span><span class="n">data1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="sh">'</span><span class="s">nextYear</span><span class="sh">'</span><span class="p">]</span>
            <span class="n">cosPairs1</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">cos</span><span class="sh">'</span><span class="p">:</span><span class="n">cos</span><span class="p">,</span> <span class="sh">'</span><span class="s">cityName</span><span class="sh">'</span><span class="p">:</span><span class="n">cityName</span><span class="p">,</span> <span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">:</span><span class="n">country</span><span class="p">,</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span>
                            <span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">:</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">:</span><span class="n">j</span><span class="p">,</span> <span class="sh">'</span><span class="s">year1</span><span class="sh">'</span><span class="p">:</span><span class="n">year1</span><span class="p">,</span> <span class="sh">'</span><span class="s">year2</span><span class="sh">'</span><span class="p">:</span><span class="n">year2</span><span class="p">,</span>
                            <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">score</span><span class="p">})</span>
    <span class="n">dfCosPairs1</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">cosPairs1</span><span class="p">)</span>
    <span class="n">edge1</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">dfCosPairs1</span><span class="p">[[</span><span class="sh">'</span><span class="s">k1</span><span class="sh">'</span><span class="p">,</span>	<span class="sh">'</span><span class="s">k2</span><span class="sh">'</span><span class="p">]].</span><span class="n">T</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">dataset1</span> <span class="o">=</span> <span class="nc">Data</span><span class="p">(</span><span class="n">edge_index</span><span class="o">=</span><span class="n">edge1</span><span class="p">)</span>
    <span class="n">dataset1</span><span class="p">.</span><span class="n">y</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">label</span><span class="p">])</span>
    <span class="n">dataset1</span><span class="p">.</span><span class="n">x</span><span class="o">=</span><span class="n">fXValuesPT1union</span>
    <span class="n">datasetTest</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">dataset1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">&gt;=</span><span class="mi">0</span><span class="p">:</span>
      <span class="n">datasetModel</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">dataset1</span><span class="p">)</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">datasetModel</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">datasetTest</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span></code></pre></figure>


<p></p>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">dataset</span><span class="o">=</span><span class="n">datasetModel</span>
<span class="nf">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="mi">1000</span></code></pre></figure>

<p></p>

<p></p>


<p></p>

<p></p>

<p><h4>Training GNN Graph Classification Model</h4>

<p></p>
Split input data to training and tesing:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span>  <span class="n">dataset</span><span class="p">[:</span><span class="mi">888</span><span class="p">]</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">888</span><span class="p">:]</span>
<span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>
For this study we used the code provided by PyTorch Geometric as tutorial on GCNConv graph classification models - we just slightly tuned it for our data:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch.nn</span> <span class="kn">import</span> <span class="n">Linear</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GCNConv</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">global_mean_pool</span>


<span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">GCN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="mi">365</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lin</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="c1"># 1. Obtain node embeddings
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>

        <span class="c1"># 2. Readout layer
</span>        <span class="n">x</span> <span class="o">=</span> <span class="nf">global_mean_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>  <span class="c1"># [batch_size, hidden_channels]
</span>
        <span class="c1"># 3. Apply a final classifier
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span></code></pre></figure>

<p></p>
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">IPython.display</span> <span class="kn">import</span> <span class="n">Javascript</span>
<span class="nf">display</span><span class="p">(</span><span class="nc">Javascript</span><span class="p">(</span><span class="sh">'''</span><span class="s">google.colab.output.setIframeHeight(0, true, {maxHeight: 300})</span><span class="sh">'''</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>  <span class="c1"># Iterate in batches over the training dataset.
</span>         <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># Perform a single forward pass.
</span>         <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># Compute the loss.
</span>         <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>  <span class="c1"># Derive gradients.
</span>         <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>  <span class="c1"># Update parameters based on gradients.
</span>         <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>  <span class="c1"># Clear gradients.
</span>
<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">loader</span><span class="p">):</span>
     <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

     <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
     <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>  <span class="c1"># Iterate in batches over the training/test dataset.
</span>         <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>  
         <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Use the class with highest probability.
</span>         <span class="n">correct</span> <span class="o">+=</span> <span class="nf">int</span><span class="p">((</span><span class="n">pred</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">).</span><span class="nf">sum</span><span class="p">())</span>  <span class="c1"># Check against ground-truth labels.
</span>     <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">)</span>  <span class="c1"># Derive ratio of correct predictions.
</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">117</span><span class="p">):</span>
    <span class="nf">train</span><span class="p">()</span>
    <span class="n">train_acc</span> <span class="o">=</span> <span class="nf">test</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="nf">test</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="mi">03</span><span class="n">d</span><span class="si">}</span><span class="s">, Train Acc: </span><span class="si">{</span><span class="n">train_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, Test Acc: </span><span class="si">{</span><span class="n">test_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>

<p></p>
<a href="#">
    <img src="/img/cosLine4.jpg" alt="Post Sample Image" width="700" />
</a>
<p></p>
<p></p>
To estimate the model results we used the same model accuracy metrics as in the PyG tutorial: training data accuracy was about 96 percents and testing data accuracy was about 99 percents.
<p></p>



<h4>Interpretation of GNN Graph Classification Model results</h4>
</p><p>
In the output of the graph classification model we have 36 outliers with the model's predictions not equal to the input labels.

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Softmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">graph1</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
  <span class="n">label</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="n">g</span><span class="p">].</span><span class="n">batch</span><span class="p">)</span>
  <span class="n">output</span> <span class="o">=</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">out</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
  <span class="n">graph1</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">index</span><span class="sh">'</span><span class="p">:</span><span class="n">g</span><span class="p">,</span>
                 <span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span><span class="n">label</span><span class="p">,</span><span class="sh">'</span><span class="s">pred</span><span class="sh">'</span><span class="p">:</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                 <span class="sh">'</span><span class="s">prob0</span><span class="sh">'</span><span class="p">:</span><span class="nf">round</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">4</span><span class="p">),</span><span class="sh">'</span><span class="s">prob1</span><span class="sh">'</span><span class="p">:</span><span class="nf">round</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">4</span><span class="p">)})</span>

<span class="n">graph2_df</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">graph1</span><span class="p">)</span>
<span class="nf">len</span><span class="p">(</span><span class="n">graph2_df</span><span class="p">[</span><span class="n">graph2_df</span><span class="p">[</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">]</span><span class="o">!=</span><span class="n">graph2_df</span><span class="p">[</span><span class="sh">'</span><span class="s">pred</span><span class="sh">'</span><span class="p">]])</span>
<span class="mi">36</span></code></pre></figure>

<p></p>
Here is detail information about these outliers:
<p></p>
<a href="#">
    <img src="/img/cosLine5.jpg" alt="Post Sample Image" width="444" />
</a>
<p></p>
The goal of this study is to identify whether a given graph represents a stable or an unstable climate pattern, based on the temperature data in the corresponding city and the GNN graph classification model was used to learn about the relationships between the nodes within graphs and make predictions about the stability of the temperature patterns over time. The output of the GNN graph classification model would be class labels, such as stable or unstable, indicating the stability of the temperature patterns by graph locations.
<p></p>
Based on our observations of average cosines in consecutive years, for cities close to the equator have very high cosine similarity values which indicates that the temperature patterns in these cities are stable and consistent over time. On the contrary, cities located at higher latitudes may experience more variability in temperature patterns, making them less stable.

These observations correspond with GNN graph classification model results: most of graphs for cities located in lower latitude are classified as stable and graphs of cities located in higher latitude are classified as unstable.

<p></p>
However, the GNN graph classification model results capture some outliers: there are some cities located in higher latitudes that have stable temperature patterns and some cities located in lower latitudes that have unstable temperature patterns. In the table below you can see outliers where the model's predictions do not match the actual temperature stability of these cities.

<p></p>
<a href="#">
    <img src="/img/cosLine6.jpg" alt="Post Sample Image" width="398" />
</a>
<p></p>
European cities located in higher latitude correspond with the results of our
<i><a href="http://sparklingdataocean.com/2022/02/22/symmetryMetrics/">previous climate time series study</a></i> where they were indicated as cities with very stable and consistent temperature patterns.
<p></p>

<p></p>
The results of our previous climate time series study showed that cities located near the Mediterranean Sea had high similarity to a smooth line, indicating stable and consistent temperature patterns.  In one of climate analysis scenarios we found that most of cities with high similarities to a smooth line are located on Mediterranean Sea not far from each other. Here is a clockwise city list: Marseille (France), Nice (France), Monaco (Monaco), Genoa (Italy), Rome (Italy), Naples (Italy), and Salerno (Italy):
<p></p>
<a href="#">
    <img src="/img/nldl_img9.jpg" alt="Post Sample Image" width="333" />
</a>
<p></p>
In the next table below you can see city outliers with the highest outlier probabilities
<p></p>
<a href="#">
    <img src="/img/cosLine7.jpg" alt="Post Sample Image" width="398" />
</a>
<p></p>

In the table below you can see outliers with probabilities close to the classification boundary.
<p></p>
<a href="#">
    <img src="/img/cosLine8.jpg" alt="Post Sample Image" width="398" />
</a>
<p></p>
<p><h3>Conclusion</h3>
<p></p>
In this study we introduced a novel method for detecting abnormal climate change patterns using GNN graph classification models. Our method involves calculating cosine similarity matrices between daily temperature vectors, transforming matrices into graphs, and using GCNConv graph classification model to classify graphs into stable and unstable classes and identify abnormal climate change patterns.
<p></p>
The results of this study showed that the GNN graph classification model was effective in learning the relationships between nodes within graphs and making predictions about the stability of the temperature patterns over time. The model results corresponded with the observed stability of temperature patterns in cities located near the equator being more stable compared to those in higher latitudes.
<p></p>
The study also highlighted some outliers where the predicted results did not match the input labels and explained the reasons of outliers.



<p></p>


<p></p>
<p></p>

<p></p>


<p></p>
<p></p>

<p><h3>Next Post - GNN Graph Classification for Time Series Analysis</h3>
In the next post we will describe how to apply GNN graph classification models to other time series scenarios.</p>
<p></p>

<p></p>
</p></p></p></p></p></p></p></p></p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[GNN Graph Classification for Climate Data Analysis]]></summary></entry><entry><title type="html">Find Semantic Similarities by GNN Link Predictions</title><link href="http://localhost:4000/2022/11/09/knowledgeGraph4NlpGnn/" rel="alternate" type="text/html" title="Find Semantic Similarities by GNN Link Predictions" /><published>2022-11-09T07:00:00-05:00</published><updated>2022-11-09T07:00:00-05:00</updated><id>http://localhost:4000/2022/11/09/knowledgeGraph4NlpGnn</id><content type="html" xml:base="http://localhost:4000/2022/11/09/knowledgeGraph4NlpGnn/"><![CDATA[<p><h3>Link Prediction for Knowledge Graphs</h3>
<p></p>
<p>
In our previous post <i><a href="http://sparklingdataocean.com/2022/07/23/knowledgeGraph4GNN/"> 'Rewiring Knowledge Graphs by Link Predictions'</a></i> we showed how to rewire knowledge graph through GNN Link Prediction models. In this post we will continue discussion of applications of GNN Link Prediction techniques to rewiring knowledge graphs.
<p></p>
The goal of this post is the same as the goal of previous post: we want to find unknown relationships between modern art artists. We will continue exploring text data from Wikipedia articles about the same 20 modern art artists as we used in the previous post, but we will use a different approach to building initial knowledge graph: instead of building it on artist names and full text of corresponding Wikipedia articles we will build it on co-located word pairs.


</p><p>
<p><h3>Methods</h3>
<p></p>


<p><h4>Building initial Knowledge Graph</h4>
<p></p>
To build initial knowledge graph we will use the following steps:

</p>
<ul>
<li>Tokenize Wikipedia text and exclude stop words.</li>
<li>Get nodes as word pairs that are co-located within articles.</li>
<li>Get edges as pair to pair neighbors following text sequences within articles.</li>
<li>Get edges as joint pairs that have common words. These edges will represent word chains within articles and across them.</li>
</ul>

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">if</span> <span class="n">pair1</span><span class="o">=</span><span class="p">[</span><span class="n">leftWord1</span><span class="p">,</span> <span class="n">rightWord1</span><span class="p">],</span>
   <span class="n">pair2</span><span class="o">=</span><span class="p">[</span><span class="n">leftWord2</span><span class="p">,</span> <span class="n">rightWord2</span><span class="p">]</span>
   <span class="ow">and</span> <span class="n">rightWord1</span><span class="o">=</span><span class="n">leftWord2</span><span class="p">,</span>
<span class="n">then</span> <span class="n">there</span> <span class="ow">is</span> <span class="n">edge12</span><span class="o">=</span><span class="p">{</span><span class="n">pair1</span><span class="p">,</span> <span class="n">pair2</span><span class="p">}</span></code></pre></figure>

<p></p>

Graph edges built based of these rules will cover word to word sequences and word to word chains within articles. More important, they will connect different articles by covering word to word chains across articles.
</p><p>
On nodes and edges described above we will built an initial knowledge graph.

</p><p>
<p><h4>Transform Text to Vectors</h4>
</p><p>
As a method of text to vector translation we will use <i><a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2"> 'all-MiniLM-L6-v2'</a></i> transformer model from Hugging Face. This is a sentence-transformers model that maps text to a 384 dimensional vector space.

</p><p>

<p><h4>Run GNN Link Prediction Model</h4>
</p><p>

As Graph Neural Networks link prediction model we will use a GraphSAGE link prediction model from Deep Graph Library (DGL). The model is built on two GrapgSAGE layers  and computes node representations by averaging neighbor information.

The code for this model is provided by DGL tutorial <i><a href="https://docs.dgl.ai/en/0.8.x/tutorials/blitz/4_link_predict.html">DGL Link Prediction using Graph Neural Networks</a></i>.

</p><p>

The results of this model are embedded nodes that can be used for further analysis such as node classification, k-means clustering, link prediction and so on. In this particular post we will calculate average vectors by artists and estimate link predictions by cosine similarities between them.
<p></p>


<p></p>
<p>Cosine Similarities function:

<p></p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="k">def</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">a_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">a_norm</span><span class="p">,</span> <span class="n">b_norm</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span></code></pre></figure>

<p></p>

<h3>Experiments</h3>
<p></p>
<h4>Data Source Analysis</h4>
<p></p>

As the data source for this study we used text data from Wikipedia articles about  the same 20 artists that we used in our previous study  
<i><a href="https://www.researchgate.net/publication/344329097_Building_Knowledge_Graph_in_Spark_Without_SPARQL">"Building Knowledge Graph in Spark without SPARQL"</a></i>.
<p></p>


<p></p>
<p>To estimate the size distribution of Wikipedia text data we tokenized the text and exploded the tokens: </p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">nltk.tokenize</span> <span class="kn">import</span> <span class="n">RegexpTokenizer</span>
<span class="n">tokenizer</span> <span class="o">=</span><span class="nc">RegexpTokenizer</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">[A-Za-z]+</span><span class="sh">'</span><span class="p">)</span>

<span class="n">wikiArtWords</span><span class="o">=</span><span class="n">wikiArtists</span><span class="p">[</span><span class="sh">'</span><span class="s">Wiki</span><span class="sh">'</span><span class="p">]</span>
  <span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nc">RegexpTokenizer</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">[A-Za-z]+</span><span class="sh">'</span><span class="p">).</span><span class="nf">tokenize</span><span class="p">(</span><span class="n">x</span><span class="p">)).</span><span class="nf">reset_index</span><span class="p">()</span>

<span class="n">wikiArtWords</span><span class="o">=</span><span class="n">wikiArtWords</span><span class="p">.</span><span class="nf">explode</span><span class="p">([</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">])</span>
<span class="n">wordStats</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">wikiArtWords</span><span class="p">,</span><span class="n">listArtists</span><span class="p">)</span>

<span class="n">artistWordStats</span><span class="o">=</span><span class="n">wordStats</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">Artist</span><span class="sh">'</span><span class="p">).</span><span class="nf">count</span><span class="p">()</span>
  <span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></figure>



<p>Based on Wikipedia text size distribution, the most well known artist in our artist list is Vincent van Gogh and the most unknown artist is Franz Marc:</p>
<p></p>
<a href="#">
    <img src="/img/artImg1.jpg" alt="Post Sample Image" width="275" />
</a>

<p></p>
<h4>Select Subsets of Words</h4>
<p></p>
Exclude stop words and short words woth length&lt;4:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">nltk</span>
<span class="n">nltk</span><span class="p">.</span><span class="nf">download</span><span class="p">(</span><span class="sh">'</span><span class="s">stopwords</span><span class="sh">'</span><span class="p">)</span>
<span class="kn">from</span> <span class="n">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="n">STOPWORDS</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">stopwords</span><span class="p">.</span><span class="nf">words</span><span class="p">(</span><span class="sh">'</span><span class="s">english</span><span class="sh">'</span><span class="p">))</span>
<span class="n">dfStopWords</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame </span><span class="p">(</span><span class="n">STOPWORDS</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">])</span>
<span class="n">dfStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">stop</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="sh">"</span><span class="s">stopWord</span><span class="sh">"</span>
<span class="n">stopWords</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">wikiArtWords</span><span class="p">,</span><span class="n">dfStopWords</span><span class="p">,</span><span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">left</span><span class="sh">'</span><span class="p">)</span>

<span class="n">nonStopWords</span><span class="o">=</span><span class="n">stopWords</span><span class="p">[</span><span class="n">stopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">stop</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()]</span>
<span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">stop</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">len</span><span class="p">()</span>
<span class="n">nonStopWords</span><span class="o">=</span><span class="n">nonStopWords</span><span class="p">[</span><span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">stop</span><span class="sh">'</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">3</span><span class="p">]</span>
<span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span> <span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span>
<span class="n">nonStopWords</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">nonStopWords</span><span class="p">[</span><span class="sh">'</span><span class="s">idxWord</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">nonStopWords</span><span class="p">.</span><span class="n">index</span></code></pre></figure>


<p></p>

The goal of this study is to find relationships between the artists. As Wikipedia articles about these artists have very different sizes,  if we would use full Wikipedia text data, well-known artists who have longest articles would get more word pairs and much more connections than artists with shorter corresponding articles.

<p></p>
To balance artist to artist relationship distribution we selected subsets of articles with approximately the same word pair counts. As Wikipedia articles about artists all start with high level artist biography descriptions, from each article we selected the first 800 words.

<p></p>


<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">nonStopWordsSubset</span> <span class="o">=</span> <span class="n">nonStopWords</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">).</span><span class="nf">head</span><span class="p">(</span><span class="mi">800</span><span class="p">)</span>
<span class="n">nonStopWordsSubset</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">nonStopWordsSubset</span><span class="p">[</span><span class="sh">'</span><span class="s">idxWord</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">nonStopWordsSubset</span><span class="p">.</span><span class="n">index</span></code></pre></figure>

<p></p>

<p></p>
<h4>Get Pairs of Co-located Words</h4>
<p></p>
Exclude stop words and short words woth length&lt;4:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">bagOfWords</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">nonStopWordsSubset</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">])</span>
<span class="n">bagOfWords</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">bagOfWords</span><span class="p">[</span><span class="sh">'</span><span class="s">idxWord</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">bagOfWords</span><span class="p">.</span><span class="n">index</span>

<span class="n">indexWords</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">nonStopWordsSubset</span><span class="p">,</span><span class="n">bagOfWords</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxWord</span><span class="sh">'</span><span class="p">])</span>
<span class="n">idxWord1</span><span class="o">=</span><span class="n">indexWords</span>
  <span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">word1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxArtist1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxWord</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxWord1</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">idxWord2</span><span class="o">=</span><span class="n">indexWords</span>
  <span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">word2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxArtist2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxWord</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxWord2</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">leftWord</span><span class="o">=</span><span class="n">idxWord1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span>
<span class="n">leftWord</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">rightWord</span> <span class="o">=</span> <span class="n">idxWord2</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span> <span class="p">,</span> <span class="p">:].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  

<span class="n">pairWords</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">leftWord</span><span class="p">,</span><span class="n">rightWord</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pairWords</span> <span class="o">=</span> <span class="n">pairWords</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">pairWords</span><span class="p">[</span><span class="n">pairWords</span><span class="p">[</span><span class="sh">'</span><span class="s">idxArtist1</span><span class="sh">'</span><span class="p">]</span><span class="o">!=</span><span class="n">pairWords</span><span class="p">[</span><span class="sh">'</span><span class="s">idxArtist2</span><span class="sh">'</span><span class="p">]].</span><span class="n">index</span><span class="p">)</span>
<span class="n">pairWords</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<p></p>

Drop duplicates {artist, word1, word2}

<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cleanPairWords</span> <span class="o">=</span> <span class="n">pairWords</span>
<span class="n">cleanPairWords</span> <span class="o">=</span> <span class="n">cleanPairWords</span><span class="p">.</span><span class="nf">drop_duplicates</span><span class="p">(</span>
  <span class="n">subset</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">idxArtist1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">word1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">word2</span><span class="sh">'</span><span class="p">],</span> <span class="n">keep</span> <span class="o">=</span> <span class="sh">'</span><span class="s">last</span><span class="sh">'</span><span class="p">).</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">cleanPairWords</span><span class="p">[</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>
  <span class="n">cleanPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">word1</span><span class="sh">"</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> </span><span class="sh">"</span> <span class="o">+</span> <span class="n">cleanPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">word2</span><span class="sh">"</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">cleanPairWords</span><span class="p">[</span><span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">cleanPairWords</span><span class="p">.</span><span class="n">index</span>
<span class="n">cleanPairWords</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="mi">14933</span></code></pre></figure>

<p></p>

Node examples:

<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">nodeList</span><span class="o">=</span><span class="n">cleanPairWords</span>
<span class="n">nodeList</span> <span class="o">=</span><span class="n">nodeList</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">'</span><span class="s">idxWord1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxWord2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxArtist2</span><span class="sh">'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">nodeList</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
<span class="n">idxArtist1</span>	<span class="n">word1</span>	<span class="n">word2</span>	<span class="n">wordpair</span>	<span class="n">nodeIdx</span>
<span class="mi">0</span>	<span class="mi">0</span>	<span class="n">braque</span>	<span class="n">french</span>	<span class="n">braque</span> <span class="n">french</span>	<span class="mi">0</span>
<span class="mi">1</span>	<span class="mi">0</span>	<span class="n">french</span>	<span class="n">august</span>	<span class="n">french</span> <span class="n">august</span>	<span class="mi">1</span>
<span class="mi">2</span>	<span class="mi">0</span>	<span class="n">august</span>	<span class="n">major</span>	<span class="n">august</span> <span class="n">major</span>	<span class="mi">2</span>
<span class="mi">3</span>	<span class="mi">0</span>	<span class="n">major</span>	<span class="n">century</span>	<span class="n">major</span> <span class="n">century</span>	<span class="mi">3</span>
<span class="mi">4</span>	<span class="mi">0</span>	<span class="n">century</span>	<span class="n">french</span>	<span class="n">century</span> <span class="n">french</span>	<span class="mi">4</span></code></pre></figure>


<p></p>
<h4>Get Edges</h4>
<p></p>
Index data:
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">nodeList1</span><span class="o">=</span><span class="n">nodeList</span>
  <span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">word2</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">theWord</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">wordpair1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">nodeIdx1</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">nodeList2</span><span class="o">=</span><span class="n">nodeList</span>
  <span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">word1</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">theWord</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxArtist1</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">idxArtist2</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wordpair</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">wordpair2</span><span class="sh">'</span><span class="p">,</span>
  <span class="sh">'</span><span class="s">nodeIdx</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">nodeIdx2</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">allNodes</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">nodeList1</span><span class="p">,</span><span class="n">nodeList2</span><span class="p">,</span><span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">theWord</span><span class="sh">'</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">inner</span><span class="sh">'</span><span class="p">)</span>
<span class="n">allNodes</span><span class="p">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">231699</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span></code></pre></figure>


<p></p>
Save edges in Google Drive:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">allNodes</span><span class="p">[[</span><span class="sh">'</span><span class="s">nodeIdx1</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">nodeIdx2</span><span class="sh">'</span><span class="p">]].</span><span class="nf">to_csv</span><span class="p">(</span><span class="n">drivePath</span><span class="o">+</span><span class="sh">"</span><span class="s">edges.csv</span><span class="sh">"</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>
<h4>Transform Text to Vectors</h4>
<p></p>
Transform node features to vectors and store in Google drive:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="nc">SentenceTransformer</span><span class="p">(</span><span class="sh">'</span><span class="s">all-MiniLM-L6-v2</span><span class="sh">'</span><span class="p">)</span>
<span class="n">wordpair_embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">cleanPairWords</span><span class="p">[</span><span class="sh">"</span><span class="s">wordpair</span><span class="sh">"</span><span class="p">],</span><span class="n">convert_to_tensor</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">wordpair_embeddings</span><span class="p">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">14933</span><span class="p">,</span> <span class="mi">384</span><span class="p">])</span></code></pre></figure>


<p></p>
Save nodes in Google Drive:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">imgPath</span><span class="o">+</span><span class="sh">'</span><span class="s">wordpairs4.pkl</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">wb</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">fOut</span><span class="p">:</span>
   <span class="n">pickle</span><span class="p">.</span><span class="nf">dump</span><span class="p">({</span><span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">:</span> <span class="n">nodeList</span><span class="p">[</span><span class="sh">"</span><span class="s">nodeIdx</span><span class="sh">"</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">:</span> <span class="n">nodeList</span><span class="p">[</span><span class="sh">"</span><span class="s">wordpair</span><span class="sh">"</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">idxArtist</span><span class="sh">'</span><span class="p">:</span> <span class="n">nodeList</span><span class="p">[</span><span class="sh">"</span><span class="s">idxArtist1</span><span class="sh">"</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">embeddings</span><span class="sh">'</span><span class="p">:</span> <span class="n">wordpair_embeddings</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()},</span> <span class="n">fOut</span><span class="p">,</span>
      <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="p">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span></code></pre></figure>

<p></p>


<p></p>
<p></p>

<h4>Run GNN Link Prediction Model</h4>
<p></p>
<p>As Graph Neural Networks (GNN) link prediction model we used a model from Deep Graph Library (DGL). The model code was provided by DGL tutorial and we only had to transform nodes and edges data from our data format to DGL data format.
<p></p>
Read embedded nodes and edges from Google Drive:  </p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">drivePath</span><span class="o">+</span><span class="sh">'</span><span class="s">wordpairs.pkl</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">rb</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">fIn</span><span class="p">:</span>
    <span class="n">stored_data</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">fIn</span><span class="p">)</span>
    <span class="n">gnn_index</span> <span class="o">=</span> <span class="n">stored_data</span><span class="p">[</span><span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">gnn_words</span> <span class="o">=</span> <span class="n">stored_data</span><span class="p">[</span><span class="sh">'</span><span class="s">words</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">gnn_embeddings</span> <span class="o">=</span> <span class="n">stored_data</span><span class="p">[</span><span class="sh">'</span><span class="s">embeddings</span><span class="sh">'</span><span class="p">]</span>

<span class="n">edges</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">drivePath</span> <span class="o">+</span> <span class="sh">'</span><span class="s">edges.csv</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>


<p></p>
<p>Convert data to DGL format and add self-loop edges:</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">unpickEdges</span><span class="o">=</span><span class="n">edges</span>
<span class="n">edge_index</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">unpickEdges</span><span class="p">[[</span><span class="sh">'</span><span class="s">idx</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">idxNode</span><span class="sh">'</span><span class="p">]].</span><span class="n">T</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="o">=</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">g</span><span class="o">=</span><span class="n">dgl</span><span class="p">.</span><span class="nf">graph</span><span class="p">((</span><span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="p">))</span>
<span class="n">g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">gnn_embeddings</span>
<span class="n">g</span><span class="o">=</span><span class="n">dgl</span><span class="p">.</span><span class="nf">add_self_loop</span><span class="p">(</span><span class="n">g</span><span class="p">)</span></code></pre></figure>


<p></p>


We used the model with the following parameters:

<ul>
<li>14933 nodes.</li>
<li>231699 edges.</li>
<li>PyTorch tensor of size [14933, 384] for embedded nodes.</li>
</ul>
<p></p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">g</span>
<span class="nc">Graph</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="mi">14933</span><span class="p">,</span> <span class="n">num_edges</span><span class="o">=</span><span class="mi">246632</span><span class="p">,</span>
      <span class="n">ndata_schemes</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">:</span> <span class="nc">Scheme</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">384</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)}</span>
      <span class="n">edata_schemes</span><span class="o">=</span><span class="p">{})</span></code></pre></figure>

<p></p>

<p></p>
For GraphSAGE model output vector size we experimented with sizes 32, 64 and 128:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="nc">GraphSAGE</span><span class="p">(</span><span class="n">train_g</span><span class="p">.</span><span class="n">ndata</span><span class="p">[</span><span class="sh">'</span><span class="s">feat</span><span class="sh">'</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">128</span><span class="p">)</span></code></pre></figure>

<p></p>

<p></p>
The model, loss function, and evaluation metric were defined the following way:
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">pred</span> <span class="o">=</span> <span class="nc">DotPredictor</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">):</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">])</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">pos_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">neg_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])])</span>
    <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="nf">binary_cross_entropy_with_logits</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compute_auc</span><span class="p">(</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">):</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">pos_score</span><span class="p">,</span> <span class="n">neg_score</span><span class="p">]).</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span>
        <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">pos_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">neg_score</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]).</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="nf">roc_auc_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span></code></pre></figure>

<p></p>

To estimate the results we calculated accuracy metrics as Area Under Curve (AUC). For all three output vector sizes the model accuracy metrics were about 96 percents.

<p></p>

<p><h4>Rewiring Knowledge Graph by Predicted Links</h4>
<p></p>

The results of the GraphSAGE model from DGL library are not actually ‘predicted links’ but node vectors that were re-embedded by the model based on input node vectors and messages passed from the neighbors. They can be used for further analysis steps to predict graph edges.
<p></p>
The results of this scenario are 14933 reembedded nodes and to detect relationships between artists first, we calculated average node vectors by artists and then we estimated link predictions by cosine similarities between them.


<p></p>


As we mentioned above we experimented with GraphSAGE model output vector sizes of 32, 64 and 128 and compared distributions of cosine similarities between artist pairs.

<p></p>

<p></p>

First we looked at cosine similarity matrix for pairs of nodes embedded by GNN link prediction model:</p>
<p></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cosine_scores_gnn</span> <span class="o">=</span> <span class="nf">pytorch_cos_sim</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>

<span class="n">pairs_gnn</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">cosine_scores_gnn</span><span class="p">)):</span>
  <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">cosine_scores_gnn</span><span class="p">)):</span>
    <span class="n">pairs_gnn</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span><span class="sh">'</span><span class="s">idx1</span><span class="sh">'</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span><span class="sh">'</span><span class="s">idx2</span><span class="sh">'</span><span class="p">:</span> <span class="n">j</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">:</span> <span class="n">cosine_scores_gnn</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()})</span>

    <span class="n">dfArtistPairs_gnn</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">pairs_gnn</span><span class="p">)</span>
    <span class="n">dfArtistPairs_gnn</span><span class="p">.</span><span class="n">shape</span>
    <span class="p">(</span><span class="mi">190</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span></code></pre></figure>


<p></p>
The number of cosine similarity pairs for 20 artists is 190 and the picture below illustrates cosine similarity distributions for model outputs of sizes 128, 64 and 32. For knowledge graph rewiring we selected the model results with output size 128 that reflects the most smooth cosine similarity distribution.


<p></p>

<a href="#">
    <img src="/img/artImg4.jpg" alt="Post Sample Image" width="444" />
</a>
<p></p>
<p></p>

<p></p>

<p><h4>Results of Rewiring Knowledge Graph</h4>
<p></p>
<p></p>

<p></p>
Artist pairs with cosine similarities &gt; 0.5:
<p></p>

<a href="#">
    <img src="/img/artImg5.jpg" alt="Post Sample Image" width="333" />
</a>
<p></p>


<p></p>
Graph illustration of artist pairs with hign cosine similarities &gt; 0.5:
<p></p>
<a href="#">
    <img src="/img/artImg3.jpg" alt="Post Sample Image" width="616" />
</a>
<p></p>


<p></p>
Pairs of artists with low cosine similarities &lt; -0.5:
<p></p>
<a href="#">
    <img src="/img/artImg2.jpg" alt="Post Sample Image" width="333" />
</a>

<p></p>
<p><h3>Observasions</h3>
Node pairs with high cosine similarities, also known as high weight edges, are actively used for graph mining techniques such as node classification, community detection or for analyzing node relationships.
<p></p>
In experiments of this study artist pairs with high cosine similarities can be considered as artist pairs with high semantic relationships through corresponding Wikipedia articles. Some of these relationships are well known: both Pablo Picasso and Georges Braque were pioneers of cubism art movement. Specialists in biographies of Paul Gauguin or Vincent van Gogh will not be surprised to find that these artists had high relationship regardless of their different art styles. Some undiscovered semantic connections such as between artists Egon Schiele and Marc Chagall might be interesting for modern art researchers.

<p></p>

Rewiring knowledge graph and finding high weight links between artists can be applied to recommender systems. If a customer is interested in Pablo Picasso art, it might be interesting for this customer to look at Georges Braque paintings or if a customer is interested in biography of Vincent van Gogh the recommender system can suggest to look at Paul Gauguin biography.

<p></p>

Applications of node pairs with high cosine similarities (or high weight edges) for graph mining techniques are well known: they are widely used for node classification, community detection and so on. On the other hand, node pairs with low cosine similarities (or negative weight edges) are not actively used. Based on our observations, dissimilar node pairs can be used for graph mining techniques in quite different way that similar node pairs or weakly connected node pairs.

<p></p>
For community detection validation strongly dissimilar node pairs act as more reliable indicators than weakly dissimilar node pairs: negative weight edges can validate that corresponding node pairs should belong to different communities.

<p></p>
Graphs with very dissimilar node pairs cover much bigger spaces that graphs with similar or weakly connected node pairs. For example, in this study we found low cosine similarities between key artists from not overlapping modern art movements: Futurism - Natalia Goncharova, Impressionism - Claude Monet and De Stijl - Piet Mondrian.
<p></p>
<p></p>
<a href="#">
    <img src="/img/moma44b.jpg" alt="Post Sample Image" width="567" />
</a>

<p></p>

Links with very low cosine similarities can be used by recommender systems. If a customer is very familiar with Claude Monet’s style and is interested in learning about different modern art movements the recommender system might suggest to look at Piet Mondrian’s paintings or Natalia Goncharova’s paintings.

<p></p>
<p></p>
<p><h3>Conclusion</h3>

<p></p>
In this study we propose methods of rewiring knowledge graphs to detect hidden relationships between graph nodes by using GNN link prediction models.
<p></p>
In our experiments we looked at semantic similarities and dissimilarities between biographies of modern art artists by applying traditional and novel methods to their Wikipedia articles. Traditional method was implemented on full test of articles and cosine similarities between re-embedded nodes.
<p></p>
The novel method was based on distribution of co-located words within and across articles. The output vectors from GNN link prediction model were aggregated by artists and link predictions were estimated by cosine similarities between them.
<p></p>
We explored advantages for graph mining techniques of using not only highly connected node pairs but also highly disconnected node pairs.

We denoted that level of disconnected word pairs can be used to define boundaries of a space covered by graph: existence of node pairs with very low cosine similarities shows that a graph covers much bigger space than a graph with only high and medium cosine similarities. Also highly disconnected node pairs are good indicators for validation of community detection.
<p></p>
We demonstrated applications of rewired knowledge graphs for recommender systems. Based on high similarity pairs recommender systems can suggest to look at paintings on biographies of artists that are similar to the artist of interest. Based on high dissimilarity pairs recommender systems can advice to look at very different art movements.

<p></p>

<p></p>

<p></p>
<p></p>
</p></p></p></p></p></p></p></p></p>]]></content><author><name>Melenar</name></author><summary type="html"><![CDATA[Link Prediction for Knowledge Graphs In our previous post 'Rewiring Knowledge Graphs by Link Predictions' we showed how to rewire knowledge graph through GNN Link Prediction models. In this post we will continue discussion of applications of GNN Link Prediction techniques to rewiring knowledge graphs. The goal of this post is the same as the goal of previous post: we want to find unknown relationships between modern art artists. We will continue exploring text data from Wikipedia articles about the same 20 modern art artists as we used in the previous post, but we will use a different approach to building initial knowledge graph: instead of building it on artist names and full text of corresponding Wikipedia articles we will build it on co-located word pairs.]]></summary></entry></feed>